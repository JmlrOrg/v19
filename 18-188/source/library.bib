Automatically generated by Mendeley Desktop 1.17.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Hubara2016a,
author = {Hubara, I and Courbariaux*, M and Soudry, D. and El-Yaniv, R. and Bengio, Y},
journal = {NIPS},
publisher = {US Patent 62/317,665, Filed},
title = {{Binarized neural networks}},
year = {2016}
}
@article{MulyPotashner04,
abstract = {Exposure of adults to loud noise can overstimulate the auditory system,

damage the cochlea, and destroy cochlear nerve axons and their synaptic

endings in the brain. Cochlear nerve loss probably results from the

death of cochlear inner hair cells (IHC). Additional degeneration

in the cochlear nucleus (CN) is hypothesized to stem from overstimulation

of the system, which may produce excitotoxicity. This study tested

these predictions by exposing one ear of anesthetized adult chinchillas

to a loud noise, which damaged the ipsilateral cochlea and induced

degeneration in the glutamatergic cochlear nerve. During the first

postexposure week, before cochlear nerve axons degenerated, glutamatergic

synaptic release in the ipsilateral CN was elevated and uptake was

depressed, consistent with hyperactivity of glutamatergic transmission

and perhaps with the operation of an excitotoxic mechanism. By 14

days, when cochlear nerve fibers degenerated, glutamatergic synaptic

release and uptake in the CN became deficient. By 90 days, a resurgence

of transmitter release and an elevation of AMPA receptor binding

suggested transmission upregulation through plasticity that resembled

changes after mechanical cochlear damage. These changes may contribute

to tinnitus and other pathologic symptoms that precede and accompany

hearing loss. In contrast, the other ear, protected with a silicone

plug during the noise exposure, exhibited virtually no damage in

the cochlea or the cochlear nerve. Altered glutamatergic release

and AMPA receptor binding activity in the CN suggested upregulatory

plasticity driven by signals emanating from the CN on the noise-exposed

side.},
author = {Muly, S M and Gross, J S and Potashner, S J},
doi = {10.1002/jnr.20011},
journal = {Journal of Neuroscience Research},
keywords = {AMPA; Research Support,Animals; Chinchilla; Cochlear Nucleus; Comparative,P.H.S.; Tritium,U.S. Gov't},
month = {feb},
number = {4},
pages = {585--596},
pmid = {14743442},
title = {{Noise trauma alters D-[3H]aspartate release and AMPA binding in chinchilla cochlear nucleus.}},
url = {http://dx.doi.org/10.1002/jnr.20011},
volume = {75},
year = {2004}
}
@article{KemereShenoy08,
author = {Kemere, Caleb and Santhanam, Gopal and Yu, Byron M and Afshar, Afsheen and Ryu, Stephen I and Meng, Teresa H and Shenoy, Krishna V},
journal = {J Neurophysiol},
pages = {2441--2452},
title = {{Detecting Neural-State Transitions Using Hidden Markov Models for Motor Cortical Prostheses}},
volume = {100},
year = {2008}
}
@misc{DatasetsComparison,
title = {{Http://www.is.umk.pl/projects/datasets.html}}
}
@inproceedings{YuSahani06b,
author = {Yu, Byron M and Shenoy, Krishna V and Sahani, Maneesh},
booktitle = {Proceedings of the Nonlinear Statistical Signal Processing Workshop},
pages = {83--86},
publisher = {IEEE},
title = {{Expectation propagation for inference in non-linear dynamical models with {\{}Poisson{\}} observations}},
year = {2006}
}
@article{CC01,
author = {Chander, D and Chichilnisky, E J},
journal = {Journal of Neuroscience},
pages = {9904--9916},
title = {{Adaptation to temporal contrast in primate and salamander retina}},
volume = {21},
year = {2001}
}
@article{Kim2012,
author = {Kim, Hyongsuk and Sah, M and Yang, Changju},
isbn = {9550101029},
journal = {Circuits and Systems I: {\ldots}},
number = {1},
pages = {148--158},
title = {{Neural synaptic weighting with a pulse-based memristor circuit}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5976989},
volume = {59},
year = {2012}
}
@article{Pickett2009,
author = {Pickett, Matthew D. and Strukov, Dmitri B. and Borghetti, Julien L. and Yang, J. Joshua and Snider, Gregory S. and Stewart, Duncan R. and Williams, R. Stanley},
doi = {10.1063/1.3236506},
issn = {00218979},
journal = {Journal of Applied Physics},
number = {7},
pages = {074508},
title = {{Switching dynamics in titanium dioxide memristive devices}},
url = {http://scitation.aip.org/content/aip/journal/jap/106/7/10.1063/1.3236506},
volume = {106},
year = {2009}
}
@article{Zia2009,
annote = {Information theory and statistical mechanics course},
author = {Zia, RKP K P and Redish, EF F and McKay, SR R},
journal = {American Journal of Physics},
title = {{Making sense of the Legendre transform}},
url = {http://link.aip.org/link/?AJPIAS/77/614/1},
year = {2009}
}
@article{SCHW67,
author = {Schwartz, L},
journal = {Z. Wahrsch. Verw. Gabiete},
pages = {10--26},
title = {{On {\{}B{\}}ayes procedures}},
volume = {4},
year = {1967}
}
@article{Nees|1994|,
abstract = {In this paper, we prove constructively two approximative versions
of the superposition theorem of Kolmogorov (19631, corresponding
to Lorentz (1962) and Sprecher (1965). The proofs are constructive
in the sense that only rationals, expressible as finite decimal sums,
are used. The approximations consist in algorithms with error bounds.
Concerning their complexity, the two results differ in the way the
occurring sequences are constructed: recursively, respectively explicitly.},
annote = {This paper provides relatively clear proof-by-construction of approximate{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}version of Kolmogorov theorem, which states that any n-dimensional{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}function can be represented as a sum of 2n+1 1D functions of sums{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of n fixed functions with different coefficients (total of n+1 parameters).{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}In nut-shell, Kolmogorov theorem is analog of the statement that{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}any function of n-dimensional index Z{\^{}}n is isomorphic to a function{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of 1D index via Z{\^{}}n-{\textgreater}Z. In general, simple index mapping Z{\^{}}n-{\textgreater}Z is{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}not continuous as step-discontinuities arise along each "line" of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the mapping. Kolmogorov{\&}{\#}039;s achievement was to provide a construction{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}which contribute a continuous map [0,1]{\^{}}n-{\textgreater}[0,1]. Such mapping is{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}constructed by finding families of 2n+1 coverings of n-cube of decreasing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}diameter and vanishing overlaps within each family such that each{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}point is covered by at least n+1 cubes from these coverings. One{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}then is able to construct continuous functions that map each of such{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}cubes non-overlaping cubes into distinct points of the [0,1] line{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}(!). Therefore, [0,1]{\^{}}n is continuously mapped 1-1 onto [0,1] and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}any continuous function of [0,1]{\^{}}n can be seen as (some) continuous{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}function of the image of [0,1]{\^{}}n. Some subtleties are present requiring{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}2n+1 such functions each approximating on a subset of n coverings{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}at a time. Note that dimensionality curse is not removed since complexity{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of R{\^{}}n space is translated into extremely complex mapping into R,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and thus, generally, no gain is achieved for actual interpolation.},
author = {Nees, M},
journal = {Journal of computational and applied mathematics},
keywords = {Kolmogorov theorem,function representation by superposition,interpolation,many dimensional,mathematics},
pages = {239},
title = {{Approximate version of Kolmogorov's superposition theorem, proved constructively}},
volume = {54}
}
@article{Ferree|2001|,
abstract = {We derive a linear neural network model of the chemotaxis control
circuit in the nematode Caenorhabditis elegans, and demonstrate that
this model is capable of producing nematode-like chemotaxis. By expanding
the analytic solution for the network output in time-derivatives
of the network input, we extract simple computational rules which
reveal how the model network controls chemotaxis. Based on these
rules we find that optimized linear networks typically control chemotaxis
by computing the first time-derivative of the chemical concentration,
and modulating the body turning rate in response to this derivative.
We argue that this is consistent with behavioral studies, and a plausible
mechanism for at least one component of chemotaxis in real nematodes.},
author = {Ferree, T C and Lockery, S R},
journal = {journal of computational neuroscience},
keywords = {c. elegans,caenorhabditis elegans,chemotaxis,computational,mathematics,model,neural network,neurobiology,recurrent neural networks,sensorimotor integration,spatial orientation},
pages = {263},
title = {{Computational rules for chemotaxis in the nematode C. elegans}},
volume = {6}
}
@article{pfau09,
author = {Pfau, D and Pitkow, X and Paninski, L},
journal = {Conference abstract: Computational and systems neuroscience},
title = {{A {\{}B{\}}ayesian method to predict the optimal diffusion coefficient in random fixational eye movements}},
year = {2009}
}
@article{Barron|1993|,
abstract = {Approximation properties of a class of artificial neural networks
are established. It is shown that feedforward networks with one layer
of sigmoidal nonlinearities achieve integrated squared error of order
O(1/n), where n is the number of nodes. The function approximated
is assumed to have a bound on the first moment of the magnitude distribution
of the Fourier transform. The nonlinear parameters associated with
the sigmoidal nodes, as well as the parameters of linear combination,
are adjusted in the approximation. In contrast, it is shown that
for series expansions with n terms, in which only the parameters
of linear combination are adjusted, the integrated squared approximation
error cannot be made smaller than order 1/n{\^{}}2/d uniformly for functions
satisfying the same smoothness assumption, where d is the dimension
of the input to the function. For the class of functions examined
here, the approximation rate and the parsimony of the parametrization
of the networks are surprisingly advantageous in high-dimensional
settings.},
annote = {This fundamental paper demonstrates approximation limits on superposition{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of sigmoidal functions, partially along the line of stochastic approximation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and large numbers law.},
author = {Barron, A R},
journal = {IEEE transaction on information theory},
keywords = {approximation of functions,artificial neural networks,computational,fourier analysis,interpolation,kolmogorov n-widths,mathematics,superpositions},
number = {3},
pages = {930},
title = {{Universal approximation bounds for superpositions of a sigmoidal function}},
volume = {39}
}
@article{Roxin2011,
abstract = {The distribution of in vivo average firing rates within local cortical networks has been reported to be highly skewed and long tailed. The distribution of average single-cell inputs, conversely, is expected to be Gaussian by the central limit theorem. This raises the issue of how a skewed distribution of firing rates might result from a symmetric distribution of inputs. We argue that skewed rate distributions are a signature of the nonlinearity of the in vivo f-I curve. During in vivo conditions, ongoing synaptic activity produces significant fluctuations in the membrane potential of neurons, resulting in an expansive nonlinearity of the f-I curve for low and moderate inputs. Here, we investigate the effects of single-cell and network parameters on the shape of the f-I curve and, by extension, on the distribution of firing rates in randomly connected networks.},
author = {Roxin, Alex and Brunel, N and Hansel, David and Mongillo, Gianluigi and van Vreeswijk, C},
doi = {10.1523/JNEUROSCI.1677-11.2011},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Computer Simulation,Models, Neurological,Nerve Net,Nerve Net: physiology,Neural Inhibition,Neural Inhibition: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Normal Distribution,Time Factors},
month = {nov},
number = {45},
pages = {16217--26},
pmid = {22072673},
title = {{On the distribution of firing rates in networks of cortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22072673},
volume = {31},
year = {2011}
}
@article{Yun2017,
abstract = {We study the error landscape of deep linear and nonlinear neural networks with square error loss. We build on the recent results in the literature and present necessary and sufficient conditions for a critical point of the empirical risk function to be a global minimum in the deep linear network case. Our simple conditions can also be used to determine whether a given critical point is a global minimum or a saddle point. We further extend these results to deep nonlinear neural networks and prove similar sufficient conditions for global optimality in the function space.},
archivePrefix = {arXiv},
arxivId = {1707.02444},
author = {Yun, Chulhee and Sra, Suvrit and Jadbabaie, Ali},
eprint = {1707.02444},
month = {jul},
title = {{Global optimality conditions for deep neural networks}},
url = {http://arxiv.org/abs/1707.02444},
year = {2017}
}
@article{Schaul2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1206.1106v2},
author = {Schaul, Tom and Zhang, S and LeCun, Y},
eprint = {arXiv:1206.1106v2},
journal = {arXiv preprint arXiv:1206.1106},
title = {{No more pesky learning rates}},
url = {http://arxiv.org/abs/1206.1106},
year = {2013}
}
@article{Avrutin2006,
annote = {2011num17},
author = {Avrutin, V and Schanz, M and Banerjee, Soumitro},
doi = {10.1088/0951-7715/19/8/007},
issn = {0951-7715},
journal = {Nonlinearity},
month = {aug},
number = {8},
pages = {1875--1906},
title = {{Multi-parametric bifurcations in a piecewise linear discontinuous map}},
url = {http://stacks.iop.org/0951-7715/19/i=8/a=007?key=crossref.fd3f22267dee38a2366527efac54a85b},
volume = {19},
year = {2006}
}
@article{MullowneyIyengar07,
author = {Mullowney, P and Iyengar, S},
journal = {Journal of Computational Neuroscience},
title = {{Parameter estimation for a leaky integrate-and-fire neuronal model from interspike interval data}},
volume = {doi:10.100},
year = {2007}
}
@article{Marom2010,
abstract = {This article aims at making readers, experimentalists and theorists, more aware of the abstractions made by an observer when measuring and reporting behavioral and neural timescales. These abstractions stow away the fact that, above lower boundaries that reflect fairly well understood physical constraints, observed and reported timescales are often not intrinsic to the biological system; rather, in most cases they reflect conditions that are imposed by the observer through the measuring procedure. This is true at practically every level of organization, from behavior down to molecules. I analyze the impacts of the resulting temporal manifold in behavioral and brain sciences on experimental designs and mathematical modeling.},
author = {Marom, S},
doi = {DOI: 10.1016/j.pneurobio.2009.10.003},
issn = {0301-0082},
journal = {Progress in Neurobiology},
keywords = {behavior,brain,excitability,ionic channel,model,network,neuron,timescale},
number = {1},
pages = {16--28},
title = {{Neural timescales or lack thereof}},
url = {http://www.sciencedirect.com/science/article/B6T0R-4XFY0MB-1/2/8a39858bf637f93b4651858da1310819},
volume = {90},
year = {2010}
}
@article{Jaeger2004,
abstract = {We present a method for learning nonlinear systems, echo state networks (ESNs). ESNs employ artificial recurrent neural networks in a way that has recently been proposed independently as a learning mechanism in biological brains. The learning method is computationally efficient and easy to use. On a benchmark task of predicting a chaotic time series, accuracy is improved by a factor of 2400 over previous techniques. The potential for engineering applications is illustrated by equalizing a communication channel, where the signal error rate is improved by two orders of magnitude.},
author = {Jaeger, H and Haas, H},
doi = {10.1126/science.1091277},
issn = {1095-9203},
journal = {Science},
month = {apr},
number = {5667},
pages = {78--80},
pmid = {15064413},
title = {{Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15064413},
volume = {304},
year = {2004}
}
@article{Puopolo2007,
abstract = {We used a preparation of acutely dissociated neurons to quantify the ionic currents driving the spontaneous firing of substantia nigra pars compacta neurons, isolated from transgenic mice in which the tyrosine hydroxylase promoter drives expression of human placental alkaline phosphatase (PLAP) on the outer surface of the cell membrane. Dissociated neurons identified by fluorescent antibodies to PLAP showed firing properties similar to those of dopaminergic neurons in brain slice, including rhythmic spontaneous firing of broad action potentials and, in some cells, rhythmic oscillatory activity in the presence of tetrodotoxin (TTX). Spontaneous activity in TTX had broader, smaller spikes than normal pacemaking and was stopped by removal of external calcium. Normal pacemaking was also consistently silenced by replacement of external calcium by cobalt and was slowed by more specific calcium channel blockers. Nimodipine produced a slowing of pacemaking frequency. Pacemaking was also slowed by the P/Q-channel blocker omega-Aga-IVA, but the N-type channel blocker omega-conotoxin GVIA had no effect. In voltage-clamp experiments, using records of pacemaking as command voltage, cobalt-sensitive current and TTX-sensitive current were both sizeable at subthreshold voltages between spikes. Cobalt-sensitive current was consistently larger than TTX-sensitive current at interspike voltages from -70 to -50 mV, with TTX-sensitive current larger at voltages positive to -45 mV. These results support previous evidence for a major role of voltage-dependent calcium channels in driving pacemaking of midbrain dopamine neurons and suggest that multiple calcium channel types contribute to this function. The results also show a significant contribution of subthreshold TTX-sensitive sodium current.},
author = {Puopolo, M and Raviola, E and Bean, B P},
doi = {10.1523/JNEUROSCI.4341-06.2007},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: genetics,Action Potentials: physiology,Animals,Calcium Channels,Calcium Channels: genetics,Calcium Channels: physiology,Dopamine,Dopamine: physiology,Humans,Mesencephalon,Mesencephalon: physiology,Mice,Neurons,Neurons: physiology,Sodium Channels,Sodium Channels: genetics,Sodium Channels: physiology,Transgenic},
month = {jan},
number = {3},
pages = {645--56},
pmid = {17234596},
title = {{Roles of subthreshold calcium current and sodium current in spontaneous firing of mouse midbrain dopamine neurons.}},
url = {http://www.jneurosci.org/cgi/content/abstract/27/3/645},
volume = {27},
year = {2007}
}
@book{Liu2008,
author = {Liu, JS},
title = {{Monte Carlo strategies in scientific computing}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=R8E-yHaKCGUC{\&}oi=fnd{\&}pg=PR7{\&}dq=Monte+Carlo+Strategies+in+Scientific+Computing{\&}ots=WdoTAUs89E{\&}sig=MT-lCyITIx4jvBefC9v3F62OGEQ},
year = {2008}
}
@article{Risler2008,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0409468v1},
author = {Risler, Thomas and Prost, Jacques},
eprint = {0409468v1},
pages = {1--10},
primaryClass = {arXiv:cond-mat},
title = {{Universal Critical Behavior of Noisy Coupled Oscillators}},
year = {2008}
}
@article{Hosaka2006,
archivePrefix = {arXiv},
arxivId = {arXiv:cs/0509086v1},
author = {Hosaka, T and Kabashima, Yoshiyuki},
eprint = {0509086v1},
journal = {Physica A: Statistical Mechanics and its {\ldots}},
pages = {1--10},
primaryClass = {arXiv:cs},
title = {{Statistical mechanical approach to lossy data compression: Theory and practice}},
url = {http://www.sciencedirect.com/science/article/pii/S0378437106000537},
year = {2006}
}
@article{Wagenaar:2006vn,
abstract = {BACKGROUND: We have collected a comprehensive set of multi-unit data
on dissociated cortical cultures. Previous studies of the development
of the electrical activity of dissociated cultures of cortical neurons
each focused on limited aspects of its dynamics, and were often based
on small numbers of observed cultures. We followed 58 cultures of
different densities--3000 to 50,000 neurons on areas of 30 to 75
mm2--growing on multi-electrode arrays (MEAs) during the first five
weeks of their development. RESULTS: Plating density had a profound
effect on development. While the aggregate spike detection rate scaled
linearly with density, as expected from the number of cells in proximity
to electrodes, dense cultures started to exhibit bursting behavior
earlier in development than sparser cultures. Analysis of responses
to electrical stimulation suggests that axonal outgrowth likewise
occurred faster in dense cultures. After two weeks, the network activity
was dominated by population bursts in most cultures. In contrast
to previous reports, development continued with changing burst patterns
throughout the observation period. Burst patterns were extremely
varied, with inter-burst intervals between 1 and 300 s, different
amounts of temporal clustering of bursts, and different firing rate
profiles during bursts. During certain stages of development bursts
were organized into tight clusters with highly conserved internal
structure. CONCLUSION: Dissociated cultures of cortical cells exhibited
a much richer repertoire of activity patterns than previously reported.
Except for the very sparsest cultures, all cultures exhibited globally
synchronized bursts, but bursting patterns changed over the course
of development, and varied considerably between preparations. This
emphasizes the importance of using multiple preparations--not just
multiple cultures from one preparation--in any study involving neuronal
cultures. These results are based on 963 half-hour-long recordings.
To encourage further investigation of the rich range of behaviors
exhibited by cortical cells in vitro, we are making the data available
to other researchers, together with Matlab code to facilitate access.},
author = {Wagenaar, D A and Pine, Jerome and Potter, S M},
doi = {10.1186/1471-2202-7-11},
journal = {BMC Neurosci},
keywords = {networks},
mendeley-tags = {networks},
pages = {11},
pmid = {16464257},
title = {{An extremely rich repertoire of bursting patterns during the development of cortical cultures}},
volume = {7},
year = {2006}
}
@article{Stevenson2009,
author = {Stevenson, I H and Rebesco, J M and Hatsopoulos, N G and Haga, Z and Miller, L E and Kording, K P},
journal = {IEEE Trans. Neural Systems and Rehab.},
pages = {203--213},
title = {{Bayesian Inference of Functional Connectivity and Network Structure From Spikes}},
volume = {17},
year = {2009}
}
@article{Amelunxen2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1512.06033v1},
author = {Amelunxen, Dennis and Lotz, Martin},
eprint = {arXiv:1512.06033v1},
number = {December},
pages = {1--23},
title = {{Intrinsic volumes of polyhedral cones: a combinatorial perspective}},
year = {2015}
}
@article{Building2010,
author = {Building, Fishbach and Network, The},
pages = {1--3},
title = {{Short Bio Current Areas of Interest}},
year = {2010}
}
@article{Kass05,
author = {Kass, Robert E and Ventura, Valerie and Brown, Emery N},
journal = {J Neurophysiol},
pages = {8--25},
title = {{Statistical Issues in the Analysis of Neuronal Data}},
volume = {94},
year = {2005}
}
@article{Perlman1998,
abstract = {The human visual system can discriminate increment and decrement light stimuli over a wide range of ambient illumination; from moonlight to bright sunlight. Several mechanisms contribute to this property but the major ones reside in the retina and more specifically within the photoreceptors themselves. Numerous studies in retinae from cold- and warm-blooded vertebrates have demonstrated the ability of the photoreceptors to respond in a graded manner to light increments and decrements even if these are applied during a background illumination that is expected to saturate the cells. In all photoreceptors regardless of type and species, three cellular mechanisms have been identified that contribute to background desensitization and light adaptation. These gain controlling mechanisms include; response-compression due to the non-linearity of the intensity-response function, biochemical modulation of the phototransduction process and pigment bleaching. The overall ability of a photoreceptor to adapt to background lights reflects the relative contribution of each of these mechanisms and the light intensity range over which they operate. In rods of most species, response-compression tends to dominate these mechanisms at light levels too weak to cause significant pigment bleaching and therefore, rods exhibit saturation. In contrast, cones are characterized by powerful background-induced modulation of the phototransduction process at moderate to bright background intensities where pigment bleaching becomes significant. Therefore, cones do not exhibit saturation even when the level of ambient illumination is raised by 6-7 log units.},
author = {Perlman, Ido and Normann, Richard a.},
doi = {10.1016/S1350-9462(98)00005-6},
isbn = {1350-9462 (Print)$\backslash$n1350-9462 (Linking)},
issn = {13509462},
journal = {Progress in Retinal and Eye Research},
number = {4},
pages = {523--563},
pmid = {9777649},
title = {{Light adaptation and sensitivity controlling mechanisms in vertebrate photoreceptors}},
volume = {17},
year = {1998}
}
@article{Cho2010,
abstract = {We introduce a new family of positive-definite kernels for large margin classification in support vector machines (SVMs). These kernels mimic the computation in large neural networks with one layer of hidden units. We also show how to derive new kernels, by recursive composition, that may be viewed as mapping their inputs through a series of nonlinear feature spaces. These recursively derived kernels mimic the computation in deep networks with multiple hidden layers. We evaluate SVMs with these kernels on problems designed to illustrate the advantages of deep architectures. Compared to previous benchmarks, we find that on some problems, these SVMs yield state-of-the-art results, beating not only other SVMs but also deep belief nets.},
author = {Cho, Youngmin and Saul, Lawrence K},
doi = {10.1162/NECO_a_00018},
issn = {1530-888X},
journal = {Neural computation},
keywords = {Algorithms,Artificial Intelligence,Neural Networks (Computer),Nonlinear Dynamics,Pattern Recognition, Automated,Pattern Recognition, Automated: standards,Signal Processing, Computer-Assisted},
month = {oct},
number = {10},
pages = {2678--97},
pmid = {20608866},
title = {{Large-margin classification in infinite neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20608866},
volume = {22},
year = {2010}
}
@article{Khalil2008,
author = {Khalil, RA},
journal = {Al-Rafidain Engineering},
keywords = {artificial,backprobagation,fpga,network,neural,vhdl,{\oe}ƒƅƀ{\v{s}} ŗşɔŧŕɔƃ{\oe} ř{\oe}ŕ{\oe}ƍŕƃ{\oe} ŗ{\.{z}}ƍ{\v{z}}ůɔ,ŗ{\v{s}}ƒŧŭ əƅŵ ŗƒŕůŷƃ{\oe} ř{\oe}ƃŕŭƅƃ,ŗƒť{\oe}ɔƃ{\oe} ŗƒƈŕƃ{\oe} ŧƒ{\v{z}}ƈř},
number = {May 2007},
pages = {62--70},
title = {{Hardware Implementation of Backpropagation Neural Networks on Field programmable Gate Array (FPGA)}},
url = {http://www.alrafidain.engineering-coll-mosul.com/files/201.pdf},
year = {2008}
}
@article{Wirth03,
author = {Wirth, S and Yanike, M and Frank, L and Smith, A and Brown, E and Suzuki, W},
journal = {Science},
pages = {1578--1581},
title = {{Single neurons in the monkey hippocampus and learning of new associations}},
volume = {300},
year = {2003}
}
@article{Sznaier2012,
author = {Sznaier, Mario},
isbn = {9783902823069},
journal = {System Identification},
number = {2008},
pages = {1559--1568},
title = {{Compressive Information Extraction: A Dynamical Systems Approach}},
url = {http://www.ifac-papersonline.net/Detailed/54953.html},
year = {2012}
}
@article{Shi-Xian2008,
author = {Shi-Xian, Q. and Yong-Zhi, L. and Lin, Z. and Da-Ren, H.},
journal = {Chinese Physics B},
keywords = {coexistence of attractors,discontinuous bifurcation,mapping hole,piecewise linear map},
pages = {4418},
publisher = {IOP Publishing},
title = {{Discontinuous bifurcation and coexistence of attractors in a piecewise linear map with a gap}},
url = {http://iopscience.iop.org/1674-1056/17/12/014},
volume = {17},
year = {2008}
}
@article{boguna2000residence,
annote = {2009num25},
author = {Boguna, M and Berezhkovskii, A M and Weiss, G H},
journal = {Physica A: Statistical Mechanics and its Applications},
number = {3-4},
pages = {475--485},
publisher = {Elsevier},
title = {{Residence time densities for non-Markovian systems.(I). The two-state system}},
volume = {282},
year = {2000}
}
@article{McCoy2014,
annote = {Concentraion of measure for intrinsic volume could be useful - e.g. see Table 1},
archivePrefix = {arXiv},
arxivId = {arXiv:1308.5265v1},
author = {McCoy, Michael B. and Tropp, Joel A.},
doi = {10.1007/s00454-014-9595-4},
eprint = {arXiv:1308.5265v1},
issn = {14320444},
journal = {Discrete and Computational Geometry},
keywords = {Concentration inequality,Convex cone,Geometric probability,Intrinsic volume,Statistical dimension,Steiner formula},
number = {4},
pages = {926--963},
title = {{From Steiner Formulas for Cones to Concentration of Intrinsic Volumes}},
volume = {51},
year = {2014}
}
@article{Gal2010,
abstract = {Although neuronal excitability is well understood and accurately modeled over timescales of up to hundreds of milliseconds, it is currently unclear whether extrapolating from this limited duration to longer behaviorally relevant timescales is appropriate. Here we used an extracellular recording and stimulation paradigm that extends the duration of single-neuron electrophysiological experiments, exposing the dynamics of excitability in individual cultured cortical neurons over timescales hitherto inaccessible. We show that the long-term neuronal excitability dynamics is unstable and dominated by critical fluctuations, intermittency, scale-invariant rate statistics, and long memory. These intrinsic dynamics bound the firing rate over extended timescales, contrasting observed short-term neuronal response to stimulation onset. Furthermore, the activity of a neuron over extended timescales shows transitions between quasi-stable modes, each characterized by a typical response pattern. Like in the case of rate statistics, the short-term onset response pattern that often serves to functionally define a given neuron is not indicative of its long-term ongoing response. These observations question the validity of describing neuronal excitability based on temporally restricted electrophysiological data, calling for in-depth exploration of activity over wider temporal scales. Such extended experiments will probably entail a different kind of neuronal models, accounting for the unbounded range, from milliseconds up.},
author = {Gal, A and Eytan, D and Wallach, A and Sandler, M and Schiller, J and Marom, S},
doi = {10.1523/JNEUROSCI.4859-10.2010},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Action Potentials: physiology,Animals,Cells,Cerebral Cortex,Cultured,Excitatory Postsynaptic Potentials: physiology,Neurons: physiology,Newborn,Rats,Sprague-Dawley,Time Factors,physiology},
language = {en},
number = {48},
pages = {16332--16342},
pmid = {21123579},
publisher = {Society for Neuroscience},
title = {{Dynamics of Excitability over Extended Timescales in Cultured Cortical Neurons}},
url = {http://www.jneurosci.org/content/30/48/16332.full},
volume = {30},
year = {2010}
}
@article{Chandrasekaran2012,
author = {Chandrasekaran, Venkat and Recht, Benjamin and Parrilo, Pablo a. and Willsky, Alan S.},
doi = {10.1007/s10208-012-9135-7},
issn = {1615-3375},
journal = {Foundations of Computational Mathematics},
keywords = {atomic norms,convex optimization,real algebraic,semidefinite programming},
month = {oct},
number = {6},
pages = {805--849},
title = {{The Convex Geometry of Linear Inverse Problems}},
url = {http://link.springer.com/10.1007/s10208-012-9135-7},
volume = {12},
year = {2012}
}
@article{AugustineTanaka03,
abstract = {Transient rises in the cytoplasmic concentration of calcium ions serve

as second messenger signals that control many neuronal functions.

Selective triggering of these functions is achieved through spatial

localization of calcium signals. Several qualitatively different

forms of local calcium signaling can be distinguished by the location

of open calcium channels as well as by the distance between these

channels and the calcium binding proteins that serve as the molecular

targets of calcium action. Local calcium signaling is especially

prominent at presynaptic active zones and postsynaptic densities,

structures that are distinguished by highly organized macromolecular

arrays that yield precise spatial arrangements of calcium signaling

proteins. Similar forms of local calcium signaling may be employed

throughout the nervous system, though much remains to be learned

about the molecular underpinnings of these events.},
author = {Augustine, George J and Santamaria, Fidel and Tanaka, Keiko},
journal = {Neuron},
keywords = {Animals; Calcium Signaling; Humans; Neurons; Synap},
month = {oct},
number = {2},
pages = {331--346},
pmid = {14556712},
title = {{Local calcium signaling in neurons.}},
volume = {40},
year = {2003}
}
@book{RueHeld05,
author = {Rue, H and Held, L},
publisher = {CRC Press},
title = {{Gaussian {\{}M{\}}arkov random fields: theory and applications}},
year = {2005}
}
@article{Prigogine2009,
author = {Prigogine, I and Landshoff, R},
journal = {Physics Today},
title = {{Non‐Equilibrium Statistical Mechanics}},
url = {http://scitation.aip.org/content/aip/magazine/physicstoday/article/16/9/10.1063/1.3051153?crawler=true},
year = {2009}
}
@article{Pearce|2004|,
abstract = {Searching for trace quantities of predefined chemical compounds in
natural environments, as in the case of explosives detection, is
a difficult and challenging technological problem. Much chemical
interference is likely to be present and the environment itself is
often complex, nonstationary and unpredictable. Here we discuss nature{\"{i}}¾'s
ultimate solution to this problem, in the form of pheromone mediated
chemotactic search of the moth. We argue here that this organism
provides an ideal model for solving the technological problem and
we discuss in detail the exploitation of specific sensory processing
and behavioural mechanisms relevant to the task. Finally, we discuss
the project AMOTH in which the authors work towards a fully implemented,
real-world instantiation of these sensorimotor mechanisms in the
form of an unmanned aerial vehicle.},
author = {Pearce, T C and Chong, K Y and Verschure, P F M and Babia, S B i and Carlsson, M A and Chanie, E and Hansson, B S},
keywords = {chemosearch,chemotaxis,computational neuroscience,moth,neurobiology,odour plumes.,olfaction,pheromone detection},
title = {{Chemotactic search in complex environments}}
}
@article{FurrerBengtsson07,
author = {Furrer, Reinhard and Bengtsson, Thomas},
journal = {J. Multivar. Anal.},
pages = {227--255},
title = {{Estimation of high-dimensional prior and posterior covariance matrices in {\{}K{\}}alman filter variants}},
volume = {98},
year = {2007}
}
@article{Cousins2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1306.5829v2},
author = {Cousins, B and Vempala, S},
eprint = {arXiv:1306.5829v2},
journal = {arXiv preprint arXiv:1306.5829},
title = {{A cubic algorithm for computing gaussian volume}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9781611973402.90},
year = {2013}
}
@article{HB97,
author = {Haag, J and Borst, A},
journal = {Journal of Neuroscience},
pages = {4809--4819},
title = {{Encoding of Visual Motion Information and Reliability in Spiking and Graded Potential Neurons}},
volume = {17},
year = {1997}
}
@article{Procaccia1983,
author = {Procaccia, I and Schuster, H},
journal = {Physical Review A},
number = {2},
title = {{Functional renormalization-group theory of universal 1/f noise in dynamical systems}},
volume = {28},
year = {1983}
}
@article{Loinaz|2000|,
abstract = {We perform a Monte Carlo simulation calculation of the critical coupling
constant for the continuum two-dimensional (lambda/4) phi{\^{}}4 theory.
The critical coupling constant we obtain is [lambda/m{\^{}}2]{\_}crit=10.26+0.8-0.04.},
author = {Loinaz, W and Willey, R S},
journal = {Physical Review D},
keywords = {critical coupling,ground state,monte carlo,phi{\^{}}4,physics,quantum field theory,symmetry breaking},
pages = {76003},
title = {{Monte Carlo simulation calculation of the critical coupling constant for two-dimensional continuum phi{\^{}}4 theory}},
volume = {58}
}
@article{Malmierca,
author = {Malmierca, Manuel S},
journal = {International Review of Neurobiology},
pages = {147--211},
title = {{The structure and physiology of the rat auditory system: an overview}},
volume = {56},
year = {2003}
}
@article{MackeBethge09,
author = {Macke, J and Berens, P and Ecker, A and Tolias, A and Bethge, M},
journal = {Neural Computation},
pages = {In press},
title = {{Generating Spike Trains with Specified Correlation Coefficients}},
volume = {21},
year = {2009}
}
@article{Johnson2010,
abstract = {Neuroscientists want to quantify how well neurons, individually and collectively, process information and encode the result in their outputs. We demonstrate that while classic information theory demarcates optimal performance boundaries, it does not provide results that would be useful in analyzing an existing system about which little is known (such as the brain). In the classical vein, non-Poisson channels, which describe the communication medium for neural signals, are shown to have individually a capacity strictly smaller than the Poisson ideal. We describe recent capacity results for Poisson neural populations, showing that connections among neurons can increase capacity. We then present an alternative theory more amenable to data analysis and to situations wherein systems actively extract and represent information. Using this theory, we show that the ability of a neural population to jointly represent information depends nature of its input signal, not on the encoded information.},
annote = {2010IInum12.9},
author = {Johnson, Don H.},
doi = {10.1109/TIT.2009.2037047},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {653--666},
title = {{Information Theory and Neural Information Processing}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=5420287},
volume = {56},
year = {2010}
}
@article{Chapman1963,
annote = {2009num18},
author = {Chapman, KM M and Smith, RS S},
publisher = {Nature Publishing Group},
title = {{A linear transfer function underlying impulse frequency modulation in a cockroach mechanoreceptor}},
url = {http://www.nature.com/nature/journal/v197/n4868/abs/197699a0.html},
year = {1963}
}
@article{PS97,
author = {Pouget, A and Sejnowski, T},
journal = {Journal of Cognitive Neuroscience},
pages = {222--237},
title = {{Spatial tranformations in the parietal cortex using basis functions}},
volume = {9},
year = {1997}
}
@article{White2004,
abstract = {We study the ability of linear recurrent networks obeying discrete time dynamics to store long temporal sequences that are retrievable from the instantaneous state of the network. We calculate this temporal memory capacity for both distributed shift register and random orthogonal connectivity matrices. We show that the memory capacity of these networks scales with system size.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0402452},
author = {White, Olivia L. and Lee, Daniel D. and Sompolinsky, Haim},
doi = {10.1103/PhysRevLett.92.148102},
eprint = {0402452},
isbn = {0031-9007},
issn = {00319007},
journal = {Physical Review Letters},
number = {14},
pages = {148102--1},
pmid = {15089576},
primaryClass = {cond-mat},
title = {{Short-term memory in orthogonal neural networks}},
volume = {92},
year = {2004}
}
@article{Tindall2008,
annote = {2010num5.4{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Tindall, M J and Porter, S L and Maini, P K},
doi = {10.1007/s11538-008-9321-6},
journal = {Bulletin of mathematical biology},
keywords = {bacterial chemotaxis,review,single cell},
number = {6},
pages = {1525--1569},
title = {{Overview of mathematical approaches used to model bacterial chemotaxis I: the single cell}},
url = {http://www.springerlink.com/index/f602r72767124602.pdf},
volume = {70},
year = {2008}
}
@article{Rajapakse2011,
abstract = {A state-dependent dynamic network is a collection of elements that interact through a network, whose geometry evolves as the state of the elements changes over time. The genome is an intriguing example of a state-dependent network, where chromosomal geometry directly relates to genomic activity, which in turn strongly correlates with geometry. Here we examine various aspects of a genomic state-dependent dynamic network. In particular, we elaborate on one of the important ramifications of viewing genomic networks as being state-dependent, namely, their controllability during processes of genomic reorganization such as in cell differentiation.},
author = {Rajapakse, Indika and Groudine, Mark and Mesbahi, Mehran},
doi = {10.1073/pnas.1113249108},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Cell Differentiation,Cell Differentiation: genetics,Cell Differentiation: physiology,Complex Networks,Feedback, Physiological,GATA1 Transcription Factor,GATA1 Transcription Factor: genetics,GATA1 Transcription Factor: metabolism,Gene Regulatory Networks,Hematopoiesis,Hematopoiesis: genetics,Hematopoiesis: physiology,Humans,Models, Biological,Models, Genetic,MyoD Protein,MyoD Protein: genetics,MyoD Protein: metabolism},
mendeley-tags = {Complex Networks},
month = {oct},
number = {42},
pages = {17257--62},
pmid = {21911407},
title = {{Dynamics and control of state-dependent networks for probing genomic organization.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3198315{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {108},
year = {2011}
}
@article{Hopfield|2003|,
abstract = {Plasticity in connections between neurons allows learning and adaptation,
but it also allows noise to degrade the function of a network. Ongoing
network self-repair is thus necessary. We describe a method to derive
spike-timing-dependent plasticity rules for self-repair, based on
the firing patterns of a functioning network. These plasticity rules
for self-repair also provide the basis for unsupervised learning
of new tasks. The particular plasticity rule derived for a network
depends on the network and task. Here, self-repair is illustrated
for a model of the mammalian olfactory system in which the computational
task is that of odor recognition. In this olfactory example, the
derived rule has qualitative similarity with experimental results
seen in spike-timing-dependent plasticity. Unsupervised learning
of new tasks by using the derived self-repair rule is demonstrated
by learning to recognize new odors.},
annote = {The paper deals with the question how a network subjected to plasticity{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}may maintain stability in performing its task [here odor recognition{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}in olfaction] in the presence of changes noise due to plasticity.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}The question is addressed on the example of artificial neural network{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}for olfaction odor recognition. The plasticity rule is as follows:{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}a value function is assigned for each presynaptic neuron depending{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}on the time difference between pre {\&} postsynaptic cells firings.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}This is a bell shaped function promoting value of neurons firing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}in synchrony with two negative wings suppressing neurons that also{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}fire out of synchrony [all the time]. After each postsynaptic cell{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}firing, all presynaptic connections are removed and a fixed number{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}[200] of new connections with the highest values are made. System{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}shows stability of recognition despite drastic update rule and ability{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to learn by initially broadly tuned cell the odor at which original{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}synaptic update was initiated. Conjecture is made that general learning{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}rule which favor better synchrony will result in rearrangement of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}connections toward "sooner" spiking. This is said to be related to{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the "center of mass" of the "value" curve associated with learning.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Small tail of positive values for "negative" relative timings is{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}needed to prevent such drift due to zeroing the center of mass. This{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}is said to reflect the fact that due to jitter in timing relevant{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}cells some times may fire before postsynaptic cell and by this should{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}be given credit in learning rule. General bottomline is as follows:{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}"conservatism" allows system to maintain its function even in the{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}presence of substantial plasticity: as long as majority follows the{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}same route, changes in the system will not disrupt its function;{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}conservatism here is implemented via synchrony criteria - when many{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}cells spike together, noise in their spiking may be overwhelmed by{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}presence of the cells number. I don{\&}{\#}039;t really buy right away the arguments{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}about drift and center of mass of learning curve.},
author = {Hopfield, J J and Brody, C D},
journal = {PNAS},
keywords = {learning,networks,neural networks,neurobiology,olfaction,plasticity,repair,spike-timing},
number = {1},
pages = {337},
title = {{Learning rules and network repair in spike-timing-based computation networks}},
volume = {101}
}
@article{zillmer2009very,
annote = {2008num35},
author = {Zillmer, R and Brunel, N and Hansel, D},
journal = {Physical Review E},
number = {3},
pages = {31909},
publisher = {APS},
title = {{Very long transients, irregular firing, and chaotic dynamics in networks of randomly connected inhibitory integrate-and-fire neurons}},
volume = {79},
year = {2009}
}
@article{Spielman2009,
abstract = {Many algorithms and heuristics work well on real data, despite having poor complexity under the standard worst-case measure. Smoothed analysis is a step towards a theory that explains the behavior of algorithms in practice. It is based on the assumption that inputs to algorithms are subject to random perturbation and modification in their formation. A concrete example of such a smoothed analysis is a proof that the simplex algorithm for linear programming usually runs in polynomial time, when its input is subject to modeling or measurement noise.},
author = {Spielman, Daniel A and Teng, Shang-hua},
doi = {http://doi.acm.org/10.1145/1562764.1562785},
issn = {00010782},
journal = {Communications of the ACM (CACM)},
keywords = {complexity theory,simplex algorithm,smoothed analysis},
number = {10},
pages = {76--84},
title = {{Smoothed analysis: an attempt to explain the behavior of algorithms in practice}},
volume = {52},
year = {2009}
}
@article{Ngiam,
author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, H and Ng, A Y},
journal = {Proc. ICML},
keywords = {Deep Learning},
mendeley-tags = {Deep Learning},
pages = {1--9},
title = {{Multimodal deep learning}},
url = {http://ai.stanford.edu/{~}ang/papers/icml11-MultimodalDeepLearning.pdf},
year = {2011}
}
@misc{SAH00,
author = {Sahani, M},
howpublished = {Presented at NIPS00 workshop on Information and statistical structure in spike trains; abstract available at http://www-users.med.cornell.edu/{\~{}}jdvicto/nips2000speakers.html},
title = {{Kernel regression for neural systems identification}},
year = {2000}
}
@article{BirdGu03,
abstract = {A major obstacle in the race to develop two-photon fluorescence endoscopy

is the use of complicated bulk optics to transmit an ultrashort-pulsed

laser beam and return the emitted fluorescence signal. We describe

an all-fiber two-photon fluorescence microendoscope based on a single-mode

optical fiber coupler, a microprism, and a gradient-index rod lens.

It is found that the new endoscope exhibits an axial resolution of

3.2 microm and is capable of imaging transverse cross sections of

internal cylindrical structures as small as approximately 3.0 mm

in diameter. This device demonstrates the potential for developing

a real-time diagnostic tool for biomedical research without the need

for surgical biopsy and may find applications in photodynamic therapy,

microsurgery, and early cancer detection.},
author = {Bird, Damian and Gu, Min},
journal = {Opt Lett},
keywords = {Endoscopy; Equipment Design; Microscopy,Fluorescence; Optics; Photons},
month = {sep},
number = {17},
pages = {1552--1554},
pmid = {12956376},
title = {{Two-photon fluorescence endoscopy with a micro-optic scanning head.}},
volume = {28},
year = {2003}
}
@article{Shen2016,
abstract = {Despite the recent great success of deep neural networks in various applications, designing and training a deep neural network is still among the greatest challenges in the field. In this work, we present a smooth optimisation perspective on designing and training multilayer Feedforward Neural Networks (FNNs) in the supervised learning setting. By characterising the critical point conditions of an FNN based optimisation problem, we identify the conditions to eliminate local optima of the corresponding cost function. Moreover, by studying the Hessian structure of the cost function at the global minima, we develop an approximate Newton FNN algorithm, which is capable of alleviating the vanishing gradient problem. Finally, our results are numerically verified on two classic benchmarks, i.e., the XOR problem and the four region classification problem.},
archivePrefix = {arXiv},
arxivId = {1611.05827},
author = {Shen, Hao},
eprint = {1611.05827},
journal = {ArXiv},
number = {i},
pages = {1--19},
title = {{Designing and Training Feedforward Neural Networks: A Smooth Optimisation Perspective}},
url = {http://arxiv.org/abs/1611.05827},
year = {2016}
}
@book{White89,
author = {White, E},
publisher = {Birkhauser},
title = {{Cortical Circuits}},
year = {1989}
}
@article{Schehr2012,
author = {Schehr, Gr{\'{e}}gory and Majumdar, Satya},
doi = {10.1103/PhysRevLett.108.040601},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {jan},
number = {4},
pages = {1--5},
title = {{Universal Order Statistics of Random Walks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.108.040601},
volume = {108},
year = {2012}
}
@misc{Holt1999,
abstract = {Ephaptic interactions between a neuron and axons or dendrites passing by its cell body can be, in principle, more significant than ephaptic interactions among axons in a fiber tract. Extracellular action potentials outside axons are small in amplitude and spatially spread out, while they are larger in amplitude and much more spatially confined near cell bodies. We estimated the extracellular potentials associated with an action potential in a cortical pyramidal cell using standard one-dimensional cable theory and volume conductor theory. Their spatial and temporal pattern reveal much about the location and timing of currents in the cell, especially in combination with a known morphology, and simple experiments could resolve questions about spike initiation. From the extracellular potential we compute the ephaptically induced polarization in a nearby passive cable. The magnitude of this induced voltage can be several mV, does not spread electrotonically, and depends only weakly on the passive properties of the cable. We discuss their possible functional relevance.},
author = {Holt, Gary R. and Koch, C},
booktitle = {Journal of Computational Neuroscience},
doi = {10.1023/A:1008832702585},
issn = {0929-5313},
keywords = {Computer Science},
number = {2},
pages = {169--184--184},
publisher = {Springer Netherlands},
title = {{Electrical Interactions via the Extracellular Potential Near Cell Bodies}},
url = {http://www.springerlink.com/content/u262m146864wu008/},
volume = {6},
year = {1999}
}
@article{Benaim2003,
annote = {

2010IInum12.27},
author = {Benaim, Michel and Weibull, Jorgen W. JW and Bena{\"{i}}m, M},
journal = {Econometrica},
number = {3},
pages = {873 -- 903},
title = {{Deterministic Approximation of Stochastic Evolution in Games}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1468-0262.00429/abstract http://www.jstor.org/stable/1555525},
volume = {71},
year = {2003}
}
@article{MajewskaSur06,
abstract = {Although plastic changes are known to occur in developing and adult

cortex, it remains unclear whether these changes require remodeling

of cortical circuitry whereby synapses are formed and eliminated

or whether they rely on changes in the strength of existing synapses.

To determine the structural stability of dendritic spines and axon

terminals in vivo, we chose two approaches. First, we performed time-lapse

two-photon imaging of dendritic spine motility of layer 5 pyramidal

neurons in juvenile [postnatal day 28 (P28)] mice in visual, auditory,

and somatosensory cortices. We found that there were differences

in basal rates of dendritic spine motility of the same neuron type

in different cortices, with visual cortex exhibiting the least structural

dynamics. Rewiring visual input into the auditory cortex at birth,

however, failed to alter dendritic spine motility, suggesting that

structural plasticity rates might be intrinsic to the cortical region.

Second, we investigated the persistence of both the presynaptic (axon

terminals) and postsynaptic (dendritic spine) structures in young

adult mice (P40-P61), using chronic in vivo two-photon imaging in

different sensory areas. Both terminals and spines were relatively

stable, with {\textgreater}80{\%} persisting over a 3 week period in all sensory

regions. Axon terminals were more stable than dendritic spines. These

data suggest that changes in network function during adult learning

and memory might occur through changes in the strength and efficacy

of existing synapses as well as some remodeling of connectivity through

the loss and gain of synapses.},
author = {Majewska, Ania K and Newton, Jessica R and Sur, Mriganka},
doi = {10.1523/JNEUROSCI.4454-05.2006},
journal = {J Neurosci},
keywords = {Animals; Auditory Cortex; Auditory Pathways; Axons,Confocal; Motion; Neuronal Plasticity; Presynapti,Inbred C57BL; Mice,Reporter; Geniculate Bodies; Green Fluorescent Pr,Transgenic; Microscopy},
month = {mar},
number = {11},
pages = {3021--3029},
pmid = {16540580},
title = {{Remodeling of synaptic structure in sensory cortical areas in vivo.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.4454-05.2006},
volume = {26},
year = {2006}
}
@article{Barbosa,
author = {Barbosa, CTF T F and Rodrigues, ARA R A and de Oliveira, R.A.C. A C and Varanda, WA A and Liebovitch, L S and Nogueira$\backslash${\&}, RA A},
journal = {Proceedings of the IEEE Computer Society},
title = {{Memory in Single Calcium-Activated Potassium Channel Kinetics}},
url = {http://www.cefala.org/sbrn2004/articles/sbrn2004-3567.pdf},
year = {2004}
}
@book{Anderson2009,
address = {Cambridge},
author = {Anderson, Greg W. G.W. and Guionnet, Alice and Zeitouni, Ofer},
doi = {10.1017/CBO9780511801334},
isbn = {9780511801334},
number = {9},
publisher = {Cambridge University Press},
title = {{An introduction to random matrices}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511801334 http://www-stat.stanford.edu/{~}adembo/stat-350/matrices/toc.ps},
volume = {200},
year = {2010}
}
@article{Ishii1992,
author = {Ishii, H and Shibata, T and Kosaka, H},
isbn = {0780308174},
journal = {Electron Devices Meeting,},
pages = {435--438},
title = {{Hardware-backpropagation learning of neuron MOS neural networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=307395},
year = {1992}
}
@article{Ransdell2013,
abstract = {Biological and theoretical evidence suggest that individual neurons may achieve similar outputs by differentially balancing variable underlying ionic conductances. Despite the substantial amount of data consistent with this idea, a direct biological demonstration that cells with conserved output, particularly within the same network, achieve these outputs via different solutions has been difficult to achieve. Here we demonstrate definitively that neurons from native neural networks with highly similar output achieve this conserved output by differentially tuning underlying conductance magnitudes. Multiple motor neurons of the crab (Cancer borealis) cardiac ganglion have highly conserved output within a preparation, despite showing a 2-4-fold range of conductance magnitudes. By blocking subsets of these currents, we demonstrate that the remaining conductances become unbalanced, causing disparate output as a result. Therefore, as strategies to understand neuronal excitability become increasingly sophisticated, it is important that such variability in excitability of neurons, even among those within the same individual, is taken into account.},
author = {Ransdell, Joseph L and Nair, Satish S and Schulz, David J},
doi = {10.1523/JNEUROSCI.1095-13.2013},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = {jun},
number = {24},
pages = {9950--6},
pmid = {23761890},
title = {{Neurons within the same network independently achieve conserved output by differentially balancing variable conductance magnitudes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23761890},
volume = {33},
year = {2013}
}
@inproceedings{Fletcher2014,
abstract = {Fluorescent calcium imaging provides a potentially powerful tool for inferring connectivity in neural circuits with up to thousands of neurons. However, a key challenge in using calcium imaging for connectivity detection is that current systems often have a temporal response and frame rate that can be orders of magnitude slower than the underlying neural spiking process. Bayesian inference methods based on expectation-maximization (EM) have been proposed to overcome these limitations, but are often computationally demanding since the E-step in the EM procedure typically involves state estimation for a high-dimensional nonlinear dynamical system. In this work, we propose a computationally fast method for the state estimation based on a hybrid of loopy belief propagation and approximate message passing (AMP). The key insight is that a neural system as viewed through calcium imaging can be factorized into simple scalar dynamical systems for each neuron with linear interconnections between the neurons. Using the structure, the updates in the proposed hybrid AMP methodology can be computed by a set of one-dimensional state estimation procedures and linear transforms with the connectivity matrix. This yields a computationally scalable method for inferring connectivity of large neural circuits. Simulations of the method on realistic neural networks demonstrate good accuracy with computation times that are potentially significantly faster than current approaches based on Markov Chain Monte Carlo methods.},
author = {Fletcher, A K and Rangan, S},
booktitle = {Neural Information Processing Systems},
pages = {1--9},
title = {{Scalable inference for neuronal connectivity from calcium imaging}},
year = {2014}
}
@article{Boukhobza2007,
author = {Boukhobza, T. and Hamelin, F. and Martinez-Martinez, S.},
doi = {10.1016/j.automatica.2006.12.004},
issn = {00051098},
journal = {Automatica},
keywords = {Reservoir Computing,generic state and input,graph theory,observability,structured systems},
mendeley-tags = {Reservoir Computing},
month = {jul},
number = {7},
pages = {1204--1210},
title = {{State and input observability for structured linear systems: A graph-theoretic approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0005109807000611},
volume = {43},
year = {2007}
}
@article{Advani,
author = {Advani, Madhu and Lahiri, Subhaneil and Ganguli, Surya},
doi = {10.1088/1742-5468/2013/03/P03014},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
keywords = {algorithms,cavity and replica method,cavity method,computational neuroscience,glasses,high dimensional data,learning,message passing,message-passing,neural networks,random matrices,random projections,replica method,spin,spin glasses,theory},
month = {mar},
number = {03},
pages = {P03014},
title = {{Statistical mechanics of complex neural systems and high dimensional data}},
url = {http://stacks.iop.org/1742-5468/2013/i=03/a=P03014?key=crossref.5f17f6bb3ee4eb696f3064bf1d40ac56},
volume = {2013},
year = {2013}
}
@article{BrownRyugo88,
author = {Brown, M C and Berglund, A M and Kiang, N Y and Ryugo, D K},
journal = {Journal of Comparative Neurology},
month = {dec},
number = {4},
pages = {581--590},
title = {{Central trajectories of type {\{}I{\}}{\{}I{\}} spiral ganglion neurons}},
volume = {278},
year = {1988}
}
@article{Sharia08,
author = {Sharia, T},
journal = {Annals of the Institute of Statistical Mathematics},
title = {{Recursive parameter estimation: asymptotic expansion}},
volume = {In press},
year = {2008}
}
@article{Takeuchi2011,
abstract = {The primate temporal cortex implements visual long-term memory. However, how its interlaminar circuitry executes cognitive computations is poorly understood. Using linear-array multicontact electrodes, we simultaneously recorded unit activities across cortical layers in the perirhinal cortex of macaques performing a pair-association memory task. Cortical layers were estimated on the basis of current source density profiles with histological verifications, and the interlaminar signal flow was determined with cross-correlation analysis between spike trains. During the cue period, canonical "feed-forward" signals flowed from granular to supragranular layers and from supragranular to infragranular layers. During the delay period, however, the signal flow reversed to the "feed-back" direction: from infragranular to supragranular layers. This reversal of signal flow highlights how the temporal cortex differentially recruits its laminar circuits for sensory and mnemonic processing.},
author = {Takeuchi, Daigo and Hirabayashi, Toshiyuki and Tamura, Keita and Miyashita, Yasushi},
doi = {10.1126/science.1199967},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Animals,Association Learning,Cues,Electrodes,Implanted,Macaca,Macaca mulatta,Memory,Memory: physiology,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Temporal Lobe,Temporal Lobe: anatomy {\&} histology,Temporal Lobe: physiology,Visual Perception},
month = {mar},
number = {6023},
pages = {1443--7},
pmid = {21415353},
title = {{Reversal of interlaminar signal between sensory and memory processing in monkey temporal cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21415353},
volume = {331},
year = {2011}
}
@article{Osterberg1935,
author = {Osterberg, G},
journal = {Acta Ophthal Suppl.},
pages = {1--103},
title = {{Topography of the layer of rods and cones in the human retina}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Topography+of+the+layer+of+rods+and+cones+in+the+human+retina.{\#}0},
volume = {6},
year = {1935}
}
@article{Jacobsson2016,
abstract = {Massive multiuser (MU) multiple-input multiple-output (MIMO) is foreseen to be one of the key technologies in fifth-generation wireless communication systems. In this paper, we investigate the problem of downlink precoding for a narrowband massive MU-MIMO system with low-resolution digital-to-analog converters (DACs) at the base station (BS). We analyze the performance of linear precoders, such as maximal-ratio transmission and zero-forcing, subject to coarse quantization. Using Bussgang's theorem, we derive a closed-form approximation of the achievable rate of the coarsely quantized system. Our results reveal that the infinite-resolution performance can be approached with DACs using only 3 to 4 bits of resolution, depending on the number of BS antennas and the number of user equipments (UEs). For the case of 1-bit DACs, we also propose novel nonlinear precoding algorithms that significantly outperform linear precoders at the cost of an increased computational complexity. Specifically, we show that nonlinear precoding incurs only a 3 dB penalty compared to the infinite-resolution case for an uncoded bit error rate of 10{\^{}}-3 in a system with 128 BS antennas that uses 1-bit DACs and serves 16 single-antenna UEs; in contrast, the penalty is about 8 dB for linear precoders.},
archivePrefix = {arXiv},
arxivId = {1610.07564},
author = {Jacobsson, Sven and Durisi, Giuseppe and Coldrey, Mikael and Goldstein, Tom and Studer, Christoph},
eprint = {1610.07564},
pages = {1--31},
title = {{Quantized Precoding for Massive MU-MIMO}},
url = {http://arxiv.org/abs/1610.07564},
year = {2016}
}
@article{Cocco09,
author = {Cocco, Simona and Leibler, Stanislas and Monasson, R{\'{e}}mi},
journal = {Proceedings of the National Academy of Sciences},
number = {33},
pages = {14058--14062},
title = {{Neuronal couplings between retinal ganglion cells inferred by efficient inverse statistical physics methods}},
volume = {106},
year = {2009}
}
@inproceedings{MCD89,
author = {McDiarmid, C},
booktitle = {Surveys in Combinatorics},
pages = {148--188},
publisher = {Cambridge University Press},
title = {{On the method of bounded differences}},
year = {1989}
}
@article{Hallett2007,
abstract = {This review deals with the physiology of the initiation of a voluntary movement and the appreciation of whether it is voluntary or not. I argue that free will is not a driving force for movement, but a conscious awareness concerning the nature of the movement. Movement initiation and the perception of willing the movement can be separately manipulated. Movement is generated subconsciously, and the conscious sense of volition comes later, but the exact time of this event is difficult to assess because of the potentially illusory nature of introspection. Neurological disorders of volition are also reviewed. The evidence suggests that movement is initiated in the frontal lobe, particularly the mesial areas, and the sense of volition arises as the result of a corollary discharge likely involving multiple areas with reciprocal connections including those in the parietal lobe and insular cortex.},
annote = {2011num55},
author = {Hallett, Mark},
doi = {10.1016/j.clinph.2007.03.019},
issn = {1388-2457},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Animals,Humans,Models, Biological,Movement,Movement: physiology,Nervous System Diseases,Nervous System Diseases: physiopathology,Nervous System Diseases: psychology,Perception,Perception: physiology,Physiology,Volition},
month = {jun},
number = {6},
pages = {1179--92},
pmid = {17466580},
title = {{Volitional control of movement: the physiology of free will.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1950571{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {118},
year = {2007}
}
@article{Young80,
author = {Young, E D},
journal = {Brain Research},
month = {oct},
number = {1},
pages = {23--37},
title = {{Identification of response properties of ascending axons from dorsal cochlear nucleus}},
volume = {200},
year = {1980}
}
@article{schneidman1998ion,
annote = {2009num36},
author = {Schneidman, E and Freedman, B and Segev, I},
journal = {Neural Computation},
number = {7},
pages = {1679--1703},
publisher = {MIT Press},
title = {{Ion channel stochasticity may be critical in determining the reliability and precision of spike timing}},
volume = {10},
year = {1998}
}
@book{RUD73,
address = {New York},
author = {Rudin, W},
publisher = {McGraw-Hill},
title = {{Functional Analysis}},
year = {1973}
}
@article{Saxe,
author = {Saxe, A M and Bhand, Maneesh and Mudur, Ritvik},
journal = {Shawe-Taylor, J.; Zemel, {\ldots}},
keywords = {Deep Learning},
mendeley-tags = {Deep Learning},
pages = {1--9},
title = {{Unsupervised learning models of primary cortical receptive fields and receptive field plasticity}},
url = {http://books.nips.cc/papers/files/nips24/NIPS2011{\_}1115.pdf},
year = {2011}
}
@article{Ephraim2002,
annote = {2010IIInum44},
author = {Ephraim, Y. and Merhav, N.},
doi = {10.1109/TIT.2002.1003838},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {jun},
number = {6},
pages = {1518--1569},
title = {{Hidden Markov processes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1003838},
volume = {48},
year = {2002}
}
@article{ARCAS03,
author = {y Arcas, B and Fairhall, A},
journal = {Neural Computation},
pages = {1789--1807},
title = {{What causes a neuron to spike?}},
volume = {15},
year = {2003}
}
@article{Tsodyks1997,
abstract = {Although signaling between neurons is central to the functioning of the brain, we still do not understand how the code used in signaling depends on the properties of synaptic transmission. Theoretical analysis combined with patch clamp recordings from pairs of neocortical pyramidal neurons revealed that the rate of synaptic depression, which depends on the probability of neurotransmitter release, dictates the extent to which firing rate and temporal coherence of action potentials within a presynaptic population are signaled to the postsynaptic neuron. The postsynaptic response primarily reflects rates of firing when depression is slow and temporal coherence when depression is fast. A wide range of rates of synaptic depression between different pairs of pyramidal neurons was found, suggesting that the relative contribution of rate and temporal signals varies along a continuum. We conclude that by setting the rate of synaptic depression, release probability is an important factor in determining the neural code.},
annote = {

Figure 1 seems very nice (too nice?), but I have two problems here:

1) 'I' cannot be a fraction since it must become negative in Eq. (1). If this is not the case, then R cannot decrease. Also, if R=1, E=0 and I=0, and then comes a pulse, then 'I' becomes negative.

Answer: the equations are indeed wrong. See Eq. 1 in "Neural networks with dynamic synapses" for the correct version.

2) I don't understand under what assumptions was eq. 2 derived, or how.},
author = {Tsodyks, M and Markram, H},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Action Potentials,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Kinetics,Membrane Potentials,Patch-Clamp Techniques,Rats,Synapses,Synapses: physiology,Synaptic Transmission,Wistar},
number = {2},
pages = {719--23},
pmid = {9012851},
title = {{The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=19580{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {94},
year = {1997}
}
@inproceedings{Tu|2001|,
abstract = {This paper presents a computational paradigm called Data Driven M
arkov Chain Monte Carlo (DDMCMC) for image segmentation in the Bayesian
statistical framework. The paper contrubutes to image segmentation
in three aspects. Firstly, it designs effective and well balanced
Markov Chain dynamics to explore the solution space and makes the
split and merge process reversible at a middle level vision formulation.
Thus it achieves globally optimal solution independent of initial
segmentations. Secondly, instead of computing a single maximum a
posteriori solution, it proposes a mathematical principle for computing
multiple distinct solutions to incorporate intrinsic ambiguities
in image segmentation. A k-adventurers algorithm is proposed for
extracting distinct multiple solutions from the Markov chain sequence.
Thirdly, it utilizes data-driven (bottom-up) techniques, such as
clustering and edge detection, to compute importance proposal probabilities,
which effectively drive the Markov chain dynamics and achieve tremendous
speedup in comparison to traditional jump-diffusion method [4]. Thus
DDMCMC paradigm provides a unifying framework where the role of existing
segmentation algorithms, such as, edge detection, clustering, region
growing, split-,erge, SNAKEs, region competition, are revealed as
either realizing Markov chain dynamics or computing importance proposal
probabilities. We report some results on color and grey level image
segmentation in this paper and refer to a detailed report on a web
site for extensive discussion.},
address = {Vancouver, Canada},
author = {Tu, Z and Zhu, S.-C. and Shum, H.-Y.},
booktitle = {Int'l Conference on Computer Vision},
keywords = {computational,edge-detection,image processing,markov chain,markov field,monte carlo,segmentation},
title = {{Image segmentation by data driven markov chain monte carlo}}
}
@article{Sharon,
abstract = {We introduce a fast, multiscale algorithm for image segmentation.
Our algorithm uses modern numeric techniques to find an approximate
solution to normalized cut measures in time that is linear in the
size of the image with only a few dozen operations per pixel. In
just one pass the algorithm provides a complete hierarchical decomposition
of the image into segments. The algorithm detects the segments by
applying a process of recursive coarsening in which the same minimization
problem is represented with fewer and fewer variables producing an
irregular pyramid. During this coarsening process we may compute
additional internal statistics of the emerging segments and use these
statistics to facilitate the segmentation process. Once the pyramid
is completed it is scanned from the top down to associate pixels
close to the boundaries of segments with the appropriate segment.
The algorithm is inspired by algebraic multigrid (AMG) solvers of
minimization problems of heat or electric networks. We demonstrate
the algorithm by applying it to real images.},
author = {Sharon, E and Brandt, A and Basri, R},
keywords = {aggregation,computational,hierarchical,image processing,multiscale,segmentation},
title = {{Fast Miltiscale Image Segmentation}}
}
@article{Finnigan2012,
author = {Finnigan, Gregory C. and Hanson-Smith, Victor and Stevens, Tom H. and Thornton, Joseph W.},
doi = {10.1038/nature10724},
issn = {0028-0836},
journal = {Nature},
month = {jan},
pages = {1--6},
publisher = {Nature Publishing Group},
title = {{Evolution of increased complexity in a molecular machine}},
url = {http://www.nature.com/doifinder/10.1038/nature10724},
year = {2012}
}
@article{Welch1967,
annote = {2010num1.10},
author = {Welch, P},
journal = {IEEE Transactions on Audio and Electroacoustics},
title = {{The use of fast Fourier transform for the estimation of power spectra: a  {\ldots}}},
url = {http://scholar.google.com/scholar?hl=en{\&}q=welch+1967{\&}btnG=Search{\&}as{\_}sdt=2000{\&}as{\_}ylo={\&}as{\_}vis=0{\#}2},
year = {1967}
}
@book{BraitenbergSchutz98,
author = {Braitenberg, V and Schutz, A},
publisher = {Springer},
title = {{Anatomy of the cortex}},
year = {1998}
}
@book{GPBook06,
author = {Rasmussen, C and Williams, C},
publisher = {MIT Press},
title = {{Gaussian Processes for Machine Learning}},
year = {2006}
}
@article{COV72,
author = {Cover, T M},
journal = {IEEE Transactions on Information Theory},
pages = {216--217},
title = {{Admissibility Properties of {\{}G{\}}ilbert's Encoding for Unknown Source Probabilities}},
volume = {18},
year = {1972}
}
@book{Brodal2004,
author = {Brodal, P},
publisher = {Oxford University Press},
title = {{The central nervous system: structure and function}},
year = {2004}
}
@article{Denker2004,
annote = {2010IInum8.1},
author = {Denker, M and Timme, M and Diesmann, M and Wolf, F and Geisel, T},
journal = {Physical Review Letters},
title = {{Breaking synchrony by heterogeneity in complex networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.92.074103},
year = {2004}
}
@article{Richmond1998,
abstract = {The available pool of sodium channels, and thus cell excitability, is regulated by both fast and slow inactivation. In cardiac tissue, the requirement for sustained firing of long-duration action potentials suggests that slow inactivation in cardiac sodium channels may differ from slow inactivation in skeletal muscle sodium channels. To test this hypothesis, we used the macropatch technique to characterize slow inactivation in human cardiac sodium channels heterologously expressed in Xenopus oocytes. Slow inactivation was isolated from fast inactivation kinetically (by selectively recovering channels from fast inactivation before measurement of slow inactivation) and structurally (by modification of fast inactivation by mutation of IFM1488QQQ). Time constants of slow inactivation in cardiac sodium channels were larger than previously reported for skeletal muscle sodium channels. In addition, steady-state slow inactivation was only 40{\%} complete in cardiac sodium channels, compared to 80{\%} in skeletal muscle channels. These results suggest that cardiac sodium channel slow inactivation is adapted for the sustained depolarizations found in normally functioning cardiac tissue. Complete slow inactivation in the fast inactivation modified IFM1488QQQ cardiac channel mutant suggests that this impairment of slow inactivation may result from an interaction between fast and slow inactivation.},
author = {Richmond, J E and Featherstone, D E and Hartmann, H a and Ruben, P C},
doi = {10.1016/S0006-3495(98)78001-4},
issn = {0006-3495},
journal = {Biophysical journal},
keywords = {Amino Acid Sequence,Animals,DNA, Complementary,Female,Heart,Heart: physiology,Humans,Membrane Potentials,Mutagenesis, Site-Directed,Oocytes,Oocytes: physiology,Patch-Clamp Techniques,Recombinant Proteins,Recombinant Proteins: biosynthesis,Recombinant Proteins: chemistry,Recombinant Proteins: metabolism,Sodium Channels,Sodium Channels: biosynthesis,Sodium Channels: chemistry,Sodium Channels: physiology,Time Factors,Xenopus laevis},
month = {jun},
number = {6},
pages = {2945--52},
pmid = {9635748},
publisher = {Elsevier},
title = {{Slow inactivation in human cardiac sodium channels.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1299635{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {74},
year = {1998}
}
@book{Golub2012,
author = {Golub, GH and Loan, CF Van},
title = {{Matrix computations}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=5U-l8U3P-VUC{\&}oi=fnd{\&}pg=PT10{\&}dq=Matrix+Computations{\&}ots=7ZDwLo2T9t{\&}sig=NVMBOWUccJ9pkw{\_}4Sj8GFWWOMRc},
year = {2012}
}
@techreport{Gagvani|1997|,
abstract = {Skeletons are useful shape abstractions and have varied applications
in visualization. The complexity of the desired skeletal structure
depends on the application. Current techniques for extracting skeletons
do not allow control over the complexity. In this paper, we describe
an algorithm which uses a thinness parameter to control the density
of the skeleton. We present applications from CFD and medical visualization
and show how the skeletal structure can be used in these domains},
annote = {This paper introduces distance function based skeletonization approach{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}with paremeter specifying thickness of the remaining distance-function{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}chopped for skeleton.},
author = {Gagvani, N and Silver, D},
institution = {Department of Electrical and Computer Engineering and CAIP center, Rutgers University},
keywords = {computational,distance function,image processing,skeletonization},
title = {{Parameter controlled skeletonization of three dimensional objects}}
}
@article{ShephardPitt97,
author = {Shephard, N and Pitt, M.{\~{}}K.},
doi = {10.1093/biomet/84.3.653},
journal = {Biometrika},
number = {3},
pages = {653--667},
title = {{Likelihood analysis of non-Gaussian measurement time series}},
url = {http://biomet.oxfordjournals.org/cgi/content/abstract/84/3/653},
volume = {84},
year = {1997}
}
@article{Gunasekar2017,
abstract = {We study implicit regularization when optimizing an underdetermined quadratic objective over a matrix {\$}X{\$} with gradient descent on a factorization of {\$}X{\$}. We conjecture and provide empirical and theoretical evidence that with small enough step sizes and initialization close enough to the origin, gradient descent on a full dimensional factorization converges to the minimum nuclear norm solution.},
archivePrefix = {arXiv},
arxivId = {1705.09280},
author = {Gunasekar, Suriya and Woodworth, Blake and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nathan},
eprint = {1705.09280},
file = {:C$\backslash$:/Users/Daniel/Downloads/1705.09280 (1).pdf:pdf},
journal = {arXiv},
pages = {1--10},
title = {{Implicit Regularization in Matrix Factorization}},
url = {http://arxiv.org/abs/1705.09280},
year = {2017}
}
@article{Fusi2005,
abstract = {Storing memories of ongoing, everyday experiences requires a high degree of plasticity, but retaining these memories demands protection against changes induced by further activity and experience. Models in which memories are stored through switch-like transitions in synaptic efficacy are good at storing but bad at retaining memories if these transitions are likely, and they are poor at storage but good at retention if they are unlikely. We construct and study a model in which each synapse has a cascade of states with different levels of plasticity, connected by metaplastic transitions. This cascade model combines high levels of memory storage with long retention times and significantly outperforms alternative models. As a result, we suggest that memory storage requires synapses with multiple states exhibiting dynamics over a wide range of timescales, and we suggest experimental tests of this hypothesis.},
author = {Fusi, Stefano and Drew, Patrick J and Abbott, L F},
doi = {10.1016/j.neuron.2005.02.001},
issn = {0896-6273},
journal = {Neuron},
keywords = {Animals,Humans,Memory,Memory: physiology,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Synapses,Synapses: physiology,Time Factors},
month = {feb},
number = {4},
pages = {599--611},
pmid = {15721245},
title = {{Cascade models of synaptically stored memories.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15721245},
volume = {45},
year = {2005}
}
@article{WoodBlack08,
author = {Wood, F and Black, M},
journal = {Journal of Neuroscience Methods},
pages = {1--12},
title = {{A nonparametric {\{}B{\}}ayesian alternative to spike sorting}},
volume = {173},
year = {2008}
}
@article{Opper2000,
abstract = {We derive a mean-field algorithm for binary classification with gaussian processes that is based on the TAP approach originally proposed in statistical physics of disordered systems. The theory also yields an approximate leave-one-out estimator for the generalization error, which is computed with no extra computational cost. We show that from the TAP approach, it is possible to derive both a simpler "naive" mean-field theory and support vector machines (SVMs) as limiting cases. For both mean-field algorithms and support vector machines, simulation results for three small benchmark data sets are presented. They show that one may get state-of-the-art performance by using the leave-one-out estimator for model selection and the built-in leave-one-out estimators are extremely precise when compared to the exact leave-one-out estimate. The second result is taken as strong support for the internal consistency of the mean-field approach.},
author = {Opper, M and Winther, O},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Animals,Artificial Intelligence,Bayes Theorem,Brachyura,Brachyura: anatomy {\&} histology,Classification,Computer Simulation,Diabetes Mellitus, Type 2,Diabetes Mellitus, Type 2: ethnology,Diabetes Mellitus, Type 2: genetics,Discrimination Learning,Discrimination Learning: physiology,Female,Genetic Predisposition to Disease,Humans,Indians, North American,Indians, North American: genetics,Likelihood Functions,Male,Models, Neurological,Normal Distribution,Sex Characteristics,Sound Spectrography},
month = {nov},
number = {11},
pages = {2655--84},
pmid = {11110131},
title = {{Gaussian processes for classification: mean-field algorithms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11110131},
volume = {12},
year = {2000}
}
@article{MM92,
author = {Miller, M and Mark, K},
journal = {Journal of the Acoustical Society of America},
pages = {202--209},
title = {{A statistical study of cochlear nerve discharge patterns in response to complex speech stimuli}},
volume = {92},
year = {1992}
}
@article{Huang2006,
author = {Huang, Guang-Bin and Zhu, Qin-Yu and Siew, Chee-Kheong},
doi = {10.1016/j.neucom.2005.12.126},
issn = {09252312},
journal = {Neurocomputing},
keywords = {back-propagation algorithm,extreme learning machine,feedforward neural networks,random,real-time learning,support vector machine},
number = {1-3},
pages = {489--501},
title = {{Extreme learning machine: Theory and applications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231206000385},
volume = {70},
year = {2006}
}
@article{Ritchie1979,
author = {Ritchie, J M and Rogart, R B and Stagg, D and Haven, New},
pages = {149--166},
title = {{(Received 25 July 1978)}},
year = {1979}
}
@article{Yeung2010,
annote = {2010IIInum43},
author = {Yeung, Raymond W.},
doi = {10.1007/s11460-010-0103-1},
issn = {1673-3460},
journal = {Frontiers of Electrical and Electronic Engineering in China},
keywords = {cryptography,network coding,network communications,wireless communications},
month = {aug},
number = {3},
pages = {363--390},
title = {{Network coding theory: An introduction}},
url = {http://www.springerlink.com/index/10.1007/s11460-010-0103-1},
volume = {5},
year = {2010}
}
@article{Braunstein2005,
archivePrefix = {arXiv},
arxivId = {arXiv:cs/0212002v4},
author = {Braunstein, A and Mezard, M and Zecchina, R},
eprint = {0212002v4},
journal = {Random Structures {\&} Algorithms},
keywords = {Message passing},
mendeley-tags = {Message passing},
primaryClass = {arXiv:cs},
title = {{Survey propagation: An algorithm for satisfiability}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/rsa.20057/abstract},
year = {2005}
}
@article{FerragamoOertel98,
abstract = {Golgi cells are poised to integrate multimodal influences by participating

in circuits involving granule cells in the cochlear nuclei. To understand

their physiological role, intracellular recordings were made from

anatomically identified Golgi cells in slices of the cochlear nuclei

from mice. Cell bodies, dendrites, and terminals for all seven labeled

cells were restricted to the narrow plane of the superficial granule

cell domain over the ventral cochlear nucleus. The axonal arborization

was the most striking feature of all Golgi cells; a dense plexus

of terminals covered an area 200-400 microm in diameter in the vicinity

of the cell body and dendrites. Axonal beads often surrounded granule

cell bodies, indicating that granule cells are probable targets.

Cells had input resistances up to 130 M omega and fired regular,

overshooting action potentials. Golgi cells probably receive auditory

nerve input, because shocks to the cut end of the auditory nerve

excited Golgi cells with excitatory postsynaptic potentials (EPSPs).

The latency of EPSPs shortened to a minimum and the amplitude of

EPSPs grew in several steps as the strength of shocks was increased.

The minimum latency of EPSPs in Golgi cells was on average 1.3 milliseconds,

0.6 milliseconds longer than the minimum latencies of EPSPs in nearby

octopus and T stellate cells. The long latency raises the possibility

that Golgi cells receive input from slowly conducting, unmyelinated

auditory nerve fibers. Golgi cells are also excited by interneurons

with N-methyl-D-aspartate receptors, probably granule cells, because

repetitive shocks and single shocks in the absence of extracellular

Mg2+ evoked late EPSPs that were reversibly blocked by DL-2-amino-5-phosphono-valeric

acid.},
author = {Ferragamo, M J and Golding, N L and Gardner, S M and Oertel, D},
journal = {J Comp Neurol},
keywords = {Animals; Cochlear Nucleus; Electric Stimulation; E,Inbred CBA; Neural Inhibition; Synapses},
month = {nov},
number = {4},
pages = {519--528},
pmid = {9786412},
title = {{Golgi cells in the superficial granule cell domain overlying the ventral cochlear nucleus: morphology and electrophysiology in slices.}},
volume = {400},
year = {1998}
}
@article{HelmchenSakmann96,
abstract = {The effect of the fluorescent {\{}Ca{\}}{\^{}}{\{}2+{\}} indicator dye Fura-2 on

{\{}Ca{\}}{\^{}}{\{}2+{\}} dynamics was studied in proximal apical dendrites of

neocortical layer V and hippocampal CA1 pyramidal neurons in rat

brain slices using somatic whole-cell recording and a charge-coupled

device camera. A single action potential evoked a transient increase

of intradendritic calcium concentration ([{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i) that

was reduced in size and prolonged when the Fura-2 concentration was

increased from 20 to 250 microM. Extrapolation to zero Fura-2 concentration

suggests that "physiological" transients at 37 degrees C have large

amplitudes (150-300 nM) and fast decays (time constant {\textless} 100 ms).

Assuming a homogeneous compartment model for the dendrite, 0.5-1{\%}

of the total {\{}Ca{\}}{\^{}}{\{}2+{\}} entering during an action potential was

estimated to remain free. Washout of cytoplasmic {\{}Ca{\}}{\^{}}{\{}2+{\}} buffers

was not detectable, suggesting that they are relatively immobile.

During trains of action potentials, [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i increased and

rapidly reached a steady state (time constant {\textless} 200 ms), fluctuating

around a plateau level which depended linearly on the action potential

frequency. Thus, the mean dendritic [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i encodes the

action potential frequency during physiological patterns of electrical

activity and may regulate {\{}Ca{\}}{\^{}}{\{}2+{\}}-dependent dendritic functions

in an activity-dependent way.},
author = {Helmchen, F and Imoto, K and Sakmann, B},
journal = {Biophys J},
keywords = {Action Potentials; Animals; Biophysics; Buffers; C,Neurological; Pyramidal Cells; Rats; Rats,Wistar; Signal Transduction},
month = {feb},
number = {2},
pages = {1069--1081},
pmid = {8789126},
title = {{{\{}Ca{\}}{\^{}}{\{}2+{\}} buffering and action potential-evoked {\{}Ca{\}}{\^{}}{\{}2+{\}} signaling in dendrites of pyramidal neurons.}},
volume = {70},
year = {1996}
}
@article{Meyerson|2005|,
abstract = {We present the Cost-Distance problem: finding a Steiner tree which
optimizes the sum of edge costs along one metric and the sum of source-sink
distances along an unrelated second metric. We give the first known
O(log k) randomized approximation scheme for Cost-Distance, where
k is the number of sources. We reduce many common network design
problems to Cost-Distance, obtaining (in some cases) the first known
logarithmic approximation for them. These problems include single-sink
buy-at-bulk type costs on edges, and maybecast with combine cost
and distance metrics. Our algorithm is also the algorithm of choice
for several previous network design problems, due to its ease of
implementation and fast running time.},
annote = {The paper proposes O(log k) accurate solution of Cost-Distance problem{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}for networks design. An algorithm is presented built using so called{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}tree-metric representation of the network.},
author = {Meyerson, A and Munagala, K and Plotkin, S},
keywords = {buy-at-bulk,computational,continuous networks,cost-distance,network metrics,networks,tree-metrics},
title = {{Cost-Distance: Two Metric Network Design}}
}
@article{Svenkeson2012,
author = {Svenkeson, Adam and Bologna, Mauro and Grigolini, Paolo},
doi = {10.1103/PhysRevE.86.041145},
issn = {1539-3755},
journal = {Physical Review E},
month = {oct},
number = {4},
pages = {1--10},
title = {{Linear response at criticality}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.86.041145},
volume = {86},
year = {2012}
}
@article{TzounopoulosTrussell07,
abstract = {Synapses may undergo long-term increases or decreases in synaptic

strength dependent on critical differences in the timing between

pre-and postsynaptic activity. Such spike-timing-dependent plasticity

(STDP) follows rules that govern how patterns of neural activity

induce changes in synaptic strength. Synaptic plasticity in the dorsal

cochlear nucleus (DCN) follows Hebbian and anti-Hebbian patterns

in a cell-specific manner. Here we show that these opposing responses

to synaptic activity result from differential expression of two signaling

pathways. Ca2+/calmodulin-dependent protein kinase II (CaMKII) signaling

underlies Hebbian postsynaptic LTP in principal cells. By contrast,

in interneurons, a temporally precise anti-Hebbian synaptic spike-timing

rule results from the combined effects of postsynaptic CaMKII-dependent

LTP and endocannabinoid-dependent presynaptic LTD. Cell specificity

in the circuit arises from selective targeting of presynaptic CB1

receptors in different axonal terminals. Hence, pre- and postsynaptic

sites of expression determine both the sign and timing requirements

of long-term plasticity in interneurons.},
author = {Tzounopoulos, Thanos and Rubio, Maria E and Keen, John E and Trussell, Laurence O},
doi = {10.1016/j.neuron.2007.03.026},
journal = {Neuron},
keywords = {Animals; Ca(2+)-Calmodulin Dependent Protein Kinas,CB1; Receptors,Cannabinoid,Electron; Nerve Fibers; Neuronal Plasticity; Rece,Inbred ICR; Microscopy,Presynaptic; Signal Transduction; Synaptic Transm},
month = {apr},
number = {2},
pages = {291--301},
pmid = {17442249},
title = {{Coactivation of pre- and postsynaptic signaling mechanisms determines cell-specific spike-timing-dependent plasticity.}},
url = {http://dx.doi.org/10.1016/j.neuron.2007.03.026},
volume = {54},
year = {2007}
}
@article{Goodhill|2002|,
abstract = {The most prominent feature of the architecture of the cortex is its
horizontal organization into layers. Each layer contains different
cell types, and forms different types of connections with other neurons.
However, a strong vertical organization is often also apparent: neurons
stacked on top of each other through the depth of the cortex tend
to be connected and have similar response properties despite residing
in different layers. This type of vertical structure is called a
cortical column, and has been hypothesized to represent a basic functional
unit for sensory processing or motor output. Columnar organization
has been most extensively studied in the somatosensory and visual
systems.},
author = {Goodhill, G J and Carreira-Perpinan, M A},
keywords = {columnar organization,cortex,cortical column,neurobiology,occular dominance,pinwheel},
title = {{Cortical Columns}}
}
@article{PAN05d,
author = {Paninski, L},
journal = {Neural Computation},
pages = {1480--1507},
title = {{Asymptotic theory of information-theoretic experimental design}},
volume = {17},
year = {2005}
}
@article{ShanerTsien04,
abstract = {Fluorescent proteins are genetically encoded, easily imaged reporters

crucial in biology and biotechnology. When a protein is tagged by

fusion to a fluorescent protein, interactions between fluorescent

proteins can undesirably disturb targeting or function. Unfortunately,

all wild-type yellow-to-red fluorescent proteins reported so far

are obligately tetrameric and often toxic or disruptive. The first

true monomer was mRFP1, derived from the Discosoma sp. fluorescent

protein "DsRed" by directed evolution first to increase the speed

of maturation, then to break each subunit interface while restoring

fluorescence, which cumulatively required 33 substitutions. Although

mRFP1 has already proven widely useful, several properties could

bear improvement and more colors would be welcome. We report the

next generation of monomers. The latest red version matures more

completely, is more tolerant of N-terminal fusions and is over tenfold

more photostable than mRFP1. Three monomers with distinguishable

hues from yellow-orange to red-orange have higher quantum efficiencies.},
author = {Shaner, Nathan C and Campbell, Robert E and Steinbach, Paul A and Giepmans, Ben N G and Palmer, Amy E and Tsien, Roger Y},
doi = {10.1038/nbt1037},
journal = {Nat Biotechnol},
keywords = {Amino Acid Sequence; Amino Acid Substitution; Anim,Fluorescence,Site-Directed; Protein Engineering; Recombinant P},
month = {dec},
number = {12},
pages = {1567--1572},
pmid = {15558047},
title = {{Improved monomeric red, orange and yellow fluorescent proteins derived from Discosoma sp. red fluorescent protein.}},
url = {http://dx.doi.org/10.1038/nbt1037},
volume = {22},
year = {2004}
}
@article{Quirin2014,
author = {Quirin, Sean and Jackson, Jesse and Peterka, Darcy S. and Yuste, R},
doi = {10.3389/fncir.2014.00029},
issn = {1662-5110},
journal = {Frontiers in Neural Circuits},
keywords = {brain,calcium imaging,spatial-light-modulator,three-dimensional imaging,three-dimensional imaging, calcium imaging, volume,volume imaging},
month = {apr},
number = {April},
pages = {1--11},
title = {{Simultaneous imaging of neural activity in three dimensions}},
url = {http://www.frontiersin.org/Neural{\_}Circuits/10.3389/fncir.2014.00029/abstract},
volume = {8},
year = {2014}
}
@article{FRYD98,
author = {Frydman, H},
journal = {Stanford Department of Statistics Technical Reports},
number = {16},
title = {{Conditioned diffusions}},
volume = {1998},
year = {1998}
}
@article{Fukumizu2000,
abstract = {Local minima and plateaus pose a serious problem in learning of neural networks. We investigate the hierarchical geometric structure of the parameter space of three-layer perceptrons in order to show the existence of local minima and plateaus. It is proved that a critical point of the model with H-1 hidden units always gives many critical points of the model with H hidden units. These critical points consist of many lines in the parameter space, which can cause plateaus in learning of neural networks. Based on this result, we prove that a point in the critical lines corresponding to the global minimum of the smaller model can be a local minimum or a saddle point of the larger model. We give a necessary and sufficient condition for this, and show that this kind of local minima exist as a line segment if any. The results are universal in the sense that they do not require special properties of the target, loss functions and activation functions, but only use the hierarchical structure of the model. Copyright (C) 2000 Elsevier Science Ltd.},
author = {Fukumizu, K. and Amari, S.},
doi = {10.1016/S0893-6080(00)00009-5},
issn = {08936080},
journal = {Neural Networks},
keywords = {Error surface,Local minima,Multilayer perceptron,Plateau},
pages = {317--327},
pmid = {10937965},
title = {{Local minima and plateaus in hierarchical structures of multilayer perceptrons}},
volume = {13},
year = {2000}
}
@article{MACLEAN05,
author = {MacLean, J and Watson, B and Aaron, G and Yuste, R},
journal = {Neuron},
pages = {811--823},
title = {{Internal Dynamics Determine the Cortical Response to Thalamic Stimulation}},
volume = {48},
year = {2005}
}
@book{Bishop1995,
author = {Bishop, C M},
publisher = {Oxford},
title = {{Neural networks for pattern recognition}},
url = {http://www.google.com/books?hl=en{\&}lr={\&}id=-aAwQO{\_}-rXwC{\&}oi=fnd{\&}pg=PA1{\&}dq=Neural+Networks+for+Pattern+Recognition{\&}ots=FJNPspEU8m{\&}sig=TJtb2MaO3s3rjv5yMBZq86SBYjs},
year = {1995}
}
@article{Meir2003,
author = {Meir, R and R{\"{a}}tsch, G},
journal = {Advanced lectures on machine learning},
title = {{An introduction to boosting and leveraging}},
url = {http://www.springerlink.com/index/8574X0TM63NVJBEM.pdf},
year = {2003}
}
@inproceedings{NgDearden05,
author = {Brenda, N D and Pfeffer, Avi and Dearden, Richard},
booktitle = {International Joint Conferences on Artificial Intelligence},
title = {{Continuous Time Particle Filtering}},
year = {2005}
}
@article{Holmgren15082003,
abstract = {The extent to which neocortical pyramidal cells function as a local network is determined by the strength and probability of their connections. By mapping connections between pyramidal cells we show here that in a local network of about 600 pyramidal cells located within a cylindrical volume of 200 ?m ? 200 ?m of neocortical layer 2/3, an individual pyramidal cell receives synaptic inputs from about 30 other pyramidal neurons, with the majority of EPSP amplitudes in the 0.2–1.0 mV range. The probability of connection decreased from 0.09 to 0.01 with intercell distance (over the range 25–200 ?m). Within the same volume, local interneuron (fast-spiking non-accomodating interneuron, FS)-pyramidal cell connections were about 10 times more numerous, with the majority of connections being reciprocal. The probability of excitatory and inhibitory connections between pyramidal cells and FS interneurons decreased only slightly with distance, being in the range 0.5–0.75. Pyramidal cells in the local network received strong synaptic input during stimulation of afferent fibres in layers 1 and 6. Minimal-like stimulation of layer 1 or layer 6 inputs simultaneously induced postsynaptic potentials in connected pyramidal cells as well as in pyramidal-FS cell pairs. These inputs readily induced firing of pyramidal cells, although synaptically connected cells displayed different firing patterns. Unitary EPSPs in pyramidal-pyramidal cell pairs did not detectably alter cell firing. FS interneurons fire simultaneously with pyramidal cells. In pyramidal-FS cell pairs, both unitary EPSPs and IPSPs efficiently modulated cell firing patterns. We suggest that computation in the local network may proceed not only by direct pyramidal-pyramidal cell communication but also via local interneurons. With such a high degree of connectivity with surrounding pyramidal cells, local interneurons are ideally poised to both coordinate and expand the local pyramidal cell network via pyramidal-interneuron-pyramidal communication.},
author = {Holmgren, Carl and Harkany, Tibor and Svennenfors, Bj{\"{o}}rn and Zilberter, Yuri},
doi = {10.1113/jphysiol.2003.044784},
journal = {The Journal of Physiology},
number = {1},
pages = {139--153},
title = {{Pyramidal cell communication within local networks in layer 2/3 of rat neocortex}},
url = {http://jp.physoc.org/content/551/1/139.abstract},
volume = {551},
year = {2003}
}
@article{Andersen|1966|,
annote = {Journal Article Sweden},
author = {Andersen, P and Holmqvist, B and Voorhoeve, P E},
journal = {Acta Physiol Scand},
keywords = {Animals Dendrites/*physiology Electric Stimulation},
number = {4},
pages = {461--472},
title = {{Excitatory synapses on hippocampal apical dendrites activated by entorhinal stimulation}},
volume = {66}
}
@article{Davis2006,
abstract = {Homeostasis is a specialized form of regulation that precisely maintains the function of a system at a set point level of activity. Recently, homeostatic signaling has been suggested to control neural activity through the modulation of synaptic efficacy and membrane excitability ( Davis {\&} Goodman 1998a, Turrigiano {\&} Nelson 2000, Marder {\&} Prinz 2002, Perez-Otano {\&} Ehlers 2005 ). In this way, homeostatic signaling is thought to constrain neural plasticity and contribute to the stability of neural function over time. Using a restrictive definition of homeostasis, this review first evaluates the phenomenological and molecular evidence for homeostatic signaling in the nervous system. Then, basic principles underlying the design and molecular implementation of homeostatic signaling are reviewed on the basis of work in other, simplified biological systems such as bacterial chemotaxis and the heat shock response. Data from these systems are then discussed in the context of homeostatic signaling in the nervous system.},
annote = {2010num5.2},
author = {Davis, Graeme W},
doi = {10.1146/annurev.neuro.28.061604.135751},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {Animals,Homeostasis,Homeostasis: physiology,Models,Neural Networks (Computer),Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology},
pages = {307--23},
pmid = {16776588},
title = {{Homeostatic control of neural activity: from phenomenology to molecular design.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16776588},
volume = {29},
year = {2006}
}
@article{KunschIonChannels01,
author = {de Gunst, M and Kunsch, M and Schouten, J},
journal = {JASA},
pages = {805--815},
title = {{Statistical Analysis of Ion Channel Data Using {\{}Hidden Markov Models{\}} With Correlated State-Dependent Noise and Filtering}},
volume = {96},
year = {2001}
}
@article{PAR02,
author = {Moreno, R and de la Rocha, J and Renart, A and Parga, N},
journal = {Physical Review Letters},
pages = {288101},
title = {{Response of spiking neurons to correlated inputs}},
volume = {89},
year = {2002}
}
@article{Macke|2008|,
abstract = {A new technique, {\"{i}}¾”Serial Block Face Scanning Electron Microscopy{\"{i}}¾”
(SBFSEM), allows for automatic sectioning and imaging of biological
tissue with a scanning electron microscope. Image stacks generated
with this technology have a resolution sufficient to distinguish
different cellular compartments, including synaptic structures, which
should make it possible to obtain detailed anatomical knowledge of
complete neuronal circuits. Such an image stack contains several
thousands of images and is recorded with a minimal voxel size of
10-20nm in the x and y- and 30nm in z-direction. Consequently, a
tissue block of 1mm3 17 (the approximate volume of the Calliphora
vicina brain) will produce several hundred terabytes of data. Therefore,
highly automated 3D reconstruction algorithms are needed. As a first
step in this direction we have developed semiautomated segmentation
algorithms for a precise contour tracing of cell membranes. These
algorithms were embedded into an easy-to-operate user interface,
which allows direct 3D observation of the extracted objects during
the segmentation of image stacks. Compared to purely manual tracing,
processing time is greatly accelerated.},
annote = {Paper deals with automation of 3D reconstructions. Uses grayscale
clustering assuming gaussian classes either with intensity changing
linearly with distance from boundary, or two constant levels + guided
via gaussian penalty for deviations from segmentation contours in
the preceding slices.},
author = {Macke, Jakob H and Maack, Nina and Gupta, Rocky and Denk, W and Scholkopf, Bernhard and Borst, Alexander},
journal = {Journal of Neuroscience Methods},
keywords = {clustering,computational,electron microscopy,gaussian classes,image processing,neurobiology,segmentation},
pages = {349--357},
title = {{Contour-propagation algorithms for semi-automated reconstruction of neural processes.}},
volume = {167}
}
@article{Martens2012,
author = {Martens, James and Sutskever, Ilya},
journal = {Neural Networks: Tricks of the Trade},
pages = {479--535},
title = {{Training deep and recurrent networks with Hessian-free optimization}},
url = {http://www.springerlink.com/index/14428JM838700060.pdf},
year = {2012}
}
@article{Druckmann2011,
abstract = {The rich dynamical nature of neurons poses major conceptual and technical challenges for unraveling their nonlinear membrane properties. Traditionally, various current waveforms have been injected at the soma to probe neuron dynamics, but the rationale for selecting specific stimuli has never been rigorously justified. The present experimental and theoretical study proposes a novel framework, inspired by learning theory, for objectively selecting the stimuli that best unravel the neuron's dynamics. The efficacy of stimuli is assessed in terms of their ability to constrain the parameter space of biophysically detailed conductance-based models that faithfully replicate the neuron's dynamics as attested by their ability to generalize well to the neuron's response to novel experimental stimuli. We used this framework to evaluate a variety of stimuli in different types of cortical neurons, ages and animals. Despite their simplicity, a set of stimuli consisting of step and ramp current pulses outperforms synaptic-like noisy stimuli in revealing the dynamics of these neurons. The general framework that we propose paves a new way for defining, evaluating and standardizing effective electrical probing of neurons and will thus lay the foundation for a much deeper understanding of the electrical nature of these highly sophisticated and non-linear devices and of the neuronal networks that they compose.},
author = {Druckmann, S and Berger, T K and Sch{\"{u}}rmann, F and Hill, S and Markram, H and Segev, I},
doi = {10.1371/journal.pcbi.1002133},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Computational Biology,Computational Biology: methods,Electric Conductivity,Electrophysiology,Electrophysiology: methods,Interneurons,Interneurons: physiology,Mice,Models,Neurological,Neurons,Neurons: physiology,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Wistar},
month = {aug},
number = {8},
pages = {e1002133},
pmid = {21876663},
title = {{Effective stimuli for constructing reliable neuron models.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3158041{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2011}
}
@article{Dolmetsch1998,
author = {Dolmetsch, R E and Keli, X and Lewis, R S},
journal = {Nature},
number = {April},
pages = {933--936},
title = {{Calcium oscillations increase the efficiency and specificity of gene expression}},
url = {http://jaguar.biologie.hu-berlin.de/{~}wolfram/pages/Seminar{\_}Regulationsnetze/literatur/Dolmetsch{\_}Calcium{\_}1998{\_}Nature.pdf},
volume = {392},
year = {1998}
}
@misc{chfibrebundles,
keywords = {fiber bundles,mathematics},
pages = {This note deals with theory of fiber bundles.},
title = {{Fibre Bundles}}
}
@article{TayYue07,
abstract = {Genetically encoded Ca(2+) sensors promise sustained in vivo detection

of Ca(2+) signals. However, these sensors are sometimes challenged

by inconsistent performance and slow/uncertain kinetic responsiveness.

The former challenge may arise because most sensors employ calmodulin

(CaM) as the Ca(2+)-sensing module, such that interference via endogenous

CaM may result. One class of sensors that could minimize this concern

utilizes troponin C as the Ca(2+) sensor. Here, we therefore probed

the reliability and kinetics of one representative of this class

(CFP/YFP-FRET sensor TN-L15) within cardiac ventricular myocytes.

These cells furnished a pertinent live-cell test environment, given

substantial endogenous CaM levels and fast reproducible Ca(2+) transients

for testing sensor kinetics. TN-L15 was virally expressed within

myocytes, and Indo-1 acutely loaded to monitor 'true' Ca(2+) transients.

This configuration permitted independent and simultaneous detection

of TN-L15 and Indo 1 signals within individual cells. The relation

between TN-L15 FRET responses and Indo-1 Ca(2+) transients appeared

reproducible, though FRET signals were delayed compared to Ca(2+)

transients. Nonetheless, a three state mechanism sufficed to map

between measured Ca(2+) transients and actual TN-L15 outputs. Overall,

reproducibility of TN-L15 dynamics, coupled with algorithmic transforms

between FRET and Ca(2+) signals, renders these sensors promising

for quantitative estimation of Ca(2+) dynamics in vivo.},
author = {Tay, Lai Hock and Griesbeck, Oliver and Yue, David T},
doi = {10.1529/biophysj.107.109629},
journal = {Biophys J},
month = {aug},
pmid = {17704158},
title = {{Live-Cell Transforms between Ca{\^{}}{\{}2+{\}} Transients and FRET Responses for a Troponin-C-Based Ca{\^{}}{\{}2+{\}} Sensor.}},
url = {http://dx.doi.org/10.1529/biophysj.107.109629},
year = {2007}
}
@article{Uzzel|2004|,
abstract = {Precision of spike trains in primate retinal ganglion cells. J Neurophysiol
92: 780{\^{A}}–789, 2004; 10.1152/jn.01171.2003. Recent studies have revealed
striking precision in the spike trains of retinal ganglion cells
in several species and suggested that this precision could be an
important aspect of visual signaling. However, the precision of spike
trains has not yet been described in primate retina. The spike time
and count variability of parasol (magnocellular-projecting) retinal
ganglion cells was examined in isolated macaque monkey retinas stimulated
with repeated presentations of high contrast, spatially uniform intensity
modulation. At the onset of clearly delineated periods of firing,
retinal ganglion cells fired spikes time-locked to the stimulus with
a variability across trials as low as 1 ms. Spike count variance
across trials was much lower than the mean and sometimes approached
the minimum variance possible with discrete counts, inconsistent
with Poisson statistics expected from independently generated spikes.
Spike time and count variability decreased systematically with stimulus
strength. These findings were consistent with a model in which firing
probability was determined by a stimulus-driven free firing rate
modulated by a recovery function representing the action potential
absolute and relative refractory period.},
annote = {

This paper describes multielectrode recordings from about 60 cells
in retina, used to analyze correlation between ganglion cells as
function of distance. Then used by Paninski to test his GLM-IF model
for neuron.},
author = {Uzzel, V J and Chichilnisky, E J and Uzzell, V},
journal = {Journal of Neurophysiology},
keywords = {correlation,ganglion cells,multielectrode,neurobiology,receptive field,recordings,retina,spike sorting},
pages = {780--789},
title = {{Precision of spike trains in primate retinal ganglion cells}},
volume = {92},
year = {2004}
}
@article{Mitter2002,
annote = {2011num10},
author = {Mitter, SK},
journal = {Control Applications, 2002. Proceedings of the  {\ldots}},
title = {{System science: The convergence of communication, computation and control}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1040148},
year = {2002}
}
@article{Zipser92,
author = {Zipser, D},
journal = {Neuroscience},
number = {4},
pages = {853--862},
title = {{Identification models of the nervous system}},
volume = {47},
year = {1992}
}
@article{de2008conduction,
abstract = {Axonal conduction velocity varies according to the level of preceding impulse activity. In unmyelinated axons this typically results in a slowing of conduction velocity and a parallel increase in threshold. It is currently held that Na(+)-K(+)-ATPase-dependent axonal hyperpolarization is responsible for this slowing but this has long been equivocal. We therefore examined conduction velocity changes during repetitive activation of single unmyelinated axons innervating the rat cranial meninges. In direct contradiction to the currently accepted postulate, Na(+)-K(+)-ATPase blockade actually enhanced activity-induced conduction velocity slowing, while the degree of velocity slowing was curtailed in the presence of lidocaine (10-300 microm) and carbamazepine (30-500 microm) but not tetrodotoxin (TTX, 10-80 nm). This suggests that a change in the number of available sodium channels is the most prominent factor responsible for activity-induced changes in conduction velocity in unmyelinated axons. At moderate stimulus frequencies, axonal conduction velocity is determined by an interaction between residual sodium channel inactivation following each impulse and the retrieval of channels from inactivation by a concomitant Na(+)-K(+)-ATPase-mediated hyperpolarization. Since the process is primarily dependent upon sodium channel availability, tracking conduction velocity provides a means of accessing relative changes in the excitability of nociceptive neurons.},
annote = {2010IInum12.11},
author = {{De Col}, Roberto and Messlinger, Karl and Carr, Richard W},
doi = {10.1113/jphysiol.2007.145383},
issn = {1469-7793},
journal = {The Journal of Physiology},
keywords = {Afferent,Afferent: metabolism,Animals,Carbamazepine,Carbamazepine: pharmacology,Cyanides,Cyanides: pharmacology,Enzyme Inhibitors,Enzyme Inhibitors: pharmacology,Female,Lidocaine,Lidocaine: pharmacology,Lithium,Lithium: metabolism,Male,Meninges,Meninges: cytology,Meninges: metabolism,Nerve Fibers,Neural Conduction,Neural Conduction: physiology,Neurons,Ouabain,Ouabain: pharmacology,Potassium,Potassium: metabolism,Rats,Sodium,Sodium Channels,Sodium Channels: drug effects,Sodium Channels: metabolism,Sodium-Potassium-Exchanging ATPase,Sodium-Potassium-Exchanging ATPase: metabolism,Sodium: metabolism,Synaptic Transmission,Synaptic Transmission: physiology,Tetrodotoxin,Tetrodotoxin: pharmacology,Unmyelinated,Unmyelinated: metabolism,Wistar},
month = {feb},
number = {4},
pages = {1089--1103},
pmid = {18096592},
publisher = {Physiological Soc},
title = {{Conduction velocity is regulated by sodium channel inactivation in unmyelinated axons innervating the rat cranial meninges}},
url = {http://jp.physoc.org/content/586/4/1089.short http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2375633{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {586},
year = {2008}
}
@article{Diba2004,
abstract = {Ion channels open and close stochastically. The fluctuation of these channels represents an intrinsic source of noise that affects the input-output properties of the neuron. We combined whole-cell measurements with biophysical modeling to characterize the intrinsic stochastic and electrical properties of single neurons as observed at the soma. We measured current and voltage noise in 18 d postembryonic cultured neurons from the rat hippocampus, at various subthreshold and near-threshold holding potentials in the presence of synaptic blockers. The observed current noise increased with depolarization, as ion channels were activated, and its spectrum demonstrated generalized 1/f behavior. Exposure to TTX removed a significant contribution from Na+ channels to the noise spectrum, particularly at depolarized potentials, and the resulting spectrum was now dominated by a single Lorentzian (1/f2) component. By replacing the intracellular K+ with Cs+, we demonstrated that a major portion of the observed noise was attributable to K+ channels. We compared the measured power spectral densities to a 1-D cable model of channel fluctuations based on Markov kinetics. We found that a somatic compartment, in combination with a single equivalent cylinder, described the effective geometry from the viewpoint of the soma. Four distinct channel populations were distributed in the membrane and modeled as Lorentzian current noise sources. Using the NEURON simulation program, we summed up the contributions from the spatially distributed current noise sources and calculated the total voltage and current noise. Our quantitative model reproduces important voltage- and frequency-dependent features of the data, accounting for the 1/f behavior, as well as the effects of various blockers.},
author = {Diba, K and Lester, H A and Koch, C},
doi = {10.1523/JNEUROSCI.1721-04.2004},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Cells,Computer-Assisted,Cultured,Electric Impedance,Electrophysiology,Fourier Analysis,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Ion Channels,Ion Channels: physiology,Markov Chains,Models,Neurological,Neurons,Neurons: physiology,Patch-Clamp Techniques,Picrotoxin,Picrotoxin: pharmacology,Quinoxalines,Quinoxalines: pharmacology,Rats,Signal Processing,Synapses,Synapses: drug effects,Synapses: physiology,Wistar},
month = {oct},
number = {43},
pages = {9723--33},
pmid = {15509761},
title = {{Intrinsic noise in cultured hippocampal neurons: experiment and modeling.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15509761},
volume = {24},
year = {2004}
}
@article{Gireesh2008,
abstract = {Maturation of the cerebral cortex involves the spontaneous emergence of distinct patterns of neuronal synchronization, which regulate neuronal differentiation, synapse formation, and serve as a substrate for information processing. The intrinsic activity patterns that characterize the maturation of cortical layer 2/3 are poorly understood. By using microelectrode array recordings in vivo and in vitro, we show that this development is marked by the emergence of nested - and beta/gamma-oscillations that require NMDA- and GABA(A)-mediated synaptic transmission. The oscillations organized as neuronal avalanches, i.e., they were synchronized across cortical sites forming diverse and millisecond-precise spatiotemporal patterns that distributed in sizes according to a power law with a slope of -1.5. The correspondence between nested oscillations and neuronal avalanches required activation of the dopamine D(1) receptor. We suggest that the repetitive formation of neuronal avalanches provides an intrinsic template for the selective linking of external inputs to developing superficial layers.},
author = {Gireesh, Elakkat D and Plenz, D},
doi = {10.1073/pnas.0800537105},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Animals,Cell Differentiation,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: growth {\&} development,Dopamine,Dopamine: physiology,GABA-A Receptor Agonists,Microelectrodes,Neurons,Neurons: cytology,Neurons: physiology,Rats,Receptors, Dopamine D1,Receptors, Dopamine D1: agonists,Receptors, N-Methyl-D-Aspartate,Receptors, N-Methyl-D-Aspartate: agonists,Synaptic Transmission},
month = {may},
number = {21},
pages = {7576--81},
pmid = {18499802},
title = {{Neuronal avalanches organize as nested theta- and beta/gamma-oscillations during development of cortical layer 2/3.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2396689{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {105},
year = {2008}
}
@article{Ns1957,
author = {Ns, I T S Applicati},
number = {x},
title = {, (1.1)},
volume = {1957},
year = {1957}
}
@article{izhikevich2007solving,
annote = {2008num21},
author = {Izhikevich, E M},
journal = {Cerebral Cortex},
publisher = {Oxford Univ Press},
title = {{Solving the distal reward problem through linkage of STDP and dopamine signaling}},
year = {2007}
}
@inproceedings{Park2011,
author = {Park, I M and Pillow, J W},
booktitle = {Neural Information Processing Systems},
pages = {1--9},
title = {{Bayesian Spike-Triggered Covariance Analysis}},
year = {2011}
}
@article{Wickersham07b,
author = {Wickersham, I and Finke, S and Conzelmann, K.-K. and Callaway, E},
journal = {Nature Methods},
pages = {47--49},
title = {{Retrograde neuronal tracing with a deletion-mutant rabies virus}},
volume = {4},
year = {2007}
}
@article{Vandenberg1984,
abstract = {Recordings of the sodium current in tissue-cultured GH3 cells show that the rate of inactivation in whole cell and averaged single channel records is voltage dependent: tau h varied e-fold/approximately 26 mV. The source of this voltage dependence was investigated by examining the voltage dependence of individual rate constants, estimated by maximum likelihood analysis of single channel records, in a five-state kinetic model. The rate constant for inactivating from the open state, rather than closing, increased with depolarization, as did the probability that an open channel inactivates. The rate constant for closing from the open state had the opposite voltage dependence. Both rate constants contributed to the mean open time, which was not very voltage dependent. Both open time and burst duration were less than tau h for voltages up to -20 mV. The slowest time constant of activation, tau m, was measured from whole cell records, by fitting a single exponential either to tail currents or to activating currents in trypsin-treated cells, in which the inactivation was abolished. tau m was a bell-shaped function of voltage and had a voltage dependence similar to tau h at voltages more positive than -35 mV, but was smaller than tau h. At potentials more negative than about -10 mV, individual channels may open and close several times before inactivating. Therefore, averaged single channel records, which correspond with macroscopic current elicited by a depolarization, are best described by a convolution of the first latency density with the autocorrelation function rather than with 1 - (channel open time distribution). The voltage dependence of inactivation from the open state, in addition to that of the activation process, is a significant factor in determining the voltage dependence of macroscopic inactivation. Although the rates of activation and inactivation overlapped greatly, independent and coupled inactivation could not be statistically distinguished for two models examined. Although rates of activation affect the observed rate of inactivation at intermediate voltages, extrapolation of our estimates of rate constants suggests that at very depolarized voltages the activation process is so fast that it is an insignificant factor in the time course of inactivation. Prediction of gating currents shows that an inherently voltage-dependent inactivation process need not produce a conspicuous component in the gating current.},
author = {Vandenberg, C. A.},
doi = {10.1085/jgp.84.4.535},
issn = {0022-1295},
journal = {The Journal of General Physiology},
month = {oct},
number = {4},
pages = {535--564},
pmid = {6094704},
title = {{Inactivation viewed through single sodium channels}},
url = {http://jgp.rupress.org/cgi/content/abstract/84/4/535},
volume = {84},
year = {1984}
}
@article{Graham2011,
abstract = {The computer metaphor has served brain science well as a tool for comprehending neural systems. Nevertheless, we propose here that this metaphor be replaced or supplemented by a new metaphor, the "Internet metaphor," to reflect dramatic new network theoretic understandings of brain structure and function. We offer a "weak" form and a "strong" form of this metaphor: The former suggests that structures and processes unique to Internet-like architectures (e.g., domains and protocols) can profitably guide our thinking about brains, whereas the latter suggests that one particular feature of the Internet-packet switching-may be instantiated in the structure of certain brain networks, particularly mammalian neocortex.},
annote = {2011num25},
author = {Graham, Daniel and Rockmore, Daniel},
doi = {10.1162/jocn.2010.21477},
issn = {1530-8898},
journal = {Journal of cognitive neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Internet,Metaphor,Models, Neurological,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology},
month = {feb},
number = {2},
pages = {267--76},
pmid = {20350173},
title = {{The packet switching brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20350173},
volume = {23},
year = {2011}
}
@article{Touboul2007,
abstract = {We discuss the statistics of spikes trains for different types of integrate-and-fire neurons and different types of synaptic noise models. In contrast with the usual approaches in neuroscience, mainly based on statistical physics methods such as the Fokker-Planck equation or the mean-field theory, we chose the point of the view of the stochastic calculus theory to characterize neurons in noisy environments. We present four stochastic calculus techniques that can be used to find the probability distributions attached to the spikes trains. We illustrate the power of these techniques for four types of widely used neuron models. Despite the fact that these techniques are mathematically intricate we believe that they can be useful for answering questions in neuroscience that naturally arise from the variability of neuronal activity. For each technique we indicate its range of applicability and its limitations.},
annote = {2010num1.9},
author = {Touboul, J and Faugeras, O},
doi = {10.1016/j.jphysparis.2007.10.008},
issn = {0928-4257},
journal = {Journal of physiology, Paris},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Humans,Models,Neurons,Neurons: physiology,Statistical,Stochastic Processes,Synapses,Synapses: physiology,Theoretical},
number = {1-3},
pages = {78--98},
pmid = {18054210},
title = {{The spikes trains probability distributions: a stochastic calculus approach.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18054210},
volume = {101},
year = {2007}
}
@article{CSKS06,
author = {Cronin, B and Schummers, J and Koerding, K and Sur, M},
journal = {SFN Abstracts},
title = {{Bayesian sampling methods for the analysis of reverse correlation data}},
year = {2006}
}
@book{robinson2003time,
abstract = {Long memory processes constitute a broad class of models for stationary and nonstationary time series data in economics, finance, and other fields. Their key feature is persistence, with high correlation between events that are remote in time. A single 'memory' parameter economically indexesthis persistence, as part of a rich parametric or nonparametric structure for the process. Unit root processes can be covered, along with processes that are stationary but with stronger persistence than autoregressive moving averages, these latter being included in a broader class which describesboth short memory and negative memory. Long memory processes have in recent years attracted considerable interest from both theoretical and empirical researchers in time series and econometrics.This book of readings collects articles on a variety of topics in long memory time series including modelling and statistical inference for stationary processes, stochastic volatility models, nonstationary processes, and regression and fractional cointegration models. Some of the articles are highlytheoretical, others contain a mix of theory and methods, and an effort has been made to include empirical applications of the main approaches covered. A review article introduces the other articles but also attempts a broader survey, traces the history of the subject, and includes a bibliography.},
address = {New York},
author = {Robinson, P M},
publisher = {Oxford Univ Pr},
title = {{Time series with long memory}},
url = {http://www.google.com/books?hl=iw{\&}lr={\&}id=w8HPcMJsk-cC{\&}oi=fnd{\&}pg=PA1{\&}dq=Time+series+with+long+memory+{\&}ots=nPmoACk5Ip{\&}sig=g9sa-EdSwNCBA3a{\_}52KXf4Qet-Y},
year = {2003}
}
@article{Hyvarinen2006,
abstract = {One often wants to estimate statisticalmodels where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlomethods, or approximations of the normalization constant. Here,we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very difficult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simplifies to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete filter set for natural image data.},
author = {Hyv{\"{a}}rinen, Aapo},
doi = {10.1.1.109.4126},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {contrastive divergence,markov chain,monte carlo,non-normalized densities,pseudo-likelihood,statistical estimation},
pages = {695--708},
title = {{Estimation of non-normalized statistical models by score matching}},
url = {http://jmlr.csail.mit.edu/papers/volume6/hyvarinen05a/old.pdf},
volume = {6},
year = {2006}
}
@article{Mikula2003,
author = {Mikula, Shawn},
pages = {2339--2358},
title = {{Synaptic Depression Leads to Nonmonotonic Frequency}},
volume = {2358},
year = {2003}
}
@article{jones2006rate,
annote = {2009num12},
author = {Jones, S W},
journal = {The Journal of Physiology},
number = {3},
pages = {502},
publisher = {Physiological Soc},
title = {{Are rate constants constant?}},
volume = {571},
year = {2006}
}
@article{Lu2002,
author = {Lu, C and Shi, BX and Chen, L},
journal = {Analog Integrated Circuits and Signal Processing},
keywords = {circuit design,hardware implementation,neural network,on-chip bp learning},
number = {1},
pages = {55--62},
title = {{An on-chip BP learning neural network with ideal neuron characteristics and learning rate adaptation}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=860751 http://link.springer.com/article/10.1023/A:1014476806076},
volume = {31},
year = {2002}
}
@article{PB68,
author = {Perkel, D and Bullock, T},
journal = {Neurosciences Research Program Bulletin},
pages = {221--348},
title = {{Neural coding}},
volume = {6},
year = {1968}
}
@book{JORD99,
address = {Cambridge, MA, USA},
editor = {Jordan, Michael I},
publisher = {MIT Press},
title = {{Learning in graphical models}},
year = {1999}
}
@article{DV99,
author = {Darbellay, G and Vajda, I},
journal = {IEEE Transactions on Information Theory},
pages = {1315--1321},
title = {{Estimation of the information by an adaptive partitioning of the observation space}},
volume = {45},
year = {1999}
}
@article{Boucsein05,
author = {Boucsein, Clemens and Nawrot, Martin and Rotter, Stefan and Aertsen, Ad and Heck, Detlef},
journal = {Journal of Neurophysiology},
month = {oct},
number = {4},
pages = {2948--2958},
title = {{Controlling synaptic input patterns in vitro by dynamic photo stimulation}},
volume = {94},
year = {2005}
}
@article{BLY02,
author = {Blythe, J},
journal = {AAAI02},
title = {{Visual Exploration and Incremental Utility Elicitation}},
year = {2002}
}
@book{ermentrout2010mathematical,
address = {New York},
author = {Ermentrout, B and Terman, D},
publisher = {Springer Verlag},
title = {{Mathematical Foundations of Neuroscience}},
url = {http://www.citeulike.org/user/NitinCR/article/7686319 http://books.google.com/books?hl=en{\&}lr={\&}id=ZkWiVu{\_}OXgIC{\&}oi=fnd{\&}pg=PR5{\&}dq=Mathematical+Foundations+of+Neuroscience{\&}ots=cizsqkYdnF{\&}sig=rHkSnUGoRDDai0Pelj-Qtqv-yIs},
volume = {35},
year = {2010}
}
@book{kilbas2006theory,
author = {Kilbas, A A and Srivastava, H M and Trujillo, J J},
publisher = {Elsevier Science Ltd},
title = {{Theory and Applications of fractional differential equations}},
year = {2006}
}
@article{CuiChu07,
abstract = {Retrograde axonal transport of nerve growth factor (NGF) signals is

critical for the survival, differentiation, and maintenance of peripheral

sympathetic and sensory neurons and basal forebrain cholinergic neurons.

However, the mechanisms by which the NGF signal is propagated from

the axon terminal to the cell body are yet to be fully elucidated.

To gain insight into the mechanisms, we used quantum dot-labeled

NGF (QD-NGF) to track the movement of NGF in real time in compartmentalized

culture of rat dorsal root ganglion (DRG) neurons. Our studies showed

that active transport of NGF within the axons was characterized by

rapid, unidirectional movements interrupted by frequent pauses. Almost

all movements were retrograde, but short-distance anterograde movements

were occasionally observed. Surprisingly, quantitative analysis at

the single molecule level demonstrated that the majority of NGF-containing

endosomes contained only a single NGF dimer. Electron microscopic

analysis of axonal vesicles carrying QD-NGF confirmed this finding.

The majority of QD-NGF was found to localize in vesicles 50-150 nm

in diameter with a single lumen and no visible intralumenal membranous

components. Our findings point to the possibility that a single NGF

dimer is sufficient to sustain signaling during retrograde axonal

transport to the cell body.},
author = {Cui, Bianxiao and Wu, Chengbiao and Chen, Liang and Ramirez, Alfredo and Bearer, Elaine L and Li, Wei-Ping and Mobley, William C and Chu, Steven},
doi = {10.1073/pnas.0706192104},
journal = {Proc Natl Acad Sci U S A},
month = {aug},
number = {34},
pages = {13666--13671},
pmid = {17698956},
title = {{One at a time, live tracking of NGF axonal transport using quantum dots.}},
url = {http://dx.doi.org/10.1073/pnas.0706192104},
volume = {104},
year = {2007}
}
@article{Lewi08b,
author = {Lewi, J and Butera, R and Paninski, L},
journal = {NIPS},
title = {{Designing neurophysiology experiments to optimally constrain receptive field models along parametric submanifolds}},
year = {2008}
}
@article{Kirov|1999|a,
author = {Kirov, S A and Harris, K M},
journal = {Nat Neurosci},
number = {10},
pages = {878--883},
title = {{Dendrites are more spiny on mature hippocampal neurons when synapses are inactivated.}},
volume = {2}
}
@article{RamdyaEngert06,
author = {Ramdya, Pavan and Reiter, Bettina and Engert, Florian},
journal = {Journal of Neuroscience Methods},
month = {oct},
number = {2},
pages = {230--237},
title = {{Reverse correlation of rapid calcium signals in the zebrafish optic tectum in vivo}},
volume = {157},
year = {2006}
}
@article{KWO04,
author = {Kanev, J and Wenning, G and Obermayer, K},
journal = {Neurocomputing},
pages = {47--52},
title = {{Approximating the response-stimulus correlation for the integrate-and-fire neuron}},
volume = {58},
year = {2004}
}
@article{Goldwyn2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1201.5428v1},
author = {Goldwyn, J H and Rubinstein, J T and Shea-Brown, E},
eprint = {arXiv:1201.5428v1},
journal = {Journal of Neurophysiology},
number = {5},
pages = {1430--1452},
title = {{A point process framework for modeling electrical stimulation of the auditory nerve}},
url = {http://arxiv.org/abs/1201.5428},
volume = {108},
year = {2012}
}
@article{Nessler2013,
abstract = {The principles by which networks of neurons compute, and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function, are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits, where pyramidal neurons inhibit each other via interneurons, are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact, a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability, since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex.},
author = {Nessler, Bernhard and Pfeiffer, Michael and Buesing, Lars and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1003037},
issn = {1553-7358},
journal = {PLoS computational biology},
month = {apr},
number = {4},
pages = {e1003037},
pmid = {23633941},
title = {{Bayesian Computation Emerges in Generic Cortical Microcircuits through Spike-Timing-Dependent Plasticity.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3636028{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2013}
}
@article{Kaplan1996,
author = {Kaplan, D T and Clay, J R and Manning, T and Glass, L and Guevara, M R and Shrier, A},
issn = {1079-7114},
journal = {Physical Review Letters},
month = {may},
number = {21},
pages = {4074--4077},
pmid = {10061185},
title = {{Subthreshold dynamics in periodically stimulated squid giant axons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10061185},
volume = {76},
year = {1996}
}
@article{Gorenflo2008,
abstract = {We introduce the linear operators of fractional integration and fractional differentiation in the framework of the Riemann-Liouville fractional calculus. Particular attention is devoted to the technique of Laplace transforms for treating these operators in a way accessible to applied scientists, avoiding unproductive generalities and excessive mathematical rigor. By applying this technique we shall derive the analytical solutions of the most simple linear integral and differential equations of fractional order. We show the fundamental role of the Mittag-Leffler function, whose properties are reported in an ad hoc Appendix. The topics discussed here will be: (a) essentials of Riemann-Liouville fractional calculus with basic formulas of Laplace transforms, (b) Abel type integral equations of first and second kind, (c) relaxation and oscillation type differential equations of fractional order.},
archivePrefix = {arXiv},
arxivId = {0805.3823},
author = {Gorenflo, Rudolf and Mainardi, Francesco},
eprint = {0805.3823},
journal = {Physics},
keywords = {Complex Variables,Fractional Calculus,History and Overview,Mathematical Physics,Statistical Mechanics},
mendeley-tags = {Fractional Calculus},
number = {378},
pages = {56},
title = {{Fractional Calculus: Integral and Differential Equations of Fractional Order}},
url = {http://arxiv.org/abs/0805.3823},
year = {2008}
}
@article{Gregor,
abstract = {We introduce a simple recurrent variational auto-encoder architecture that significantly improves image modeling. The system represents the state-of-the-art in latent variable models for both the ImageNet and Omniglot datasets. We show that it naturally separates global conceptual information from lower level details, thus addressing one of the fundamentally desired properties of unsupervised learning. Furthermore, the possibility of restricting ourselves to storing only global information about an image allows us to achieve high quality 'conceptual compression'.},
archivePrefix = {arXiv},
arxivId = {1604.08772},
author = {Gregor, Karol and Besse, Frederic and Rezende, Danilo Jimenez and Danihelka, Ivo and Wierstra, Daan},
eprint = {1604.08772},
journal = {Arxiv},
pages = {14},
title = {{Towards Conceptual Compression}},
url = {http://arxiv.org/abs/1604.08772},
year = {2016}
}
@article{WeinbergRustioni87,
author = {Weinberg, R J and Rustioni, A},
journal = {Neuroscience},
month = {jan},
number = {1},
pages = {209--219},
title = {{A cuneocochlear pathway in the rat}},
volume = {20},
year = {1987}
}
@article{Nagel2011,
abstract = {The responses of olfactory receptor neurons (ORNs) to odors have complex dynamics. Using genetics and pharmacology, we found that these dynamics in Drosophila ORNs could be separated into sequential steps, corresponding to transduction and spike generation. Each of these steps contributed distinct dynamics. Transduction dynamics could be largely explained by a simple kinetic model of ligand-receptor interactions, together with an adaptive feedback mechanism that slows transduction onset. Spiking dynamics were well described by a differentiating linear filter that was stereotyped across odors and cells. Genetic knock-down of sodium channels reshaped this filter, implying that it arises from the regulated balance of intrinsic conductances in ORNs. Complex responses can be understood as a consequence of how the stereotyped spike filter interacts with odor- and receptor-specific transduction dynamics. However, in the presence of rapidly fluctuating natural stimuli, spiking simply increases the speed and sensitivity of encoding.},
author = {Nagel, Katherine I and Wilson, Rachel I},
doi = {10.1038/nn.2725},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Drosophila,Electrophysiology,Odors,Olfactory Receptor Neurons,Olfactory Receptor Neurons: physiology,Signal Transduction,Signal Transduction: physiology,Smell,Smell: physiology},
month = {feb},
number = {2},
pages = {208--16},
pmid = {21217763},
publisher = {Nature Publishing Group},
title = {{Biophysical mechanisms underlying olfactory receptor neuron dynamics.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3030680{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2011}
}
@book{Webvision95,
author = {Kolb, H and Fernandez, E and Nelson, R},
title = {{Visual Acuity - Webvision: The Organization of the Retina and Visual System}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21413375},
year = {1995}
}
@article{Vaas|2003|,
abstract = {Lens distortion is often an issue in post production houses when combining
footage taken with different cameras or integrating computer graphics
into live action plates. While this error of the imaging process
has been studied thoroughly for many years in the field of computer
vision, almost none of the existing tools have all the key features
users need. Some algorithms work well for any kind of distortion
but are hard to calibrate, while others are fully automatic but fail
for fisheye or anamorphic lenses. In this paper the different approaches
of removing lens distortion are summarized, and a semi-automatic
system is introduced that fits the need of post production facilities.},
annote = {This is a good paper discussing mathematical approaches to removing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}lens distortion using post-image processing},
author = {Vaas, G and Perlaki, T},
keywords = {algorithmic,compensation,lens distortion,mathematics,physics,removing},
title = {{Applying and removing lens distortion in post production}}
}
@article{Ratcliff|2004|,
abstract = {The diffusion model for 2-choice decisions (R. Ratcliff, 1978) was
applied to data from lexical decision experiments in which word frequency,
proportion of high- versus low-frequency words, and type of nonword
were manipulated. The model gave a good account of all of the dependent
variables{\^{A}}—accuracy, correct and error response times, and their
distributions{\^{A}}—and provided a description of how the component processes
involved in the lexical decision task were affected by experimental
variables. All of the variables investigated affected the rate at
which information was accumulated from the stimuli{\^{A}}— called drift
rate in the model. The different drift rates observed for the various
classes of stimuli can all be explained by a 2-dimensional signal-detection
representation of stimulus information. The authors discuss how this
representation and the diffusion model{\"{i}}¾'s decision process might
be integrated with current models of lexical access.},
author = {Ratcliff, R and McKoon, G and Gomez, P},
journal = {Psychological review},
keywords = {decision making,diffusion model,lexical decision task,neurobiology,psychology,unread},
number = {1},
pages = {159},
title = {{A diffusion model account of the lexical decision task}},
volume = {111}
}
@article{Chawla2004,
author = {Chawla, NV and Japkowicz, Nathalie and Kotcz, A},
journal = {ACM SIGKDD Explorations Newsletter},
number = {1},
pages = {2000--2004},
title = {{Editorial: special issue on learning from imbalanced data sets}},
url = {http://dl.acm.org/citation.cfm?id=1007733},
volume = {6},
year = {2004}
}
@article{Bair94,
abstract = {It is widely held that visual cortical neurons encode information primarily in their mean firing rates. Some proposals, however, emphasize the information potentially available in the temporal structure of spike trains (Optican and Richmond, 1987; Bialek et al., 1991), in particular with respect to stimulus-related synchronized oscillations in the 30-70 Hz range (Eckhorn et al., 1988; Gray et al., 1989; Kreiter and Singer, 1992) as well as via bursting cells (Cattaneo et al., 1981a; Bonds, 1992). We investigate the temporal fine structure of spike trains recorded in extrastriate area MT of the trained macaque monkey, a region that plays a major role in processing motion information. The data were recorded while the monkey performed a near-threshold direction discrimination task so that both physiological and psychophysical data could be obtained on the same set of trials (Britten et al., 1992). We identify bursting cells and quantify their properties, in particular in relation to the behavior of the animal. We compute the power spectrum and the distribution of interspike intervals (ISIs) associated with individual spike trains from 212 cells, averaging these quantities across similar trials. (1) About 33{\%} of the cells have a relatively flat power spectrum with a dip at low temporal frequencies. We analytically derive the power spectrum of a Poisson process with refractory period and show that it matches the observed spectrum of these cells. (2) About 62{\%} of the cells have a peak in the 20-60 Hz frequency band. In about 10{\%} of all cells, this peak is at least twice the height of its base. The presence of such a peak strongly correlates with a tendency of the cell to respond in bursts, that is, two to four spikes within 2-8 msec. For 93{\%} of cells, the shape of the power spectrum did not change dramatically with stimulus conditions. (3) Both the ISI distribution and the power spectrum of the vast majority of bursting cells are compatible with the notion that these cells fire Poisson-distributed bursts, with a burst-related refractory period. Thus, for our stimulus conditions, no explicitly oscillating neuronal process is required to yield a peak in the power spectrum. (4) We found no statistically significant relationship between the peak in the power spectrum and psychophysical measures of the monkeys' performance on the direction discrimination task.(ABSTRACT TRUNCATED AT 400 WORDS)},
author = {Bair, W and Koch, C and Newsome, W and Britten, K},
issn = {0270-6474},
journal = {J. Neurosci.},
keywords = {Action Potentials,Animals,Macaca,Mathematics,Models,Motor Activity,Neurological,Neurons,Neurons: physiology,Poisson Distribution,Psychomotor Performance,Stochastic Processes,Time Factors,Visual Cortex,Visual Cortex: physiology,Visual Fields},
month = {may},
number = {5 Pt 1},
pages = {2870--2892},
pmid = {8182445},
title = {{Power spectrum analysis of $\backslash$protect{\{}MT{\}} neurons in the behaving monkey}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8182445},
volume = {14},
year = {1994}
}
@inproceedings{Kingma2015,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions. The method is straightforward to implement and is based on adaptive estimates of lower-order moments of the gradients. The method is computationally efficient, has little memory requirements and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The method exhibits invariance to diagonal rescaling of the gradients by adapting to the geometry of the objective function. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. We demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.6980v5},
author = {Kingma, Diederik P and Ba, Jimmy Lei},
booktitle = {ICLR},
eprint = {arXiv:1412.6980v5},
pages = {1--13},
title = {{Adam: a Method for Stochastic Optimization}},
year = {2015}
}
@article{Gai2010,
abstract = {Fundamental properties of phasic firing neurons are usually characterized in a noise-free condition. In the absence of noise, phasic neurons exhibit Class 3 excitability, which is a lack of repetitive firing to steady current injections. For time-varying inputs, phasic neurons are band-pass filters or slope detectors, because they do not respond to inputs containing exclusively low frequencies or shallow slopes. However, we show that in noisy conditions, response properties of phasic neuron models are distinctly altered. Noise enables a phasic model to encode low-frequency inputs that are outside of the response range of the associated deterministic model. Interestingly, this seemingly stochastic-resonance (SR) like effect differs significantly from the classical SR behavior of spiking systems in both the signal-to-noise ratio and the temporal response pattern. Instead of being most sensitive to the peak of a subthreshold signal, as is typical in a classical SR system, phasic models are most sensitive to the signal's rising and falling phases where the slopes are steep. This finding is consistent with the fact that there is not an absolute input threshold in terms of amplitude; rather, a response threshold is more properly defined as a stimulus slope/frequency. We call the encoding of low-frequency signals with noise by phasic models a slope-based SR, because noise can lower or diminish the slope threshold for ramp stimuli. We demonstrate here similar behaviors in three mechanistic models with Class 3 excitability in the presence of slow-varying noise and we suggest that the slope-based SR is a fundamental behavior associated with general phasic properties rather than with a particular biological mechanism.},
author = {Gai, Yan and Doiron, Brent and Rinzel, John},
doi = {10.1371/journal.pcbi.1000825},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Age Factors,Animals,Brain Stem,Brain Stem: cytology,Brain Stem: physiology,Gerbillinae,Microscopy,Models,Neurological,Neurons,Neurons: physiology,Stochastic Processes,Video},
month = {jun},
number = {6},
pages = {e1000825},
pmid = {20585612},
title = {{Slope-based stochastic resonance: how noise enables phasic neurons to encode slow signals.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2891698{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2010}
}
@article{Hein1993,
author = {Hein, Sgren and Zakhor, Avideh},
journal = {Signal Processing, IEEE Transactions on},
number = {7},
pages = {2322--2348},
title = {{On the stability of sigma delta modulators}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=224243},
volume = {41},
year = {1993}
}
@article{Schwartz98,
author = {Schwartz, T and Rabinowitz, D and Unni, V K and Kumar, V S and Smetters, D K and Tsiola, A and Yuste, R},
journal = {Neuron},
pages = {1271--1283},
title = {{Networks of coactive neurons in developing layer 1.}},
volume = {20},
year = {1998}
}
@article{MajewskaYuste00,
abstract = {We describe in detail a custom-built two-photon microscope based on

a modified confocal scanhead (Olympus Fluoview) and mode-locked Ti:sapphire

laser (Coherent Mira 900). This system has internal detectors as

well as external whole-field detection and an electrooptical modulator

for blanking the beam on flyback and effecting fast changes in excitation

intensity. This microscope can be used in deep, scattering samples

for quantitative measurements with a wide range of fluorophores (GFP,

fura, calcium green, calcium orange, fluo-3, DiI, DiO, fluorescein,

rhodamine), for fluorescent photobleaching recovery and for uncaging.

Images obtained with this system can be deconvolved with the Estimation

Maximization algorithm using the program XCOSM (freeware available

at: http://www.ibc.wustl.edu/bcl/ xcosm/).},
author = {Majewska, A and Yiu, G and Yuste, R},
journal = {Pflugers Arch},
keywords = {Animals; Brain; Dendrites; Image Enhancement; Lase},
month = {dec},
number = {2-3},
pages = {398--408},
pmid = {11211128},
title = {{A custom-made two-photon microscope and deconvolution system.}},
volume = {441},
year = {2000}
}
@article{SOL96,
author = {Sollich, P},
journal = {Physical Review E},
pages = {R2060----R2063},
title = {{Learning from minimum entropy queries in a large committee machine}},
volume = {53},
year = {1996}
}
@incollection{PAN08,
author = {Paninski, L and Iyengar, S and Kass, R and Brown, E},
booktitle = {Stochastic Methods in Neuroscience},
publisher = {Oxford University Press},
title = {{Statistical models of spike trains}},
year = {2008}
}
@article{Thivierge2008,
abstract = {Neural synchronization is of wide interest in neuroscience and has been argued to form the substrate for conscious attention to stimuli, movement preparation, and the maintenance of task-relevant representations in active memory. Despite a wealth of possible functions, the mechanisms underlying synchrony are still poorly understood. In particular, in vitro preparations have demonstrated synchronization with no apparent periodicity, which cannot be explained by simple oscillatory mechanisms. Here, we investigate the possible origins of nonperiodic synchronization through biophysical simulations. We show that such aperiodic synchronization arises naturally under a simple set of plausible assumptions, depending crucially on heterogeneous cell properties. In addition, nonperiodicity occurs even in the absence of stochastic fluctuation in membrane potential, suggesting that it may represent an intrinsic property of interconnected networks. Simulations capture some of the key aspects of population-level synchronization in spontaneous network spikes (NSs) and suggest that the intrinsic nonperiodicity of NSs observed in reduced cell preparations is a phenomenon that is highly robust and can be reproduced in simulations that involve a minimal set of realistic assumptions. In addition, a model with spike timing-dependent plasticity can overcome a natural tendency to exhibit nonperiodic behavior. After rhythmic stimulation, the model does not automatically fall back to a state of nonperiodic behavior, but keeps replaying the pattern of evoked NSs for a few cycles. A cluster analysis of synaptic strengths highlights the importance of population-wide interactions in generating this result and describes a possible route for encoding temporal patterns in networks of neurons.},
annote = {2010IInum9.3},
author = {Thivierge, Jean-Philippe and Cisek, Paul},
doi = {10.1523/JNEUROSCI.0870-08.2008},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Algorithms,Animals,Cluster Analysis,Computer Simulation,Cortical Synchronization,Electric Stimulation,Electric Stimulation: methods,Humans,Models,Nerve Net,Nerve Net: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Reaction Time,Reaction Time: physiology,Synapses,Synapses: physiology},
number = {32},
pages = {7968--7978},
pmid = {18685022},
title = {{Nonperiodic synchronization in heterogeneous networks of spiking neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18685022},
volume = {28},
year = {2008}
}
@article{Mishchenko2009a,
author = {Mishchenko, Y},
journal = {Journal of Neuroscience Methods},
pages = {276--289},
title = {{Strategies for identifying exact structure of neural circuits with broad light microscopy connectivity probes}},
volume = {176},
year = {2009}
}
@article{Thomson2000,
author = {Thomson, A M},
doi = {DOI: 10.1016/S0166-2236(00)01580-0},
issn = {0166-2236},
journal = {Trends in Neurosciences},
keywords = {Presynaptic},
number = {7},
pages = {305--312},
title = {{Facilitation, augmentation and potentiation at central synapses}},
url = {http://www.sciencedirect.com/science/article/pii/S0166223600015800},
volume = {23},
year = {2000}
}
@book{DEND99,
editor = {Stuart, G and Spruston, N and H{\"{a}}usser, M},
publisher = {Oxford University Press},
title = {{Dendrites}},
year = {1999}
}
@article{Maass1994,
archivePrefix = {arXiv},
arxivId = {1707.04615},
author = {Maass, W},
eprint = {1707.04615},
isbn = {0 19 853492 2},
journal = {Computational Learning Theory: Eurocolt '93},
pages = {1--17},
title = {{On the Complexity of Learning on Neural Nets}},
volume = {New Series},
year = {1994}
}
@article{Nowak2010,
abstract = {Eusociality, in which some individuals reduce their own lifetime reproductive potential to raise the offspring of others, underlies the most advanced forms of social organization and the ecologically dominant role of social insects and humans. For the past four decades kin selection theory, based on the concept of inclusive fitness, has been the major theoretical attempt to explain the evolution of eusociality. Here we show the limitations of this approach. We argue that standard natural selection theory in the context of precise models of population structure represents a simpler and superior approach, allows the evaluation of multiple competing hypotheses, and provides an exact framework for interpreting empirical observations.},
author = {Nowak, Martin a and Tarnita, Corina E and Wilson, Edward O},
doi = {10.1038/nature09205},
issn = {1476-4687},
journal = {Nature},
keywords = {Animal,Animal: physiology,Animals,Behavior,Biological,Biological Evolution,Female,Genetic,Humans,Insects,Insects: physiology,Male,Models,Selection,Social Behavior},
month = {aug},
number = {7310},
pages = {1057--62},
pmid = {20740005},
publisher = {Nature Publishing Group},
title = {{The evolution of eusociality}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20740005},
volume = {466},
year = {2010}
}
@article{Shah2007,
author = {Shah, D},
doi = {10.1561/1300000014},
issn = {1554-057X},
journal = {Foundations and Trends in Machine Learning},
keywords = {Network functionality},
mendeley-tags = {Network functionality},
number = {1},
pages = {1--125},
title = {{Gossip Algorithms}},
url = {http://www.nowpublishers.com/product.aspx?product=NET{\&}doi=1300000014},
volume = {3},
year = {2007}
}
@article{CallawayKatz93,
author = {Callaway, E and Katz, L C},
journal = {PNAS},
pages = {7661--7665},
title = {{Photostimulation using caged glutamate reveals functional circuitry in living brain slices.}},
volume = {90},
year = {1993}
}
@article{EV68,
author = {Evarts, E},
journal = {Journal of Neurophysiology},
pages = {14--27},
title = {{Relation of pyramidal tract activity to force exerted during voluntary movement}},
volume = {31},
year = {1968}
}
@book{Lorente81,
address = {New York},
author = {de N{\'{o}}, R},
publisher = {Raven Press},
title = {{The Primary Acoustic Nuclei}},
year = {1981}
}
@book{Bourgain2010,
abstract = {Let n be a large integer and Mn be an n by n complex matrix whose entries are independent (but not necessarily identically distributed) discrete random variables. The main goal of this paper is to prove a general upper bound for the probability that Mn is singular. For a constant 0 {\textless} p {\textless} 1 and a constant positive integer r, we will define a property p-bounded of exponent r. Our main result shows that if the entries of Mn satisfy this property, then the probability that Mn is singular is at most (p1 / r + o (1))n. All of the results in this paper hold for any characteristic zero integral domain replacing the complex numbers. In the special case where the entries of Mn are "fair coin flips" (taking the values + 1, - 1 each with probability 1/2), our general bound implies that the probability that Mn is singular is at most (frac(1, sqrt(2)) + o (1))n, improving on the previous best upper bound of (frac(3, 4) + o (1))n, proved by Tao and Vu [Terence Tao, Van Vu, On the singularity probability of random Bernoulli matrices, J. Amer. Math. Soc. 20 (2007) 603-628]. In the special case where the entries of Mn are "lazy coin flips" (taking values + 1, - 1 each with probability 1/4 and value 0 with probability 1/2), our general bound implies that the probability that Mn is singular is at most (frac(1, 2) + o (1))n, which is asymptotically sharp. Our method is a refinement of those from [Jeff Kahn, J{\'{a}}nos Koml{\'{o}}s, Endre Szemer{\'{e}}di, On the probability that a random ±1-matrix is singular, J. Amer. Math. Soc. 8 (1) (1995) 223-240; Terence Tao, Van Vu, On the singularity probability of random Bernoulli matrices, J. Amer. Math. Soc. 20 (2007) 603-628]. In particular, we make a critical use of the structure theorem from [Terence Tao, Van Vu, On the singularity probability of random Bernoulli matrices, J. Amer. Math. Soc. 20 (2007) 603-628], which was obtained using tools from additive combinatorics. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:0905.0461v1},
author = {Bourgain, Jean and Vu, Van H. and Wood, Philip Matchett},
booktitle = {Journal of Functional Analysis},
doi = {10.1016/j.jfa.2009.04.016},
eprint = {arXiv:0905.0461v1},
isbn = {0000000000000},
issn = {00221236},
keywords = {Discrete random matrix,Singularity},
number = {2},
pages = {559--603},
title = {{On the singularity probability of discrete random matrices}},
volume = {258},
year = {2010}
}
@article{Panzeri2010,
abstract = {Determining how neuronal activity represents sensory information is central for understanding perception. Recent work shows that neural responses at different timescales can encode different stimulus attributes, resulting in a temporal multiplexing of sensory information. Multiplexing increases the encoding capacity of neural responses, enables disambiguation of stimuli that cannot be discriminated at a single response timescale, and makes sensory representations stable to the presence of variability in the sensory world. Thus, as we discuss here, temporal multiplexing could be a key strategy used by the brain to form an information-rich and stable representation of the environment.},
author = {Panzeri, Stefano and Brunel, N and Logothetis, Nikos K and Kayser, Christoph},
doi = {10.1016/j.tins.2009.12.001},
issn = {1878-108X},
journal = {Trends in Neurosciences},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Brain,Brain: physiology,Computer Simulation,Humans,Information Theory,Perception,Perception: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Sensation,Sensation: physiology,Sensory Receptor Cells,Sensory Receptor Cells: physiology,Time Perception,Time Perception: physiology},
month = {mar},
number = {3},
pages = {111--120},
pmid = {20045201},
publisher = {Elsevier Ltd},
title = {{Sensory neural codes using multiplexed temporal scales.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20045201},
volume = {33},
year = {2010}
}
@article{Litke2004,
author = {Litke, A and Bezayiff, N and Chichilnisky, E J and Cunningham, W and Dabrowski, W and Grillo, A and Grivich, M and Grybos, P and Hottowy, P and Kachiguine, S and Kalmar, R and Mathieson, K and Petrusca, D and Rahman, M and Sher, A},
journal = {IEEE Trans Nucl Sci},
pages = {1434--1440},
title = {{What does the eye tell the brain? Development of a system for the large scale recording of retinal output activity}},
year = {2004}
}
@article{LFPR04,
author = {Lampl, I and Ferster, D and Poggio, T and Riesenhuber, M},
journal = {Journal of Neurophysiology},
pages = {2704--2713},
title = {{Intracellular Measurements of Spatial Integration and the {\{}MAX{\}} Operation in Complex Cells of the Cat Primary Visual Cortex}},
volume = {92},
year = {2004}
}
@article{Krumin2010a,
abstract = {The correlation structure of neural activity is believed to play a major role in the encoding and possibly the decoding of information in neural populations. Recently, several methods were developed for exactly controlling the correlation structure of multi-channel synthetic spike trains (Brette, 2009; Krumin and Shoham, 2009; Macke et al., 2009; Gutnisky and Josic, 2010; Tchumatchenko et al., 2010) and, in a related work, correlation-based analysis of spike trains was used for blind identification of single-neuron models (Krumin et al., 2010), for identifying compact auto-regressive models for multi-channel spike trains, and for facilitating their causal network analysis (Krumin and Shoham, 2010). However, the diversity of correlation structures that can be explained by the feed-forward, non-recurrent, generative models used in these studies is limited. Hence, methods based on such models occasionally fail when analyzing correlation structures that are observed in neural activity. Here, we extend this framework by deriving closed-form expressions for the correlation structure of a more powerful multivariate self- and mutually exciting Hawkes model class that is driven by exogenous non-negative inputs. We demonstrate that the resulting Linear-Non-linear-Hawkes (LNH) framework is capable of capturing the dynamics of spike trains with a generally richer and more biologically relevant multi-correlation structure, and can be used to accurately estimate the Hawkes kernels or the correlation structure of external inputs in both simulated and real spike trains (recorded from visually stimulated mouse retinal ganglion cells). We conclude by discussing the method's limitations and the broader significance of strengthening the links between neural spike train analysis and classical system identification.},
author = {Krumin, Michael and Reutsky, Inna and Shoham, Shy},
doi = {10.3389/fncom.2010.00147},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {correlation,functions,integral equations,linear system identification,multi-channel recordings,point process,recurrent,retinal ganglion cells,spike train analysis},
month = {jan},
number = {November},
pages = {147},
pmid = {21151360},
title = {{Correlation-based analysis and generation of multiple spike trains using hawkes models with an exogenous input.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2995522{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2010}
}
@article{Ferguson2013,
abstract = {OBJECTIVE: To report normative data for retinal thickness in wild-type C57BL/6 mouse utilizing a miniature SD-OCT system.

METHODS: THIRTY ADULT MICE (RANGE: 3-5 months) were anesthetized and secured into the Bioptigen Spectral Domain Ophthalmic Imaging System. Right eye SD-OCT images were standardized by centralizing the optic nerve head (ONH) prior to image acquisition. Global and quadrant total retinal thickness (TRT) values were measured from retinal nerve fiber layer to retinal pigment epithelial layer. Posterior segment analyses also included the outer retinal layer (ORL) and inner retinal layer (IRL). Further sublayer analyses of four layers from the ORL and three layers comprising the IRL were also performed.

RESULTS: The overall mean±SD global TRT in a C57BL/6 mouse model was 204.41±5.19 µm. Quadrant mean TRT values were 204.85±5.81 µm inferiorly, 204.97±6.71 µm nasally, 205.08±5.44 µm temporally, and 202.74±4.85 µm superiorly. Mean±SD thickness for ORL, and IRL were 126.37±10.01 µm, and 107.03±10.98 µm respectively. The mean±SD estimates for the four layers of the ORL were 18.23±2.73 µm, 26.04±4.21 µm, 63.8±6.23 µm, and 19.22±4.34 µm. Mean±SD values for the three IRL sublayers were 27.82±4.04 µm, 59.62±6.66 µm and 19.12±3.71 µm.

CONCLUSION: This study established normative values for the total retinal thickness and sublayer thickness for the wild-type C57BL/6 mice. Moreover, it provides a standard of retinal morphology, in a commonly used animal model, for evaluating therapeutic interventions and retinal disease pathophysiology.},
author = {Ferguson, Lee R and {Dominguez Ii}, James M and Balaiya, Sankarathi and Grover, Sandeep and Chalam, Kakarla V},
doi = {10.1371/journal.pone.0067265},
file = {::},
issn = {1932-6203},
journal = {PloS one},
month = {jan},
number = {6},
pages = {e67265},
pmid = {23826252},
title = {{Retinal Thickness Normative Data in Wild-Type Mice Using Customized Miniature SD-OCT.}},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0067265},
volume = {8},
year = {2013}
}
@article{Roudi2009,
abstract = {One of the most critical problems we face in the study of biological systems is building accurate statistical descriptions of them. This problem has been particularly challenging because biological systems typically contain large numbers of interacting elements, which precludes the use of standard brute force approaches. Recently, though, several groups have reported that there may be an alternate strategy. The reports show that reliable statistical models can be built without knowledge of all the interactions in a system; instead, pairwise interactions can suffice. These findings, however, are based on the analysis of small subsystems. Here, we ask whether the observations will generalize to systems of realistic size, that is, whether pairwise models will provide reliable descriptions of true biological systems. Our results show that, in most cases, they will not. The reason is that there is a crossover in the predictive power of pairwise models: If the size of the subsystem is below the crossover point, then the results have no predictive power for large systems. If the size is above the crossover point, then the results may have predictive power. This work thus provides a general framework for determining the extent to which pairwise models can be used to predict the behavior of large biological systems. Applied to neural data, the size of most systems studied so far is below the crossover point.},
author = {Roudi, Y and Nirenberg, Sheila and Latham, Peter E},
doi = {10.1371/journal.pcbi.1000380},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Algorithms,Computer Simulation,Entropy,Models, Biological,Models, Statistical,Systems Biology,Systems Biology: methods},
month = {may},
number = {5},
pages = {e1000380},
pmid = {19424487},
title = {{Pairwise maximum entropy models for studying large biological systems: when they can work and when they can't.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2674569{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@incollection{Faisal2009,
address = {New York},
annote = {2011num2},
author = {Faisal, A A},
booktitle = {Stochastic Methods in Neuroscience},
editor = {Laing, C and Gabrieal, J L},
pages = {297--343},
publisher = {Oxford Univ Press},
title = {{STOCHASTIC SIMULATION OF NEURONS, AXONS, AND ACTION POTENTIALS}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Stochastic+simulation+of+neurons,+axons+and+action+potentials{\#}0},
year = {2009}
}
@article{Fang1997,
author = {Fang, S C and Venkatesh, S S},
journal = {SIAM Journal on Discrete Mathematics},
keywords = {binary,harmonic update,integer programming,large deviations,neural networks,normal approximation,poisson approxima-,polytopes,randomized algorithm,threshold function},
number = {3},
pages = {482--498},
title = {{A THRESHOLD FUNCTION FOR HARMONIC UPDATE}},
url = {http://epubs.siam.org/doi/pdf/10.1137/S0895480195283701},
volume = {10},
year = {1997}
}
@article{Takahashi2012,
author = {Takahashi, N and Kitamura, K and Matsuo, N and Mayford, M and Kano, M and Matsuki, N and Ikegaya, Y},
journal = {Science},
number = {January},
pages = {353--356},
title = {{Locally synchronized synaptic inputs}},
url = {http://stke.sciencemag.org/cgi/content/abstract/sci;335/6066/353},
volume = {335},
year = {2012}
}
@article{PAN03d,
author = {Paninski, L and Fellows, M and Shoham, S and Hatsopoulos, N and Donoghue, J},
journal = {J. Neurosci.},
pages = {8551--8561},
title = {{Superlinear population encoding of dynamic hand trajectory in primary motor cortex}},
volume = {24},
year = {2004}
}
@article{Stepanyants|2002|,
author = {Stepanyants, A and Hof, P R and Chklovskii, D B},
journal = {Neuron},
pages = {275--288},
title = {{Geometry and structural plasticity of synaptic connectivity.}},
volume = {34}
}
@article{Blatz1986,
author = {Blatz, A L and Magleby, K L},
journal = {The Journal of Physiology},
number = {1},
pages = {141},
publisher = {Physiological Soc},
title = {{Quantitative description of three modes of activity of fast chloride channels from rat skeletal muscle}},
url = {http://jp.physoc.org/cgi/content/abstract/378/1/141},
volume = {378},
year = {1986}
}
@book{Kolb2007,
editor = {Kolb, Helga and Fernandez, Eduardo and Nelson, Ralph},
publisher = {Bethesda},
title = {{Webvision : the organization of the retina and visual system}},
year = {2007}
}
@inproceedings{Hinton1993,
author = {Hinton, G E and Camp, D Van},
booktitle = {COLT '93},
title = {{Keeping the neural networks simple by minimizing the description length of the weights}},
url = {http://dl.acm.org/citation.cfm?id=168306},
year = {1993}
}
@article{Blake|1995|,
abstract = {A development of a method for tracking visual contours is described.
Given an "un-trained" tracker, a training-motion of an object can
be observed over some extended time and sorted as an image sequence.
The image sequence is used to learn parameters in a stochastic differential
equation model. These are used in turn, to build a tracker whose
predictor imitates the motion in the training set. Tests show that
the resulting trackers can be markedly tuned to desired curve shapes
and classes of motions.},
annote = {The paper details contour tracking algorithm based on fitting given{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}motion model to a set of frame, more specifically described by translations{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and deformations.},
author = {Blake, A and Isard, M and Reynard, D},
keywords = {computational,contours,image processing,motion,tracking},
title = {{Learning to track the visual motion of contours}}
}
@article{OleskevichWalmsley02,
abstract = {The deafness (dn/dn) mutant mouse provides a valuable model of human

congenital deafness. We investigated the properties of synaptic transmission

in the anteroventral cochlear nucleus (AVCN) of normal and congenitally

deaf dn/dn mice. Excitatory postsynaptic currents (EPSCs) were evoked

by focal stimulation of single auditory nerve fibres, and measured

by whole-cell recordings from neurones in AVCN slices (mean postnatal

age = P13). Absolute amplitudes of both AMPA- and NMDA-mediated components

of evoked EPSCs were greater (170 {\%}) in deaf versus control animals.

Enhanced transmission in deaf mice was due to a presynaptic mechanism.

Variance-mean analysis revealed that the probability of transmitter

release was significantly greater in deaf (P(r) = 0.8) versus control

animals (P(r) = 0.5). Following high frequency stimulation, deaf

mice showed a greater depression of evoked EPSCs, and a significant

increase in the frequency of delayed-release (asynchronous) miniature

EPSCs (aEPSCs) (deaf 100 Hz vs. control 7 Hz). The acetoxymethyl

ester of EGTA (EGTA-AM) blocked the increase in miniature aEPSCs

and returned tetanic depression to control values. In deaf mice,

reduction of mean P(r) using cadmium caused an expected increase

in paired-pulse ratio (PPR). However, in the same cells, a similar

reduction in release by EGTA-AM did not result in a change in PPR,

demonstrating that a change may occur in P(r) without a concomitant

change in PPR. In many respects, transmission in deaf mice was found

to be remarkably similar to control mice, implying that many parameters

of synaptic transmission develop normally in these animals. The two

significant differences (higher P(r) and asynchronous release in

deaf mice) could both be reversed by the addition of EGTA-AM, suggesting

that endogenous calcium buffering may be impaired or undeveloped

in the presynaptic terminals of the auditory nerve in deaf mice.},
author = {Oleskevich, Sharon and Walmsley, Bruce},
journal = {J Physiol},
keywords = {Animals; Brain Stem; Calcium Channels,Auditory,Brain Stem; Excitatory Postsynaptic Potentials; I,N-Type; Calcium Channels,Neurologic Mutants; Nerve Fibers; Neurons; Patch-,Q-Type; Chelating Agents; Cochlear Nucleus; Deafn},
month = {apr},
number = {Pt 2},
pages = {447--455},
pmid = {11956335},
title = {{Synaptic transmission in the auditory brainstem of normal and congenitally deaf mice.}},
volume = {540},
year = {2002}
}
@article{NYK03,
author = {Nykamp, D Q},
journal = {Network},
pages = {673--702},
title = {{Measuring linear and quadratic contributions to neuronal response}},
volume = {14},
year = {2003}
}
@article{Li2014,
abstract = {We study the use of very sparse random projections for compressed sensing (sparse signal recovery) when the signal entries can be either positive or negative. In our setting, the entries of a Gaussian design matrix are randomly sparsified so that only a very small fraction of the entries are nonzero. Our proposed decoding algorithm is simple and efficient in that the major cost is one linear scan of the coordinates. We have developed two estimators: (i) the {\{}$\backslash$em tie estimator{\}}, and (ii) the {\{}$\backslash$em absolute minimum estimator{\}}. Using only the tie estimator, we are able to recover a {\$}K{\$}-sparse signal of length {\$}N{\$} using {\$}1.551 eK \backslashlog K/\backslashdelta{\$} measurements (where {\$}\backslashdelta\backslashleq 0.05{\$} is the confidence). Using only the absolute minimum estimator, we can detect the support of the signal using {\$}eK\backslashlog N/\backslashdelta{\$} measurements. For a particular coordinate, the absolute minimum estimator requires fewer measurements (i.e., with a constant {\$}e{\$} instead of {\$}1.551e{\$}). Thus, the two estimators can be combined to form an even more practical decoding framework. Prior studies have shown that existing one-scan (or roughly one-scan) recovery algorithms using sparse matrices would require substantially more (e.g., one order of magnitude) measurements than L1 decoding by linear programming, when the nonzero entries of signals can be either negative or positive. In this paper, following a known experimental setup, we show that, at the same number of measurements, the recovery accuracies of our proposed method are (at least) similar to the standard L1 decoding.},
archivePrefix = {arXiv},
arxivId = {1408.2504},
author = {Li, Ping and Zhang, Cun-hui},
eprint = {1408.2504},
pages = {1--13},
title = {{Compressed Sensing with Very Sparse Gaussian Random Projections}},
url = {http://arxiv.org/abs/1408.2504},
volume = {38},
year = {2014}
}
@article{Petreanu|2007|,
author = {Petreanu, L and Huber, D and Sobczyk, A and Svoboda, K},
journal = {Nature Neuroscience},
pages = {663--668},
title = {{Channelrhodopsin-2-assisted circuit mapping of long-range callosal projections.}},
volume = {10}
}
@inproceedings{Soudry2016,
author = {Soudry, D. and Carmon, Y},
booktitle = {arXiv:1605.08361},
title = {{No bad local minima: Data independent training error guarantees for multilayer neural networks}},
year = {2016}
}
@article{APD03,
author = {Arabzadeh, E and Petersen, R and Diamond, M},
journal = {Journal of Neuroscience},
pages = {9146--9154},
title = {{Encoding of whisker vibration by rat barrel cortex neurons: implications for texture discrimination}},
volume = {23},
year = {2003}
}
@article{Meeks2004,
abstract = {High-frequency synaptic transmission is depressed by moderate rises in the extracellular potassium concentration ([K+]o). Previous reports have indicated that depression of action potential signaling may underlie the synaptic depression. Here, we investigated the specific contribution of K+-induced action potential changes to synaptic depression. We found that glutamatergic transmission in the hippocampal area CA1 was significantly depressed by 8-10 mM [K+]o, but that GABAergic transmission remained intact. Riluzole, a drug that slows recovery from inactivation of voltage-gated sodium channels (NaChs), interacts with subthreshold [K+]o to depress afferent volleys and EPSCs strongly. Thus, elevated [K+]o likely depresses synapses by slowing NaCh recovery from inactivation. It is unclear from previous studies whether [K+]o-induced action potential depression is caused by changes in initiation, reliability, or waveform. We investigated these possibilities explicitly. [K+]o-induced afferent volley depression was independent of stimulus strength, suggesting that changes in action potential initiation do not explain [K+]o-induced depression. Measurements of action potentials from single axons revealed that 8 mM [K+]o increased conduction failures in a subpopulation of fibers and depressed action potential amplitude in all fibers. Together, these changes quantitatively account for the afferent volley depression. We estimate that conduction failure explains more than half of the synaptic depression observed at 8 mM [K+]o, with the remaining depression likely explained by waveform changes. These mechanisms of selective sensitivity of glutamate release to [K+]o accumulation represent a unique neuromodulatory mechanism and a brake on runaway excitation.},
author = {Meeks, J P and Mennerick, S},
doi = {10.1523/JNEUROSCI.4845-03.2004},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Animals,Cells,Cultured,Electric Conductivity,Excitatory Postsynaptic Potentials,Glutamic Acid,Glutamic Acid: metabolism,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Long-Term Synaptic Depression,Patch-Clamp Techniques,Potassium,Potassium: pharmacology,Pyramidal Cells,Pyramidal Cells: drug effects,Pyramidal Cells: physiology,Rats,Signal Transduction,Sodium Channels,Sodium Channels: metabolism,Sprague-Dawley,Synaptic Transmission,Synaptic Transmission: drug effects},
month = {jan},
number = {1},
pages = {197--206},
pmid = {14715952},
title = {{Selective effects of potassium elevations on glutamate signaling and action potential conduction in hippocampus.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14715952},
volume = {24},
year = {2004}
}
@article{Du2017a,
abstract = {We analyze the convergence of (stochastic) gradient descent algorithm for learning a convolutional filter with Rectified Linear Unit (ReLU) activation function. Our analysis does not rely on any specific form of the input distribution and our proofs only use the definition of ReLU, in contrast with previous works that are restricted to standard Gaussian input. We show that (stochastic) gradient descent with random initialization can learn the convolutional filter in polynomial time and the convergence rate depends on the smoothness of the input distribution and the closeness of patches. To the best of our knowledge, this is the first recovery guarantee of gradient-based algorithms for convolutional filter on non-Gaussian input distributions. Our theory also justifies the two-stage learning rate strategy in deep neural networks. While our focus is theoretical, we also present experiments that illustrate our theoretical findings.},
archivePrefix = {arXiv},
arxivId = {1709.06129},
author = {Du, Simon S. and Lee, Jason D. and Tian, Yuandong},
eprint = {1709.06129},
journal = {arXiv},
month = {sep},
title = {{When is a Convolutional Filter Easy To Learn?}},
url = {http://arxiv.org/abs/1709.06129},
year = {2017}
}
@article{FEL01,
author = {Fellows, M and Paninski, L and Hatsopoulos, N and Donoghue, J},
journal = {SFN abstracts},
pages = {940.1},
title = {{Diverse spatial and temporal features of velocity and position tuning in primary motor cortical neurons during continuous tracking}},
year = {2001}
}
@inproceedings{Jaeger2005,
author = {Jaeger, H},
booktitle = {Neural Networks, 2005. IJCNN'05. Proceedings. 2005 IEEE International Joint Conference on},
keywords = {Reservoir Computing},
mendeley-tags = {Reservoir Computing},
pages = {1460--1462},
publisher = {IEEE},
title = {{Reservoir riddles: Suggestions for echo state network research}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1556090},
volume = {3},
year = {2005}
}
@article{Bauer1961,
author = {Bauer, F. L. and Stoer, J. and Witzgall, C.},
doi = {10.1007/BF01386026},
issn = {0029-599X},
journal = {Numerische Mathematik},
month = {dec},
number = {1},
pages = {257--264},
title = {{Absolute and monotonic norms}},
url = {http://link.springer.com/10.1007/BF01386026},
volume = {3},
year = {1961}
}
@article{Meeks2007,
abstract = {Thin, unmyelinated axons densely populate the mammalian hippocampus and cortex. However, the location and dynamics of spike initiation in thin axons remain unclear. We investigated basic properties of spike initiation and propagation in CA3 neurons of juvenile rat hippocampus. Sodium channel alpha subunit distribution and local applications of tetrodotoxin demonstrate that the site of first threshold crossing in CA3 neurons is approximately 35 microm distal to the soma, somewhat more proximal than our previous estimates. This discrepancy can be explained by the finding, obtained with simultaneous whole cell somatic and extracellular axonal recordings, that a zone of axon stretching to approximately 100 microm distal to the soma reaches a maximum rate of depolarization nearly synchronously by the influx of sodium from the high-density channels. Models of the proximal axon incorporating observed distributions of sodium channel staining recapitulated salient features of somatic and axonal spike waveforms, including the predicted initiation zone, characteristic spike latencies, and conduction velocity. The preferred initiation zone was unaltered by stimulus strength or repetitive spiking, but repetitive spiking increased threshold and significantly slowed initial segment recruitment time and conduction velocity. Our work defines the dynamics of initiation and propagation in hippocampal principal cell axons and may help reconcile recent controversies over initiation site in other axons.},
author = {Meeks, JP P Julian P and Mennerick, Steven},
doi = {10.1152/jn.01288.2006},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Anesthetics,Animals,Axons,Axons: physiology,Computer Simulation,Dose-Response Relationship,Drug,Electric Stimulation,Electric Stimulation: methods,Hippocampus,Hippocampus: cytology,Local,Local: pharmacology,Models,Neural Conduction,Neural Conduction: drug effects,Neural Conduction: physiology,Neurological,Newborn,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: cytology,Rats,Sodium Channels,Sodium Channels: metabolism,Sprague-Dawley,Tetrodotoxin,Tetrodotoxin: pharmacology},
month = {may},
number = {5},
pages = {3460--72},
pmid = {17314237},
title = {{Action potential initiation and propagation in CA3 pyramidal axons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17314237 http://jn.physiology.org/content/97/5/3460.short},
volume = {97},
year = {2007}
}
@article{Riedler2012,
author = {Riedler, Martin G.},
doi = {10.1016/j.cam.2012.09.021},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
keywords = {1,60j75,65c20,65l99,almost sure convergence,ams subject classifications,hybrid algorithm,hybrid stochastic,in recent years the,introduction,number of applications of,piecewise deterministic markov process,stochastic simulation},
month = {sep},
title = {{Almost sure convergence of numerical approximations for Piecewise Deterministic Markov Processes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0377042712003925},
year = {2012}
}
@article{Larkum1999,
abstract = {Action potentials in juvenile and adult rat layer-5 neocortical pyramidal neurons can be initiated at both axonal and distal sites of the apical dendrite. However, little is known about the interaction between these two initiation sites. Here, we report that layer 5 pyramidal neurons are very sensitive to a critical frequency of back-propagating action potentials varying between 60 and 200 Hz in different neurons. Bursts of four to five back-propagating action potentials above the critical frequency elicited large regenerative potentials in the distal dendritic initiation zone. The critical frequency had a very narrow range (10-20 Hz), and the dendritic regenerative activity led to further depolarization at the soma. The dendritic frequency sensitivity was suppressed by blockers of voltage-gated calcium channels, and also by synaptically mediated inhibition. Calcium-fluorescence imaging revealed that the site of largest transient increase in intracellular calcium above the critical frequency was located 400-700 micrometer from the soma at the site for initiation of calcium action potentials. Thus, the distal dendritic initiation zone can interact with the axonal initiation zone, even when inputs to the neuron are restricted to regions close to the soma, if the output of the neuron exceeds a critical frequency.},
annote = {מיקי לונדון הזכיר את המאמר בשיחה איתו.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}ייתכן כי אינאקטיבציה של תעלות נתרן מפסיקה את התופעה.},
author = {Larkum, M E and Kaiser, K M and Sakmann, B},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Action Potentials,Animals,Calcium,Calcium: metabolism,Dendrites,Dendrites: metabolism,Pyramidal Cells,Pyramidal Cells: metabolism,Rats,Rats, Wistar},
month = {dec},
number = {25},
pages = {14600--4},
pmid = {10588751},
title = {{Calcium electrogenesis in distal apical dendrites of layer 5 pyramidal cells at a critical frequency of back-propagating action potentials.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=24482{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {96},
year = {1999}
}
@inproceedings{Dean2012,
address = {Lake Tahoe, NV},
author = {Dean, J and Corrado, G S and Monga, R and Chen, K and Devin, M and Le, Q V and Mao, M Z and Ranzato, M and Senior, A and Tucker, P and Yang, K and Ng, A Y},
booktitle = {NIPS},
month = {dec},
pages = {1--9},
title = {{Large scale distributed deep networks}},
url = {http://books.nips.cc/papers/files/nips25/NIPS2012{\_}0598.pdf},
year = {2012}
}
@article{Higgins|1991|,
abstract = {Nonlinear edge-preserving filtering techniques have long been popular
in image processing. One of these techniques, the maximum-homogeneity
filter, has shown promise for reducing random noise, sharpening blurred
regional borders, and removing unwanted thin artifacts. Unfortunately,
previous authors have only defined the maximum-homogeneity filter
for fixed circumstances. We define, for bot three-dimensional and
two-dimensional images, a more flexible implementation of the maximum-homogeneity
filter. The implementation, based on a mathematically defined "spotlight"
operator, permits varying levels of region sharpening and artifact
removal. Test results demonstrate that the technique gives performance
comparable to other edge-preserving filters.},
author = {Higgins, W E},
journal = {IEEE transactions on image processing},
keywords = {computational,edge-detection,homogeneity,image processing,nonlinear filters,unread},
number = {10},
pages = {2325},
title = {{A flexible implementation of maximum-homogeneity filtering for 2D and 3D images}},
volume = {39}
}
@article{Seid|2005|,
abstract = {Behavioral development in the worker caste of many adult ants follows
a pattern of task transitions that contribute to the division of
labor within colonies. In the ant Pheidole dentata, the number of
tasks that minor workers attend to increases as they progress from
brood-care activities within the nest to acts outside the nest such
as foraging and defense. In this study we investigated synapse maturation
in the lip region of mushroom bodies in young and old minor workers
because of its potentially crucial role in behavioral development,
task performance, and repertoire expansion. As minor workers aged,
individual presynaptic boutons enlarged and acquired more synapses
and vesicles, but the total number of synapses in the lip region
did not change significantly. Glial cell processes occupied less
of the synaptic neuropil as ants matured. These findings indicate
an expansion and enhancement of efficacy at specific sets of synaptic
connections between the projection interneurons and Kenyon cell dendrites
and a commensurate loss of other connections as minor workers age
and expand their behavioral repertoire.},
annote = {R01EB002170/EB/United States NIBIB Comparative Study Journal Article{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Research Support, N.I.H., Extramural Research Support, U.S. Gov{\&}{\#}039;t,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}P.H.S. United States},
author = {Seid, M A and Harris, K M and Traniello, J F},
journal = {J Comp Neurol},
keywords = {Age Factors Aging/*physiology Animals Ants Axons/u,Electron,Three-Dimensional/methods Microscopy,Transmission/methods Mushroom Bodies/*cytology/*g},
number = {3},
pages = {269--277},
title = {{Age-related changes in the number and structure of synapses in the lip region of the mushroom bodies in the ant Pheidole dentata}},
volume = {488}
}
@article{THEU96,
author = {Theunissen, F and Roddey, J and Stufflebeam, S and Clague, H and Miller, J},
journal = {Journal of Neurophysiology},
pages = {1345--1364},
title = {{Information theoretic analysis of dynamical encoding by four primary sensory interneurons in the cricket cercal system}},
volume = {75},
year = {1996}
}
@article{MM03,
author = {Morrow, M and Miller, L},
journal = {Journal of Neurophysiology},
title = {{Prediction of muscle activity by populations of sequentially recorded primary motor cortex neurons}},
year = {2003}
}
@article{FSST97,
author = {Freund, Yoav and Seung, H Sebastian and Shamir, Eli and Tishby, Naftali},
journal = {Machine Learning},
number = {2-3},
pages = {133--168},
title = {{Selective Sampling Using the Query by Committee Algorithm}},
url = {citeseer.nj.nec.com/article/freund95selective.html},
volume = {28},
year = {1997}
}
@article{Bruno2006,
abstract = {Sensory stimuli reach the brain via the thalamocortical projection, a group of axons thought to be among the most powerful in the neocortex. Surprisingly, these axons account for only approximately 15{\%} of synapses onto cortical neurons. The thalamocortical pathway might thus achieve its effectiveness via high-efficacy thalamocortical synapses or via amplification within cortical layer 4. In rat somatosensory cortex, we measured in vivo the excitatory postsynaptic potential evoked by a single synaptic connection and found that thalamocortical synapses have low efficacy. Convergent inputs, however, are both numerous and synchronous, and intracortical amplification is not required. Our results suggest a mechanism of cortical activation by which thalamic input alone can drive cortex.},
author = {Bruno, Randy M and Sakmann, B},
doi = {10.1126/science.1124593},
issn = {1095-9203},
journal = {Science},
keywords = {Action Potentials,Animals,Axons,Axons: physiology,Dendrites,Dendrites: physiology,Electric Stimulation,Excitatory Postsynaptic Potentials,Membrane Potentials,Neural Pathways,Neurons,Neurons: physiology,Rats,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Thalamus,Thalamus: cytology,Thalamus: physiology,Vibrissae,Vibrissae: innervation,Vibrissae: physiology,Wistar},
month = {jun},
number = {5780},
pages = {1622--7},
pmid = {16778049},
title = {{Cortex is driven by weak but synchronously active thalamocortical synapses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16778049},
volume = {312},
year = {2006}
}
@article{Heiss2008,
abstract = {Sustained stimulation of sensory organs results in adaptation of the neuronal response along the sensory pathway. Whether or not cortical adaptation affects equally excitation and inhibition is poorly understood. We examined this question using patch recordings of neurons in the barrel cortex of anesthetized rats while repetitively stimulating the principal whisker. We found that inhibition adapts more than excitation, causing the balance between them to shift toward excitation. A comparison of the latency of thalamic firing and evoked excitation and inhibition in the cortex strongly suggests that adaptation of inhibition results mostly from depression of inhibitory synapses rather than adaptation in the firing of inhibitory cells. The differential adaptation of the evoked conductances that shifts the balance toward excitation may act as a gain mechanism which enhances the subthreshold response during sustained stimulation, despite a large reduction in excitation.},
author = {Heiss, Jaime E and Katz, Yonatan and Ganmor, Elad and Lampl, Ilan},
doi = {10.1523/JNEUROSCI.2646-08.2008},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Afferent Pathways,Afferent Pathways: physiology,Animals,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Inhibitory Postsynaptic Potentials,Inhibitory Postsynaptic Potentials: physiology,Mechanoreceptors,Mechanoreceptors: physiology,Neural Inhibition,Neural Inhibition: physiology,Neurons,Neurons: physiology,Patch-Clamp Techniques,Physical Stimulation,Physiological,Physiological: physiology,Rats,Sensory Thresholds,Sensory Thresholds: physiology,Somatosensory Cortex,Somatosensory Cortex: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Touch,Touch: physiology,Trigeminal Nerve,Trigeminal Nerve: physiology,Vibrissae,Vibrissae: physiology,Wistar},
month = {dec},
number = {49},
pages = {13320--30},
pmid = {19052224},
title = {{Shift in the balance between excitation and inhibition during sensory adaptation of S1 neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19052224},
volume = {28},
year = {2008}
}
@article{RUST03,
author = {Rust, N and Schwartz, O and Movshon, A and Simoncelli, E},
journal = {Neuron},
pages = {945--956},
title = {{Spatiotemporal elements of macaque {\{}V1{\}} receptive fields}},
volume = {46},
year = {2005}
}
@article{StosiekKonnerth03,
author = {Stosiek, Christoph and Garaschuk, Olga and Holthoff, Knut and Konnerth, Arthur},
journal = {Proceedings of The National Academy Of Sciences Of The United States Of America},
month = {jun},
number = {12},
pages = {7319--7324},
title = {{In vivo two-photon calcium imaging of neuronal networks}},
volume = {100},
year = {2003}
}
@article{SK97,
author = {Scott, S and Kalaska, J},
journal = {Journal of Neurophysiology},
pages = {826--852},
title = {{Reaching movements with similar hand paths but different arm orientations. {\{}I{\}}. {\{}A{\}}ctivity of individual cells in motor cortex}},
volume = {77},
year = {1997}
}
@book{LowenTeich2005,
author = {Lowen, S B and Teich, M C},
edition = {1st},
editor = {Wiley-Blackwell},
title = {{Fractal-based point processes}},
url = {http://books.google.com/books?hl=iw{\&}lr={\&}id=kSAaOXuJeEwC{\&}oi=fnd{\&}pg=PR5{\&}dq=fractal+based+point+processes{\&}ots=V4kpcrniMj{\&}sig=C-Tu2UxMY9vm-se5wTL4TD9oH2k},
year = {2005}
}
@article{DornRingach03,
author = {Dorn, Jessy D and Ringach, Dario L},
journal = {Journal of Neurophysiology},
number = {4},
pages = {2271--2278},
title = {{Estimating Membrane Voltage Correlations From Extracellular Spike Trains}},
volume = {89},
year = {2003}
}
@article{Pasquale2008,
abstract = {Dissociated cortical neurons from rat embryos cultured onto micro-electrode arrays exhibit characteristic patterns of electrophysiological activity, ranging from isolated spikes in the first days of development to highly synchronized bursts after 3-4 weeks in vitro. In this work we analyzed these features by considering the approach proposed by the self-organized criticality theory: we found that networks of dissociated cortical neurons also generate spontaneous events of spreading activity, previously observed in cortical slices, in the form of neuronal avalanches. Choosing an appropriate time scale of observation to detect such neuronal avalanches, we studied the dynamics by considering the spontaneous activity during acute recordings in mature cultures and following the development of the network. We observed different behaviors, i.e. sub-critical, critical or super-critical distributions of avalanche sizes and durations, depending on both the age and the development of cultures. In order to clarify this variability, neuronal avalanches were correlated with other statistical parameters describing the global activity of the network. Criticality was found in correspondence to medium synchronization among bursts and high ratio between bursting and spiking activity. Then, the action of specific drugs affecting global bursting dynamics (i.e. acetylcholine and bicuculline) was investigated to confirm the correlation between criticality and regulated balance between synchronization and variability in the bursting activity. Finally, a computational model of neuronal network was developed in order to interpret the experimental results and understand which parameters (e.g. connectivity, excitability) influence the distribution of avalanches. In summary, cortical neurons preserve their capability to self-organize in an effective network even when dissociated and cultured in vitro. The distribution of avalanche features seems to be critical in those cultures displaying medium synchronization among bursts and poor random spiking activity, as confirmed by chemical manipulation experiments and modeling studies.},
author = {Pasquale, V and Massobrio, P and Bologna, L L and Chiappalone, M and Martinoia, S},
doi = {10.1016/j.neuroscience.2008.03.050},
issn = {0306-4522},
journal = {Neuroscience},
keywords = {Acetylcholine,Acetylcholine: pharmacology,Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Animals,Cells,Cerebral Cortex,Cerebral Cortex: cytology,Cultured,Embryo,Mammalian,Models,Nerve Net,Nerve Net: drug effects,Nerve Net: physiology,Neurological,Neurons,Neurons: drug effects,Neurons: physiology,Rats,Time Factors},
month = {jun},
number = {4},
pages = {1354--69},
pmid = {18448256},
title = {{Self-organization and neuronal avalanches in networks of dissociated cortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18448256},
volume = {153},
year = {2008}
}
@article{WDG06,
author = {Wu, M and David, S and Gallant, J},
journal = {Annual Review of Neuroscience},
number = {1},
pages = {477--505},
title = {{COMPLETE FUNCTIONAL CHARACTERIZATION OF SENSORY NEURONS BY SYSTEM IDENTIFICATION}},
volume = {29},
year = {2006}
}
@article{HOLY97,
author = {Holy, T},
journal = {Physical Review Letters},
pages = {3545--3548},
title = {{The analysis of data from continuous probability distributions}},
volume = {79},
year = {1997}
}
@article{Murphy2009,
abstract = {In cerebral cortex, ongoing activity absent a stimulus can resemble stimulus-driven activity in size and structure. In particular, spontaneous activity in cat primary visual cortex (V1) has structure significantly correlated with evoked responses to oriented stimuli. This suggests that, from unstructured input, cortical circuits selectively amplify specific activity patterns. Current understanding of selective amplification involves elongation of a neural assembly's lifetime by mutual excitation among its neurons. We introduce a new mechanism for selective amplification without elongation of lifetime: "balanced amplification." Strong balanced amplification arises when feedback inhibition stabilizes strong recurrent excitation, a pattern likely to be typical of cortex. Thus, balanced amplification should ubiquitously contribute to cortical activity. Balanced amplification depends on the fact that individual neurons project only excitatory or only inhibitory synapses. This leads to a hidden feedforward connectivity between activity patterns. We show in a detailed biophysical model that this can explain the cat V1 observations.},
annote = {2010IInum11.3},
author = {Murphy, Brendan K and Miller, Kenneth D},
doi = {10.1016/j.neuron.2009.02.005},
issn = {1097-4199},
journal = {Neuron},
keywords = {Algorithms,Animals,Brain Mapping,Cats,Electrophysiology,Evoked Potentials,Evoked Potentials: physiology,Linear Models,Models,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Presynaptic,Presynaptic: physiology,Receptors,Synapses,Synapses: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
month = {feb},
number = {4},
pages = {635--48},
pmid = {19249282},
publisher = {Elsevier Ltd},
title = {{Balanced amplification: a new mechanism of selective amplification of neural activity patterns.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2667957{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pubmed/19249282 http://dx.doi.org/10.1016/j.neuron.2009.02.005},
volume = {61},
year = {2009}
}
@inproceedings{Pillow2007,
author = {Pillow, J W and Latham, P},
booktitle = {Neural Information Processing Systems},
keywords = {Estimation},
mendeley-tags = {Estimation},
pages = {1--9},
title = {{Neural characterization in partially observed populations of spiking neurons}},
year = {2007}
}
@article{Vogelstein08,
author = {Vogelstein, J and Babadi, B and Watson, B and Yuste, R and Paninski, L},
journal = {Statistical analysis of neural data (SAND) conference},
title = {{Fast nonnegative deconvolution via tridiagonal interior-point methods, applied to calcium fluorescence data.}},
year = {2008}
}
@article{Mark2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1107.2446v1},
author = {Mark, Brian L and Ephraim, Yariv},
eprint = {arXiv:1107.2446v1},
journal = {Computer Engineering},
keywords = {continuous-time bivariate markov chain,em algorithm,markov modulated processes,parameter estimation},
pages = {1--19},
title = {{An EM Algorithm for Continuous-time Bivariate Markov Chains}},
year = {2011}
}
@article{Yaglom1957,
author = {Yaglom, AM},
journal = {Theory of Probability and its Applications},
number = {x},
pages = {273},
title = {{Some classes of random fields in n -dimensional space, related to stationary random processes}},
url = {http://link.aip.org/link/?TPRBAU/2/273/1},
volume = {2},
year = {1957}
}
@incollection{Opper1998,
author = {Opper, M and Winther, O},
booktitle = {On-line Learning in Neural Networks},
title = {{A Bayesian approach to on-line learning}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=iu2v6C5nx4oC{\&}oi=fnd{\&}pg=PA363{\&}dq=a+bayesian+approach+to+on-line+learning{\&}ots=oxLfQHgQNa{\&}sig=GxtFYUHcY4yQ48DvS{\_}JRtGZyLvE},
year = {1998}
}
@article{marom2009adaptive,
annote = {2008num1},
author = {Marom, S},
journal = {Frontiers in Computational Neuroscience},
publisher = {Frontiers Research Foundation},
title = {{Adaptive transition rates in excitable membranes}},
volume = {3},
year = {2009}
}
@article{Freeman2016a,
abstract = {The loss surface of deep neural networks has recently attracted interest in the optimization and machine learning communities as a prime example of high-dimensional non-convex problem. Some insights were recently gained using spin glass models and mean-field approximations, but at the expense of strongly simplifying the nonlinear nature of the model. In this work, we do not make any such assumption and study conditions on the data distribution and model architecture that prevent the existence of bad local minima. Our theoretical work quantifies and formalizes two important $\backslash$emph{\{}folklore{\}} facts: (i) the landscape of deep linear networks has a radically different topology from that of deep half-rectified ones, and (ii) that the energy landscape in the non-linear case is fundamentally controlled by the interplay between the smoothness of the data distribution and model over-parametrization. These results are in accordance with empirical practice and recent literature. {\%}Together with {\%}recent results that rigorously establish that no gradient descent can {\%}get stuck on saddle points, we conclude that gradient descent converges {\%}to a global optimum in deep rectified networks. The conditioning of gradient descent is the next challenge we address. We study this question through the geometry of the level sets, and we introduce an algorithm to efficiently estimate the regularity of such sets on large-scale networks. Our empirical results show that these level sets remain connected throughout all the learning phase, suggesting a near convex behavior, but they become exponentially more curvy as the energy level decays, in accordance to what is observed in practice with very low curvature attractors.},
archivePrefix = {arXiv},
arxivId = {1611.01540},
author = {Freeman, C. Daniel and Bruna, Joan},
eprint = {1611.01540},
journal = {ArXiv: 1611.01540},
title = {{Topology and Geometry of Deep Rectified Network Optimization Landscapes}},
url = {http://arxiv.org/abs/1611.01540},
year = {2016}
}
@article{WS04,
author = {Webber, R and Stanley, G},
journal = {Journal of Neurophysiology},
pages = {2010--2022},
title = {{Nonlinear encoding of tactile patterns in the barrel cortex}},
volume = {91},
year = {2004}
}
@article{Debanne2003,
annote = {

2010IIInum30},
author = {Debanne, Dominique and Russier, Micha{\"{e}}l},
doi = {10.1113/jphysiol.2002.037812},
issn = {0022-3751},
journal = {The Journal of physiology},
keywords = {Animals,Axons,Axons: physiology,Axons: ultrastructure,Brain,Brain: physiology,Neural Conduction,Neural Conduction: physiology,Neurons,Neurons: physiology,Neurons: ultrastructure,Rats},
month = {may},
number = {Pt 3},
pages = {663},
pmid = {12640012},
title = {{Axonal propagation: does the spike stop here?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2342886{\&}tool=pmcentrez{\&}rendertype=abstract http://jp.physoc.org},
volume = {548},
year = {2003}
}
@article{KaltenbachZhang98,
author = {Kaltenbach, J A and Godfrey, D A and Neumann, J B and McCaslin, D L and Afman, C E and Zhang, J},
journal = {Hearing Research},
month = {oct},
number = {1-2},
pages = {78--84},
title = {{Changes in spontaneous neural activity in the dorsal cochlear nucleus following exposure to intense sound: relation to threshold shift}},
volume = {124},
year = {1998}
}
@article{Lazar2010,
abstract = {The recovery of (weak) stimuli encoded with a population of Hodgkin-Huxley neurons is investigated. In the absence of a stimulus, the Hodgkin-Huxley neurons are assumed to be tonically spiking. The methodology employed calls for 1) finding an input-output (I/O) equivalent description of the Hodgkin-Huxley neuron and 2) devising a recovery algorithm for stimuli encoded with the I/O equivalent neuron(s). A Hodgkin-Huxley neuron with multiplicative coupling is I/O equivalent with an Integrate-and-Fire neuron with a variable threshold sequence. For bandlimited stimuli a perfect recovery of the stimulus can be achieved provided that a Nyquist-type rate condition is satisfied. A Hodgkin-Huxley neuron with additive coupling and deterministic conductances is first-order I/O equivalent with a Project-Integrate-and-Fire neuron that integrates a projection of the stimulus on the phase response curve. The stimulus recovery is formulated as a spline interpolation problem in the space of finite length bounded energy signals. A Hodgkin-Huxley neuron with additive coupling and stochastic conductances is shown to be first-order I/O equivalent with a Project-Integrate-and-Fire neuron with random thresholds. For stimuli modeled as elements of Sobolev spaces the reconstruction algorithm minimizes a regularized quadratic optimality criterion. Finally, all previous recovery results of stimuli encoded with Hodgkin-Huxley neurons with multiplicative and additive coupling, and deterministic and stochastic conductances are extended to stimuli encoded with a population of Hodgkin-Huxley neurons.},
author = {Lazar, A A},
doi = {10.1109/TIT.2009.2037040},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {821--837},
title = {{Population Encoding With Hodgkin Huxley Neurons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5420291},
volume = {56},
year = {2010}
}
@article{Fang2012,
author = {Fang, Huijuan and Luo, Jiliang and Wang, Fei},
doi = {10.1016/S1004-9541(12)60611-9},
issn = {10049541},
journal = {Chinese Journal of Chemical Engineering},
keywords = {learning algorithm,learning rate adaptation,spiking neural networks,tennessee eastman process},
month = {dec},
number = {6},
pages = {1219--1224},
title = {{Fast Learning in Spiking Neural Networks by Learning Rate Adaptation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1004954112606119},
volume = {20},
year = {2012}
}
@article{Wesson2008,
abstract = {To gain insight into which parameters of neural activity are important in shaping the perception of odors, we combined a behavioral measure of odor perception with optical imaging of odor representations at the level of receptor neuron input to the rat olfactory bulb. Instead of the typical test of an animal's ability to discriminate two familiar odorants by exhibiting an operant response, we used a spontaneously expressed response to a novel odorant-exploratory sniffing-as a measure of odor perception. This assay allowed us to measure the speed with which rats perform spontaneous odor discriminations. With this paradigm, rats discriminated and began responding to a novel odorant in as little as 140 ms. This time is comparable to that measured in earlier studies using operant behavioral readouts after extensive training. In a subset of these trials, we simultaneously imaged receptor neuron input to the dorsal olfactory bulb with near-millisecond temporal resolution as the animal sampled and then responded to the novel odorant. The imaging data revealed that the bulk of the discrimination time can be attributed to the peripheral events underlying odorant detection: receptor input arrives at the olfactory bulb 100-150 ms after inhalation begins, leaving only 50-100 ms for central processing and response initiation. In most trials, odor discrimination had occurred even before the initial barrage of receptor neuron firing had ceased and before spatial maps of activity across glomeruli had fully developed. These results suggest a coding strategy in which the earliest-activated glomeruli play a major role in the initial perception of odor quality, and place constraints on coding and processing schemes based on simple changes in spike rate.},
author = {Wesson, Daniel W and Carey, Ryan M and Verhagen, Justus V and Wachowiak, Matt},
doi = {10.1371/journal.pbio.0060082},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Animal,Animals,Behavior,Female,Long-Evans,Odorant,Odorant: metabolism,Odors,Olfactory Bulb,Olfactory Bulb: metabolism,Olfactory Pathways,Olfactory Pathways: physiology,Perception,Perception: physiology,Rats,Receptors,Spike time neural coding},
mendeley-tags = {Spike time neural coding},
month = {apr},
number = {4},
pages = {e82},
pmid = {18399719},
title = {{Rapid encoding and perception of novel odors in the rat.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2288628{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2008}
}
@article{Riedler2011,
author = {Riedler, M.G. G},
keywords = {neuron},
mendeley-tags = {neuron},
number = {July},
title = {{Spatio-temporal Stochastic Hybrid Models of Biological Excitable Membranes}},
url = {http://www.ma.hw.ac.uk/{~}mgr2/riedler{\_}thesis{\_}final{\_}onesided.pdf},
year = {2011}
}
@article{HT06,
author = {Holcman, D and Tsodyks, M},
journal = {PLoS Comput Biol},
title = {{The Emergence of Up and Down States in Cortical Networks.}},
volume = {2},
year = {2006}
}
@article{Ranganath2014,
author = {Ranganath, Rajesh and Gerrish, Sean and Blei, David M},
journal = {Aistats},
title = {{Black Box Variational Inference}},
volume = {33},
year = {2014}
}
@article{Wu07,
author = {Wu, W and Kulkarni, J and Hatsopoulos, N and Paninski, L},
journal = {IEEE Trans. Biomed. Eng.},
title = {{Neural decoding of goal-directed movements using a linear statespace model with hidden states}},
volume = {In press},
year = {2008}
}
@article{Bargh2008,
annote = {2010IInum12.10},
author = {Bargh, JA J.A.},
journal = {Are we free?: psychology and free will},
pages = {128},
publisher = {Oxford University Press, USA},
title = {{Free Will Is Un-natural}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id={\_}t4k{\_}r7-2jgC{\&}oi=fnd{\&}pg=PA128{\&}dq=Free+Will+Is+Un-natural{\&}ots=I4aBqAFm96{\&}sig=2MpEShJCaKXVAcpa3iLXwi6eoDk http://books.google.com/books?hl=en{\&}lr={\&}id={\_}t4k{\_}r7-2jgC{\&}oi=fnd{\&}pg=PA128{\&}dq=Free+Will+Is+Un-natural{\&}ots=I3cuqyNsc9{\&}sig=QdA321vW{\_}{\_}hwW4HPY4vziqp2fNw},
year = {2008}
}
@article{RiceYoung92,
author = {Rice, J J and May, B J and Spirou, G A and Young, E D},
journal = {Hearing Research},
month = {mar},
number = {2},
pages = {132--152},
title = {{Pinna-based spectral cues for sound localization in cat}},
volume = {58},
year = {1992}
}
@article{Ferster1996,
author = {Ferster, D and Chung, S and Wheat, H},
journal = {Nature},
title = {{Orientation selectivity of thalamic input to simple cells of cat visual cortex}},
url = {http://neurosciences.us/courses/systems/CentralVision/ferster2.pdf},
year = {1996}
}
@article{KettunenGan02,
abstract = {The use of fluorescence-based calcium indicators has, over the years,

unraveled important calcium-dependent mechanisms underlying neuronal

function and development. However, difficulties associated with the

loading of calcium indicators have limited their widespread use,

particularly for the study of neuronal processing in the adult nervous

system. Here, we show that in the central and peripheral nervous

systems, populations of neurons and their processes, including dendritic

spines and filopodia, can be labeled rapidly and efficiently by delivering

calcium indicator-coated particles using a 'gene gun'. Importantly,

neuronal labeling occurred both in vitro and in vivo, and across

a wide range of ages and preparations. The labeled cells demonstrate

spontaneous and evoked calcium transients, indicating that particle-mediated

delivery is not deleterious to neuronal function. Furthermore, unlike

loading with patch pipettes, cytoplasmic content is preserved following

ballistic loading. This enables the study of calcium-dependent second

messenger pathways without loss of signaling components. The ballistic

delivery of calcium indicators thus opens up many new avenues for

further exploration of the structure and function of the nervous

system from single spines to neuronal networks.},
author = {Kettunen, Petronella and Demas, Jay and Lohmann, Christian and Kasthuri, Narayanan and Gong, Yandao and Wong, Rachel O L and Gan, Wen-Biao},
journal = {J Neurosci Methods},
keywords = {Animals; Biolistics; Calcium; Chick Embryo; Cultur,Wistar; Retina; Staining and Labeling; Superior C},
month = {sep},
number = {1},
pages = {37--43},
pmid = {12234633},
title = {{Imaging calcium dynamics in the nervous system by means of ballistic delivery of indicators.}},
volume = {119},
year = {2002}
}
@article{VONVAUPELKLEIN2000,
author = {Liebovitch, LS},
journal = {CRUSTACEANA-INTERNATIONAL JOURNAL OF CRUSTACEAN RESEARCH-},
number = {1},
pages = {126--126},
publisher = {EJ BRILL},
title = {{Fractals and chaos simplified for the life sciences}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Liebovitch+-+Fractals+And+Chaos+Simplified+For+The+Life+Sciences{\#}0 http://www.getcited.org/pub/100235644},
volume = {73},
year = {1998}
}
@article{FarberGrinvald83,
author = {Farber, I C and Grinvald, A},
journal = {Science},
pages = {1025--1027},
title = {{Identification of presynaptic neurons by laser photostimulation.}},
volume = {222},
year = {1983}
}
@article{Chich01,
author = {Chichilnisky, E J},
journal = {Network: Computation in Neural Systems},
pages = {199--213},
title = {{A simple white noise analysis of neuronal light responses}},
volume = {12},
year = {2001}
}
@article{KV01,
author = {Kass, R and Ventura, V},
journal = {Neural Comp.},
pages = {1713--1720},
title = {{A Spike-Train Probability Model}},
volume = {13},
year = {2001}
}
@article{Abbott2000,
abstract = {Synaptic plasticity provides the basis for most models of learning, memory and development in neural circuits. To generate realistic results, synapse-specific Hebbian forms of plasticity, such as long-term potentiation and depression, must be augmented by global processes that regulate overall levels of neuronal and network activity. Regulatory processes are often as important as the more intensively studied Hebbian processes in determining the consequences of synaptic plasticity for network function. Recent experimental results suggest several novel mechanisms for regulating levels of activity in conjunction with Hebbian synaptic modification. We review three of them-synaptic scaling, spike-timing dependent plasticity and synaptic redistribution-and discuss their functional implications.},
annote = {2010IIInum14},
author = {Abbott, L F and Nelson, S B},
doi = {10.1038/81453},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Glutamate,Glutamate: metabolism,Humans,Long-Term Potentiation,Long-Term Potentiation: physiology,Models,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: cytology,Neurons: physiology,Receptors,Synapses,Synapses: physiology,Synapses: ultrastructure,Synaptic Transmission,Synaptic Transmission: physiology,synapse},
mendeley-tags = {synapse},
month = {nov},
number = {november},
pages = {1178--83},
pmid = {11127835},
title = {{Synaptic plasticity: taming the beast}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11127835},
volume = {3 Suppl},
year = {2000}
}
@article{bresler2004postsynaptic,
annote = {2008num31},
author = {Bresler, T and Shapira, M and Boeckers, T and Dresbach, T and Futter, M and Garner, C C and Rosenblum, K and Gundelfinger, E D and Ziv, N E},
journal = {Journal of Neuroscience},
number = {6},
pages = {1507},
publisher = {Soc Neuroscience},
title = {{Postsynaptic density assembly is fundamentally different from presynaptic active zone assembly}},
volume = {24},
year = {2004}
}
@article{Hiratani2012,
abstract = {The postsynaptic potentials of pyramidal neurons have a non-Gaussian amplitude distribution with a heavy tail in both hippocampus and neocortex. Such distributions of synaptic weights were recently shown to generate spontaneous internal noise optimal for spike propagation in recurrent cortical circuits. However, whether this internal noise generation by heavy-tailed weight distributions is possible for and beneficial to other computational functions remains unknown. To clarify this point, we construct an associative memory (AM) network model of spiking neurons that stores multiple memory patterns in a connection matrix with a lognormal weight distribution. In AM networks, non-retrieved memory patterns generate a cross-talk noise that severely disturbs memory recall. We demonstrate that neurons encoding a retrieved memory pattern and those encoding non-retrieved memory patterns have different subthreshold membrane-potential distributions in our model. Consequently, the probability of responding to inputs at strong synapses increases for the encoding neurons, whereas it decreases for the non-encoding neurons. Our results imply that heavy-tailed distributions of connection weights can generate noise useful for AM recall.},
author = {Hiratani, Naoki and Teramae, Jun-Nosuke and Fukai, T},
doi = {10.3389/fncom.2012.00102},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {attractor,hippocampus,integrate-and-fire,integrate-and-fire, storage capacity, stochastic r,mean-field,stochastic resonance,storage capacity},
month = {jan},
number = {February},
pages = {102},
pmid = {23403536},
title = {{Associative memory model with long-tail-distributed Hebbian synaptic connections.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3566427{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2012}
}
@article{Navlakha2011,
author = {Navlakha, Saket and Bar-Joseph, Z.},
doi = {10.1038/msb.2011.78},
issn = {1744-4292},
journal = {Molecular Systems Biology},
keywords = {algorithms,biological coordination,interaction networks},
month = {nov},
number = {546},
pages = {1--11},
publisher = {Nature Publishing Group},
title = {{Algorithms in nature: the convergence of systems biology and computational thinking}},
url = {http://www.nature.com/doifinder/10.1038/msb.2011.78},
volume = {7},
year = {2011}
}
@article{Spiegelhalter02,
author = {Spiegelhalter, David J and Best, Nicola G and Carlin, Bradley P and van der Linde, Angelika},
journal = {Journal Of The Royal Statistical Society Series B},
month = {oct},
number = {4},
pages = {583--639},
title = {{Bayesian measures of model complexity and fit}},
volume = {64},
year = {2002}
}
@article{MSW98,
author = {Moeller, J and Syversveen, A and Waagepetersen, R},
journal = {Scandinavian Journal of Statistics},
pages = {451--482},
title = {{Log-{\{}G{\}}aussian {\{}C{\}}ox processes}},
volume = {25},
year = {1998}
}
@article{Colquhoun1975,
author = {Colquhoun, D and Dionne, VE and Steinbach, JH},
title = {{Conductance of channels opened by acetylcholine-like drugs in muscle end-plate}},
url = {http://www.nature.com/nature/journal/v253/n5488/abs/253204a0.html},
year = {1975}
}
@article{Huang2013,
author = {Huang, Yandong and R{\"{u}}diger, Sten and Shuai, Jianwei},
doi = {10.1016/j.physleta.2013.10.008},
issn = {03759601},
journal = {Physics Letters A},
month = {oct},
pages = {8--12},
publisher = {Elsevier B.V.},
title = {{Langevin approach for stochastic Hodgkin-Huxley dynamics with discretization of channel open fraction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0375960113009262},
volume = {1},
year = {2013}
}
@article{HJ04,
author = {Herberts, T and Jensen, U},
journal = {Scandinavian Journal of Statistics},
pages = {347--366},
title = {{Optimal detection of a change Point in a Poisson process for different observation schemes}},
volume = {31},
year = {2004}
}
@article{Pnevmatikakis2012,
abstract = {We discuss methods for fast spatiotemporal smoothing of calcium signals in dendritic trees, given single-trial, spatially localized imaging data obtained via multi-photon microscopy. By analyzing the dynamics of calcium binding to probe molecules and the effects of the imaging procedure, we show that calcium concentration can be estimated up to an affine transformation, i.e., an additive and multiplicative constant. To obtain a full spatiotemporal estimate, we model calcium dynamics within the cell using a functional approach. The evolution of calcium concentration is represented through a smaller set of hidden variables that incorporate fast transients due to backpropagating action potentials (bAPs), or other forms of stimulation. Because of the resulting state space structure, inference can be done in linear time using forward-backward maximum-a-posteriori methods. Non-negativity constraints on the calcium concentration can also be incorporated using a log-barrier method that does not affect the computational scaling. Moreover, by exploiting the neuronal tree structure we show that the cost of the algorithm is also linear in the size of the dendritic tree, making the approach applicable to arbitrarily large trees. We apply this algorithm to data obtained from hippocampal CA1 pyramidal cells with experimentally evoked bAPs, some of which were paired with excitatory postsynaptic potentials (EPSPs). The algorithm recovers the timing of the bAPs and provides an estimate of the induced calcium transient throughout the tree. The proposed methods could be used to further understand the interplay between bAPs and EPSPs in synaptic strength modification. More generally, this approach allows us to infer the concentration on intracellular calcium across the dendritic tree from noisy observations at a discrete set of points in space.},
author = {Pnevmatikakis, E A and Kelleher, K and Chen, R and Saggau, P and Josi{\'{c}}, K and Paninski, L},
doi = {10.1371/journal.pcbi.1002569},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Calcium,Calcium Signaling,Calcium Signaling: physiology,Calcium: analysis,Calcium: metabolism,Computational Biology,Computational Biology: methods,Computer-Assisted,Dendrites,Dendrites: chemistry,Dendrites: metabolism,Fluorescence,Hippocampus,Hippocampus: cytology,Hippocampus: metabolism,Microscopy,Models,Multiphoton,Neurological,Rats,Reproducibility of Results,Signal Processing},
number = {6},
pages = {e1002569},
pmid = {22787437},
title = {{Fast spatiotemporal smoothing of calcium measurements in dendritic trees.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3386185{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {8},
year = {2012}
}
@article{Wikle99,
author = {Wikle, C K and Cressie, N},
journal = {Biometrika},
number = {4},
pages = {815--829},
title = {{A dimension-reduced approach to space-time Kalman filtering}},
volume = {86},
year = {1999}
}
@article{Tsai|2006|,
abstract = {We present two fast and simple algorithms for approximating the distance
function for given isolated points on uniform grids. The algorithms
are then generalized to compute the distance to piecewise linear
objects. By incorporating the geometry of Huygen{\"{i}}¾'s principle in
the reverse order with the classical viscosity solution theory for
the eikonal equation |$\backslash$grad u|=1 the algorithms become almost purely
algebraic and yield very accurate approximations. The generalized
closest point formulation used in the second algorithm provides a
framework for further extension to compute the distance accurately
to smooth geometric objects on different grid geometries, without
the construction of the Voronoi diagrams. This method provides a
fast and simple translator of data commonly given in computational
geometry to the volumetric representation used in level set methods.},
annote = {The paper presents a form of fast marching algorithm modified to{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}give better accuracy on line- and point-segments, as claimed, as{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}compared to regular fast marching method.},
author = {Tsai, Y.-H. R},
keywords = {computational,distance function,fast marching,image processing},
title = {{Rapid and accurate computation of the distance function using grids.}}
}
@article{Ram|2006|,
author = {Ram, S and Ward, E S and Ober, R J},
journal = {PNAS},
number = {12},
pages = {4457},
title = {{Beyond Rayleigh's criterion: a resolution measure with application to single-molecule microscopy.}},
volume = {103}
}
@article{WoodGurneyWilson04,
author = {Wood, R and Gurney, K and Wilson, C},
journal = {Neurocomputing},
pages = {1109--1116},
title = {{A novel parameter optimisation technique for compartmental models applied to a model of a striatal medium spiny neuron}},
volume = {58-60},
year = {2004}
}
@article{Sprecher|1972|,
annote = {The paper improves original Kolmogorov{\&}{\#}039;s superposition theorem, inwhich it is said that any n-dimensional continuous function can berepresented as superposition of 2n+1 (some) continuous 1D functionsg of superpositions of n continuous 1D functions psi (possibly differentfor each of the functions g), by showing that (2n+1)*n continuousfunctions psi may be replaced by translations of single functionPsi from Lip(1) (function is in Lip(a) if |f(t1)-f(t2)|},
author = {Sprecher, D A},
journal = {Journal of mathematical anslysis and applications},
keywords = {Kolmogorov theorem,function representation by superposition,interpolation,many dimensional,mathematics},
pages = {208},
title = {{An improvement in the superposition theorem of Kolmogorov}},
volume = {38}
}
@article{NM00,
author = {Nelson, J and Movellan, J},
journal = {NIPS},
title = {{Active inference in concept learning}},
year = {2000}
}
@article{Lazar2003,
author = {Lazar, A A and Toth, L T},
journal = {Acoustics, Speech, and Signal Processing},
pages = {709--712},
title = {{Time encoding and perfect recovery of bandlimited signals}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1201780},
volume = {VI},
year = {2003}
}
@article{Chen|2006|,
author = {Chen, B L and Hall, D H and Chlovskii, D B},
journal = {PNAS},
pages = {4723--4728},
title = {{Wiring optimization can relate neuronal structure and function.}},
volume = {103}
}
@article{Andersen|1971|,
author = {Andersen, P and Bliss, T V and Skrede, K K},
journal = {Exp Brain Res},
pages = {222--238},
title = {{Lamellar organization of hippocampal excitatory pathways}},
volume = {13}
}
@article{Frieden1989,
abstract = {It is shown that the Helmholtz wave equation follows from a new uncertainty principle: Given, as data, the position of a photon in an unknown diffraction pattern, the estimated position of the centroid of the pattern will suffer minimum precision. This implies a maximally spread out diffraction pattern, obeying a principle of minimum Fisher information. The minimum is constrained by knowledge of the refractive-index function n(x, y, z) of the medium through a requirement that the mean-square spatial phase gradient across the medium should be generally nonzero. Operationally the principle works directly with intensities and not complex amplitudes. As a practical matter the numerical use of the intensity-based principle might permit a widening of the known scope of solutions to diffraction problems.},
author = {Frieden, B R},
issn = {0146-9592},
journal = {Optics letters},
month = {feb},
number = {4},
pages = {199--201},
pmid = {19749868},
title = {{Fisher information as the basis for diffraction optics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19749868},
volume = {14},
year = {1989}
}
@article{EscolaPaninski07,
author = {Escola, Sean and Paninski, Liam},
journal = {submitted},
title = {{Hidden Markov models capture the complex stimulus-response relationships of multi-state neurons}},
year = {2007}
}
@article{BAS59,
author = {Basharin, G},
journal = {Theory of Probability and its Applications},
pages = {333--336},
title = {{On a statistical estimate for the entropy of a sequence of independent random variables}},
volume = {4},
year = {1959}
}
@article{Rosenblatt1958,
author = {Rosenblatt, F},
journal = {Psychological review},
number = {6},
pages = {386},
title = {{The perceptron: a probabilistic model for information storage and organization in the brain.}},
url = {http://psycnet.apa.org/journals/rev/65/6/386/},
volume = {65},
year = {1958}
}
@inproceedings{Kawaguchi2016,
abstract = {In this paper, we prove a conjecture published in 1989 and also partially address an open problem announced at the Conference on Learning Theory (COLT) 2015. For an expected loss function of a deep nonlinear neural network, we prove the following statements under the independence assumption adopted from recent work: 1) the function is non-convex and non-concave, 2) every local minimum is a global minimum, 3) every critical point that is not a global minimum is a saddle point, and 4) the property of saddle points differs for shallow networks (with three layers) and deeper networks (with more than three layers). Moreover, we prove that the same four statements hold for deep linear neural networks with any depth, any widths and no unrealistic assumptions. As a result, we present an instance, for which we can answer to the following question: how difficult to directly train a deep model in theory? It is more difficult than the classical machine learning models (because of the non-convexity), but not too difficult (because of the nonexistence of poor local minima and the property of the saddle points). We note that even though we have advanced the theoretical foundations of deep learning, there is still a gap between theory and practice.},
archivePrefix = {arXiv},
arxivId = {1605.07110},
author = {Kawaguchi, Kenji},
booktitle = {NIPS},
eprint = {1605.07110},
title = {{Deep Learning without Poor Local Minima}},
url = {http://arxiv.org/abs/1605.07110},
year = {2016}
}
@book{OKS02,
author = {Oksendal, B},
publisher = {Springer},
title = {{Stochastic Differential Equations}},
year = {2002}
}
@article{Hering2004a,
abstract = {T-type calcium channels (the Ca(V)3 channel family) are involved in defining the resting membrane potential and in neuronal activities such as oscillations and rebound depolarization. Their physiological roles depend upon the channel activation and inactivation kinetics. A fast inactivation that stops the ionic flux of calcium in tens of milliseconds has already been described in both native and heterologously expressed channels. Here, using HEK 293 cells expressing the rat Ca(V)3.1 channel and whole-cell voltage clamp, we investigate an additional inactivation process, which can be distinguished from the previously described fast inactivation by its slow time course of recovery from inactivation (tau= 1 s) and by its sensitivity to external calcium. Steady-state slow inactivation is voltage dependent around the resting membrane potential (the potential of half-inactivation (V(0.5)) =-70 mV, slope factor = 7.4 mV) and can reduce the calcium current by up to 50{\%}. Near resting potential, the slow inactivation displays a half-time of induction of tens of seconds. The slow inactivation therefore modulates the availability of T-type calcium channels depending upon recent cell history, providing a mechanism to store information in a time scale of seconds.},
author = {Hering, Julien and Feltz, Anne and Lambert, R{\'{e}}gis C},
doi = {10.1113/jphysiol.2003.054361},
issn = {0022-3751},
journal = {The Journal of physiology},
keywords = {Algorithms,Axons,Calcium,Calcium Channel Blockers,Calcium Channel Blockers: pharmacology,Calcium Channels,Calcium: physiology,Cell Line,Electric Stimulation,Electrophysiology,Humans,Kinetics,Membrane Potentials,Membrane Potentials: physiology,Neurons,Neurons: physiology,Patch-Clamp Techniques,T-Type,T-Type: drug effects},
month = {mar},
number = {Pt 2},
pages = {331--44},
pmid = {14694144},
title = {{Slow inactivation of the Ca(V)3.1 isotype of T-type calcium channels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14694144 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1664842{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {555},
year = {2004}
}
@article{Zhou2010,
author = {Zhou, Hongchao and Chen, Ho-Lin and Bruck, J},
doi = {10.1109/ISIT.2010.5513754},
isbn = {978-1-4244-7892-7},
journal = {2010 IEEE International Symposium on Information Theory},
month = {jun},
pages = {1330--1334},
publisher = {Ieee},
title = {{On the synthesis of stochastic flow networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5513754},
year = {2010}
}
@article{Takemura2013,
author = {Takemura, Shin-ya and Bharioke, Arjun and Lu, Zhiyuan and Nern, Aljoscha and Vitaladevuni, Shiv and Rivlin, Patricia K. and Katz, William T. and Olbris, Donald J. and Plaza, Stephen M. and Winston, Philip and Zhao, Ting and Horne, Jane Anne and Fetter, Richard D. and Takemura, Satoko and Blazek, Katerina and Chang, Lei-Ann and Ogundeyi, Omotara and Saunders, Mathew A. and Shapiro, Victor and Sigmund, Christopher and Rubin, Gerald M. and Scheffer, Louis K. and Meinertzhagen, Ian A. and Chklovskii, D B},
doi = {10.1038/nature12450},
issn = {0028-0836},
journal = {Nature},
month = {aug},
number = {7461},
pages = {175--181},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nature},
title = {{A visual motion detection circuit suggested by Drosophila connectomics}},
url = {http://dx.doi.org/10.1038/nature12450},
volume = {500},
year = {2013}
}
@article{Mayoraz1996,
abstract = {Quantization of the parameters of a Perceptron is a central problem in hardware implementation of neural networks using a numerical technology. A neural model with each weight limited to a small integer range will require little surface of silicon. Moreover, according to Occam's razor principle, better generalization abilities can be expected from a simpler computational model. The price to pay for these benefits lies in the difficulty to train these kind of networks. This paper proposes essentially two new ideas for constructive training algorithms, and demonstrates their efficiency for the generation of feedforward networks composed of Boolean threshold gates with discrete weights. A proof of the convergence of these algorithms is given. Some numerical experiments have been carried out and the results are presented in terms of the size of the generated networks and of their generalization abilities.},
author = {Mayoraz, E and Aviolat, F},
issn = {0129-0657},
journal = {International journal of neural systems},
keywords = {Algorithms,Cybernetics,Neural Networks (Computer),Probability Learning},
number = {2},
pages = {149--66},
pmid = {8823625},
title = {{Constructive training methods for feedforward neural networks with binary weights.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8823625},
volume = {7},
year = {1996}
}
@article{Wythe|2001|,
abstract = {Strong lensing is a powerful probe of the distribution of matter in
the cores of clusters of galaxies. Recent studies suggest that the
cold dark matter model predicts cores that are denser than those
observed in galaxies, groups, and clusters. One possible resolution
of the discrepancy is that the dark matter has strong interactions
(SIDM), which leads to lower central densities. A generalized form
of the Navarro, Frenk, {\&} White profile (Zhao profile) can be used
to describe these halos. In this paper we examine gravitational lensing
statistics for this class of model. The optical depth to multiple
imaging is a very sensitive function of the profile parameters in
the range of interest for SIDM halos around clusters of galaxies.
Less concentrated profiles, which result from larger self-interaction
cross sections, can produce many fewer lensed pairs. Furthermore,
profiles that result in a small optical depth exhibit reduced typical
splittings, but produce multiple images that are more highly magnified.
However, the resulting increased magnification bias does not alter
our conclusions. We find that lensing statistics based on profile
parameters obtained from fits out to the virial radius are dependent
on the minimization scheme adopted, and may be seriously in error.
However, profile fits weighted toward the core region have parameter
degeneracies that are approximately equivalent to those for strong-lensing
cross sections. Lensing statistics provide a powerful test for SIDM.
More realistic and observationally oriented calculations remain to
be done; however, larger self-interaction cross sections may well
be ruled out by the very existence of strong lenses on galaxy cluster
scales. The inclusion of centrally dominant cluster galaxies should
boost the cross section to multiple imaging. However, our preliminary
calculations suggest that the additional multiple imaging rate is
small with respect to the differences in multiple imaging rate for
different halo profiles. In future statistical studies, it will be
important to properly account for the scatter among halo profiles,
since the optical depth to multiple imaging is dominated by the most
concentrated members of a cluster population.},
author = {Wythe, J S B and Turner, E L and Sperghl, D N},
journal = {The astrophysical journal},
keywords = {astrophysics,dark matter,gravitational lensing,interaction,physics,strongly interacting dark matter,survey},
pages = {504},
title = {{Gravitational Lens Statistics for Generalized NFW profiles: parameter degeneracy and implications for self-interacting cold dark matter}},
volume = {555}
}
@article{RhodeKettner87,
author = {Rhode, W S and Kettner, R E},
journal = {Journal of Neurophysiology},
month = {feb},
number = {2},
pages = {414--442},
title = {{Physiological study of neurons in the dorsal and posteroventral cochlear nucleus of the unanesthetized cat}},
volume = {57},
year = {1987}
}
@article{L.O.Chua,
author = {Chua, L},
journal = {Applied Physics A},
number = {4},
pages = {765--783},
title = {{Resistance switching memories are memristors}},
url = {http://link.springer.com/article/10.1007/s00339-011-6264-9},
volume = {102},
year = {2011}
}
@article{Wark2009,
abstract = {Adaptation is a hallmark of sensory function. Adapting optimally requires matching the dynamics of adaptation to those of changes in the stimulus distribution. Here we show that the dynamics of adaptation in the responses of mouse retinal ganglion cells depend on stimulus history. We hypothesized that the accumulation of evidence for a change in the stimulus distribution controls the dynamics of adaptation, and developed a model for adaptation as an ongoing inference problem. Guided by predictions of this model, we found that the dynamics of adaptation depend on the discriminability of the change in stimulus distribution and that the retina exploits information contained in properties of the stimulus beyond the mean and variance to adapt more quickly when possible.},
annote = {2010num4.1},
author = {Wark, Barry and Fairhall, A L and Rieke, Fred},
doi = {10.1016/j.neuron.2009.01.019},
issn = {1097-4199},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Animals,Computer Simulation,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Inbred C57BL,Luminescence,Mice,Models,Motion Perception,Motion Perception: physiology,Neurological,Nonlinear Dynamics,Patch-Clamp Techniques,Photic Stimulation,Photic Stimulation: methods,Physiological,Physiological: physiology,Retina,Retina: cytology,Retina: physiology,Retinal Ganglion Cells,Retinal Ganglion Cells: drug effects,Retinal Ganglion Cells: physiology,Time Factors},
number = {5},
pages = {750--61},
pmid = {19285471},
publisher = {Elsevier Ltd},
title = {{Timescales of inference in visual adaptation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19285471 http://dx.doi.org/10.1016/j.neuron.2009.01.019},
volume = {61},
year = {2009}
}
@book{BKRW98,
author = {Bickel, P and Klaassen, C and Ritov, Y and Wellner, J},
publisher = {Springer},
title = {{Efficient and Adaptive Estimation for Semiparametric Models}},
year = {1998}
}
@article{Faisal,
author = {Faisal, A Aldo and White, John A and Laughlin, Simon B},
number = {V},
pages = {1--6},
title = {{Ion-Channel Noise Places Limits on the Miniaturization of the Brain ' s Wiring}},
volume = {100}
}
@article{Druckmann2012,
author = {Druckmann, Shaul and Chklovskii, D B},
doi = {10.1016/j.cub.2012.08.058},
issn = {09609822},
journal = {Current Biology},
month = {oct},
pages = {1--9},
publisher = {Elsevier Ltd},
title = {{Neuronal Circuits Underlying Persistent Representations Despite Time Varying Activity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982212010810},
year = {2012}
}
@phdthesis{SabinoPHD,
author = {Sabino, J},
school = {Rice University},
title = {{Solution of large-scale Lyapunov equations via the block modified Smith method}},
year = {2007}
}
@article{Cook,
author = {Cook, M and Soloveichik, D and Winfree, E and Bruck, J},
journal = {Algorithmic Bioprocesses},
title = {{Programmability of chemical reaction networks}},
url = {http://www.springerlink.com/index/jx53634661630334.pdf},
year = {2009}
}
@article{SunejaPotashner98,
abstract = {In young adult guinea pigs, the effects of unilateral cochlear ablation

were determined on the specific binding of [3H]strychnine measured

in subdivisions of the cochlear nucleus (CN), the superior olivary

complex, and the auditory midbrain, after 2, 7, 31, 60, and 147 postlesion

days. Changes in binding relative to that in age-matched controls

were interpreted as altered activity and/or expression of synaptic

glycine receptors. Postlesion binding declined ipsilaterally in most

of the ventral CN and in the lateral superior olive (LSO). Binding

was modestly deficient in the ipsilateral dorsal CN and in the anterior

part of the contralateral anteroventral CN. Binding was elevated

in the contralateral LSO. Transient changes also occurred. Binding

was elevated transiently, between 2 and 31 days, contralaterally

in parts of the anteroventral CN, bilaterally in the medial superior

olive (MSO), and bilaterally in most of the midbrain nuclei. Binding

was deficient transiently, at 60 days, in most of the contralateral

CN and bilaterally in the midbrain nuclei. The present findings,

together with previously reported postlesion changes in glycine release,

were consistent with persistently weakened glycinergic inhibitory

transmission ipsilaterally in the ventral CN and the LSO and bilaterally

in the dorsal CN. Glycinergic inhibitory transmission was strengthened

in the contralateral LSO and transiently strengthened in the MSO

bilaterally. A hypothetical model of the findings suggested that

glycine receptor regulation may depend on excitatory and glycinergic

input to auditory neurons. The present changes in glycine receptor

activity may contribute to altered auditory functions, which often

accompany hearing loss.},
author = {Suneja, S K and Benson, C G and Potashner, S J},
doi = {10.1006/exnr.1998.6946},
journal = {Experimental Neurology},
keywords = {Afferent; Olivary Nucleus; Radioligand Assay; Rec,Animals; Cell Survival; Cochlea; Cochlear Nucleus;,Glycine; Research Support,P.H.S.; Strychnine; Synapses; Tritium,U.S. Gov't},
month = {dec},
number = {2},
pages = {473--488},
pmid = {9878183},
title = {{Glycine receptors in adult guinea pig brain stem auditory nuclei: regulation after unilateral cochlear ablation.}},
url = {http://dx.doi.org/10.1006/exnr.1998.6946},
volume = {154},
year = {1998}
}
@article{Yankova|2001|,
author = {Yankova, M and Hart, S A and Woolley, C S},
journal = {Proc. Natl. Acad. Sci. USA},
number = {6},
pages = {3525--3530},
title = {{Estrogen increases synaptic connectivity between single presynaptic inputs and multiple postsynaptic CA1 pyramidal cells: a serial electron-microscopic study.}},
volume = {98}
}
@article{Amari1998,
author = {Amari, Shun-ichi},
doi = {10.1162/089976698300017746},
issn = {0899-7667},
journal = {Neural Computation},
month = {feb},
number = {2},
pages = {251--276},
title = {{Natural Gradient Works Efficiently in Learning}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976698300017746},
volume = {10},
year = {1998}
}
@article{JungbackerKoopman07,
author = {Jungbacker, B and Koopman, S},
journal = {Biometrika},
pages = {827--839},
title = {{Monte Carlo estimation for nonlinear non-Gaussian state space models}},
volume = {94},
year = {2007}
}
@article{Rabinovich2008a,
author = {Rabinovich, M I and Huerta, R and Varona, P and Afraimovich, V S},
journal = {PLoS Computational Biology},
number = {5},
pages = {e1000072},
title = {{Transient cognitive dynamics, metastability, and decision making}},
volume = {4},
year = {2008}
}
@article{SB01,
author = {Stanley, G and Boloori, A},
journal = {Proceedings of the Annual EMBS International Conference},
title = {{Decoding in neural systems: stimulus reconstruction from nonlinear encoding}},
volume = {23},
year = {2001}
}
@article{LUT85,
author = {Luttrell, S},
journal = {Inverse Problems},
pages = {199--218},
title = {{The Use of Transinformation in the Design of Data Sampling Schemes for Inverse Problems}},
volume = {1},
year = {1985}
}
@article{Meinrenken2002,
abstract = {Phasic transmitter release at synapses in the mammalian CNS is regulated by local [Ca2+] transients, which control the fusion of readily releasable vesicles docked at active zones (AZs) in the presynaptic membrane. The time course and amplitude of these [Ca2+] transients critically determine the time course and amplitude of the release and thus the frequency and amplitude tuning of the synaptic connection. As yet, the spatiotemporal nature of the [Ca2+] transients and the number and location of release-controlling Ca2+ channels relative to the vesicles, the "topography" of the release sites, have remained elusive. We used a time-dependent model to simulate Ca2+ influx, three-dimensional buffered Ca2+ diffusion, and the binding of Ca2+ to the release sensor. The parameters of the model were constrained by recent anatomical and biophysical data of the calyx of Held. Comparing the predictions of the model with previously measured release probabilities under a variety of experimental conditions, we inferred which release site topography is likely to operate at the calyx: At each AZ one or a few clusters of Ca2+ channels control the release of the vesicles. The distance of a vesicle to the cluster(s) varies across the multiple release sites of a single calyx (ranging from 30 to 300 nm; average approximately 100 nm). Assuming this topography, vesicles in different locations are exposed to different [Ca2+] transients, with peak amplitudes ranging from 0.5 to 40 microm (half-width approximately 400 microsec) during an action potential. Consequently the vesicles have different release probabilities ranging from {\textless}0.01 to 1. We demonstrate how this spatially heterogeneous release probability creates functional advantages for synaptic transmission.},
author = {Meinrenken, Christoph J and Borst, J Gerard G and Sakmann, B},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Brain Stem,Brain Stem: metabolism,Buffers,Calcium,Calcium: metabolism,Cell Compartmentation,Cell Compartmentation: physiology,Computer Simulation,Diffusion,Glutamic Acid,Glutamic Acid: metabolism,Ion Channel Gating,Ion Channel Gating: physiology,Models, Neurological,Presynaptic Terminals,Presynaptic Terminals: metabolism,Synapses,Synapses: metabolism,Synaptic Transmission,Synaptic Transmission: physiology,Synaptic Vesicles,Synaptic Vesicles: metabolism},
month = {mar},
number = {5},
pages = {1648--67},
pmid = {11880495},
title = {{Calcium secretion coupling at calyx of held governed by nonuniform channel-vesicle topography.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11880495},
volume = {22},
year = {2002}
}
@article{Zhou2006a,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0604070v1},
author = {Zhou, Changsong and Motter, AE and Kurths, J},
eprint = {0604070v1},
journal = {Physical review letters},
number = {2006},
pages = {1--5},
primaryClass = {arXiv:cond-mat},
title = {{Universality in the synchronization of weighted random networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.96.034101},
volume = {034101},
year = {2006}
}
@article{Clay1995,
abstract = {A model is proposed for activation of potassium ion channel current, IK, in squid giant axons, which consists of two closed states and one open state. The rate parameter in the forward direction between the two closed states depends upon previous history. That is, it relaxes exponentially to its steady-state value appropriate to the membrane potential of a voltage clamp step rather than change instantaneously as in traditional models of channel gating. The model successfully describes both the enhancement of the delay in activation of IK with relatively negative prepulse potentials, i.e. the Cole-Moore effect, and the time-dependent rising phase of "on" gating current, which has been reported recently for several types of potassium channels.},
annote = {2010num3.4},
author = {Clay, J R},
doi = {10.1006/jtbi.1995.0138},
issn = {0022-5193},
journal = {Journal of theoretical biology},
keywords = {Animals,Axons,Axons: metabolism,Biological,Decapodiformes,Ion Channel Gating,Ion Channel Gating: physiology,Models,Potassium Channels,Potassium Channels: physiology},
month = {jul},
number = {2},
pages = {257--62},
pmid = {7564400},
title = {{A simple model of K+ channel activation in nerve membrane.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7564400 http://dx.doi.org/10.1006/jtbi.1995.0138},
volume = {175},
year = {1995}
}
@article{Moreno-Bote2010,
author = {Moreno-Bote, R and Parga, N},
journal = {Neural Computation},
pages = {1528--1572},
title = {{Response of Integrate-and-Fire Neurons to Noisy Inputs Filtered by Synapses with Arbitrary Timescales :}},
volume = {22},
year = {2010}
}
@article{Yuste97,
author = {Yuste, R and Tank, D W and Kleinfeld, D},
journal = {Cerebral Cortex},
pages = {546--558},
title = {{Functional study of the rat cortical microcircuitry with voltage-sensitive dye imaging of neocortical slices}},
volume = {6/7},
year = {1997}
}
@book{GLM89,
address = {London},
author = {McCullagh, Peter and Nelder, John},
publisher = {Chapman and Hall},
title = {{Generalized linear models}},
year = {1989}
}
@article{Buhl94,
author = {Buhl, E H and Halasy, K and P., Somogyi and Somogyi, P},
journal = {Nature},
number = {6474},
pages = {823--828},
title = {{Diverse sources of hippocampal unitary inhibitory postynaptic potentials and the number of synaptic release sites}},
volume = {368},
year = {1994}
}
@article{Sutter1992,
abstract = {A technique of multi-input systems analysis is used to explore the field topography of ERG responses to local luminance modulation. Variations in amplitude and wave form are studied within the central 23 degrees. Outside the fovea, the amplitude appears to follow a simple power law rx as a function of eccentricity r where x is approximately -2/3. The largest inter-subject variability is found in the fovea. Some nasal-temporal asymmetry is observed in all subjects with higher response densities in the temporal field outside the blind spot. The topography of the luminance response shares all these properties with the density of retinal cones.},
author = {Sutter, E E and Tran, D},
issn = {0042-6989},
journal = {Vision research},
keywords = {Electrophysiology,Electroretinography,Electroretinography: methods,Humans,Photic Stimulation,Systems Analysis,Visual Field Tests,Visual Fields,Visual Fields: physiology},
month = {mar},
number = {3},
pages = {433--46},
pmid = {1604830},
title = {{The field topography of ERG components in man--I. The photopic luminance response.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1604830},
volume = {32},
year = {1992}
}
@article{PalmerStuart06,
author = {Palmer, Lucy M and Stuart, Greg J},
journal = {J. Neurosci.},
number = {6},
pages = {1854--1863},
title = {{Site of Action Potential Initiation in Layer 5 Pyramidal Neurons}},
volume = {26},
year = {2006}
}
@book{erdelyi1953higher,
address = {New York},
author = {Erdeyi, A},
publisher = {McGraw-Hill},
title = {{Higher transcendental functions}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Higher+transcendental+functions{\#}0},
year = {1953}
}
@article{Laiho2012,
author = {Laiho, Mika and Lehtonen, Eero and Lu, Wei},
doi = {10.1109/ISCAS.2012.6271855},
isbn = {978-1-4673-0219-7},
journal = {2012 IEEE International Symposium on Circuits and Systems},
month = {may},
pages = {2665--2668},
publisher = {Ieee},
title = {{Memristive analog arithmetic within cellular arrays}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6271855},
year = {2012}
}
@article{Gerken|1995|,
abstract = {Polygon/spline approximation of arbitrary image region shapes is submitted
for tool evaluation. First, polygon approximation is performed. Starting
with an initial 4{\^{A}}–vertices polygon which represents the farest elongations
into different directions, the polygon approximation is iteratively
refined taking into account the local requirements until a given
tolerance criterion is satisfied everywhere. Then, spline approximation
is calculated using the polygon vertices. Whenever spline approximation
also satisfies the tolerance criterion for a certain part of the
shape, spline approximation substitutes polygon approximation for
that part thus giving the approximated shape a more natural look.
By this combined approach, the advantages of both techniques are
utilized and their disadvantages avoided. Thus, the combined approach
is efficient in terms of reduction of the number of shape points
for which coordinates must be transmitted and with this also in terms
of bit rate reduction. It has no interdependency during the iterative
refinement of the approximation in different parts of the shape,
and it has a natural look. Predictive coding is proposed for further
bit rate reduction.},
annote = {Article introduces a method for polygon/spline approximation of arbitrary{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}binary shape by itterative reduction of unacceptable edges of the{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}polygon and subsequent spline smoothing},
author = {Gerken, P and Wollborn, M and Schultz, S},
keywords = {approximation,computational,image processing,polygon,shape,spline},
title = {{Polygon/spline approximation of arbitrary image region shapes as proposal for MPEG{\^{A}}–4 tool evaluation {\^{A}}– Technical description}}
}
@article{Wen2016,
abstract = {This paper considers a multiple-input multiple-output (MIMO) receiver with very low precision analog-to-digital convertors (ADCs), motivated by the interest of massive MIMO antenna systems operating with low cost and power requirements. In this case, prior work demonstrated that the training duration is required to be very large just to obtain an acceptable channel state information (CSI). To tackle this, we adopt joint channel-and-data (JCD) estimation based on the Bayes-optimal inference which results in the minimal mean-square-error (MSE) with respect to (w.r.t.) the channels as well as the payload data. We realize the Bayes-optimal JCD estimator using a recent technique based on approximate message passing and present an analytical framework to study its theoretical performances in the large-system limit. Simulation results confirm our analytical results, which allow efficient evaluation of the performance for the quantized massive MIMO systems and provide insights to system design.},
archivePrefix = {arXiv},
arxivId = {1507.07766},
author = {Wen, Chao Kai and Wang, Chang Jen and Jin, Shi and Wong, Kai Kit and Ting, Pangan},
doi = {10.1109/TSP.2015.2508786},
eprint = {1507.07766},
isbn = {9781467377041},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Bayes-optimal inference,joint channel-and-data estimation,low-precision ADC,massive MIMO,replica method},
number = {10},
pages = {2541--2556},
title = {{Bayes-Optimal Joint Channel-and-Data Estimation for Massive MIMO With Low-Precision ADCs}},
volume = {64},
year = {2016}
}
@article{Bressloff1990,
author = {Bressloff, P and Stark, J},
doi = {10.1016/0375-9601(90)90119-9},
issn = {03759601},
journal = {Physics Letters A},
month = {nov},
number = {3-4},
pages = {187--195},
title = {{Neuronal dynamics based on discontinuous circle maps}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0375960190901199},
volume = {150},
year = {1990}
}
@article{MP95,
author = {MacKay, D J C and Peto, L},
journal = {Natural Language Engineering},
pages = {289--307},
title = {{A Hierachical Dirichlet Model}},
volume = {1},
year = {1995}
}
@inproceedings{Larochelle2007,
author = {Larochelle, H and Erhan, D and Courville, A},
booktitle = {Proceedings of the 24th international conference on Machine learning},
title = {{An empirical evaluation of deep architectures on problems with many factors of variation}},
url = {http://dl.acm.org/citation.cfm?id=1273556},
year = {2007}
}
@article{Ka|1998|,
abstract = {A one-electron model for the photodissociation and recombination dynamics
of a diatomic anion has been proposed. The main purpose of the study
is to provide a simple model to better understand the effect of strong
coupling between the solvent polarization and the extra charge in
a system like I2 2. The model diatomic anion consists of two identical
nuclei and an extra electron whose dynamics are treated explicitly.
The effect of solvent polarization is modeled by introducing an effective
solvent field representing a nonequilibrium solvent configuration.
Nonadiabatic theoretical calculations, in which the electronic and
the nuclear dynamics are treated simultaneously, can reveal the importance
of nonadiabatic effects by including intrinsically all the electronic
states involved. It is found that a purely dissociative excited state
can support recombination due to coupling of the anomalous charge
distribution with the solvent polarization. The charge switching
and the subsequent charge separation for the dissociating fragments
are strongly coupled with the fluctuating solvent polarization, as
represented by the time-dependent solvent field in the present model.
The results of the calculations with varying time scales for the
solvent response have demonstrated the possibility of numerous diverse
phenomena resulting from nonadiabatic transitions. In particular,
we found charge transfer induced by changing solvent polarization.
The general model presented in the study provides a reasonable interpretation,
at least on a qualitative level, for the interesting features obtained
from recent experiments and nonadiabatic molecular dynamics studies
on the photodissociation of I2 2 in molecular clusters.},
author = {Ka, J and Shin, S},
journal = {Journal of Chemical Physics},
keywords = {diatomic,photodissociation,physics,solid state},
number = {22},
pages = {10087},
title = {{One-electron model for photodissociation dynamics of diatomic anion}},
volume = {109}
}
@article{Hardt2016,
abstract = {An emerging design principle in deep learning is that each layer of a deep artificial neural network should be able to easily express the identity transformation. This idea not only motivated various normalization techniques, such as $\backslash$emph{\{}batch normalization{\}}, but was also key to the immense success of $\backslash$emph{\{}residual networks{\}}. In this work, we put the principle of $\backslash$emph{\{}identity parameterization{\}} on a more solid theoretical footing alongside further empirical progress. We first give a strikingly simple proof that arbitrarily deep linear residual networks have no spurious local optima. The same result for linear feed-forward networks in their standard parameterization is substantially more delicate. Second, we show that residual networks with ReLu activations have universal finite-sample expressivity in the sense that the network can represent any function of its sample provided that the model has more parameters than the sample size. Directly inspired by our theory, we experiment with a radically simple residual architecture consisting of only residual convolutional layers and ReLu activations, but no batch normalization, dropout, or max pool. Our model improves significantly on previous all-convolutional networks on the CIFAR10, CIFAR100, and ImageNet classification benchmarks.},
archivePrefix = {arXiv},
arxivId = {1611.04231},
author = {Hardt, Moritz and Ma, Tengyu},
eprint = {1611.04231},
journal = {ICLR},
pages = {1--19},
title = {{Identity Matters in Deep Learning}},
url = {http://arxiv.org/abs/1611.04231},
year = {2017}
}
@article{BS89,
author = {Ball, F and Sansom, M},
journal = {Proceedings of the Royal Society of London. Series B, Biological Sciences},
pages = {385--416},
title = {{Ion-Channel Gating Mechanisms: Model Identification and Parameter Estimation from Single Channel Recordings}},
volume = {236},
year = {1989}
}
@article{HiraseYuste02,
author = {Hirase, Hajime and Nikolenko, Volodymyr and Goldberg, Jesse H and Yuste, R},
journal = {Journal of Neurobiology},
month = {jun},
number = {3},
pages = {237--247},
title = {{Multiphoton stimulation of neurons}},
volume = {51},
year = {2002}
}
@inproceedings{KondorLafferty02,
author = {Kondor, R and Lafferty, J},
booktitle = {Proc. Int. Conf. on Machine Learning},
pages = {315--322},
title = {{Diffusion Kernels on Graphs and Other Discrete Structures}},
year = {2002}
}
@article{Perin29032011,
abstract = {Neuronal circuitry is often considered a clean slate that can be dynamically and arbitrarily molded by experience. However, when we investigated synaptic connectivity in groups of pyramidal neurons in the neocortex, we found that both connectivity and synaptic weights were surprisingly predictable. Synaptic weights follow very closely the number of connections in a group of neurons, saturating after only 20{\%} of possible connections are formed between neurons in a group. When we examined the network topology of connectivity between neurons, we found that the neurons cluster into small world networks that are not scale-free, with less than 2 degrees of separation. We found a simple clustering rule where connectivity is directly proportional to the number of common neighbors, which accounts for these small world networks and accurately predicts the connection probability between any two neurons. This pyramidal neuron network clusters into multiple groups of a few dozen neurons each. The neurons composing each group are surprisingly distributed, typically more than 100 ?m apart, allowing for multiple groups to be interlaced in the same space. In summary, we discovered a synaptic organizing principle that groups neurons in a manner that is common across animals and hence, independent of individual experiences. We speculate that these elementary neuronal groups are prescribed Lego-like building blocks of perception and that acquired memory relies more on combining these elementary assemblies into higher-order constructs.},
author = {Perin, Rodrigo and Berger, Thomas K and Markram, Henry},
doi = {10.1073/pnas.1016051108},
journal = {Proceedings of the National Academy of Sciences},
number = {13},
pages = {5419--5424},
title = {{A synaptic organizing principle for cortical neuronal groups}},
url = {http://www.pnas.org/content/108/13/5419.abstract},
volume = {108},
year = {2011}
}
@book{Rock70,
author = {Rockafellar, R T},
publisher = {Princeton University Press},
title = {{Convex Analysis}},
year = {1970}
}
@article{Milojkovic07,
abstract = {Higher cortical functions (perception, cognition, learning and memory) are in large part based on the integration of electrical and calcium signals that takes place in thin dendritic branches of neocortical pyramidal cells (synaptic integration). The mechanisms underlying the synaptic integration in thin basal dendrites are largely unexplored. We use a recently developed technique, multisite voltage-calcium imaging, to compare voltage and calcium transients from multiple locations along individual dendritic branches. Our results reveal characteristic electrical transients (plateau potentials) that trigger and shape dendritic calcium dynamics and calcium distribution during suprathreshold glutamatergic synaptic input. We regularly observed three classes of voltage-calcium interactions occurring simultaneously in three different zones of the same dendritic branch: (1) proximal to the input site, (2) at the input site, and (3) distal to the input site. One hundred micrometers away from the synaptic input site, both proximally and distally, dendritic calcium transients are in tight temporal correlation with the dendritic plateau potential. However, on the same dendrite, at the location of excitatory input, calcium transients outlast local dendritic plateau potentials by severalfold. These Ca2+ plateaus (duration 0.5-2 s) are spatially restricted to the synaptic input site, where they cause a brief down-regulation of dendritic excitability. Ca2+ plateaus are not mediated by Ca2+ release from intracellular stores, but rather by an NMDA-dependent small-amplitude depolarization, which persists after the collapse of the dendritic plateau potential. These unique features of dendritic voltage and calcium distributions may provide distinct zones for simultaneous long-term (bidirectional) modulation of synaptic contacts along the same basal branch.
},
author = {Milojkovic, Bogdan A and Zhou, Wen-Liang and Antic, Srdjan D},
doi = {10.1113/jphysiol.2007.142315},
journal = {J Physiol},
number = {2},
pages = {447--468},
title = {{Voltage and calcium transients in basal dendrites of the rat prefrontal cortex}},
url = {http://jp.physoc.org/cgi/content/abstract/585/2/447},
volume = {585},
year = {2007}
}
@article{Kispersky2011,
author = {Kispersky, T and Gutierrez, GJ and Marder, E},
journal = {Neural Syst Circuits},
pages = {9},
title = {{Functional connectivity in a rhythmic inhibitory circuit using Granger causality}},
url = {http://www.biomedcentral.com/content/pdf/2042-1001-1-9.pdf},
volume = {1},
year = {2011}
}
@article{Paninski2004a,
abstract = {We examine a cascade encoding model for neural response in which a linear filtering stage is followed by a noisy, leaky, integrate-and-fire spike generation mechanism. This model provides a biophysically more realistic alternative to models based on Poisson (memoryless) spike generation, and can effectively reproduce a variety of spiking behaviors seen in vivo. We describe the maximum likelihood estimator for the model parameters, given only extracellular spike train responses (not intracellular voltage data). Specifically, we prove that the log-likelihood function is concave and thus has an essentially unique global maximum that can be found using gradient ascent techniques. We develop an efficient algorithm for computing the maximum likelihood solution, demonstrate the effectiveness of the resulting estimator with numerical simulations, and discuss a method of testing the model's validity using time-rescaling and density evolution techniques.},
author = {Paninski, L and Pillow, J W and Simoncelli, E P},
doi = {10.1162/0899766042321797},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Biophysical Phenomena,Biophysics,Electrophysiology,Likelihood Functions,Membrane Potentials,Models,Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Poisson Distribution,Statistical},
month = {dec},
number = {12},
pages = {2533--61},
pmid = {15516273},
title = {{Maximum likelihood estimation of a stochastic integrate-and-fire neural encoding model.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15516273},
volume = {16},
year = {2004}
}
@inproceedings{Hasan2014,
address = {Beijing},
author = {Hasan, Raqibul and Taha, TM},
booktitle = {Neural Networks (IJCNN), 2014 International Joint Conference on. IEEE},
isbn = {9781479914845},
keywords = {memristor crossbars,neural networks,neuromorphic},
month = {jul},
pages = {21--28},
title = {{Enabling back propagation training of memristor crossbar neuromorphic processors}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6889893},
year = {2014}
}
@article{Minka2001,
author = {Minka, T P},
journal = {NIPS},
pages = {362--369},
title = {{Expectation Propagation for Approximate Bayesian Inference}},
url = {http://dl.acm.org/citation.cfm?id=2074067},
year = {2001}
}
@article{Ahmari|2000|,
author = {Ahmari, S E and Buchanan, J and Smith, S J},
journal = {Nat Neurosci},
number = {5},
pages = {445--451},
title = {{Assembly of presynaptic active zones from cytoplasmic transport packets.}},
volume = {3}
}
@article{Kajiwara|2008|,
abstract = {The entorhinal cortex (EC) conveys information to hippocampal field
CA1 either directly by way of projections from principal neurons
in layer III, or indirectly by axons from layer II via the dentate
gyrus, CA3, and Schaffer collaterals. These two pathways differentially
influence activity in CA1, yet conclusive evidence is lacking whether
and to what extent they converge onto single CA1 neurons. Presently
we studied such convergence. Different neuroanatomical tracers injected
into layer III of EC and into CA3, respectively, tagged simultaneously
the direct entorhino-hippocampal fibers and the indirect innervation
of CA1 neurons by Schaffer collaterals. In slices of fixed brains
we intracellularly filled CA1 pyramidal cells and interneurons in
stratum lacunosum-moleculare (LM) and stratum radiatum (SR). Sections
of these slices were scanned in a confocal laser scanning microscope.
3D-reconstruction was used to determine whether boutons of the labeled
input fibers were in contact with the intracellularly filled neurons.
We analyzed 12 pyramidal neurons and 21 interneurons. Perforant path
innervation to pyramidal neurons in our material was observed to
be denser than that from CA3. All pyramidal neurons and 17 of the
interneurons received contacts of both perforant pathway and Schaffer
input on their dendrites and cell bodies. Four interneurons, which
were completely embedded in LM, received only labeled perforant pathway
input. Thus, we found convergence of both projection systems on single
CA1 pyramidal and interneurons with dendrites that access the layers
where perforant pathway fibers and Schaffer collaterals end.},
annote = {Journal Article Research Support, Non-U.S. Gov{\&}{\#}039;t United States},
author = {Kajiwara, R and Wouterlood, F G and Sah, A and Boekel, A J and {Baks-te Bulte}, L T and Witter, M P},
journal = {Hippocampus},
keywords = {Animals Axons/physiology/ultrastructure Biotin/ana,Confocal Neural Pathways/*cytology/physiology Per,Wistar Staining and Labeling Synapses/physiology/},
number = {3},
pages = {266--280},
title = {{Convergence of entorhinal and CA3 inputs onto pyramidal neurons and interneurons in hippocampal area CA1--an anatomical study in the rat}},
volume = {18}
}
@article{SS05,
author = {Schafer, J and Strimmer, K},
journal = {Statistical Applications in Genetics and Molecular Biology},
pages = {32},
title = {{A Shrinkage Approach to Large-Scale Covariance Matrix Estimation and Implications for Functional Genomics}},
volume = {4},
year = {2005}
}
@incollection{PAN06c,
author = {Paninski, L and Pillow, J W and Lewi, J},
booktitle = {Computational Neuroscience: Progress in Brain Research},
editor = {Cisek, P and Drew, T and Kalaska, J},
publisher = {Elsevier},
title = {{Statistical models for neural encoding, decoding, and optimal stimulus design}},
year = {2007}
}
@article{BRIL92,
author = {Brillinger, D},
journal = {Journal of the American Statistical Association},
pages = {260--271},
title = {{Nerve cell spike train data analysis: a progression of technique}},
volume = {87},
year = {1992}
}
@article{Stepanyants08,
author = {Stepanyants, Armen and Hirsch, Judith A and Martinez, Luis M and Kisvarday, Zoltan F and Ferecsko, Alex S and Chklovskii, Dmitri B},
journal = {Cereb. Cortex},
pages = {13--28},
title = {{Local Potential Connectivity in Cat Primary Visual Cortex}},
volume = {18},
year = {2008}
}
@article{Frotscher|1986|,
abstract = {We report here on cholinergic neurons in the rat hippocampal formation
that were identified by immunocytochemistry employing a monoclonal
antibody against choline acetyltransferase (ChAT), the acetylcholine-synthesizing
enzyme. In general, ChAT-immunoreactive cells were rare, but were
observed in all layers of the hippocampus proper and fascia dentata
with a preponderance in zones adjacent to the hippocampal fissure
and in the part of CA1 bordering the subiculum. All immunoreactive
cells found were non-pyramidal neurons. They were relatively small
with round or ovoid perikarya, which gave rise to thin spine-free
dendrites. These hippocampal neurons were very similar to ChAT-immunoreactive
cells in the neocortex of the same animals but were quite different
from cholinergic neurons in the basal forebrain, medial septal nucleus,
and neostriatum, which were larger and more intensely immunostained.
Electron-microscopic analysis of ChAT-immunoreactive cells in the
hippocampus and fascia dentata revealed synaptic contacts, mainly
of the asymmetric type, on cell bodies and smooth proximal dendrites.
The nuclei of the immunoreactive cells exhibited deep indentations,
which are characteristic for non-pyramidal neurons. Our results provide
evidence for an intrinsic source of the hippocampal cholinergic innervation
in addition to the well-established septo-hippocampal cholinergic
projection.},
annote = {Journal Article Research Support, Non-U.S. Gov{\&}{\#}039;t Germany, west},
author = {Frotscher, M and Schlander, M and Leranth, C},
journal = {Cell Tissue Res},
keywords = {Animals Choline O-Acetyltransferase/metabolism Cho,Electron Neurons/*cytology/enzymology Rats Rats,Inbred Strains},
number = {2},
pages = {293--301},
title = {{Cholinergic neurons in the hippocampus. A combined light- and electron-microscopic immunocytochemical study in the rat}},
volume = {246}
}
@article{EllisDavies07,
author = {Ellis-Davies, Graham C R and Matsuzaki, Masanori and Paukert, Martin and Kasai, Haruo and Bergles, Dwight E},
journal = {J. Neurosci.},
number = {25},
pages = {6601--6604},
title = {{4-Carboxymethoxy-5,7-Dinitroindolinyl-Glu: An Improved Caged Glutamate for Expeditious Ultraviolet and Two-Photon Photolysis in Brain Slices}},
volume = {27},
year = {2007}
}
@article{Serfling1978,
author = {Serfling, RJ J},
journal = {Siam review},
title = {{Some elementary results on Poisson approximation in a sequence of Bernoulli trials}},
url = {http://www.jstor.org/stable/2030354},
year = {1978}
}
@article{Martens2011a,
abstract = {Recurrent Neural Networks (RNNs) are very powerful sequence models that do not enjoy widespread use because it is extremely diffi- cult to train them properly. Fortunately, re- cent advances in Hessian-free optimization have been able to overcome the difficulties associated with training RNNs, making it possible to apply them successfully to challenging sequence prob- lems. In this paper we demonstrate the power of RNNs trained with the new Hessian-Free op- timizer (HF) by applying them to character-level language modeling tasks. The standard RNN ar- chitecture, while effective, is not ideally suited for such tasks, so we introduce a new RNN variant that uses multiplicative (or gated) con- nections which allow the current input charac- ter to determine the transition matrix from one hidden state vector to the next. After training the multiplicative RNN with the HF optimizer for five days on 8 high-end Graphics Processing Units, we were able to surpass the performance of the best previous single method for character- level language modeling a hierarchical non- parametric sequence model. To our knowledge this represents the largest recurrent neural net- work application to date.},
author = {Sutskever, Ilya and Martens, James and {Geoffrey E Hinton}},
isbn = {9781450306195},
journal = {ICML '11},
number = {1},
pages = {1017--1024},
title = {{Generating Text with Recurrent Neural Networks}},
url = {http://www.icml-2011.org/papers/524{\_}icmlpaper.pdf},
volume = {131},
year = {2011}
}
@article{Young89,
author = {Hellstrom, L I and Young, Eric D},
journal = {Journal of The Acoustical Society Of America},
month = {jan},
number = {1},
pages = {243--253},
title = {{Physiological responses to the pulsation threshold paradigm II: Representations of high-pass noise in average rate measures of auditory-nerve fiber discharge}},
volume = {85},
year = {1989}
}
@article{Brecht2004,
abstract = {Neuronal activity in the motor cortex is understood to be correlated with movements, but the impact of action potentials (APs) in single cortical neurons on the generation of movement has not been fully determined. Here we show that trains of APs in single pyramidal cells of rat motor cortex can evoke long sequences of small whisker movements. For layer-5 pyramids, we find that evoked rhythmic movements have a constant phase relative to the AP train, indicating that single layer-5 pyramids can reset the rhythm of whisker movements. Action potentials evoked in layer-6 pyramids can generate bursts of rhythmic whisking, with a variable phase of movements relative to the AP train. An increasing number of APs decreases the latency to onset of movement, whereas AP frequency determines movement direction and amplitude. We find that the efficacy of cortical APs in evoking whisker movements is not dependent on background cortical activity and is greatly enhanced in waking rats. We conclude that in vibrissae motor cortex sparse AP activity can evoke movements.},
author = {Brecht, M and Schneider, M and Sakmann, B and Margrie, T W},
doi = {10.1038/nature02266},
issn = {1476-4687},
journal = {Nature},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Electric Stimulation,Motor Cortex,Motor Cortex: cytology,Motor Cortex: physiology,Movement,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Vibrissae,Vibrissae: physiology,Wakefulness,Wakefulness: physiology,Wistar},
month = {feb},
number = {6976},
pages = {704--10},
pmid = {14973477},
title = {{Whisker movements evoked by stimulation of single pyramidal cells in rat motor cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14973477},
volume = {427},
year = {2004}
}
@article{KaneGordon81,
author = {Kane, E S and Puglisi, S G and Gordon, B S},
journal = {Journal of Comparative Neurology},
month = {may},
number = {3},
pages = {483--513},
title = {{Neuronal types in the deep dorsal cochlear nucleus of the cat: {\{}I{\}} {\{}G{\}}iant neurons}},
volume = {198},
year = {1981}
}
@book{Asmussen2007,
author = {Asmussen, S. and Glynn, P. W},
isbn = {9780387306797},
publisher = {Springer},
title = {{Stochastic Simulation: Algorithms and Analysis}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=rmGfsJxRDqgC{\&}oi=fnd{\&}pg=PP2{\&}dq=Stochastic+Simulation{\&}ots=HZC7p-vzIy{\&}sig={\_}GLJ8zi3dbGeWaGhD3RIkKrls5A},
year = {2007}
}
@book{Vanderbei|2001|,
address = {New York},
author = {Vanderbei, R J},
publisher = {Springer-Verlag},
series = {International Series in Operations Research and Management Science},
title = {{Linear Programming: Foundations and Extensions}}
}
@article{Sontag2003,
author = {Sontag, E.},
doi = {10.1016/S0167-6911(03)00136-1},
issn = {01676911},
journal = {Systems {\&} control letters},
keywords = {adaptation,disturbances,internal model,regulation},
number = {2},
pages = {119--126},
publisher = {Elsevier},
title = {{Adaptation and regulation with signal detection implies internal model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167691103001361 http://www.sciencedirect.com/science/article/pii/S0167691103001361},
volume = {50},
year = {2003}
}
@article{HH52a,
author = {Hodgkin, A L and Huxley, A F},
journal = {Proceedings of The Royal Society Of London. Series B: Biological Sciences},
month = {oct},
number = {899},
pages = {177--183},
title = {{Propagation of electrical signals along giant nerve fibers}},
volume = {140},
year = {1952}
}
@article{Kuriscak2012,
author = {Kuriscak, Eduard and Marsalek, Petr},
doi = {10.1155/2012/595398},
journal = {{\ldots} Mathematical Methods in {\ldots}},
title = {{The Effect of Neural Noise on Spike Time Precision in a Detailed CA3 Neuron Model}},
url = {http://www.hindawi.com/journals/cmmm/2012/595398/abs/},
volume = {2012},
year = {2012}
}
@article{Smith2017,
abstract = {This paper tackles two related questions at the heart of machine learning; how can we predict if a minimum will generalize to the test set, and why does stochastic gradient descent find minima that generalize well? Our work is inspired by Zhang et al. (2017), who showed deep networks can easily memorize randomly labeled training data, despite generalizing well when shown real labels of the same inputs. We show here that the same phenomenon occurs in small linear models. These observations are explained by evaluating the Bayesian evidence in favor of each model, which penalizes sharp minima. Next, we explore the "generalization gap" between small and large batch training, identifying an optimum batch size which maximizes the test set accuracy. Noise in the gradient updates is beneficial, driving the dynamics towards robust minima for which the evidence is large. Interpreting stochastic gradient descent as a stochastic differential equation, we predict the optimum batch size is proportional to both the learning rate and the size of the training set, and verify these predictions empirically.},
archivePrefix = {arXiv},
arxivId = {1710.06451},
author = {Smith, Samuel L. and Le, Quoc V.},
eprint = {1710.06451},
file = {:C$\backslash$:/Users/Daniel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith, Le - 2017 - Understanding Generalization and Stochastic Gradient Descent(3).pdf:pdf},
journal = {arXiv},
month = {oct},
title = {{Understanding Generalization and Stochastic Gradient Descent}},
url = {http://arxiv.org/abs/1710.06451},
year = {2017}
}
@article{Sandler2010,
annote = {2010IIInum5},
author = {Sandler, M},
title = {{Synaptic processing in fine tuft dendrites of layer 5 neocortical pyramidal neurons of the rat - Phd research proposal}},
year = {2010}
}
@article{Rosen1991,
author = {Rosen, R},
journal = {Word Journal Of The International Linguistic Association},
title = {{Life itself}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Life+itself{\#}2},
year = {1991}
}
@article{Elston|2002|,
author = {Elston, G N and Rockland, K S},
journal = {Cereb. Cortex},
number = {10},
pages = {1071--1078},
title = {{The pyramidal cell of the sensorimotor cortex of the macaque monkey: phenotypic variation.}},
volume = {12}
}
@article{Achard2006,
abstract = {The electrical activity of a neuron is strongly dependent on the ionic channels present in its membrane. Modifying the maximal conductances from these channels can have a dramatic impact on neuron behavior. But the effect of such modifications can also be cancelled out by compensatory mechanisms among different channels. We used an evolution strategy with a fitness function based on phase-plane analysis to obtain 20 very different computational models of the cerebellar Purkinje cell. All these models produced very similar outputs to current injections, including tiny details of the complex firing pattern. These models were not completely isolated in the parameter space, but neither did they belong to a large continuum of good models that would exist if weak compensations between channels were sufficient. The parameter landscape of good models can best be described as a set of loosely connected hyperplanes. Our method is efficient in finding good models in this complex landscape. Unraveling the landscape is an important step towards the understanding of functional homeostasis of neurons.},
author = {Achard, P and {De Schutter}, E},
doi = {10.1371/journal.pcbi.0020094},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Algorithms,Cell Line,Computational Biology,Humans,Models,Neurological,Neurons,Neurons: metabolism,Purkinje Cells,Purkinje Cells: metabolism,Synapses,Synapses: metabolism},
month = {jul},
number = {7},
pages = {e94},
pmid = {16848639},
title = {{Complex parameter landscape for a complex neuron model.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1513272{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2},
year = {2006}
}
@article{MengRubin91,
author = {Meng, Xiao-Li and Rubin, Donald B},
journal = {Journal of the American Statistical Association},
number = {416},
pages = {899--909},
title = {{Using {\{}EM{\}} to Obtain Asymptotic Variance-Covariance Matrices: The {\{}SEM{\}} Algorithm}},
volume = {86},
year = {1991}
}
@article{Wilson2017,
abstract = {Adaptive optimization methods, which perform local optimization with a metric constructed from the history of iterates, are becoming increasingly popular for training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We show that for simple overparameterized problems, adaptive methods often find drastically different solutions than gradient descent (GD) or stochastic gradient descent (SGD). We construct an illustrative binary classification problem where the data is linearly separable, GD and SGD achieve zero test error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to half. We additionally study the empirical generalization capability of adaptive methods on several state-of-the-art deep learning models. We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.},
archivePrefix = {arXiv},
arxivId = {1705.08292},
author = {Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nathan and Recht, Benjamin},
eprint = {1705.08292},
journal = {arXiv},
pages = {1--14},
title = {{The Marginal Value of Adaptive Gradient Methods in Machine Learning}},
url = {http://arxiv.org/abs/1705.08292},
year = {2017}
}
@book{Flajolet2010,
author = {Flajolet, Philippe and Sedgewick, Robert},
booktitle = {ACM SIGACT News},
doi = {10.1145/1814370.1814373},
isbn = {9780521898065},
issn = {01635700},
month = {jun},
number = {2},
pages = {11},
publisher = {Cambridge Univ Pr},
title = {{Analytic combinatorics}},
url = {http://portal.acm.org/citation.cfm?doid=1814370.1814373 http://books.google.com/books?hl=en{\&}lr={\&}id=0h-4QcA1c1QC{\&}oi=fnd{\&}pg=PR7{\&}dq=Analytic+combinatorics{\&}ots=fEGMC9x59C{\&}sig=52KJtd82Dt8cmkJIPNgN8n9{\_}pck},
volume = {41},
year = {2009}
}
@article{Ekeberg2005,
abstract = {Physiological studies in walking cats have indicated that two sensory signals are involved in terminating stance in the hind legs: one related to unloading of the leg and the other to hip extension. To study the relative importance of these two signals, we developed a three-dimensional computer simulation of the cat hind legs in which the timing of the swing-to-stance transition was controlled by signals related to the force in ankle extensor muscles, the angle at the hip joint, or a combination of both. Even in the absence of direct coupling between the controllers for each leg, stable stepping was easily obtained using either a combination of ankle force and hip position signals or the ankle force signal alone. Stable walking did not occur when the hip position signal was used alone. Coupling the two controllers by mutual inhibition restored stability, but it did not restore the correct timing of stepping of the two hind legs. Small perturbations applied during the swing phase altered the movement of the contralateral leg in a manner that tended to maintain alternating stepping when the ankle force signal was included but tended to shift coordination away from alternating when the hip position signal was used alone. We conclude that coordination of stepping of the hind legs depends critically on load-sensitive signals from each leg and that mechanical linkages between the legs, mediated by these signals, play a significant role in establishing the alternating gait.},
author = {Ekeberg, Orjan and Pearson, Keir},
doi = {10.1152/jn.00065.2005},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Animal,Animals,Behavior,Biological,Biomechanics,Cats,Computer Simulation,Electromyography,Electromyography: methods,Hindlimb,Hindlimb: physiology,Imaging,Models,Muscle,Skeletal,Skeletal: physiology,Three-Dimensional,Three-Dimensional: methods,Walking,Walking: physiology,motor control},
mendeley-tags = {motor control},
month = {dec},
number = {6},
pages = {4256--68},
pmid = {16049149},
title = {{Computer simulation of stepping in the hind legs of the cat: an examination of mechanisms regulating the stance-to-swing transition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16049149},
volume = {94},
year = {2005}
}
@article{Gavish2011,
author = {Gavish, Matan and Donoho, David},
doi = {10.1016/j.procs.2011.04.067},
issn = {18770509},
journal = {Procedia Computer Science},
month = {jan},
pages = {637--647},
title = {{A Universal Identifier for Computational Results}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050911001256},
volume = {4},
year = {2011}
}
@article{Brockwell07b,
author = {Brockwell, A E},
journal = {Statistics and Probability Letters},
pages = {1473--1478},
title = {{Universal residuals: a multivariate transformation}},
volume = {77},
year = {2007}
}
@article{Cheng-yu2009,
author = {Li, C Y T and Poo, M M and D, Y},
journal = {Science},
title = {{Burst spiking of a single cortical neuron modifies global brain state}},
url = {http://www.sciencemag.org/content/324/5927/643.short},
year = {2009}
}
@article{Prokhvatilov|1995|,
abstract = {We introduce a new method to include condensates in the light-cone
Hamiltonian. By using a Gaussian approximation to the ordinary vacuum
in a theory close to the light front, we derive an effective Hamiltonian
on the light cone, which has new terms reflecting the nontriviality
of the vacuum. We demonstrate our method for scalar phi{\^{}}4 theory
and the massive Schwinger mode.},
annote = {This rather interesing paper considers approaching light-front quantization{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}with a vanishing angle (but still nonsingular quantization) and derives{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the origin of nontrivial vacuum effects in "trivial vacuum" light-front{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}dynamics},
author = {Prokhvatilov, E V and Naus, H W L and Pirner, H.-J.},
journal = {Physical Review D},
keywords = {angle-dependent,canonical hamiltonian,general light front frame,generalized parton distribution,light front dynamics,perturbation theory,physics,quantum chromodynamics,renormalization,trivial vacuum},
number = {6},
pages = {2933},
title = {{Effective light-front quantization of scalar field theories and two-dimensional electrodynamics}},
volume = {51}
}
@phdthesis{Saias1995,
author = {Saias, Alain Isaac},
booktitle = {Science},
number = {1984},
title = {{Randomness versus Non-Determinism in Distributed Computing t}},
year = {1995}
}
@article{Doi1995,
abstract = {The response characteristics of the BVP (Bonhoeffer-van der Pol or FitzHugh-Nagumo) neuronal model to periodic pulse trains were investigated. The global bifurcation structure of model relative to stimulus intensity and period were analyzed using a one-dimensional mapping called the phase transition curve (PTC) extended by Maginu. The PTC clarified how periodic and chaotic responses bifurcate and revealed in particular several examples of chaotic responses bifurcating through period-doubling bifurcations, as well as the coexistences at the same parameter values, of two different periodic orbits, or of a chaotic and a periodic responses.},
author = {Doi, S and Sato, S},
issn = {0025-5564},
journal = {Mathematical biosciences},
keywords = {Animals,Electric Stimulation,Electrophysiology,Humans,Mathematics,Models, Neurological,Neurons,Neurons: physiology,Periodicity},
month = {mar},
number = {2},
pages = {229--50},
pmid = {7881196},
title = {{The global bifurcation structure of the BVP neuronal model driven by periodic pulse trains.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7881196},
volume = {125},
year = {1995}
}
@book{BatemanBook1955,
author = {Bateman, H},
booktitle = {California Institute of Technology Bateman Manuscript Project, New York: McGraw-Hill, 1953-1955},
editor = {Bateman, H},
title = {{Higher transcendental functions}},
volume = {1},
year = {1955}
}
@book{VINT00,
author = {Vinter, R},
publisher = {Birkhauser},
title = {{Optimal Control}},
year = {2000}
}
@article{Thompson88,
author = {Thompson, A and Girdlestone, D and West, D},
journal = {J Neurophysiol},
pages = {1896--1907},
title = {{Voltage-dependent currents prolong single-axon postsynaptic potentials in layer {\{}III{\}} pyramidal neurons in rat neocortical slices}},
volume = {60},
year = {1988}
}
@article{KKE05,
author = {Karmeier, K and Krapp, H and Egelhaaf, M},
journal = {Journal of Neurophysiology},
pages = {2182--2194},
title = {{Population Coding of Self-Motion: Applying Bayesian Analysis to a Population of Visual Interneurons in the Fly}},
volume = {94},
year = {2005}
}
@article{IkegayaYuste04,
author = {Ikegaya, Yuji and Aaron, Gloster and Cossart, Rosa and Aronov, Dmitriy and Lampl, Ilan and Ferster, David and Yuste, R},
journal = {Science},
month = {apr},
number = {5670},
pages = {559--564},
title = {{Synfire chains and cortical songs: temporal modules of cortical activity}},
volume = {304},
year = {2004}
}
@article{Tyrcha2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1203.5673v2},
author = {Tyrcha, J and Roudi, Y and Marsili, M and Hertz, J},
eprint = {arXiv:1203.5673v2},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
number = {3},
pages = {P03005},
title = {{The effect of nonstationarity on models inferred from neural data}},
url = {http://iopscience.iop.org/1742-5468/2013/03/P03005},
year = {2013}
}
@article{DS53,
author = {Darling, D and Siegert, J},
journal = {Annals of Mathematical Statistics},
pages = {624--639},
title = {{The First Passage Problem for a Continuous Markov Process}},
volume = {24},
year = {1953}
}
@article{Zakai2009,
author = {Zakai, M},
journal = {arXiv preprint arXiv:0904.2888},
number = {563},
title = {{The optimal filtering of Markov jump processes in additive white noise}},
url = {http://arxiv.org/abs/0904.2888},
year = {2009}
}
@article{shpigelman-kernel,
annote = {2008num27},
author = {Shpigelman, L and Lalazar, H and Vaadia, E},
title = {{Kernel-ARMA for Hand Tracking and Brain-Machine Interfacing During 3D Motor Control}}
}
@article{Keshet2006a,
author = {Crammer, K and Dekel, O},
journal = {The Journal of Machine {\ldots}},
pages = {551--585},
title = {{Online passive-aggressive algorithms}},
url = {http://dl.acm.org/citation.cfm?id=1248566},
volume = {7},
year = {2006}
}
@article{Morse01,
author = {Morse, T and Davison, A and Hines, M},
journal = {Society for Neuroscience Abstracts},
title = {{Parameter space reduction in neuron model optimization through minimization of residual voltage clamp current}},
year = {2001}
}
@article{RueTjelmeland02,
author = {Rue, H and Tjelmeland, H},
journal = {Scandinavian Journal of Statistics},
pages = {31--49},
title = {{Fitting {\{}Gaussian Markov{\}} random fields to {\{}G{\}}aussian fields}},
volume = {29},
year = {2002}
}
@inproceedings{Rosset2004,
author = {Rosset, Saharon and Zhu, Ji and Hastie, Trevor J},
booktitle = {NIPS},
file = {:C$\backslash$:/Users/Daniel/Downloads/margmax1 (1).pdf:pdf},
isbn = {0-262-20152-6},
issn = {10495258},
pages = {1237--1244},
title = {{Margin Maximizing Loss Functions}},
url = {http://papers.nips.cc/paper/2433-margin-maximizing-loss-functions.pdf{\%}5Cnfiles/3713/Rosset et al. - 2004 - Margin Maximizing Loss Functions.pdf{\%}5Cnfiles/3714/2433-margin-maximizing-loss-functions.html},
year = {2004}
}
@article{Shepherd|2002|,
author = {Shepherd, G M and Raastad, M and Andersen, P},
journal = {Proc. Natl. Acad. Sci. USA},
number = {9},
pages = {6340--6344},
title = {{General and variable features of varicosity spacing along unmyelinated axons in the hippocampus and cerebellum.}},
volume = {99}
}
@article{WangZhong04,
abstract = {To study the representation of olfactory information in higher brain

centers, we expressed a green fluorescent protein-based {\{}Ca{\}}{\^{}}{\{}2+{\}}

sensor, G-CaMP, in the Drosophila mushroom body (MB). Using two-photon

microscopy, we imaged odor-evoked G-CaMP fluorescence transients

in MB neurons [Kenyon cells (KCs)] with single-cell resolution. Odors

produced large fluorescence transients in a subset of KC somata and

in restricted regions of the calyx, the neuropil of the MB. In different

KCs, odor-evoked fluorescence transients showed diverse changes with

odor concentration: in some KCs, fluorescence transients were evoked

by an odor at concentrations spanning several orders of magnitude,

whereas in others only at a narrow concentration range. Different

odors produced fluorescence transients in different subsets of KCs.

The spatial distributions of KCs showing fluorescence transients

evoked by a given odor were similar across individuals. For some

odors, individual KCs with fluorescence transients evoked by a particular

odor could be found in similar locations in different flies with

spatial precisions on the order of the size of KC somata. These results

indicate that odor-evoked activity can have remarkable spatial specificity

in the MB.},
author = {Wang, Yalin and Guo, Hui-Fu and Pologruto, Thomas A and Hannan, Frances and Hakker, Inessa and Svoboda, Karel and Zhong, Yi},
doi = {10.1523/JNEUROSCI.3727-03.2004},
journal = {J Neurosci},
keywords = {Animals; Calcium; Drosophila; Green Fluorescent Pr,Fluorescence,Multiphoton; Mushroom Bodies; Neurons; Odors},
month = {jul},
number = {29},
pages = {6507--6514},
pmid = {15269261},
title = {{Stereotyped odor-evoked activity in the mushroom body of Drosophila revealed by green fluorescent protein-based {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.3727-03.2004},
volume = {24},
year = {2004}
}
@article{Markram2007,
abstract = {We present a novel framework for automatically constraining parameters of compartmental models of neurons, given a large set of experimentally measured responses of these neurons. In experiments, intrinsic noise gives rise to a large variability (e.g., in firing pattern) in the voltage responses to repetitions of the exact same input. Thus, the common approach of fitting models by attempting to perfectly replicate, point by point, a single chosen trace out of the spectrum of variable responses does not seem to do justice to the data. In addition, finding a single error function that faithfully characterizes the distance between two spiking traces is not a trivial pursuit. To address these issues, one can adopt a multiple objective optimization approach that allows the use of several error functions jointly. When more than one error function is available, the comparison between experimental voltage traces and model response can be performed on the basis of individual features of interest (e.g., spike rate, spike width). Each feature can be compared between model and experimental mean, in units of its experimental variability, thereby incorporating into the fitting this variability. We demonstrate the success of this approach, when used in conjunction with genetic algorithm optimization, in generating an excellent fit between model behavior and the firing pattern of two distinct electrical classes of cortical interneurons, accommodating and fast-spiking. We argue that the multiple, diverse models generated by this method could serve as the building blocks for the realistic simulation of large neuronal networks.},
annote = {

2010IIInum48},
author = {Markram, H and Druckmann, S and Banitt, Y and Gidon, A and Sch, F and Segev, I and Sch{\"{u}}rmann, F},
doi = {10.3389/neuro.01.1.1.001.2007},
issn = {1662-453X},
journal = {Neural Computation},
keywords = {compartmental model,cortical interneurons,firing pattern,multi-objective optimization,noisy neurons},
month = {nov},
number = {1},
pages = {7--18},
pmid = {18982116},
title = {{A novel multiple objective optimization framework for constraining conductance-based neuron models}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2570085{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {1},
year = {2007}
}
@article{ChanNg96,
author = {Chan, Raymond H and Ng, Michael K},
journal = {SIAM Review},
pages = {427--482},
title = {{Conjugate Gradient Methods for Toeplitz Systems}},
volume = {38},
year = {1996}
}
@article{Hopfield1998,
author = {Hopfield, J J and Brody, C D and Roweis, S},
journal = {Advances in neural information processing systems 10: {\ldots}},
title = {{Computing with action potentials}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=M55BL-GvQ8IC{\&}oi=fnd{\&}pg=PA166{\&}dq=Computing+with+Action+Potentials{\&}ots=FrBBXzBNpX{\&}sig={\_}xvGDUbAJCPfl7TqxewBNn7xQWs},
year = {1998}
}
@article{Gupta00,
author = {Gupta, A and Wang, Y and Markram, H},
journal = {Science},
pages = {273--278},
title = {{Organizing principles for a diversity of GABAergic interneurons and synapses in the neocortex.}},
volume = {287},
year = {2000}
}
@inproceedings{attias98coding,
author = {Attias, H and Schreiner, C},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Jordan, Michael I and Kearns, Michael J and Solla, Sara A},
publisher = {The {\{}MIT{\}} Press},
title = {{Coding of Naturalistic Stimuli by Auditory Midbrain Neurons}},
url = {citeseer.ist.psu.edu/attias98coding.html},
volume = {10},
year = {1998}
}
@article{Adams79,
author = {Adams, J C},
journal = {The Journal of Comparative Neurology},
number = {3},
pages = {519--538},
title = {{Ascending projections to the inferior colliculus}},
volume = {183},
year = {1979}
}
@book{BurnhamAnderson02,
abstract = {Book Description


The second edition of this book is unique in that it focuses on methods

for making formal statistical inference from all the models in an

a priori set (Multi-Model Inference). A philosophy is presented for

model-based data analysis and a general strategy outlined for the

analysis of empirical data. The book invites increased attention

on a priori science hypotheses and modeling. Kullback-Leibler Information

represents a fundamental quantity in science and is Hirotugu Akaike's

basis for model selection. The maximized log-likelihood function

can be bias-corrected as an estimator of expected, relative Kullback-Leibler

information. This leads to Akaike's Information Criterion (AIC) and

various extensions. These methods are relatively simple and easy

to use in practice, but based on deep statistical theory. The information

theoretic approaches provide a unified and rigorous theory, an extension

of likelihood theory, an important application of information theory,

and are objective and practical to employ across a very wide class

of empirical problems. The book presents several new ways to incorporate

model selection uncertainty into parameter estimates and estimates

of precision. An array of challenging examples is given to illustrate

various technical issues. This is an applied book written primarily

for biologists and statisticians wanting to make inferences from

multiple models and is suitable as a graduate text or as a reference

for professional analysts.



Book Info


A philosophy is presented for model-based data analysis and a general

strategy outlined for the analysis of empirical data. Written primarily

for biologists and statisticians wanting to make inferences from

multiple models.},
author = {Burnham, Kenneth P and Anderson, David},
edition = {2nd},
pages = {496},
publisher = {Springer},
title = {{Model Selection and Multi-Model Inference}},
year = {2002}
}
@article{Brophy1969,
abstract = {Variancefluctuations in band-limited vacuum-tube flicker noise, current noise in agermanium p-n junction, and current noise in a carbon resistorare measured by determining probability amplitude distributions of the noisesignals with a multichannel pulse-height analyzer. The variances of 30noise specimens, each 100 sec in duration, for the threenoise sources are obtained from the width of the probabilityamplitude distributions, all of which obey a normal-distribution law. Fluctuationsin variance are largest in the case of resistor currentnoise and least for current noise in a p-n junction.Even in the latter case, however, the variations are wellin excess of artifacts resulting from sampling errors, as demonstratedby examining Nyquist noise signals. It is concluded that allthree 1/f noise sources exhibit variance fluctuations to varying degrees.

        
         {\textcopyright}1969 The American Institute of Physics},
author = {Brophy, James J.},
journal = {Journal of Applied Physics},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {aug},
number = {9},
pages = {3551--3553},
publisher = {AIP},
shorttitle = {J. Appl. Phys.},
title = {{Variance Fluctuations in Flicker Noise and Current Noise}},
url = {http://link.aip.org/link/?JAP/40/3551/1},
volume = {40},
year = {1969}
}
@article{Fields1976,
author = {Fields, Receptive and Block, Conduction and Sensory, O F and In, Neurones},
pages = {513--538},
title = {{Massachusetts and the Department of Neurobiology , Stanford University}},
year = {1976}
}
@article{lattanzi1997stochastic,
annote = {2008num28{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Lattanzi, G and Nardulli, G and Pasquariello, G and Stramaglia, S},
doi = {10.1103/PhysRevE.56.4567},
issn = {1063-651X},
journal = {Physical Review E},
month = {oct},
number = {4},
pages = {4567--4573},
publisher = {APS},
title = {{Stochastic learning in a neural network with adapting synapses}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.56.4567},
volume = {56},
year = {1997}
}
@article{GEO84,
author = {Georgopoulos, A and Caminiti, R and Kalaska, J},
journal = {Experimental Brain Research},
pages = {446--454},
title = {{Static spatial effects in motor cortex and area 5: quantitative relations in a two-dimensional space}},
volume = {54},
year = {1984}
}
@article{Hensman2014,
author = {Hensman, James and Zwie{\ss}ele, M and Lawrence, ND},
journal = {staffwww.dcs.sheffield.ac.uk},
title = {{Tilted Variational Bayes}},
url = {http://staffwww.dcs.sheffield.ac.uk/people/J.Hensman/hensman{\_}2014{\_}TVB.pdf},
volume = {33},
year = {2014}
}
@article{Vaswani2017,
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. 1},
archivePrefix = {arXiv},
arxivId = {1706.03762},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
eprint = {1706.03762},
file = {::},
journal = {arXiv},
keywords = {google,toronto},
month = {jun},
pages = {1--15},
title = {{Attention Is All You Need}},
url = {http://arxiv.org/abs/1706.03762},
year = {2017}
}
@book{Widrow1985,
address = {Englewood Cliffs, NJ},
author = {Widrow, B and Stearns, SD},
publisher = {Prentice-Hall, inc},
title = {{Adaptive signal processing}},
year = {1985}
}
@article{BDK96,
author = {Bressloff, P and Dwyer, V and Kearney, M},
journal = {Journal of Physics A},
pages = {1881--1896},
title = {{A `sum-over-paths' approach to diffusion on trees}},
volume = {29},
year = {1996}
}
@article{Advani2017,
abstract = {We perform an average case analysis of the generalization dynamics of large neural networks trained using gradient descent. We study the practically-relevant "high-dimensional" regime where the number of free parameters in the network is on the order of or even larger than the number of examples in the dataset. Using random matrix theory and exact solutions in linear models, we derive the generalization error and training error dynamics of learning and analyze how they depend on the dimensionality of data and signal to noise ratio of the learning problem. We find that the dynamics of gradient descent learning naturally protect against overtraining and overfitting in large networks. Overtraining is worst at intermediate network sizes, when the effective number of free parameters equals the number of samples, and thus can be reduced by making a network smaller or larger. Additionally, in the high-dimensional regime, low generalization error requires starting with small initial weights. We then turn to non-linear neural networks, and show that making networks very large does not harm their generalization performance. On the contrary, it can in fact reduce overtraining, even without early stopping or regularization of any sort. We identify two novel phenomena underlying this behavior in overcomplete models: first, there is a frozen subspace of the weights in which no learning occurs under gradient descent; and second, the statistical properties of the high-dimensional regime yield better-conditioned input correlations which protect against overtraining. We demonstrate that naive application of worst-case theories such as Rademacher complexity are inaccurate in predicting the generalization performance of deep neural networks, and derive an alternative bound which incorporates the frozen subspace and conditioning effects and qualitatively matches the behavior observed in simulation.},
archivePrefix = {arXiv},
arxivId = {1710.03667},
author = {Advani, Madhu S. and Saxe, Andrew M.},
eprint = {1710.03667},
file = {:C$\backslash$:/Users/Daniel/Downloads/1710.03667.pdf:pdf},
journal = {arXiv},
pages = {1--32},
title = {{High-dimensional dynamics of generalization error in neural networks}},
url = {http://arxiv.org/abs/1710.03667},
year = {2017}
}
@article{GholmiehBerger06,
author = {Gholmieh, Ghassan and Soussou, Walid and Han, Martin and Ahuja, Ashish and Hsiao, Min-Chi and Song, Dong and Tanguay, Armand R Jr and Berger, Theodore W},
journal = {Journal of Neuroscience Methods},
month = {apr},
number = {1-2},
pages = {116--129},
title = {{Custom-designed high-density conformal planar multielectrode arrays for brain slice electrophysiology}},
volume = {152},
year = {2006}
}
@article{Zhang2014a,
abstract = {We study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints. A new algorithm is proposed in this setting where the communication and coordination of work among concurrent processes (local workers), is based on an elastic force which links the parameters they compute with a center variable stored by the parameter server (master). The algorithm enables the local workers to perform more exploration, i.e. the algorithm allows the local variables to fluctuate further from the center variable by reducing the amount of communication between local workers and the master. We empirically demonstrate that in the deep learning setting, due to the existence of many local optima, allowing more exploration can lead to the improved performance. We propose synchronous and asynchronous variants of the new algorithm. We provide the stability analysis of the asynchronous variant in the round-robin scheme and compare it with the more common parallelized method ADMM. We show that the stability of EASGD is guaranteed when a simple stability condition is satisfied, which is not the case for ADMM. We additionally propose the momentum-based version of our algorithm that can be applied in both synchronous and asynchronous settings. Asynchronous variant of the algorithm is applied to train convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Experiments demonstrate that the new algorithm accelerates the training of deep architectures compared to DOWNPOUR and other common baseline approaches and furthermore is very communication efficient.},
archivePrefix = {arXiv},
arxivId = {1412.6651},
author = {Zhang, Sixin and Choromanska, Anna and LeCun, Yann},
eprint = {1412.6651},
issn = {10495258},
pages = {1--24},
title = {{Deep learning with Elastic Averaging SGD}},
url = {http://arxiv.org/abs/1412.6651},
year = {2014}
}
@book{FED72,
address = {New York},
author = {Fedorov, V},
publisher = {Academic Press},
title = {{Theory of Optimal Experiments}},
year = {1972}
}
@article{Weiler2008,
abstract = {Cortical layering is a hallmark of the mammalian neocortex and a major determinant of local synaptic circuit organization in sensory systems. In motor cortex, the laminar organization of cortical circuits has not been resolved, although their input-output operations are crucial for motor control. Here, we developed a general approach for estimating layer-specific connectivity in cortical circuits and applied it to mouse motor cortex. From these data we computed a laminar presynaptic --{\textgreater} postsynaptic connectivity matrix, W(post,pre), revealing a complement of stereotypic pathways dominated by layer 2 outflow to deeper layers. Network modeling predicted, and experiments with disinhibited slices confirmed, that stimuli targeting upper, but not lower, cortical layers effectively evoked network-wide events. Thus, in motor cortex, descending excitation from a preamplifier-like network of upper-layer neurons drives output neurons in lower layers. Our analysis provides a quantitative wiring-diagram framework for further investigation of the excitatory networks mediating cortical mechanisms of motor control.},
annote = {2010IIInum10},
author = {Weiler, Nicholas and Wood, Lydia and Yu, Jianing and Solla, S A and Shepherd, G.M. M},
doi = {10.1038/nn2049},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Animals,Brain Mapping,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: drug effects,Excitatory Postsynaptic Potentials: physiology,Glutamic Acid,Glutamic Acid: metabolism,Glutamic Acid: pharmacology,Jackie,Mice,Motor Cortex,Motor Cortex: anatomy {\&} histology,Motor Cortex: drug effects,Motor Cortex: physiology,Nerve Net,Nerve Net: anatomy {\&} histology,Nerve Net: drug effects,Nerve Net: physiology,Neural Networks (Computer),Neural Pathways,Neural Pathways: anatomy {\&} histology,Neural Pathways: drug effects,Neural Pathways: physiology,Neurons,Neurons: drug effects,Neurons: physiology,Organ Culture Techniques,Photic Stimulation,Photochemistry,Synaptic Transmission,Synaptic Transmission: drug effects,Synaptic Transmission: physiology},
mendeley-tags = {Jackie},
month = {mar},
number = {3},
pages = {360--366},
pmid = {18246064},
title = {{Top-down laminar organization of the excitatory network in motor cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2748826{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {11},
year = {2008}
}
@article{ManisRyugo94,
abstract = {Intracellular recordings from the dorsal cochlear nucleus have identified

cells with both simple and complex action potential waveforms. We

investigated the hypothesis that cartwheel cells are a specific cell

type that generates complex action potentials, based on their analogous

anatomical, developmental, and biochemical similarities to cerebellar

Purkinje cells, which are known to discharge complex action potentials.

Intracellular recordings were made from a brain slice preparation

of the guinea pig dorsal cochlear nucleus. A subpopulation of cells

discharged a series of two or three action potentials riding on a

slow depolarization as an all-or-none event; this discharge pattern

is called a complex spike or burst. These cells also exhibited anodal

break bursts, anomalous rectification, subthreshold inward rectification,

and frequent inhibitory postsynaptic potentials (IPSPs). Seven complex-spiking

cells were stained with intracellular dyes and subsequently identified

as cartwheel neurons. In contrast, six identified simple-spiking

cells recorded in concurrent experiments were pyramidal cells. The

cartwheel cell bodies reside in the lower part of layer 1 and the

upper part of layer 2 of the nucleus. The cells are characterized

by spiny dendrites penetrating the molecular layer, a lack of basal

dendritic processes, and an axonal plexus invading layers 2 and 3,

and the inner regions of layer 1. The cartwheel cell axons made putative

synaptic contacts at the light microscopic level with pyramidal cells

and small cells, including stellate cells, granule cells, and other

cartwheel cells in layers 1 and 2. The axonal plexus of individual

cartwheel cells suggests that they can inhibit cells receiving input

from either the same or adjacent parallel fibers and that this inhibition

is distributed along the isofrequency contours of the nucleus.},
author = {Manis, P B and Spirou, G A and Wright, D D and Paydar, S and Ryugo, D K},
doi = {10.1002/cne.903480208},
journal = {J Comp Neurol},
keywords = {Action Potentials; Animals; Cochlear Nucleus; Guin},
month = {oct},
number = {2},
pages = {261--276},
pmid = {7814691},
title = {{Physiology and morphology of complex spiking neurons in the guinea pig dorsal cochlear nucleus.}},
url = {http://dx.doi.org/10.1002/cne.903480208},
volume = {348},
year = {1994}
}
@article{Dombeck04,
author = {Dombeck, Daniel A and Blanchard-Desce, Mireille and Webb, Watt W},
journal = {J. Neurosci.},
number = {4},
pages = {999--1003},
title = {{Optical Recording of Action Potentials with Second-Harmonic Generation Microscopy}},
volume = {24},
year = {2004}
}
@article{Saad1997,
author = {Saad, D and Rattray, Magnus},
doi = {10.1103/PhysRevLett.79.2578},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {sep},
number = {13},
pages = {2578--2581},
title = {{Globally Optimal Parameters for On-Line Learning in Multilayer Neural Networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.79.2578},
volume = {79},
year = {1997}
}
@article{Lindeberg|1999|,
abstract = {This paper reviews a systematic methodology for formulating mechanisms
for automatic scale selection when performing feature detection.
An important property of the proposed approach is that the notion
of scale is included already in the definition of image features.},
annote = {The paper introduces concept of scale-space for edge detection with{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}scale selection.},
author = {Lindeberg, T},
keywords = {automatic scale selection,computational,edge detection,image processing,multiscale,scale space},
title = {{Automatic Scale Selection as a Pre-Processing Stage for Interpreting the Visual World}}
}
@article{Meister1995,
abstract = {To analyze the rules that govern communication between eye and brain, visual responses were recorded from an intact salamander retina. Parallel observation of many retinal ganglion cells with a microelectrode array showed that nearby neurons often fired synchronously, with spike delays of less than 10 milliseconds. The frequency of such synchronous spikes exceeded the correlation expected from a shared visual stimulus up to 20-fold. Synchronous firing persisted under a variety of visual stimuli and accounted for the majority of action potentials recorded. Analysis of receptive fields showed that concerted spikes encoded information not carried by individual cells; they may represent symbols in a multineuronal code for vision.},
author = {Meister, M and Lagnado, L and Baylor, D a},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
keywords = {Action Potentials,Animals,Microelectrodes,Ocular,Ocular: physiology,Photic Stimulation,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,Signal Transduction,Spike time neural coding,Urodela,Vision},
mendeley-tags = {Spike time neural coding},
month = {nov},
number = {5239},
pages = {1207--10},
pmid = {7502047},
title = {{Concerted signaling by retinal ganglion cells.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7502047},
volume = {270},
year = {1995}
}
@article{Garner|2002|,
author = {Garner, C C and Zhai, R G and Gundelfinger, E D and Ziv, N E},
journal = {Trends Neurosci.},
number = {5},
pages = {243--251},
title = {{Molecular mechanisms of CNS synaptogenesis.}},
volume = {25}
}
@article{JiWilson07,
author = {Ji, D and Wilson, M},
journal = {Nature Neuroscience},
pages = {100--107},
title = {{Coordinated memory replay in the visual cortex and hippocampus during sleep}},
volume = {10},
year = {2007}
}
@article{Braunstein,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0511159v2},
author = {Braunstein, A and Zecchina, R},
eprint = {0511159v2},
journal = {Physical review letters},
keywords = {Message passing},
mendeley-tags = {Message passing},
number = {3},
primaryClass = {arXiv:cond-mat},
title = {{Learning by message passing in networks of discrete synapses}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.96.030201 http://prl.aps.org/abstract/PRL/v96/i3/e030201},
volume = {96},
year = {2006}
}
@article{Helmstaedter2009,
author = {Helmstaedter, M and Briggman, K L and Denk, W},
journal = {Current Opinions in Neurobiology},
pages = {Epub},
title = {{3D structural imaging of the brain with photons and electrons.}},
year = {2009}
}
@article{Zhang2017,
abstract = {We study the efficacy of learning neural networks with neural networks by the (stochastic) gradient descent method. While gradient descent enjoys empirical success in a variety of applications, there is a lack of theoretical guarantees that explains the practical utility of deep learning. We focus on two-layer neural networks with a linear activation on the output node. We show that under some mild assumptions and certain classes of activation functions, gradient descent does learn the parameters of the neural network and converges to the global minima. Using a node-wise gradient descent algorithm, we show that learning can be done in finite, sometimes {\$}poly(d,1/\backslashepsilon){\$}, time and sample complexity.},
archivePrefix = {arXiv},
arxivId = {1702.00458},
author = {Zhang, Qiuyi and Panigrahy, Rina and Sachdeva, Sushant and Rahimi, Ali},
eprint = {1702.00458},
journal = {arXiv:1702.00458},
pages = {1--31},
title = {{Electron-Proton Dynamics in Deep Learning}},
url = {http://arxiv.org/abs/1702.00458},
year = {2017}
}
@article{Baranauskas2007,
annote = {2010IIInum69},
author = {Baranauskas, G},
doi = {10.1007/s12035-007-8001-0},
issn = {0893-7648},
journal = {Molecular Neurobiology},
keywords = {activation kinetics biophysical properties,potassium channels,slow sodium inactivation,sodium channels},
mendeley-tags = {slow sodium inactivation},
number = {2},
pages = {129--150},
title = {{Ionic Channel Function in Action Potential Generation: Current Perspective}},
url = {http://www.springerlink.com/index/10.1007/s12035-007-8001-0},
volume = {35},
year = {2007}
}
@article{Tsien81,
author = {Tsien, R Y},
journal = {Nature},
pages = {527--528},
title = {{A non-disruptive technique for loading calcium buffers and indicators into cells.}},
volume = {290},
year = {1981}
}
@article{Romberg|2008|,
author = {Romberg, J},
journal = {IEEE Signal Processing Magazine},
number = {2},
pages = {14--20},
title = {{Imaging via compressive sampling}},
volume = {25}
}
@article{Timm2009,
annote = {2010IIInum3},
archivePrefix = {arXiv},
arxivId = {arXiv:0905.2859v2},
author = {Timm, Carsten},
eprint = {arXiv:0905.2859v2},
journal = {Physical Review E},
number = {4},
title = {{Random transition-rate matrices for the master equation}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.80.021140 http://pre.aps.org/abstract/PRE/v80/i2/e021140},
year = {2009}
}
@article{Muller2015,
abstract = {Neural network algorithms simulated on standard computing platforms typically make use of high resolution weights, with floating-point notation. However, for dedicated hardware implementations of such algorithms, fixed-point synaptic weights with low resolution are preferable. The basic approach of reducing the resolution of the weights in these algorithms by standard rounding methods incurs drastic losses in performance. To reduce the resolution further, in the extreme case even to binary weights, more advanced techniques are necessary. To this end, we propose two methods for mapping neural network algorithms with high resolution weights to corresponding algorithms that work with low resolution weights and demonstrate that their performance is substantially better than standard rounding. We further use these methods to investigate the performance of three common neural network algorithms under fixed memory size of the weight matrix with different weight resolutions. We show that dedicated hardware systems, whose technology dictates very low weight resolutions (be they electronic or biological) could in principle implement the algorithms we study.},
archivePrefix = {arXiv},
arxivId = {1504.05767},
author = {Muller, Lorenz K. and Indiveri, Giacomo},
eprint = {1504.05767},
month = {apr},
title = {{Rounding Methods for Neural Networks with Low Resolution Synaptic Weights}},
url = {http://arxiv.org/abs/1504.05767},
year = {2015}
}
@article{Glauber1963,
annote = {2011num8},
author = {Glauber, RJ},
journal = {Journal of mathematical physics},
title = {{Time Dependent Statistics of the Ising Model}},
url = {http://link.aip.org/link/?JMAPAQ/4/294/1 http://link.aip.org/link/{\%}3FJMAPAQ/4/294/1},
year = {1963}
}
@article{Zaharijas|2004|,
abstract = {We consider the cross section limits for light dark matter candidates
(m = 0.4 to 10 GeV). We calculate the interaction of dark matter
in the crust above underground dark matter detectors and find that
in the intermediate cross section range, the energy loss of dark
matter is sufficient to fall below the energy threshold of current
underground experiments. This implies the existence of a window in
the dark matter exclusion limits in the micro-barn range.},
annote = {This paper considers low-range exclusion limits on interacting dark{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}matter.},
author = {Zaharijas, G and Farrar, G R},
journal = {arXiv},
keywords = {astrophysics,cross-section,dark matter,experimental,interaction,mass,physics,strongly interacting dark matter},
pages = {40653},
title = {{A window in the dark matter exclusion limits}},
volume = {astro-ph}
}
@article{JEFFREY2007,
author = {JEFFREY, JH},
journal = {Asia-Pacific Journal of Operational Research},
pages = {209--226},
title = {{Simple procedures for finding mean first passage times in Markov chains}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0217595907001553},
volume = {8},
year = {2007}
}
@article{Liu1998,
abstract = {The Kv3.1 channel subunit, when expressed heterologously, gives rise to a high-threshold noninactivating potassium current. Experiments with auditory neurons have suggested that the presence of this channel subunit enables them to fire action potentials at high frequencies. We have found that the expression levels of Kv3.1 transcripts increase in inferior colliculus neurons before the onset of hearing and then remain relatively constant. Because spontaneous neuronal activity plays an important role in modulating neuronal excitability during development, we examined the effects of depolarization with an elevated concentration of external potassium ions on the expression of Kv3.1 channel subunits in immature inferior colliculus neurons. Elevated potassium produced a marked increase in Kv3.1 mRNA levels and in the amplitude of a high-threshold, noninactivating current before the onset of hearing. This increase was prevented by the presence of a calcium channel blocker, indicating that calcium influx mediated the depolarization-induced increase in this current. In contrast, treatment with an elevated external potassium concentration caused only a moderate increase in the peak amplitude of a lower-threshold inactivating current. The repolarization of action potentials in the high-potassium-treated cells was more rapid and complete than in the control cells. Computer simulations confirmed that this change could be explained by a change in Kv3.1-like current of the same magnitude as recorded in voltage-clamp experiments. Thus, depolarization and calcium influx may alter the excitability of immature inferior colliculus neurons by selectively increasing the levels of a Kv3. 1-like potassium current.},
author = {Liu, S J Q and Kaczmarek, L K},
issn = {0270-6474},
journal = {The Journal of neuroscience},
keywords = {Aging,Animals,Calcium,Calcium: metabolism,Developmental,Gene Expression Regulation,Inferior Colliculi,Inferior Colliculi: metabolism,Membrane Potentials,Membrane Potentials: drug effects,Messenger,Messenger: metabolism,Neuropeptides,Neuropeptides: metabolism,Newborn,Patch-Clamp Techniques,Potassium,Potassium Channels,Potassium Channels: metabolism,Potassium: pharmacology,RNA,Rats,Shaw Potassium Channels,Sprague-Dawley,Voltage-Gated},
month = {nov},
number = {21},
pages = {8758--69},
pmid = {9786983},
publisher = {Soc Neuroscience},
title = {{Depolarization selectively increases the expression of the Kv3.1 potassium channel in developing inferior colliculus neurons}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9786983},
volume = {18},
year = {1998}
}
@article{Harindranath|1993|,
abstract = {In this third part in a series of papers on light-front QCD, we continue
the study of regularization and renormalization in old-fashioned
perturbative light-front formalism. We calculate lowest order radiative
corrections to the quark-gluon coupling constant in ligth-front QCD.
An attempt is made to understand the origin of antiscreening in a
formulation of QCD with only physical degrees of freedom in terms
of contributions fro mdistinct Fock space sectors. The relevance
of our results to bound state calculations in QCD with a truncated
Fock space are discussed.},
author = {Harindranath, A and Zhang, W.-M.},
journal = {Physical Review D},
keywords = {generalized parton distribution,light front dynamics,perturbation theory,physics,quantum chromodynamics,renormalization,unread},
number = {10},
pages = {4903},
title = {{Light-front QCD III. Coupling constant renormalization}},
volume = {48}
}
@article{Thompson05,
author = {Thompson, P and Brooks, K and Hammett, S},
journal = {Vision Research},
pages = {782--786},
title = {{Speed can go up as well as down at low contrast: Implications for models of motion perception}},
volume = {46},
year = {2005}
}
@book{AtkinsonDonev92,
author = {Atkinson, A C and Donev, A N},
publisher = {Oxford University Press},
title = {{Optimum Experimental Designs}},
year = {1992}
}
@book{RamonyCajal04,
author = {y Cajal, S},
publisher = {Moya},
title = {{La Textura del Sistema Nerviosa del Hombre y los Vertebrados}},
year = {1904}
}
@article{Mozzachiodi2010,
abstract = {Decades of research on the cellular mechanisms of memory have led to the widely held view that memories are stored as modifications of synaptic strength. These changes involve presynaptic processes, such as direct modulation of the release machinery, or postsynaptic processes, such as modulation of receptor properties. Parallel studies have revealed that memories might also be stored by nonsynaptic processes, such as modulation of voltage-dependent membrane conductances, which are expressed as changes in neuronal excitability. Although in some cases nonsynaptic changes can function as part of the engram itself, they might also serve as mechanisms through which a neural circuit is set to a permissive state to facilitate synaptic modifications that are necessary for memory storage.},
annote = {2010num5.8},
author = {Mozzachiodi, Riccardo and Byrne, John H},
doi = {10.1016/j.tins.2009.10.001},
issn = {1878-108X},
journal = {Trends in Neurosciences},
number = {1},
pages = {17--26},
pmid = {19889466},
title = {{More than synaptic plasticity: role of nonsynaptic plasticity in learning and memory.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19889466},
volume = {33},
year = {2010}
}
@article{WOOL05,
author = {Woolley, S and Fremouw, T and Hsu, A and Theunissen, F},
journal = {Nature Neuroscience},
pages = {1371--1378},
title = {{Tuning for spectro-temporal modulations as a mechanism for auditory discrimination of natural sounds}},
volume = {8},
year = {2005}
}
@article{BUONCORE87,
author = {Buoncore, A and Nobile, A and Ricciardi, L},
journal = {Adv Appl Prob},
pages = {784--800},
title = {{A New Integral Equation for the Evaluation of First-Passage-Time Probability Densities}},
volume = {19},
year = {1987}
}
@article{Murray1993,
author = {Murray, A F and Edwards, P J},
journal = {Neural Networks, IEEE Transactions on},
number = {4},
pages = {722--725},
publisher = {IEEE},
title = {{Synaptic weight noise during multilayer perceptron training: Fault tolerance and training improvements}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=238328},
volume = {4},
year = {1993}
}
@article{Baum1988,
abstract = {What is the smallest multilayer perceptron able to compute arbitrary and random functions? Previous results show that a net with one hidden layer containing N - 1 threshold units is capable of implementing an arbitrary dichotomy of N points. A construction is presented here for implementing an arbitrary dichotomy with one hidden layer containing [ N d] units, for any set of N points in general position in d dimensions. This is in fact the smallest such net as dichotomies which cannot be implemented by any net with fewer units are described. Several constructions are presented of one-hidden-layer nets implementing arbitrary functions into the e-dimensional hypercube. One of these has only [ 4N d][ e [log2( N d)]] units in its hidden layer. Arguments based on a function counting theorem of Cover establish that any net implementing arbitrary functions must have at least Ne log2(N) weights, so that no net with one hidden layer containing less than Ne/(d log2(N)) units will suffice. Simple counts also show that if the weights are only allowed to assume one of ng possible values, no net with fewer than Ne log2(ng) weights will suffice. Thus the gain coming from using real valued synapses appears to be only logarithmic. The circuit implementing functions into the e hypercube realizes such logarithmic gains. Since the counting arguments limit below only the number of weights, the possibility is suggested that, if suitable restrictions are imposed on the input vector set to avoid topological obstructions, two-hidden-layer nets with O(N) weights but only O(???N) threshold units might suffice for arbitrary dichotomies. Interesting and potentially sufficient restrictions include (a) if the vectors are binary, i.e., lie on the d hypercube or (b) if they are randomly and uniformly selected from a bounded region. ?? 1988.},
author = {Baum, Eric B.},
doi = {10.1016/0885-064X(88)90020-9},
issn = {10902708},
journal = {Journal of Complexity},
number = {3},
pages = {193--215},
title = {{On the capabilities of multilayer perceptrons}},
volume = {4},
year = {1988}
}
@article{BAK01,
author = {Baker, S and Spinks, R and Jackson, A and Lemon, R},
journal = {Journal of Neurophysiology},
pages = {869--885},
title = {{Synchronization in monkey motor cortex during a precision grip task}},
volume = {85},
year = {2001}
}
@article{SmithLewicki06,
author = {Smith, Evan C and Lewicki, Michael S},
journal = {Nature},
month = {feb},
number = {7079},
pages = {978--982},
title = {{Efficient auditory coding}},
volume = {439},
year = {2006}
}
@article{Huggins2012,
abstract = {Due to the limitations of current voltage sensing techniques, optimal filtering of noisy, undersampled voltage signals on dendritic trees is a key problem in computational cellular neuroscience. These limitations lead to voltage data that is incomplete (in the sense of only capturing a small portion of the full spatiotemporal signal) and often highly noisy. In this paper we use a Kalman filtering framework to develop optimal experimental design methods for voltage sampling. Our approach is to use a simple greedy algorithm with lazy evaluation to minimize the expected square error of the estimated spatiotemporal voltage signal. We take advantage of some particular features of the dendritic filtering problem to efficiently calculate the Kalman estimator's covariance. We test our framework with simulations of real dendritic branching structures and compare the quality of both time-invariant and time-varying sampling schemes. While the benefit of using the experimental design methods was modest in the time-invariant case, improvements of 25-100{\%} over more na{\"{i}}ve methods were found when the observation locations were allowed to change with time. We also present a heuristic approximation to the greedy algorithm that is an order of magnitude faster while still providing comparable results.},
author = {Huggins, Jonathan Hunter and Paninski, L},
doi = {10.1007/s10827-011-0357-5},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Animals,Computer Simulation,Dendrites,Dendrites: physiology,Estimation,Humans,Models, Neurological,Neurons,Neurons: cytology,Neurons: physiology,Normal Distribution,Research Design},
mendeley-tags = {Estimation},
month = {apr},
number = {2},
pages = {347--66},
pmid = {21861199},
title = {{Optimal experimental design for sampling voltage on dendritic trees in the low-SNR regime.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21861199},
volume = {32},
year = {2012}
}
@article{GL95,
author = {Gill, R and Levit, B},
journal = {Bernoulli},
pages = {59--79},
title = {{Applications of the van Trees inequality: A {\{}B{\}}ayesian {\{}C{\}}ramer-{\{}R{\}}ao bound}},
volume = {1/2},
year = {1995}
}
@article{bresler2001dynamics,
annote = {2008num30},
author = {Bresler, T and Ramati, Y and Zamorano, P L and Zhai, R and Garner, C C and Ziv, N E},
journal = {Molecular and Cellular Neuroscience},
number = {2},
pages = {149--167},
publisher = {Elsevier},
title = {{The dynamics of SAP90/PSD-95 recruitment to new synaptic junctions}},
volume = {18},
year = {2001}
}
@article{TzounopoulosTrussell04,
author = {Tzounopoulos, Thanos and Kim, Yuil and Oertel, Donata and Trussell, Laurence O},
journal = {Nat Neurosci},
month = {jul},
number = {7},
pages = {719--725},
title = {{Cell-specific, spike timing-dependent plasticities in the dorsal cochlear nucleus}},
volume = {7},
year = {2004}
}
@article{BARB04,
author = {Barbieri, R and Frank, L and Nguyen, D and Quirk, M and Solo, V and Wilson, M and Brown, E},
journal = {Neural Computation},
pages = {277--307},
title = {{Dynamic Analyses of Information Encoding in Neural Ensembles}},
volume = {16},
year = {2004}
}
@article{Powel|1963|,
author = {Powel, E W},
journal = {Exp Neurol},
pages = {406--422},
title = {{Septal efferents revealed by axonal degeneration in the rat}},
volume = {8}
}
@article{Mikula2003a,
abstract = {In this letter, we extend our previous analytical results (Mikula {\&} Niebur, 2003) for the coincidence detector by taking into account probabilistic frequency-dependent synaptic depression. We present a solution for the steady-state output rate of an ideal coincidence detector receiving an arbitrary number of input spike trains with identical binomial count distributions (which includes Poisson statistics as a special case) and identical arbitrary pairwise cross-correlations, from zero correlation (independent processes) to perfect correlation (identical processes). Synapses vary their efficacy probabilistically according to the observed depression mechanisms. Our results show that synaptic depression, if made sufficiently strong, will result in an inverted U-shaped curve for the output rate of a coincidence detector as a function of input rate. This leads to the counterintuitive prediction that higher presynaptic (input) rates may lead to lower postsynaptic (output) rates where the output rate may fall faster than the inverse of the input rate.},
annote = {2010IInum12.21},
author = {Mikula, Shawn and Niebur, Ernst},
doi = {10.1162/089976603322362383},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Central Nervous System,Central Nervous System: physiology,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Humans,Long-Term Potentiation,Long-Term Potentiation: physiology,Models,Neural Inhibition,Neural Inhibition: physiology,Neurological,Neuron Model,Neurons,Neurons: physiology,Perception,Perception: physiology,Sensation,Sensation: physiology,Statistical,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,synapse},
mendeley-tags = {Neuron Model,synapse},
month = {oct},
number = {10},
pages = {2339--58},
pmid = {14511524},
title = {{Synaptic depression leads to nonmonotonic frequency dependence in the coincidence detector.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14511524},
volume = {15},
year = {2003}
}
@article{Lavzin2012,
abstract = {Layer 4 neurons in primary sensory cortices receive direct sensory information from the external world. A general feature of these neurons is their selectivity to specific features of the sensory stimulation. Various theories try to explain the manner in which these neurons are driven by their incoming sensory information. In all of these theories neurons are regarded as simple elements summing small biased inputs to create tuned output through the axosomatic amplification mechanism. However, the possible role of active dendritic integration in further amplifying the sensory responses and sharpening the tuning curves of neurons is disregarded. Our findings show that dendrites of layer 4 spiny stellate neurons in the barrel cortex can generate local and global multi-branch N-methyl-d-aspartate (NMDA) spikes, which are the main regenerative events in these dendrites. In turn, these NMDA receptor (NMDAR) regenerative mechanisms can sum supralinearly the coactivated thalamocortical and corticocortical inputs. Using in vivo whole-cell recordings combined with an intracellular NMDAR blocker and membrane hyperpolarization, we show that dendritic NMDAR-dependent regenerative responses contribute substantially to the angular tuning of layer 4 neurons by preferentially amplifying the preferred angular directions over non-preferred angles. Taken together, these findings indicate that dendritic NMDAR regenerative amplification mechanisms contribute markedly to sensory responses and critically determine the tuning of cortical neurons.},
author = {Lavzin, Maria and Rapoport, Sophia and Polsky, Alon and Garion, Liora and Schiller, J},
doi = {10.1038/nature11451},
issn = {1476-4687},
journal = {Nature},
month = {sep},
pages = {5--9},
pmid = {22940864},
publisher = {Nature Publishing Group},
title = {{Nonlinear dendritic processing determines angular tuning of barrel cortex neurons in vivo.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22940864},
year = {2012}
}
@misc{chegcornerdet,
annote = {This lecture presentation contains overview of edge {\&} corner detection,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}scale space and phase vs. amplitude in the fourier space and relation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to edges {\&} recognition},
keywords = {computational,edge detection,features,fourier space,image processing,multiscale,scale space},
title = {{Examples of Corner Detection}}
}
@article{Serrano-gotarredona2013a,
author = {Serrano-gotarredona, Teresa and Prodromakis, Themistoklis},
journal = {Circuits and Systems Magazine, IEEE},
month = {may},
number = {2},
pages = {74--88},
title = {{A Proposal for Hybrid Spiking Neuromorphic Learning}},
volume = {12},
year = {2013}
}
@article{Donoho2009,
abstract = {Compressed sensing aims to undersample certain high-dimensional signals yet accurately reconstruct them by exploiting signal characteristics. Accurate reconstruction is possible when the object to be recovered is sufficiently sparse in a known basis. Currently, the best known sparsity-undersampling tradeoff is achieved when reconstructing by convex optimization, which is expensive in important large-scale applications. Fast iterative thresholding algorithms have been intensively studied as alternatives to convex optimization for large-scale problems. Unfortunately known fast algorithms offer substantially worse sparsity-undersampling tradeoffs than convex optimization. We introduce a simple costless modification to iterative thresholding making the sparsity-undersampling tradeoff of the new algorithms equivalent to that of the corresponding convex optimization procedures. The new iterative-thresholding algorithms are inspired by belief propagation in graphical models. Our empirical measurements of the sparsity-undersampling tradeoff for the new algorithms agree with theoretical calculations. We show that a state evolution formalism correctly derives the true sparsity-undersampling tradeoff. There is a surprising agreement between earlier calculations based on random convex polytopes and this apparently very different theoretical formalism.},
author = {Donoho, David L and Maleki, Arian and Montanari, Andrea},
doi = {10.1073/pnas.0909892106},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Algorithms,Models, Statistical,Sample Size,Statistics as Topic,Statistics as Topic: methods},
month = {nov},
number = {45},
pages = {18914--9},
pmid = {19858495},
title = {{Message-passing algorithms for compressed sensing.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2767368{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {106},
year = {2009}
}
@article{Burket|2000|,
abstract = {The evolution of halos consisting of weakly self-interacting dark
matter particles is investigated using a new numerical Monte-Carlo
N-body method. The halos initially contain kinematically cold, dense
r{\^{a}}ˆ'1-power-law cores. For interaction cross sections {\"{I}}ƒ{\^{a}}ˆ— = {\"{I}}ƒ/mp
{\^{a}}‰¥ 10 - 100 cm2 g{\^{a}}ˆ'1 weak self-interaction leads to the formation
of isothermal, constant density cores within a Hubble time as a result
of heat transfer into the cold inner regions. This core structure
is in good agreement with the observations of dark matter rotation
curves in dwarf galaxies. The isothermal core radii and core densities
are a function of the halo scale radii and scale masses which depend
on the cosmological model. Adopting the currently popular CDM model,
the predicted core radii and core densities are in good agreement
with the observations. For large interaction cross sections, massive
dark halos with scale radii rs {\^{a}}‰¥ 1.4 {\~{A}}— 104 (cm2 g{\^{a}}ˆ'1 /{\"{I}}ƒ{\^{a}}ˆ—)
kpc could experience core collapse during their lifetime, leading
to cores with singular isothermal density profiles.},
author = {Burket, A},
journal = {arXiv},
keywords = {astrophysics,dark matter,halos,interaction,physics,simulation,strongly interacting dark matter},
pages = {2409},
title = {{The structure and evolution of weakly self-interacting cold dark matter halos}},
volume = {astro-ph}
}
@article{powers1999multiple,
annote = {2009num15},
author = {Powers, R K and Sawczuk, A and Musick, J R and Binder, M D},
journal = {Journal of Physiology-Paris},
number = {1-2},
pages = {101--114},
publisher = {Elsevier},
title = {{Multiple mechanisms of spike-frequency adaptation in motoneurones}},
volume = {93},
year = {1999}
}
@article{Fiala|2001|a,
author = {Fiala, J C and Harris, K M},
journal = {J Microsc},
pages = {468--472},
title = {{Cylindrical diameters method for calibrating section thickness in serial electron microscopy}},
volume = {202}
}
@article{Morie1994,
author = {Morie, T. and Amemiya, Y.},
doi = {10.1109/4.309904},
issn = {00189200},
journal = {IEEE Journal of Solid-State Circuits},
month = {sep},
number = {9},
pages = {1086--1093},
title = {{An all-analog expandable neural network LSI with on-chip backpropagation learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=309904},
volume = {29},
year = {1994}
}
@article{Colquhoun1982,
abstract = {Characteristics of observed bursts of single channel openings were derived recently for two particular ion channel mechanisms. In this paper these methods are generalized so that the observable characteristics of bursts can be calculated directly for any mechanism that has transition probabilities that are independent of time as long as the process is at equilibrium or is maintained in a steady state by an energy supply. General expressions are given for the distributions of the open time, the number of openings per burst, the total open time per burst, the gaps within and between bursts, and so on. With the aid of these general results a single computer program can be written that will provide numerical values for such distributions for any postulated mechanism, given only the transition rates between the various states. The results are illustrated by a numerical example of a mechanism in which two agonist molecules can bind sequentially, and either singly or doubly occupied receptor ion channels may open. The analogous theory is also given for the case where bursts of channel openings are grouped into clusters; many of the results bear a close analogy with those found for simple bursts.},
author = {Colquhoun, D and Hawkes, A. G.},
doi = {10.1098/rstb.1982.0156},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
month = {dec},
number = {1098},
pages = {1--59},
title = {{On the Stochastic Properties of Bursts of Single Ion Channel Openings and of Clusters of Bursts}},
url = {http://rstb.royalsocietypublishing.org/cgi/content/abstract/300/1098/1},
volume = {300},
year = {1982}
}
@article{Hertz2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1106.1752v1},
author = {Hertz, J and Roudi, Y and Tyrcha, J},
eprint = {arXiv:1106.1752v1},
journal = {arXiv:1106.1752},
pages = {1--28},
title = {{Ising Models for Inferring Network Structure From Spike Data}},
url = {http://arxiv.org/abs/1106.1752},
year = {2011}
}
@article{Marom1994,
author = {Marom, S and Abbott, L F},
doi = {10.1016/S0006-3495(94)80518-1},
issn = {00063495},
journal = {Biophysical Journal},
month = {aug},
number = {2},
pages = {515--520},
publisher = {Elsevier},
title = {{Modeling state-dependent inactivation of membrane currents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349594805181},
volume = {67},
year = {1994}
}
@article{Abarbanel08,
author = {Abarbanel, H and Creveling, D and Jeanne, J},
journal = {Phys. Rev. E},
pages = {16208},
title = {{Estimation of parameters in nonlinear systems using balanced synchronization}},
volume = {77},
year = {2008}
}
@article{Vogels2009,
abstract = {Recent theoretical work has provided a basic understanding of signal propagation in networks of spiking neurons, but mechanisms for gating and controlling these signals have not been investigated previously. Here we introduce an idea for the gating of multiple signals in cortical networks that combines principles of signal propagation with aspects of balanced networks. Specifically, we studied networks in which incoming excitatory signals are normally cancelled by locally evoked inhibition, leaving the targeted layer unresponsive. Transmission can be gated 'on' by modulating excitatory and inhibitory gains to upset this detailed balance. We illustrate gating through detailed balance in large networks of integrate-and-fire neurons. We show successful gating of multiple signals and study failure modes that produce effects reminiscent of clinically observed pathologies. Provided that the individual signals are detectable, detailed balance has a large capacity for gating multiple signals.},
author = {Vogels, Tim P and Abbott, L F},
doi = {10.1038/nn.2276},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cell Communication,Cell Communication: physiology,Computer Simulation,Ion Channel Gating,Models, Neurological,Nerve Net,Nerve Net: physiology,Neural Inhibition,Neural Inhibition: physiology,Neural Networks (Computer),Neurons,Neurons: classification,Neurons: physiology,Signal Transduction,Signal Transduction: physiology},
month = {apr},
number = {4},
pages = {483--91},
pmid = {19305402},
title = {{Gating multiple signals through detailed balance of excitation and inhibition in spiking networks.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2693069{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {12},
year = {2009}
}
@techreport{Segonne|2005|,
abstract = {We present a novel framework to exert a topology control over a level
set evolution. Level set methods offer several advantages over parametric
active contours, in particular automated topological changes. In
some applications, where some a priori knowledge of the target topology
is available, topological changes may not be desirable. A method,
based on the concept of simple point borrowed from digital topology,
was recently proposed to achieve a strict topology preservation during
a level set evolution. However, topologically constrained evolutions
often generate topological barriers that lead to large geometric
inconsistencies. We introduce a topologically controlled level set
framework that greatly alleviates this problem. Unlike existing work,
our method allows connected components to merge, split or vanish
under some specific conditions that ensure that no topological defects
are generated. We demonstrate the strength of our method on a wide
range of numerical experiments.},
annote = {This very interesting paper introduces a novel level set algorithm{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}allowing level set evolution with topology control enforced via preservation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of the total Euler number of the set. Topology control is exerted{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}via the concept of multi-simple points},
author = {Segonne, F and Pons, J.-P. and Fischl, B and Grimson, E},
institution = {MIT},
keywords = {Euler number,active contour,active shape,computational,image processing,level set,segmentation,topology preserving level set},
month = {jun},
title = {{A novel active contour framework. Multi-component level set evolution under topology control}}
}
@article{Titterington2004,
author = {Titterington, D. M.},
doi = {10.1214/088342304000000099},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,bayesian methods,bayesian model choice,feed-,forward neural network,graphical model,laplace approximation,learning,machine,markov chain monte carlo,variational approximation},
month = {feb},
number = {1},
pages = {128--139},
title = {{Bayesian Methods for Neural Networks and Related Models}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ss/1089808278/},
volume = {19},
year = {2004}
}
@article{Spitzer1999,
author = {Spitzer, N C},
doi = {10.1038/9132},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Animals,Electrophysiology,Ion Channel Gating,Ion Channel Gating: physiology,Ion Channels,Ion Channels: physiology,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology},
month = {jun},
number = {6},
pages = {489--91},
pmid = {10448206},
publisher = {Nature Publishing Group},
title = {{New dimensions of neuronal plasticity}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10448206},
volume = {2},
year = {1999}
}
@inproceedings{Srivastava2015,
abstract = {Theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success. However, training becomes more difficult as depth increases, and training of very deep networks remains an open problem. Here we introduce a new architecture designed to overcome this. Our so-called highway networks allow unimpeded information flow across many layers on information highways. They are inspired by Long Short-Term Memory recurrent networks and use adaptive gating units to regulate the information flow. Even with hundreds of layers, highway networks can be trained directly through simple gradient descent. This enables the study of extremely deep and efficient architectures.},
archivePrefix = {arXiv},
arxivId = {1507.06228},
author = {Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"{u}}rgen},
booktitle = {NIPS},
eprint = {1507.06228},
pages = {1--9},
title = {{Training Very Deep Networks}},
url = {http://arxiv.org/abs/1507.06228},
year = {2015}
}
@article{Jensen1989,
author = {Jensen, HJ and Christensen, K and Fogedby, HC},
journal = {Physical Review B},
number = {10},
pages = {1--3},
title = {1/f noise, distribution of lifetimes, and a pile of sand},
url = {http://prb.aps.org/abstract/PRB/v40/i10/p7425{\_}1},
volume = {40},
year = {1989}
}
@article{BEI97,
author = {Beirlant, J and Dudewicz, E and Gyorfi, L and van der Meulen, E},
journal = {International Journal of the Mathematical Statistics Sciences},
pages = {17--39},
title = {{Nonparametric entropy estimation: an overview}},
volume = {6},
year = {1997}
}
@article{baylor1974electrical,
author = {Baylor, D A and Hodgkin, A L and Lamb, T D},
journal = {The Journal of physiology},
number = {3},
pages = {685--727},
publisher = {Physiological Soc},
title = {{The electrical response of turtle cones to flashes and steps of light}},
volume = {242},
year = {1974}
}
@article{Litke2003,
author = {Litke, A M and Chichilnisky, E J and Dabrowski, W and Grillo, A A and Grybos, P and Kachiguine, S and Rahman, M and Taylor, G},
journal = {Nucl. Instrum. Methods A},
pages = {298--307},
title = {{Large-scale imaging of retinal output activity}},
volume = {501},
year = {2003}
}
@article{Zhang|1993|,
abstract = {The light-fron gauge A{\^{}}+{\_}alpha=0 is known to be a convenient gauge
in practical QCD calculations for short-distance behavior, but there
are persistent concerns about its use because of its singular nature.
The study of nonperturbative field theory quantizing on a light-front
plane for hadronic bound states requires one to gain a priori systematic
control of such gauge singularities. In the second paper of this
series we study the two-component old-fashioned perturbation theory
and various severe infrared divergences occurring in old-fashioned
light-front Hamiltonian calculations for QCD. We also analyze the
ultraviolet divergences associated with a large transverse dimensional
regularization, and a global cutoff. We discuss possible difficulties
caused by the light-front gauge singularity in the applications of
light-front QCD to both old-fashioned perturbative calculations for
short-distance physics and upcoming nonperturbative investigations
for hadronic bound states.},
author = {Zhang, W.-M. and Harindranath, A},
journal = {Physical Review D},
keywords = {light front dynamics,perturbation theory,physics,quantum chromodynamics,renormalization,unread},
number = {10},
pages = {4881},
title = {{Light-front QCD II. Two-component theory}},
volume = {48}
}
@article{LEW96,
author = {Lewis, A},
journal = {SIAM Journal on Optimization},
pages = {164--177},
title = {{Convex analysis on the {\{}H{\}}ermitian matrices}},
volume = {6},
year = {1996}
}
@article{KSG88,
author = {Kettner, R and Schwartz, A and Georgopoulos, A},
journal = {Journal of Neuroscience},
pages = {2938--2947},
title = {{Primate motor cortex and free arm movements to visual targets in three- dimensional space. {\{}III. P{\}}ositional gradients and population coding of movement direction from various movement origins}},
volume = {8},
year = {1988}
}
@article{SjulsonMiesenbock07,
abstract = {Optical imaging of physiological events in real time can yield insights

into biological function that would be difficult to obtain by other

experimental means. However, the detection of all-or-none events,

such as action potentials or vesicle fusion events, in noisy single-trial

data often requires a careful balance of tradeoffs. The analysis

of such experiments, as well as the design of optical reporters and

instrumentation for them, is aided by an understanding of the principles

of signal detection. This review illustrates these principles, using

as an example action potential recording with optical voltage reporters.},
author = {Sjulson, Lucas and Miesenb{\"{o}}ck, Gero},
doi = {10.1152/physiol.00036.2006},
journal = {Physiology (Bethesda)},
keywords = {Action Potentials; Animals; Microscopy,Confocal; Models,Theoretical; Neurons; Optics; Photons},
month = {feb},
pages = {47--55},
pmid = {17289930},
title = {{Optical recording of action potentials and other discrete physiological events: a perspective from signal detection theory.}},
url = {http://dx.doi.org/10.1152/physiol.00036.2006},
volume = {22},
year = {2007}
}
@article{Prenger04,
author = {Prenger, R and Wu, M and David, S and Gallant, J},
journal = {Neural Networks},
pages = {663--679},
title = {{Nonlinear {\{}V1{\}} responses to natural scenes revealed by neural network analysis}},
volume = {17},
year = {2004}
}
@article{PortforsRoberts07,
abstract = {The dorsal cochlear nucleus (DCN) is an initial site of central auditory

processing and also the first site of multisensory convergence in

the auditory pathway. The auditory nerve imparts a tonotopic frequency

organization on the responses of principal cells in the DCN. Cartwheel

cells modify the responses of principal cells, but they do not receive

direct auditory nerve input. This study shows that cartwheel cells

respond well to tonal stimuli in the awake mouse and they have a

well-defined characteristic frequency that corresponds to the tonotopic

organization of the DCN. The auditory responses of cartwheel cells

exhibit complex spectrotemporal responses to tones, with excitation

and inhibition modulating the firing patterns in both frequency and

time after onset of the stimulus. Temporal responses to best-frequency

tones are highly variable between cartwheel cells, but a simple model

is used to unify this variability as differences in the timing of

synaptic currents. Cartwheel cell responses to two-tone stimuli show

that interactions from different frequencies affect the output of

cartwheel cells. The results suggest that at this primary auditory

structure, processing of sound at one frequency can be modified by

sounds of different frequency. These complex frequency and temporal

interactions in cartwheel cells suggest that these neurons play an

active role in basic sound processing.},
author = {Portfors, Christine V and Roberts, Patrick D},
doi = {10.1152/jn.01356.2006},
journal = {J Neurophysiol},
month = {aug},
number = {2},
pages = {744--756},
pmid = {17581852},
title = {{Temporal and frequency characteristics of cartwheel cells in the dorsal cochlear nucleus of the awake mouse.}},
url = {http://dx.doi.org/10.1152/jn.01356.2006},
volume = {98},
year = {2007}
}
@article{Jlevrq,
author = {Jlevrq, Plfkdho D},
title = {{D {\&}  ic | D2d | S | v  {\"{A}}dt |  S R{\~{A}}Bd | vc vu {\%} {\"{A}}iR  dB SAt | iRt " | {\"{A}}}}
}
@article{Dickson1993,
author = {Dickson, JA},
isbn = {0780309995},
journal = {Neural Networks, 1993., {\ldots}},
title = {{Stochastic arithmetic implementations of neural networks with in situ learning}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=298642},
year = {1993}
}
@misc{Mosis,
author = {{The Mosis service}},
title = {http://www.mosis.com}
}
@article{RG99,
author = {Roweis, S and Ghahramani, Z},
journal = {Neural Computation},
pages = {305--345},
title = {{A unifying review of linear {\{}G{\}}aussian models}},
volume = {11},
year = {1999}
}
@article{BornRubel88,
abstract = {Studies of the avian auditory system indicate that neurons in nucleus

magnocellularis (NM) and nucleus laminaris of young animals are dramatically

altered by changes in the auditory receptor. We examined the role

of presynaptic activity on these transneuronal regulatory events.

TTX was used to block action potentials in the auditory nerve. TTX

injections into the perilymph reliably blocked all neuronal activity

in the cochlear nerve and NM. Far-field recordings of sound-evoked

potentials revealed that responses returned within 6-12 hr after

a single TTX injection. Changes in protein synthesis by NM neurons

were measured by determining the incorporation of 3H-leucine using

autoradiography. NM neurons on the side of the brain ipsilateral

to the TTX injection were compared to normally active cells on the

other side of the same tissue section. Grain counts over individual

neurons revealed that a single injection of TTX produced a 40{\%} decrease

in grain density in ipsilateral NM neurons within 1.5 hr after the

TTX injection. However, by 24 hr after a single TTX injection, grain

densities were not different on the 2 sides of the brain. Continuous

activity blockade for 6 hr caused the cessation of amino acid incorporation

in a portion of NM neurons and a 15-20{\%} decrease in the remaining

neurons. These changes in amino acid incorporation are comparable

to those following complete removal of the cochlea (Steward and Rubel,

1985). We also examined NM for neuron loss and soma shrinkage after

blocking eighth nerve action potentials. TTX injected every 12 hr

for 48 hr caused a 20{\%} neuron loss and an 8{\%} shrinkage of the remaining

neurons. Similar reductions were found following cochlea removal

(Born and Rubel, 1985). It is concluded that neuronal activity plays

a major role in the maintenance of normal NM neurons. Furthermore,

these results suggest that transneuronal morphological changes seen

in neurons following deafferentation or alterations of sensory experience

are a result of changes in the level of presynaptic activity.},
author = {Born, D E and Rubel, E W},
journal = {Journal of Neuroscience},
keywords = {Action Potentials; Afferent Pathways; Amino Acids;,Auditory; Research Support,Non-U.S. Gov't; Research Support,P.H.S.; Synapses; Tetrodotoxin,U.S. Gov't},
month = {mar},
number = {3},
pages = {901--919},
pmid = {3346728},
title = {{Afferent influences on brain stem auditory nuclei of the chicken: presynaptic action potentials regulate protein synthesis in nucleus magnocellularis neurons.}},
volume = {8},
year = {1988}
}
@misc{Sokolic2016,
abstract = {The generalization error of deep neural networks via their classification margin is studied in this work. Our approach is based on the Jacobian matrix of a deep neural network and can be applied to networks with arbitrary non-linearities and pooling layers, and to networks with different architectures such as feed forward networks and residual networks. Our analysis leads to the conclusion that a bounded spectral norm of the network's Jacobian matrix in the neighbourhood of the training samples is crucial for a deep neural network of arbitrary depth and width to generalize well. This is a significant improvement over the current bounds in the literature, which imply that the generalization error grows with either the width or the depth of the network. Moreover, it shows that the the recently proposed batch normalization and weight normalization re-parametrizations enjoy good generalization properties, and leads to a novel network regularizer based on the network's Jacobian matrix. The analysis is supported with experimental results on the MNIST and CIFAR-10 datasets.},
archivePrefix = {arXiv},
arxivId = {1605.08254},
author = {Sokolic, Jure and Giryes, Raja and Sapiro, Guillermo and Rodrigues, Miguel R. D.},
booktitle = {arXiv},
eprint = {1605.08254},
keywords = {Max-Margin,Neural Network},
pages = {1--31},
title = {{Robust Large Margin Deep Neural Networks}},
url = {http://arxiv.org/abs/1605.08254},
year = {2016}
}
@book{Evensen09,
author = {Evensen, G},
publisher = {Springer},
title = {{Data assimilation: the Ensemble {\{}K{\}}alman Filter}},
year = {2009}
}
@article{Oymak2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1212.3753v2},
author = {Oymak, Samet and Jalali, Amin and Fazel, M and Eldart, Yonina C. and Hassibi, Babak},
eprint = {arXiv:1212.3753v2},
journal = {arXiv},
keywords = {compressed sensing,convex relaxation,performance bounds,regularization},
title = {{Simultaneously structured models with application to sparse and low-rank matrices}},
url = {http://arxiv.org/abs/1212.3753},
year = {2012}
}
@article{Smith04,
author = {Smith, Anne C and Frank, Loren M and Wirth, Sylvia and Yanike, Marianna and Hu, Dan and Kubota, Yasuo and Graybiel, Ann M and Suzuki, Wendy A and Brown, Emery N},
doi = {10.1523/JNEUROSCI.2908-03.2004},
journal = {J. Neurosci.},
number = {2},
pages = {447--461},
title = {{Dynamic Analysis of Learning in Behavioral Experiments}},
volume = {24},
year = {2004}
}
@article{Repp2005,
abstract = {Sensorimotor synchronization (SMS), the rhythmic coordination of perception and action, occurs in many contexts, but most conspicuously in music performance and dance. In the laboratory, it is most often studied in the form of finger tapping to a sequence of auditory stimuli. This review summarizes theories and empirical findings obtained with the tapping task. Its eight sections deal with the role of intention, rate limits, the negative mean asynchrony, variability, models of error correction, perturbation studies, neural correlates of SMS, and SMS in musical contexts. The central theoretical issue is considered to be how best to characterize the perceptual information and the internal processes that enable people to achieve and maintain SMS. Recent research suggests that SMS is controlled jointly by two error correction processes (phase correction and period correction) that differ in their degrees of cognitive control and may be associated with different brain circuits. They exemplify the general distinction between subconscious mechanisms of action regulation and conscious processes involved in perceptual judgment and action planning.},
author = {Repp, Bruno H},
issn = {1069-9384},
journal = {Psychonomic bulletin {\&} review},
keywords = {Humans,Music,Periodicity,Psychomotor Performance,Psychomotor Performance: physiology,Time Factors},
month = {dec},
number = {6},
pages = {969--992},
pmid = {16615317},
title = {{Sensorimotor synchronization: a review of the tapping literature.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16615317},
volume = {12},
year = {2005}
}
@article{Alivisatos2012,
author = {Alivisatos, A Paul and Chun, Miyoung and Church, George M and Greenspan, Ralph J and Roukes, Michael L and Yuste, R},
doi = {10.1016/j.neuron.2012.06.006},
issn = {0896-6273},
journal = {Neuron},
number = {6},
pages = {970--974},
publisher = {Elsevier Inc.},
title = {{The Brain Activity Map Project and the Challenge of Functional Connectomics}},
url = {http://dx.doi.org/10.1016/j.neuron.2012.06.006},
volume = {74},
year = {2012}
}
@incollection{Esser2015,
author = {Esser, S K and Appuswamy, R and Merolla, P and Arthur, J V and Modha, D S},
booktitle = {NIPS},
editor = {Cortes, C and Lawrence, N D and Lee, D D and Sugiyama, M and Garnett, R},
pages = {1117--1125},
publisher = {Curran Associates, Inc.},
title = {{Backpropagation for Energy-Efficient Neuromorphic Computing}},
url = {http://papers.nips.cc/paper/5862-backpropagation-for-energy-efficient-neuromorphic-computing.pdf},
year = {2015}
}
@article{Memmesheimer2006,
annote = {2010IInum8.3},
author = {Memmesheimer, R M and Timme, M},
journal = {Physical Review Letters},
title = {{Designing the dynamics of spiking neural networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.97.188101},
year = {2006}
}
@article{Mehta2002,
annote = {2010IIInum60},
author = {Mehta, M R and Lee, A K and Wilson, M A},
doi = {10.1038/nature00808.1.},
journal = {Nature},
keywords = {Spike time neural coding},
mendeley-tags = {Spike time neural coding},
pages = {8--11},
title = {{Role of experience and oscillations in transforming a rate code into a temporal code}},
url = {http://www.nature.com/nature/journal/v417/n6890/abs/nature00807.html},
year = {2002}
}
@incollection{PB94,
address = {NY},
author = {Parmigiani, G and Berry, D},
booktitle = {Aspects of Uncertainty: A tribute to D. V. Lindley},
pages = {333--352},
publisher = {Wiley},
title = {{Applications of {\{}L{\}}indley Information Measure to the Design of Clinical Experiments}},
url = {citeseer.nj.nec.com/347593.html},
year = {1994}
}
@article{Movellan2006,
author = {Movellan, Javier R},
keywords = {math},
mendeley-tags = {math},
title = {{Tutorial on Stochastic Differential Equations}},
year = {2006}
}
@article{Monjaraz2000,
abstract = {The effects of chronic pharmacological modulation of L-type Ca2+ channel activity on the cell surface expression of Na+ channels were examined in GH3 cells. Prolonged inhibition (4-5 days) of L-channels with nimodipine caused a 50-60 {\%} decrease in the peak amplitude of whole-cell Na+ currents recorded with the patch-clamp technique. On the contrary, prolonged exposure to the L-channel agonist Bay K 8644 induced an {\{}approx{\}}2.5-fold increase in peak Na+ current. In both cases, there were only minor changes in cell capacitance and no significant changes in Na+ channel gating properties. Measurements of the specific binding of radiolabelled saxitoxin to intact cells showed that nimodipine treatment reduced the number of cell surface Na+ channels, whereas treatment with Bay K 8664 produced the opposite effect. The dual regulation of Na+ channel abundance explained the mentioned changes in Na+ current amplitude. Plasma membrane Na+ channels had a half-life of {\{}approx{\}}17 h both in control cells and in cells treated with Bay K 8644, as estimated from the rate of decay of peak Na+ current after inhibition of protein synthesis with cycloheximide. Actinomycin D, an inhibitor of gene transcription, and also cycloheximide, occluded the stimulatory effect of Bay K 8644 on Na+ current density when measured over a 24 h period. These findings indicate that the entry of Ca2+ through L-type channels influences in a positive way the number of functional Na+ channels in GH3 cells, and suggest that Ca2+ influx stimulates either Na+ channel gene expression or the expression of a regulatory protein that promotes translocation of pre-assembled Na+ channels into the plasma membrane.},
author = {Monjaraz, E and Navarrete, A and Lopez-Santiago, L F and Vega, A V and Cota, G},
doi = {10.1111/j.1469-7793.2000.00045.x},
issn = {0022-3751},
journal = {The Journal of Physiology},
month = {feb},
number = {1},
pages = {45--55},
title = {{L-type calcium channel activity regulates sodium channel levels in rat pituitary GH3 cells}},
url = {http://jp.physoc.org/cgi/content/abstract/523/1/45},
volume = {523},
year = {2000}
}
@article{Chothani11,
author = {Chothani, Paarth and Mehta, Vivek and Stepanyants, Armen},
journal = {Neuroinformatics},
pages = {263--278},
title = {{Automated Tracing of Neurites from Light Microscopy Stacks of Images.}},
volume = {9},
year = {2011}
}
@article{DCM05,
author = {Douc, R and Cappe, O and Moulines, E},
journal = {Proc. 4th Int. Symp. Image and Signal Processing and Analyis},
pages = {64--69},
title = {{Comparison of resampling schemes for particle filtering}},
year = {2005}
}
@article{Brody99,
author = {Brody, C},
journal = {Neural Computation},
pages = {1537--1551},
title = {{Correlations without synchrony}},
volume = {11},
year = {1999}
}
@article{Biehl2009,
author = {Biehl, Michael and Caticha, Nestor and Riegler, Peter},
journal = {Similarity-Based Clustering},
pages = {1--22},
title = {{Statistical mechanics of on-line learning}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-01805-3{\_}1},
year = {2009}
}
@article{Tokuda1998,
abstract = {Neuronal plasticity can be defined as adaptive changes in structure and function of the nervous system, an obvious example of which is the capacity to remember and learn. Long-term potentiation and long-term depression are the experimental models of memory in the central nervous system (CNS), and have been frequently utilized for the analysis of the molecular mechanisms of memory formation. Extensive studies have demonstrated that various kinases and phosphatases regulate neuronal plasticity by phosphorylating and dephosphorylating proteins essential to the basic processes of adaptive changes in the CNS. These proteins include receptors, ion channels, synaptic vesicle proteins, and nuclear proteins. Multifunctional kinases (cAMP-dependent protein kinase, Ca2+/phospholipid-dependent protein kinase, and Ca2+/calmodulin-dependent protein kinases) and phosphatases (calcineurin, protein phosphatases 1, and 2A) that specifically modulate the phosphorylation status of neuronal-signaling proteins have been shown to be required for neuronal plasticity. In general, kinases are involved in upregulation of the activity of target substrates, and phosphatases downregulate them. Although this rule is applicable in most of the cases studied, there are also a number of exceptions. A variety of regulation mechanisms via phosphorylation and dephosphorylation mediated by multiple kinases and phosphatases are discussed.},
author = {Tokuda, M and Hatase, O},
doi = {10.1007/BF02802028},
issn = {0893-7648},
journal = {Molecular neurobiology},
keywords = {Animals,Brain,Brain: physiology,Cell Surface,Cell Surface: physiology,GTP-Binding Proteins,GTP-Binding Proteins: physiology,Homeostasis,Humans,Long-Term Potentiation,Long-Term Potentiation: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Phosphoprotein Phosphatases,Phosphoprotein Phosphatases: metabolism,Phosphorylation,Protein Kinases,Protein Kinases: metabolism,Receptors,Spinal Cord,Spinal Cord: physiology,neuron,regulation},
mendeley-tags = {neuron,regulation},
month = {jan},
number = {1-3},
pages = {137--56},
pmid = {9887450},
title = {{Regulation of neuronal plasticity in the central nervous system by phosphorylation and dephosphorylation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9887450},
volume = {17},
year = {1998}
}
@article{BairdTsien99,
abstract = {Many areas of biology and biotechnology have been revolutionized by

the ability to label proteins genetically by fusion to the Aequorea

green fluorescent protein (GFP). In previous fusions, the GFP has

been treated as an indivisible entity, usually appended to the amino

or carboxyl terminus of the host protein, occasionally inserted within

the host sequence. The tightly interwoven, three-dimensional structure

and intricate posttranslational self-modification required for chromophore

formation would suggest that major rearrangements or insertions within

GFP would prevent fluorescence. However, we now show that several

rearrangements of GFPs, in which the amino and carboxyl portions

are interchanged and rejoined with a short spacer connecting the

original termini, still become fluorescent. These circular permutations

have altered pKa values and orientations of the chromophore with

respect to a fusion partner. Furthermore, certain locations within

GFP tolerate insertion of entire proteins, and conformational changes

in the insert can have profound effects on the fluorescence. For

example, insertions of calmodulin or a zinc finger domain in place

of Tyr-145 of a yellow mutant (enhanced yellow fluorescent protein)

of GFP result in indicator proteins whose fluorescence can be enhanced

severalfold upon metal binding. The calmodulin graft into enhanced

yellow fluorescent protein can monitor cytosolic {\{}Ca{\}}{\^{}}{\{}2+{\}} in single

mammalian cells. The tolerance of GFPs for circular permutations

and insertions shows the folding process is surprisingly robust and

offers a new strategy for creating genetically encodable, physiological

indicators.},
author = {Baird, G S and Zacharias, D A and Tsien, R Y},
journal = {Proc Natl Acad Sci U S A},
keywords = {Amino Acid Sequence; Calcium; Calmodulin; Fluoresc},
month = {sep},
number = {20},
pages = {11241--11246},
pmid = {10500161},
title = {{Circular permutation and receptor insertion within green fluorescent proteins.}},
volume = {96},
year = {1999}
}
@article{Munford77,
author = {Munford, A},
journal = {The American Statistician},
pages = {119},
title = {{A Note on the Uniformity Assumption in the Birthday Problem}},
volume = {31},
year = {1977}
}
@article{Elliott2008,
abstract = {In a recently proposed, stochastic model of spike-timing-dependent plasticity, we derived general expressions for the expected change in synaptic strength, DeltaS n, induced by a typical sequence of precisely n spikes. We found that the rules DeltaS n, n {\textgreater}or= 3, exhibit regions of parameter space in which stable, competitive interactions between afferents are present, leading to the activity-dependent segregation of afferents on their targets. The rules DeltaS n, however, allow an indefinite period of time to elapse for the occurrence of precisely n spikes, while most measurements of changes in synaptic strength are conducted over definite periods of time during which a potentially unknown number of spikes may occur. Here, therefore, we derive an expression, DeltaS(t), for the expected change in synaptic strength of a synapse experiencing an average sequence of spikes of typical length occurring during a fixed period of time, t. We find that the resulting synaptic plasticity rule Delta S(t) exhibits a number of remarkable properties. It is an entirely self-stabilizing learning rule in all regions of parameter space. Further, its parameter space is carved up into three distinct, contiguous regions in which the exhibited synaptic interactions undergo different transitions as the time t is increased. In one region, the synaptic dynamics change from noncompetitive to competitive to entirely depressing. In a second region, the dynamics change from noncompetitive to competitive without the second transition to entirely depressing dynamics. In a third region, the dynamics are always noncompetitive. The locations of these regions are not fixed in parameter space but may be modified by changing the mean presynaptic firing rates. Thus, neurons may be moved among these three different regions and so exhibit different sets of synaptic dynamics depending on their mean firing rates.},
author = {Elliott, Terry},
doi = {10.1162/neco.2008.06-07-555},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Stochastic Processes},
month = {sep},
number = {9},
pages = {2253--2307},
pmid = {18336079},
title = {{Temporal dynamics of rate-based synaptic plasticity rules in a stochastic model of spike-timing-dependent plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18336079},
volume = {20},
year = {2008}
}
@article{VIC00,
author = {Victor, J},
journal = {Neural Computation},
pages = {2797--2804},
title = {{Asymptotic bias in information estimates and the exponential (Bell) polynomials}},
volume = {12},
year = {2000}
}
@article{Lindsten2013,
author = {Lindsten, Fredrik},
doi = {10.1561/2200000045},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
keywords = {Bayesian learning,Markov chain Monte Carlo,Nonlinear signal processing},
number = {1},
pages = {1--143},
title = {{Backward Simulation Methods for Monte Carlo Statistical Inference}},
url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-machine-learning/MAL-045},
volume = {6},
year = {2013}
}
@article{Santhanam09,
annote = {In press},
author = {Santhanam, G and Yu, B M and Gilja, V and Ryu, S I and Afshar, A and Sahani, M and Shenoy, K V},
journal = {Journal of Neurophysiology},
title = {{Factor-analysis methods for higher-performance neural prostheses}},
year = {2009}
}
@article{Guevara1982,
author = {Guevara, M.R. and Glass, L.},
issn = {0303-6812},
journal = {Journal of Mathematical Biology},
keywords = {cardiac dysrhythmias -,doubling bifurcations},
number = {1},
pages = {1--23},
publisher = {Springer},
title = {{Phase locking, period doubling bifurcations and chaos in a mathematical model of a periodically driven oscillator: A theory for the entrainment of biological oscillators and the generation of cardiac dysrhythmias}},
url = {http://www.springerlink.com/index/H248X22535453216.pdf},
volume = {14},
year = {1982}
}
@article{Graves2013,
abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
archivePrefix = {arXiv},
arxivId = {1308.0850},
author = {Graves, Alex},
eprint = {1308.0850},
month = {aug},
title = {{Generating Sequences With Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1308.0850},
year = {2013}
}
@article{Briggs|1974|,
abstract = {A model of the stopping of a low-velocity heavy ion moving through
an electron gas is used to calculate the stopping power of solids
for channelled heavy ions. The heavy ion is considered to lose energy
by transferring momentum to target electrons which scatter elastically
from it, so that the stopping cross section is proportional to the
momentumtransfer cross section. This cross section varies periodically
with the Z , of the incident ion, the periodicity being shown to
be connected with the successive filling of atomic sub-shells of
electrons. The model is applied to the stopping power of silicon
for ions channelled along the {\textless}1 1 0{\textgreater} and {\textless}1 1 1 {\textgreater} directions and
good agreement is obtained with the data of Eisen. A feature of this
approach is the reproduction of deep minima in channelled stopping
power in certain regions of the periodic table.},
author = {Briggs, J S and Pathak, A P},
journal = {Journal of Physics C: Solid State Physics},
keywords = {heavy ions,physics,solids,stopping power},
pages = {1929},
title = {{The stopping power of solids for low-velocity channelled heavy ions}},
volume = {7}
}
@article{Arima1991,
author = {Arima, Yutaka and Mashiko, Koichiro and Okada, Keisuke and Yamada, Tsuyoshi and Maeda, Atsushi and Kondoh, Harufusa and Kayano, Shimpei},
journal = {Solid-State Circuits, {\ldots}},
number = {4},
pages = {607--611},
title = {{A self-learning neural network chip with 125 neurons and 10 K self-organization synapses}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=75062},
volume = {26},
year = {1991}
}
@article{Story2008,
author = {Story, This and Been, H A S and For, Formatted and Printing, Easy and Of, Life and Mind, T H E},
title = {{Daydream achiever A wandering mind can do important work , scientists}},
year = {2008}
}
@article{kolodziejski2008mathematical,
annote = {2008num13},
author = {Kolodziejski, C and Porr, B and Wotter, F},
journal = {Biological Cybernetics},
number = {3},
pages = {259--272},
publisher = {Springer},
title = {{Mathematical properties of neuronal TD-rules and differential Hebbian learning: a comparison}},
volume = {98},
year = {2008}
}
@article{Chain1800,
author = {Chain, Markov},
pages = {6--8},
title = {{SUPPORTING INFORMATION S3 Simulations with a fixed voltage trajectory}},
year = {1800}
}
@article{Webb2009,
abstract = {Circadian rhythms are modeled as reliable and self-sustained oscillations generated by single cells. The mammalian suprachiasmatic nucleus (SCN) keeps near 24-h time in vivo and in vitro, but the identity of the individual cellular pacemakers is unknown. We tested the hypothesis that circadian cycling is intrinsic to a unique class of SCN neurons by measuring firing rate or Period2 gene expression in single neurons. We found that fully isolated SCN neurons can sustain circadian cycling for at least 1 week. Plating SCN neurons at {\textless}100 cells/mm(2) eliminated synaptic inputs and revealed circadian neurons that contained arginine vasopressin (AVP) or vasoactive intestinal polypeptide (VIP) or neither. Surprisingly, arrhythmic neurons (nearly 80{\%} of recorded neurons) also expressed these neuropeptides. Furthermore, neurons were observed to lose or gain circadian rhythmicity in these dispersed cell cultures, both spontaneously and in response to forskolin stimulation. In SCN explants treated with tetrodotoxin to block spike-dependent signaling, neurons gained or lost circadian cycling over many days. The rate of PERIOD2 protein accumulation on the previous cycle reliably predicted the spontaneous onset of arrhythmicity. We conclude that individual SCN neurons can generate circadian oscillations; however, there is no evidence for a specialized or anatomically localized class of cell-autonomous pacemakers. Instead, these results indicate that AVP, VIP, and other SCN neurons are intrinsic but unstable circadian oscillators that rely on network interactions to stabilize their otherwise noisy cycling.},
author = {Webb, Alexis B and Angelo, Nikhil and Huettner, James E and Herzog, Erik D},
doi = {10.1073/pnas.0902768106},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Animals,Arginine Vasopressin,Arginine Vasopressin: metabolism,Cell Cycle Proteins,Cell Cycle Proteins: genetics,Cell Cycle Proteins: metabolism,Cells,Circadian Rhytems,Circadian Rhythm,Circadian Rhythm: physiology,Cultured,Gene Knock-In Techniques,Immunohistochemistry,Inbred C57BL,Luciferases,Luciferases: genetics,Luciferases: metabolism,Luminescent Measurements,Luminescent Measurements: methods,Mice,Neurons,Neurons: cytology,Neurons: metabolism,Neurons: physiology,Nuclear Proteins,Nuclear Proteins: genetics,Nuclear Proteins: metabolism,Patch-Clamp Techniques,Period Circadian Proteins,Suprachiasmatic Nucleus,Suprachiasmatic Nucleus: cytology,Suprachiasmatic Nucleus: metabolism,Suprachiasmatic Nucleus: physiology,Tissue Culture Techniques,Transcription Factors,Transcription Factors: genetics,Transcription Factors: metabolism,Vasoactive Intestinal Peptide,Vasoactive Intestinal Peptide: metabolism},
mendeley-tags = {Circadian Rhytems},
month = {sep},
number = {38},
pages = {16493--8},
pmid = {19805326},
title = {{Intrinsic, nondeterministic circadian rhythm generation in identified mammalian neurons}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2752526{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {106},
year = {2009}
}
@article{LG98,
author = {Lee, D and Georgopoulos, A},
journal = {Journal of Neuroscience},
pages = {1161--1170},
title = {{Variability and correlated noise in the discharge of neurons in motor and parietal areas of the primate cortex}},
volume = {18},
year = {1998}
}
@article{Chang05,
author = {Chang, T and Chung, P and Chiu, T and Poon, P},
journal = {Biosystems},
pages = {213--222},
title = {{A new method for adjusting neural response jitter in the {\{}STRF{\}} obtained by spike-trigger averaging}},
volume = {79},
year = {2005}
}
@article{Smirnakis1997,
author = {Smirnakis, S.M. and Berry, M.J. and Warland, D.K. and Bialek, W and Meister, M},
journal = {Nature},
number = {6620},
pages = {69--73},
title = {{Adaptation of retinal processing to image contrast and spatial scale}},
url = {http://cnl-t.salk.edu/Teaching/Adaptation of retinal processig.pdf},
volume = {386},
year = {1997}
}
@article{YusteDenk95,
abstract = {Most excitatory synaptic connections occur on dendritic spines. Calcium

imaging experiments have suggested that spines constitute individual

calcium compartments, but recent results have challenged this idea.

Using two-photon microscopy to image fluorescence with high resolution

in strongly scattering tissue, we measured calcium dynamics in spines

from CA1 pyramidal neurons in slices of rat hippocampus. Subthreshold

synaptic stimulation and spontaneous synaptic events produced calcium

accumulations that were localized to isolated spines, showed stochastic

failure, and were abolished by postsynaptic blockers. Single somatic

spikes induced fast-peaking calcium accumulation in spines throughout

the cell. Pairing of spikes with synaptic stimulation was frequently

cooperative, that is, it resulted in supralinear calcium accumulations.

We conclude: (1) calcium channels exist in spine heads; (2) action

potentials invade the spines; (3) spines are individual calcium compartments;

and (4) spines can individually detect the temporal coincidence of

pre- and postsynaptic activity, and thus serve as basic functional

units of neuronal integration.},
author = {Yuste, R and Denk, W},
doi = {10.1038/375682a0},
journal = {Nature},
keywords = {Action Potentials; Animals; Calcium; Calcium Chann,Cultured; Dendrites; Differential Threshold; Fluo,Fluorescence; Organic Chemicals; Pyramidal Cells;},
month = {jun},
number = {6533},
pages = {682--684},
pmid = {7791901},
title = {{Dendritic spines as basic functional units of neuronal integration.}},
url = {http://dx.doi.org/10.1038/375682a0},
volume = {375},
year = {1995}
}
@article{AaronYuste06,
author = {Aaron, G and Yuste, R},
journal = {Synapse},
month = {jul},
number = {6},
pages = {437--440},
title = {{Reverse optical probing (ROPING) of neocortical circuits}},
volume = {60},
year = {2006}
}
@article{Gould1985,
abstract = {The author presents practical conditions under which the$\backslash$nexistence and uniqueness of a finite solution to a given$\backslash$nequality quadratic program may be examined. Different sets$\backslash$nof conditions allow this examination to take place when$\backslash$nnull-space, range-space or Lagrangian methods are used to$\backslash$nfind stationary points for the quadratic program.},
author = {Gould, N I M},
doi = {10.1007/BF01585660},
journal = {Mathematical Programming},
keywords = {equality quadratic program,existence and uniqueness of,lagrangian methods,methods,null-space,range-space methods,solutions},
number = {1},
pages = {90--99},
title = {{On practical conditions for the existence and uniqueness of solutions to the general equality quadratic programming problem}},
volume = {32},
year = {1985}
}
@book{WAND95,
address = {Boston},
author = {Wandell, B},
publisher = {Sinauer},
title = {{Foundations of Vision}},
year = {1995}
}
@article{Wallhausser-FrankeLangner03,
author = {Wallhausser-Franke, E and Mahlke, C and Oliva, R and Braun, S and Wenz, G and Langner, G},
journal = {Experimental Brain Research},
month = {dec},
number = {4},
pages = {649--654},
title = {{Expression of c-fos in auditory and non-auditory brain regions of the gerbil after manipulations that induce tinnitus}},
volume = {153},
year = {2003}
}
@article{Brown1998,
author = {Brown, E N and Frank, LM and Tang, D and Quirk, M C and Wilson, M A},
journal = {The Journal of Neuroscience},
keywords = {bayesian statistics,decoding algorithm,filter,formation encoding,hippocampal place cells,in-,inhomogeneous poisson process,nonlinear recursive,point,random walk},
number = {18},
pages = {7411--7425},
title = {{A statistical paradigm for neural spike train decoding applied to position prediction from ensemble firing patterns of rat hippocampal place cells}},
volume = {18},
year = {1998}
}
@article{Stegenga2009,
abstract = {We have studied the effect that learning a new stimulus-response (SR) relationship had within a neuronal network cultured on a multielectrode array. For training, we applied repetitive focal electrical stimulation delivered at a low rate ({\textless}1/s). Stimulation was withdrawn when a desired SR success ratio was achieved. It has been shown elsewhere, and we verified that this training algorithm, named conditional repetitive stimulation (CRS), can be used to strengthen an initially weak SR. So far, it remained unclear what the role of the rest of the network during learning was. We therefore studied the effect of CRS on spontaneously occurring network bursts. To this end, we made profiles of the firing rates within network bursts. We have earlier shown that these profiles change shape on a time base of several hours during spontaneous development. We show here that profiles of summed activity, called burst profiles, changed shape at an increased rate during CRS. This suggests that the whole network was involved in making the changes necessary to incorporate the desired SR relationship. However, a local (path-specific) component to learning was also found by analyzing profiles of single-electrode-activity phase profiles. Phase profiles that were not part of the SR relationship changed far less during CRS than the phase profiles of the electrodes that were part of the SR relationship. Finally, the manner in which phase profiles changed shape varied and could not be linked to the SR relationship.},
annote = {2008num11},
author = {Stegenga, Jan and {Le Feber}, Joost and Marani, Enrico and Rutten, Wim L C and Feber, J Le},
doi = {10.1109/TBME.2008.2006856},
issn = {1558-2531},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Algorithms,Animals,Cells,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Cultured,Electric Stimulation,Evoked Potentials,Learning,Learning: physiology,Nerve Net,Nerve Net: physiology,Neuronal Plasticity,Newborn,Pilot Projects,Rats,Wistar},
month = {apr},
number = {4},
pages = {1220--7},
pmid = {19272893},
title = {{The effect of learning on bursting.}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4663623 http://www.ncbi.nlm.nih.gov/pubmed/19272893},
volume = {56},
year = {2009}
}
@article{Grassberger1979,
author = {Grassberger, P and Torre, A De La},
journal = {Annals of Physics},
pages = {373--396},
title = {{Reggeon field theory (Schl{\"{o}}gl's first model) on a lattice: Monte Carlo calculations of critical behaviour}},
url = {http://www.sciencedirect.com/science/article/pii/0003491679902070},
volume = {396},
year = {1979}
}
@article{FellerTank96,
abstract = {1. We characterized the kinetics of presynaptic Ca2+ ion concentration

in optic nerve fibers and terminals of the optic tectum in Rana pipiens

with the use of microfluorimetry. Isolated frog brains were incubated

with the membrane-permeant tetraacetoxymethyl ester (AM) of the Ca2+

indicator fura-2. An optic nerve shock caused a transient decrease

in the 380-nm excited fluorescence in the optic tectum with a rise

time of {\textless}15 ms and a recovery to prestimulus levels on a time scale

of seconds. 2. In normal saline, the amplitude of the fluorescence

transients was dependent on stimulus intensity and at all levels

it was directly correlated with the amplitude of postsynaptic field

potentials produced by activation of unmyelinated optic nerve fibers.

In the presence of the non-N-methyl-D-aspartate glutamate receptor

antagonist 6-cyano-7-nitroquinoxaline-2,3-dione, the amplitude and

time course of fluorescence transients remained essentially unchanged

while postsynaptic field potential amplitude was greatly reduced.

Replacing extracellular Ca2+ with Ba2+ blocked unfacilitated postsynaptic

field potentials while fluorescence transients remained significant.

In reduced-Ca2+ salines ({\textless}1 mM), the amplitude of fluorescence transients

increased approximately linearly with extracellular [Ca2+], whereas

the amplitude the corresponding field potential was nonlinearly related

to the fluorescent transient amplitude (approximately 2.5 power).

In thin sections of labeled tecta, fluorescence labeling was localized

to 1-micron puncta in the termination zone of optic nerve fibers

in the superficial layers. Taken together, these results provide

strong evidence that the fluorescence transients correspond to an

increase in Ca2+ in presynaptic terminals of unmyelinated optic nerve

fibers. 3. During trains of optic nerve stimulation, the amplitude

of fluorescence transients to succeeding action potentials became

smaller. The decrement of the amplitudes was not observed in mag-fura-5-labeled

tecta, when the intracellular Ca2+ buffering capacity of fura-2-labeled

terminals was increased by incubation with bis-(o-aminophenoxy)-N,N,N',N'-tetraacetic

acid (BAPTA)-AM or ethylene glycol-bis (beta-aminoethyl ether)-N,N,N',N'-tetraacetic

acid (EGTA)-AM, or in low-Ca2+ saline. We conclude that the Ca2+

influx per action potential is constant during the train and that

the reduced response was produced by saturation of the fura-2. We

provide a mathematical analysis of this saturation effect and use

it to estimate the Ca2+ change per action potential. 4. Both BAPTA-AM

and EGTA-AM reduced the overall amplitude of fura-2-measured Ca2+

transients and reduced the saturation effect in action potential

trains. However, there was a qualitative difference in their effects

on the shape of the transient. Incubation with the fast buffer BAPTA

prolonged the decay to baseline. In contrast, the slow buffer EGTA

(or EDTA) produced an initial decay faster than the control condition

while also producing the slower subsequent phase observed with BAPTA.

We demonstrate that these results are consistent with numerical simulations

of Ca2+ dynamics in a single-compartment model where the fast initial

decay is produced by the forward rate of Ca2+ binding to EGTA. 5.

Ca2+ influx into tectal presynaptic structures, and also into unmyelinated

axons in the isolated optic nerve, was diminished (60-70{\%}) in the

presence of the voltage-activated Ca2+ channel blocker omega-conotoxin

GVIA, but was only weakly affected (approximately 10{\%}) by omega-agatoxin

IVA. 6. After 10- to 50-Hz stimulus trains, synaptic enhancement

of unmyelinated fibers decayed with a characteristic time similar

to fura-2 fluorescence decays. Incubation with EDTA-AM or EGTA-AM

produced little effect on evoked release but reduced both the amplitude

of the fura-2-measured Ca2+ transient and the amplitude of short-term

synaptic enhancement.},
author = {Feller, M B and Delaney, K R and Tank, D W},
journal = {J Neurophysiol},
keywords = {Afferent Pathways; Animals; Calcium; Computer Simu},
month = {jul},
number = {1},
pages = {381--400},
pmid = {8836232},
title = {{Presynaptic calcium dynamics at the frog retinotectal synapse.}},
volume = {76},
year = {1996}
}
@inproceedings{Jungwirth|2005|,
annote = {Presentation deals with hydrogen photodissociation},
author = {Jungwirth, P and Slavicek, P and Zdanska, P},
keywords = {hydrogen,photodissociation,physics,solid state},
title = {{Quantum structure and photodissociation dynamics of hydrogen halides in/on rare gas clusters}}
}
@article{Szentagothai78,
author = {Szentagothai, J},
journal = {Proc R Soc Lond B},
pages = {219--248},
title = {{The neuron network of the cerebral cortex: a functional interpretation}},
volume = {201},
year = {1978}
}
@article{Ribeiro2011,
abstract = {We discuss the expectation propagation (EP) algorithm for approximate Bayesian inference using a factorizing posterior approximation. For neural network models, we use a central limit theorem argument to make EP tractable when the number of parameters is large. For two types of models, we show that EP can achieve optimal generalization performance when data are drawn from a simple distribution.},
author = {Ribeiro, F and Opper, M},
doi = {10.1162/NECO_a_00104},
journal = {Neural computation},
keywords = {Algorithms,Bayes Theorem,Computers,Likelihood Functions,Models,Molecular,Neural Networks (Computer),Normal Distribution,Random Allocation,Statistical},
month = {apr},
number = {4},
pages = {1047--1069},
pmid = {21222527},
title = {{Expectation propagation with factorizing distributions: a Gaussian approximation and performance results for simple models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21222527},
volume = {23},
year = {2011}
}
@article{Anderson1966,
author = {Anderson, B D O and Newcomb, RW and Kalman, R E and Youla, D C},
journal = {Journal of the Franklin Institute},
number = {5},
pages = {371--378},
publisher = {Elsevier},
title = {{Equivalence of linear time-invariant dynamical systems}},
url = {http://www.sciencedirect.com/science/article/pii/0016003266902985},
volume = {281},
year = {1966}
}
@article{Saey2010,
annote = {2010IInum12.28b},
author = {Saey, Tina Hesman},
journal = {Science News},
title = {{You Are Who You Are By Default}},
volume = {176},
year = {2010}
}
@article{Ahmadian2010,
annote = {2011num39},
author = {Ahmadian, Yashar and Packer, Adam M and Yuste, R and Paninski, L},
pages = {1--30},
title = {{Designing optimal stimuli to control neuronal spike timing}},
year = {2010}
}
@article{MiyawakiTsien99,
abstract = {Cameleons are genetically-encoded fluorescent indicators for {\{}Ca{\}}{\^{}}{\{}2+{\}}

based on green fluorescent protein variants and calmodulin (CaM).

Because cameleons can be targeted genetically and imaged by one-

or two-photon excitation microscopy, they offer great promise for

monitoring {\{}Ca{\}}{\^{}}{\{}2+{\}} in whole organisms, tissues, organelles, and

submicroscopic environments in which measurements were previously

impossible. However, the original cameleons suffered from significant

pH interference, and their {\{}Ca{\}}{\^{}}{\{}2+{\}}-buffering and cross-reactivity

with endogenous CaM signaling pathways was uncharacterized. We have

now greatly reduced the pH-sensitivity of the cameleons by introducing

mutations V68L and Q69K into the acceptor yellow green fluorescent

protein. The resulting new cameleons permit {\{}Ca{\}}{\^{}}{\{}2+{\}} measurements

despite significant cytosolic acidification. When {\{}Ca{\}}{\^{}}{\{}2+{\}} is

elevated, the CaM and CaM-binding peptide fused together in a cameleon

predominantly interact with each other rather than with free CaM

and CaM-dependent enzymes. Therefore, if cameleons are overexpressed,

the primary effect is likely to be the unavoidable increase in {\{}Ca{\}}{\^{}}{\{}2+{\}}

buffering rather than specific perturbation of CaM-dependent signaling.},
author = {Miyawaki, A and Griesbeck, O and Heim, R and Tsien, R Y},
journal = {Proc Natl Acad Sci U S A},
keywords = {3',5'-Cyclic-Nucleotide Phosphodiesterase; Adenovirid,Fluorescence; Transfection,Site-Directed; Neurons; Recombinant Proteins; Sig},
month = {mar},
number = {5},
pages = {2135--2140},
pmid = {10051607},
title = {{Dynamic and quantitative {\{}Ca{\}}{\^{}}{\{}2+{\}} measurements using improved cameleons.}},
volume = {96},
year = {1999}
}
@article{HAN05,
author = {Amarasingham, A and Harrison, M and Geman, S},
journal = {SFN Abstracts},
title = {{Statistical techniques for analyzing non-repeating spike trains}},
year = {2005}
}
@article{Hoffer2017,
abstract = {Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.},
archivePrefix = {arXiv},
arxivId = {1611.01449},
author = {Hoffer, Elad and Ailon, Nir},
eprint = {1611.01449},
journal = {Iclr},
pages = {1--10},
title = {{Semi-supervised deep learning by metric embedding}},
url = {http://arxiv.org/abs/1611.01449},
year = {2017}
}
@phdthesis{PANPHD,
author = {Paninski, L},
school = {NYU},
title = {{Some rigorous results on the neural coding problem}},
year = {2003}
}
@article{BarbourWang03a,
author = {Barbour, Dennis L and Wang, Xiaoqin},
journal = {Science},
month = {feb},
number = {5609},
pages = {1073--1075},
title = {{Contrast tuning in auditory cortex}},
volume = {299},
year = {2003}
}
@article{Gobel07b,
abstract = {Spatiotemporal activity patterns in local neural networks are fundamental
to brain function. Network activity can now be measured in vivo using
two-photon imaging of cell populations that are labeled with fluorescent
calcium indicators. In this review, we discuss basic aspects of in
vivo calcium imaging and highlight recent developments that will
help to uncover operating principles of neural circuits.},
author = {Gobel, Werner and Helmchen, Fritjof},
doi = {10.1152/physiol.00032.2007},
journal = {Physiology},
number = {6},
pages = {358--365},
title = {{In Vivo Calcium Imaging of Neural Network Function}},
url = {http://physiologyonline.physiology.org/cgi/content/abstract/22/6/358},
volume = {22},
year = {2007}
}
@book{Schuster2005,
address = {Weinheim, FRG},
author = {Schuster, H. G. and Just, Wolfram},
doi = {10.1002/3527604804},
isbn = {9783527604807},
month = {jan},
publisher = {Wiley-VCH Verlag GmbH {\&} Co. KGaA},
title = {{Deterministic Chaos}},
url = {http://doi.wiley.com/10.1002/3527604804},
year = {2005}
}
@article{Konecny2014,
author = {Kone{\v{c}}n{\'{y}}, J and Liu, J and Richt{\'{a}}rik, P and Tak{\'{a}}{\v{c}}, M},
journal = {arXiv preprint arXiv:1410.4744},
pages = {1--5},
title = {{mS2GD: Mini-Batch Semi-Stochastic Gradient Descent in the Proximal Setting}},
url = {http://arxiv.org/abs/1410.4744},
year = {2014}
}
@article{Abbott2008a,
abstract = {Theoretical neuroscience has experienced explosive growth over the past 20 years. In addition to bringing new researchers into the field with backgrounds in physics, mathematics, computer science, and engineering, theoretical approaches have helped to introduce new ideas and shape directions of neuroscience research. This review presents some of the developments that have occurred and the lessons they have taught us.},
author = {Abbott, L F},
doi = {10.1016/j.neuron.2008.10.019},
issn = {1097-4199},
journal = {Neuron},
keywords = {Algorithms,Animals,Information Theory,Mathematics,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Neurosciences,Theoretical},
month = {nov},
number = {3},
pages = {489--95},
pmid = {18995824},
publisher = {Elsevier Inc.},
title = {{Theoretical neuroscience rising}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18995824},
volume = {60},
year = {2008}
}
@article{Pfister2010,
annote = {2010IIInum50},
author = {Pfister, J P and Dayan, P and Lengyel, M},
doi = {10.1038/nn.2640},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {sep},
number = {10},
pages = {1271--1275},
publisher = {Nature Publishing Group},
title = {{Synapses with short-term plasticity are optimal estimators of presynaptic membrane potentials}},
url = {http://www.nature.com/doifinder/10.1038/nn.2640},
volume = {13},
year = {2010}
}
@article{MACH02,
author = {Machens, C},
journal = {Physical Review Letters},
pages = {228104--228107},
title = {{Adaptive sampling by information maximization}},
volume = {88},
year = {2002}
}
@article{baylor1974changes,
author = {Baylor, D A and Hodgkin, A L},
journal = {The Journal of Physiology},
number = {3},
pages = {729},
publisher = {Physiological Soc},
title = {{Changes in time scale and sensitivity in turtle photoreceptors}},
volume = {242},
year = {1974}
}
@article{Bressloff2011,
author = {Bressloff, Paul C and Lai, Yi},
doi = {10.1186/2190-8567-1-2},
issn = {2190-8567},
journal = {The Journal of Mathematical Neuroscience},
number = {1},
pages = {2},
title = {{Stochastic synchronization of neuronal populations with intrinsic and extrinsic noise}},
url = {http://www.mathematical-neuroscience.com/content/1/1/2},
volume = {1},
year = {2011}
}
@book{FW84,
author = {Freidlin, M and Wentzell, A},
publisher = {Springer-Verlag},
title = {{Random Perturbations of Dynamical Systems}},
year = {1984}
}
@article{BC80,
author = {Bell, R and Cover, T M},
journal = {Mathematics of operations research},
pages = {161--166},
title = {{Competitive optimality of logarithmic investment}},
volume = {5},
year = {1980}
}
@article{RGDA97,
author = {Riehle, A and Grun, S and Diesmann, M and Aertsen, A},
journal = {Science},
pages = {1950--1953},
title = {{Spike synchronization and rate modulation differentially involved in motor cortical function}},
volume = {278},
year = {1997}
}
@article{Cunningham2015,
abstract = {Linear dimensionality reduction methods are a cornerstone of analyzing high dimensional data, due to their simple geometric interpretations and typically attractive computational properties. These methods capture many data features of interest, such as covariance, dynamical structure, correlation between data sets, input-output relationships, and margin between data classes. Methods have been developed with a variety of names and motivations in many fields, and perhaps as a result the connections between all these methods have not been highlighted. Here we survey methods from this disparate literature as optimization programs over matrix manifolds. We discuss principal component analysis, factor analysis, linear multidimensional scaling, Fisher's linear discriminant analysis, canonical correlations analysis, maximum autocorrelation factors, slow feature analysis, sufficient dimensionality reduction, undercomplete independent component analysis, linear regression, distance metric learning, and more. This optimization framework gives insight to some rarely discussed shortcomings of well-known methods, such as the suboptimality of certain eigenvector solutions. Modern techniques for optimization over matrix manifolds suggest a generic linear dimensionality reduction solver, which accepts as input data and an objective to be optimized, and returns, as output, an optimal low-dimensional projection of the data. This simple optimization framework further allows straightforward generalizations and novel variants of classical methods, which we demonstrate here by creating an orthogonal-projection canonical correlations analysis. More broadly, this survey and generic solver suggest that linear dimensionality reduction can move toward becoming a blackbox, objective-agnostic numerical technology.},
author = {Cunningham, John P},
journal = {Journal of Machine Learning Research},
pages = {1--42},
title = {{Linear Dimensionality Reduction: Survey, Insights, and Generalizations}},
volume = {16},
year = {2015}
}
@article{Diaz-Quesada2008,
abstract = {Barrel cortex neuronal responses adapt to changes in the statistics of complex whisker stimuli. This form of adaptation involves an adjustment in the input-output tuning functions of the neurons, such that their gain rescales depending on the range of the current stimulus distribution. Similar phenomena have been observed in other sensory systems, suggesting that adaptive adjustment of responses to ongoing stimulus statistics is an important principle of sensory function. In other systems, adaptation and gain rescaling can depend on intrinsic properties; however, in barrel cortex, whether intrinsic mechanisms can contribute to adaptation to stimulus statistics is unknown. To examine this, we performed whole-cell patch-clamp recordings of pyramidal cells in acute slices while injecting stochastic current stimuli. We induced changes in statistical context by switching across stimulus distributions. The firing rates of neurons adapted in response to changes in stimulus statistics. Adaptation depended on the form of the changes in stimulus distribution: in vivo-like adaptation occurred only for rectified stimuli that maintained neurons in a persistent state of net depolarization. Under these conditions, neurons rescaled the gain of their input-output functions according to the scale of the stimulus distribution, as observed in vivo. This stimulus-specific adaptation was caused by intrinsic properties and correlated strongly with the amplitude of calcium-dependent slow afterhyperpolarizations. Our results suggest that widely expressed intrinsic mechanisms participate in barrel cortex adaptation but that their recruitment is highly stimulus specific.},
author = {D{\'{i}}az-Quesada, Marta and Maravall, Miguel},
doi = {10.1523/JNEUROSCI.4931-07.2008},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation, Physiological,Adaptation, Physiological: physiology,Animals,Animals, Newborn,Dose-Response Relationship, Radiation,Electric Stimulation,Electric Stimulation: methods,Neurons,Neurons: physiology,Nonlinear Dynamics,Patch-Clamp Techniques,Rats,Rats, Wistar,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology},
month = {jan},
number = {3},
pages = {696--710},
pmid = {18199769},
title = {{Intrinsic mechanisms for adaptive gain rescaling in barrel cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18199769},
volume = {28},
year = {2008}
}
@article{Mayoraz1993,
author = {Mayoraz, E},
title = {{Feedforward boolean neural networks with discrete weights: computational power and training}},
url = {http://ftp.idiap.ch/pub/OLD/mayoraz/Publications/thesis-booklet.ps.Z},
year = {1993}
}
@article{Lowen1997,
author = {Lowen, S B and Cash, S.S. S and Poo, M M and Teich, M C},
journal = {Journal of Neuroscience},
number = {15},
pages = {5666},
publisher = {Soc Neuroscience},
title = {{Quantal neurotransmitter secretion rate exhibits fractal behavior}},
url = {http://www.jneurosci.org/cgi/content/abstract/17/15/5666},
volume = {17},
year = {1997}
}
@article{Neal04,
author = {Neal, R M},
journal = {University of Toronto Statistics Tech Report},
title = {{Improving asymptotic variance of {\{}MCMC{\}} estimators: Non-reversible chains are better}},
volume = {0406},
year = {2004}
}
@article{OHRD01,
author = {Oram, M and Hatsopoulos, N and Richmond, B and Donoghue, J},
journal = {Journal of Neurophysiology},
pages = {1700--1716},
title = {{Excess Synchrony in Motor Cortical Neurons Provides Redundant Direction Information With That From Coarse Temporal Measures}},
volume = {86},
year = {2001}
}
@article{Bak1988,
author = {Bak, P. and Tang, C. and Wiesenfeld, K.},
journal = {Physical review A},
number = {1},
pages = {364--374},
publisher = {Woodbury},
title = {{Self-organized criticality}},
url = {http://chaos.swarthmore.edu/courses/Physics120{\_}2008/docs/btw.pdf},
volume = {38},
year = {1988}
}
@article{Ba2014,
author = {Ba, Jimmy and Caruana, Rich},
journal = {Advances in Neural Information Processing Systems},
pages = {2654--2662},
title = {{Do deep nets really need to be deep?}},
year = {2014}
}
@article{PAN06,
author = {Paninski, L},
journal = {Advances in Neural Information Processing Systems},
title = {{Inferring prior probabilities from {\{}B{\}}ayes-optimal behavior}},
volume = {18},
year = {2005}
}
@article{Chandramouli,
author = {Chandramouli, R and Ranganathan, N and Ieee, Senior Member},
journal = {Signal Processing Letters, {\ldots}},
keywords = {- bivariate gaussian pdf,1,ar,characteristic function,con uent hyper-,process},
number = {1},
title = {{Computing the bivariate Gaussian probability integral}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=763142},
year = {1999}
}
@article{DG06,
author = {Dimitrov, A and Gedeon, T},
journal = {Journal of Computational Neuroscience},
pages = {265--283},
title = {{Effects of stimulus transformations on characteristics of sensory neuron function}},
volume = {20},
year = {2006}
}
@article{peskun73,
author = {Peskun, P},
journal = {Biometrika},
pages = {607--612},
title = {{Optimum Monte-Carlo sampling using Markov chains}},
volume = {60},
year = {1973}
}
@article{Jain2010,
abstract = {Connections between neurons can be found by checking whether synapses exist at points of contact, which in turn are determined by neural shapes. Finding these shapes is a special case of image segmentation, which is laborious for humans and would ideally be performed by computers. New metrics properly quantify the performance of a computer algorithm using its disagreement with 'true' segmentations of example images. New machine learning methods search for segmentation algorithms that minimize such metrics. These advances have reduced computer errors dramatically. It should now be faster for a human to correct the remaining errors than to segment an image manually. Further reductions in human effort are expected, and crucial for finding connectomes more complex than that of Caenorhabditis elegans.},
annote = {2010IIInum29},
author = {Jain, V and Seung, H S and Turaga, S C},
doi = {10.1016/j.conb.2010.07.004},
issn = {1873-6882},
journal = {Current Opinion in Neurobiology},
month = {aug},
pages = {1--32},
pmid = {20801638},
title = {{Machines that learn to segment images: a crucial technology for connectomics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20801638},
year = {2010}
}
@article{Lee,
author = {Lee, David and Bruck, J},
title = {{Generating Probability Distributions using Multivalued Stochastic Relay Circuits}},
year = {2011}
}
@article{Mishra2017,
abstract = {For computer vision applications, prior works have shown the efficacy of reducing numeric precision of model parameters (network weights) in deep neural networks. Activation maps, however, occupy a large memory footprint during both the train-ing and inference step when using mini-batches of inputs. One way to reduce this large memory footprint is to reduce the precision of activations. However, past works have shown that reducing the precision of activations hurts model accuracy. We study schemes to train networks from scratch using reduced-precision activa-tions without hurting accuracy. We reduce the precision of activation maps (along with model parameters) and increase the number of filter maps in a layer, and find that this scheme matches or surpasses the accuracy of the baseline full-precision network. As a result, one can significantly improve the execution efficiency (e.g. reduce dynamic memory footprint, memory bandwidth and computational energy) and speed up the training and inference process with appropriate hardware sup-port. We call our scheme WRPN -wide reduced-precision networks. We report results and show that WRPN scheme is better than previously reported accuracies on ILSVRC-12 dataset while being computationally less expensive compared to previously reported reduced-precision networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1709.01134v1},
author = {Mishra, Asit and Nurvitadhi, Eriko and Cook, Jeffrey J and Marr, Debbie},
eprint = {arXiv:1709.01134v1},
pages = {1--11},
title = {{WRPN: Wide Reduced-Precision Networks}},
url = {https://arxiv.org/pdf/1709.01134.pdf},
year = {2017}
}
@article{MolitorManis97,
author = {Molitor, S C and Manis, P B},
journal = {Journal of Neurophysiology},
month = {apr},
number = {4},
pages = {1889--1905},
title = {{Evidence for functional metabotropic glutamate receptors in the dorsal cochlear nucleus}},
volume = {77},
year = {1997}
}
@article{Pistohl08,
author = {Pistohl, Tobias and Ball, Tonio and Schulze-Bonhage, Andreas and Aertsen, Ad and Mehring, Carsten},
journal = {Journal of Neuroscience Methods},
pages = {105--114},
title = {{Prediction of arm movement trajectories from ECoG-recordings in humans}},
volume = {167},
year = {2008}
}
@article{Description1952,
author = {Description, Quantitative and Hodgkin, B Y A L},
pages = {500--544},
title = {{Ik), (i,)}},
year = {1952}
}
@article{Hayward|1999|,
abstract = {A generally relativistic theory of thermodynamics is developed, based
on four main physical principles: heat is a local form of energy,
therefore described by a thermal energy tensor; conservation of mass,
equivalent to conservation of heat, or the local rst law; entropy
is a local current; and non-destruction of entropy, or the local
second law. A uid is defined by the thermostatic energy tensor being
isotropic. The entropy current is related to the other yields by
certain equations, including a generalised Gibbs equation for the
thermostatic entropy, followed by linear and quadratic terms in the
dissipative (thermal minus thermostatic) energy tensor. Then the
second law suggests certain equations for the dissipative energy
tensor, generalising the Israel-Stewart dissipative relations, which
describe heat conduction and viscosity including relativistic effects
and relaxation effects. In the thermostatic case, the perfect-liquid
model is recovered. In the linear approximation for entropy, the
Eckart theory is recovered. In the quadratic approximation for entropy,
the theory is similar to that of Israel {\&} Stewart, but involving
neither state-space differentials, nor a non-equilibrium Gibbs equation,
nor non-material frames. Also, unlike conventional thermodynamics,
the thermal energy density is not assumed to be purely thermostatic,
though this is derived in the linear approximation. Otherwise, the
theory reduces in the non-relativistic limit to the extended thermodynamics
of irreversible processes due to Muller. The dissipative energy density
seems to be a new thermodynamical eld, but also exists in relativistic
kinetic theory of gases.},
author = {Hayward, S A},
journal = {arXiv},
keywords = {astrophysics,physics,relativistic,thermodynamics},
pages = {9803007},
title = {{Relativistic thermodynamics}},
volume = {gr-qc}
}
@article{Pouille2009,
abstract = {The cortex is sensitive to weak stimuli, but responds to stronger inputs without saturating. The mechanisms that enable this wide range of operation are not fully understood. We found that the amplitude of excitatory synaptic currents necessary to fire rodent pyramidal cells, the threshold excitatory current, increased with stimulus strength. Consequently, the relative contribution of individual afferents in firing a neuron was inversely proportional to the total number of active afferents. Feedforward inhibition, acting homogeneously across pyramidal cells, ensured that threshold excitatory currents increased with stimulus strength. In contrast, heterogeneities in the distribution of excitatory currents in the neuronal population determined the specific set of pyramidal cells recruited. Together, these mechanisms expand the range of afferent input strengths that neuronal populations can represent.},
author = {Pouille, Fr{\'{e}}d{\'{e}}ric and Marin-Burgin, Antonia and Adesnik, Hillel and Atallah, Bassam V and Scanziani, Massimo},
doi = {10.1038/nn.2441},
issn = {1546-1726},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,CA1 Region,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Feedback,Hippocampal,Hippocampal: cytology,Hippocampal: physiology,Interneurons,Interneurons: physiology,Models,Neural Inhibition,Neural Inhibition: physiology,Neural Pathways,Neural Pathways: physiology,Neurological,Physiological,Physiological: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Rodentia,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology,Synapses,Synapses: physiology},
number = {12},
pages = {1577--1585},
pmid = {19881502},
title = {{Input normalization by global feedforward inhibition expands cortical dynamic range.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19881502},
volume = {12},
year = {2009}
}
@article{Hinton2006,
author = {Hinton, G E and Osindero, S and Teh, Y W},
journal = {Neural computation},
number = {7},
pages = {1527--1554},
title = {{A fast learning algorithm for deep belief nets}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2006.18.7.1527},
volume = {1554},
year = {2006}
}
@incollection{BER89,
author = {Berger, J and Bernardo, J and Mendoza, M},
booktitle = {Bayesian Statistics 4},
pages = {35--60},
publisher = {Oxford University Press},
title = {{On priors that maximize expected information}},
year = {1989}
}
@book{Abramowitz1964a,
author = {Abramowitz, Milton and Stegun, Irene A},
publisher = {Courier Corporation},
title = {{Handbook of Mathematical Functions}},
year = {1964}
}
@article{Gerstner2012,
author = {Gerstner, W and Sprekeler, Henning and Deco, Gustavo},
journal = {Science},
number = {October},
pages = {60--65},
title = {{Theory and Simulation in Neuroscience}},
url = {http://www.sciencemag.org/content/338/6103/60.abstract},
year = {2012}
}
@book{SCH95,
address = {New York},
author = {Schervish, M},
publisher = {Springer-Verlag},
title = {{Theory of statistics}},
year = {1995}
}
@article{Forger2011,
annote = {2011num38},
author = {Forger, Daniel B. and Paydarfar, David and Clay, John R.},
doi = {10.1371/journal.pcbi.1002089},
editor = {Morrison, Abigail},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {jul},
number = {7},
pages = {e1002089},
title = {{Optimal Stimulus Shapes for Neuronal Excitation}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002089},
volume = {7},
year = {2011}
}
@article{Butts07,
author = {Butts, D and Weng, C and Jin, J and Yeh, C and Lesica, N and Alonso, J.-M. and Stanley, G},
journal = {Nature},
pages = {92--95},
title = {{Temporal precision in the neural code and the timescales of natural vision}},
volume = {449},
year = {2007}
}
@book{frieden2004science,
author = {Frieden, B R},
publisher = {Cambridge Univ Pr},
title = {{Science from Fisher information: a unification}},
url = {http://www.google.com/books?hl=en{\&}lr={\&}id=qoFW76lXlEMC{\&}oi=fnd{\&}pg=PA1{\&}dq=Physics+from+Fisher+Information:+A+Unification{\&}ots=nCjBqMDZmH{\&}sig=s5cyonbnE9Z{\_}5hdqK3DeHQQsyrU},
year = {2004}
}
@article{Snider2007,
author = {Snider, G S},
doi = {10.1088/0957-4484/18/36/365202},
issn = {0957-4484},
journal = {Nanotechnology},
month = {sep},
number = {36},
pages = {365202},
title = {{Self-organized computation with unreliable, memristive nanodevices}},
url = {http://stacks.iop.org/0957-4484/18/i=36/a=365202?key=crossref.84d0b0c766f7a53c8d1dcbab386fca94},
volume = {18},
year = {2007}
}
@article{Liu2011,
abstract = {The ultimate proof of our understanding of natural or technological systems is reflected in our ability to control them. Although control theory offers mathematical tools for steering engineered and natural systems towards a desired state, a framework to control complex self-organized systems is lacking. Here we develop analytical tools to study the controllability of an arbitrary complex directed network, identifying the set of driver nodes with time-dependent control that can guide the system's entire dynamics. We apply these tools to several real networks, finding that the number of driver nodes is determined mainly by the network's degree distribution. We show that sparse inhomogeneous networks, which emerge in many real complex systems, are the most difficult to control, but that dense and homogeneous networks can be controlled using a few driver nodes. Counterintuitively, we find that in both model and real systems the driver nodes tend to avoid the high-degree nodes.},
annote = {

2num2012},
author = {Liu, YY Yang-Yu and Slotine, Jean-Jacques and Barab{\'{a}}si, Albert-L{\'{a}}szl{\'{o}}},
doi = {10.1038/nature10011},
issn = {1476-4687},
journal = {Nature},
keywords = {Algorithms,Animals,Complex Networks,Computer Simulation,Models,Neural Networks (Computer),Theoretical},
mendeley-tags = {Complex Networks},
month = {may},
number = {7346},
pages = {167--73},
pmid = {21562557},
title = {{Controllability of complex networks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21562557 http://www.nature.com/nature/journal/v473/n7346/abs/nature10011.html?amp},
volume = {473},
year = {2011}
}
@article{Ciresan2012a,
author = {Ciresan, D and Giusti, A and Schmidhuber, J},
journal = {NIPS},
title = {{Deep neural networks segment neuronal membranes in electron microscopy images}},
url = {http://books.nips.cc/papers/files/nips25/NIPS2012{\_}1292.pdf},
year = {2012}
}
@article{Goldwyn2011,
author = {Goldwyn, J H and Imennov, N S and Famulare, M and Shea-Brown, E},
doi = {10.1103/PhysRevE.83.041908},
issn = {1539-3755},
journal = {Physical Review E},
month = {apr},
number = {4},
pages = {041908},
publisher = {APS},
title = {{Stochastic differential equation models for ion channel noise in Hodgkin-Huxley neurons}},
url = {http://pre.aps.org/abstract/PRE/v83/i4/e041908},
volume = {83},
year = {2011}
}
@article{Welch|2004|,
abstract = {In 1960, R.E. Kalman published his famous paper describing a recursive
solution to the discrete-data linear filtering problem. Since that
time, due in large part to advances in digital computing, the Kalman
filter has been the subject of extensive research and application,
particularly in the area of autonomous or assisted navigation. The
Kalman filter is a set of mathematical equations that provides an
efficient computational (recursive) means to estimate the state of
a process, in a way that minimizes the mean of the squared error.
The filter is very powerful in several aspects: it supports estimations
of past, present, and even future states, and it can do so even when
the precise nature of the modeled system is unknown. The purpose
of this paper is to provide a practical introduction to the discrete
Kalman filter. This introduction includes a description and some
discussion of the basic discrete Kalman filter, a derivation, description
and some discussion of the extended Kalman filter, and a relatively
simple (tangible) example with real numbers {\&} results.},
author = {Welch, G and Bishop, G},
keywords = {computational,image processing,kalman filter},
title = {{An Introduction to the Kalman Filter}}
}
@article{Tsodyks2000,
abstract = {Throughout the neocortex, groups of neurons have been found to fire synchronously on the time scale of several milliseconds. This near coincident firing of neurons could coordinate the multifaceted information of different features of a stimulus. The mechanisms of generating such synchrony are not clear. We simulated the activity of a population of excitatory and inhibitory neurons randomly interconnected into a recurrent network via synapses that display temporal dynamics in their transmission; surprisingly, we found a behavior of the network where action potential activity spontaneously self-organized to produce highly synchronous bursts involving virtually the entire network. These population bursts were also triggered by stimuli to the network in an all-or-none manner. We found that the particular intensities of the external stimulus to specific neurons were crucial to evoke population bursts. This topographic sensitivity therefore depends on the spectrum of basal discharge rates across the population and not on the anatomical individuality of the neurons, because this was random. These results suggest that networks in which neurons are even randomly interconnected via frequency-dependent synapses could exhibit a novel form of reflex response that is sensitive to the nature of the stimulus as well as the background spontaneous activity.},
author = {Tsodyks, M and Uziel, a and Markram, H},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Models,Nerve Net,Nerve Net: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Synapses,Synapses: physiology,synapse},
mendeley-tags = {synapse},
month = {jan},
number = {1},
pages = {RC50},
pmid = {10627627},
title = {{Synchrony generation in recurrent networks with frequency-dependent synapses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10627627},
volume = {20},
year = {2000}
}
@article{Budd2006,
author = {Budd, C and Piiroinen, P},
doi = {10.1016/j.physd.2006.07.001},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
keywords = {multiple impacts,non-smooth forcing,piecewise linear maps,piecewise smooth dynamical systems},
month = {aug},
number = {2},
pages = {127--145},
title = {{Corner bifurcations in non-smoothly forced impact oscillators}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167278906002351},
volume = {220},
year = {2006}
}
@article{VanierBower99,
author = {Vanier, M and Bower, J},
journal = {J. Comput. Neurosci.},
number = {2},
pages = {149--171},
title = {{A comparative survey of automated parameter-search methods for compartmental neural models}},
volume = {7},
year = {1999}
}
@inproceedings{Goncalves2004,
author = {Goncalves, JM},
booktitle = {Decision and Control, 2003. Proceedings. 42nd IEEE Conference on},
isbn = {0780379241},
issn = {0191-2216},
number = {December},
pages = {651--656},
publisher = {IEEE},
title = {{Regions of stability for limit cycles of piecewise linear systems}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1272638},
volume = {1},
year = {2004}
}
@article{JS60,
author = {James, W and Stein, C},
journal = {Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability},
pages = {361--379},
title = {{Estimation with Quadratic Loss}},
volume = {1},
year = {1960}
}
@article{Halko09,
author = {Halko, Nathan and Martinsson, Per-Gunnar and Tropp, Joel A},
journal = {Arxiv},
pages = {0909.4061},
title = {{Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions}},
year = {2009}
}
@article{Geweke89,
author = {Geweke, J},
journal = {Econometrica},
number = {6},
pages = {1317--1339},
publisher = {JSTOR},
title = {{Bayesian Inference in Econometric Models Using Monte Carlo Integration}},
volume = {57},
year = {1989}
}
@article{WinterPalmer95,
author = {Winter, I M and Palmer, A R},
journal = {Journal of Neurophysiology},
month = {jan},
number = {1},
pages = {141--159},
title = {{Level dependence of cochlear nucleus onset unit responses and facilitation by second tones or broadband noise}},
volume = {73},
year = {1995}
}
@inproceedings{Barber1998b,
author = {Barber, D and Bishop, C M},
booktitle = {Advances in Neural Information Processing Systems},
pages = {395--401},
title = {{Ensemble learning for multi-layer networks}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=M55BL-GvQ8IC{\&}oi=fnd{\&}pg=PA395{\&}dq=Ensemble+learning+for+multi-layer+networks{\&}ots=Fsyx0wyKmU{\&}sig=WqiSbpJZBdFfuMuIEHrWqGqO9Sg},
year = {1998}
}
@article{Diseases1970,
author = {Diseases, Neurological},
pages = {707--728},
title = {{Physiologisches Homburg-Saar,}},
year = {1970}
}
@article{Major2004,
abstract = {Persistent neural activity refers to a sustained change in action potential discharge that long outlasts a stimulus. It is found in a diverse set of brain regions and organisms and several in vitro systems, suggesting that it can be considered a universal form of circuit dynamics that can be used as a mechanism for short-term storage and accumulation of sensory or motor information. Both single cell and network mechanisms are likely to co-operate in generating persistent activity in many brain areas.},
annote = {2010IInum12.17},
author = {Major, Guy and Tank, David},
doi = {10.1016/j.conb.2004.10.017},
issn = {0959-4388},
journal = {Current Opinion in Neurobiology},
keywords = {Action Potentials,Action Potentials: physiology,Animal,Animals,Central Nervous System,Central Nervous System: physiology,Feedback,Feedback: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Neural Pathways,Neural Pathways: physiology,Neuron Model,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
mendeley-tags = {Neuron Model},
month = {dec},
number = {6},
pages = {675--84},
pmid = {15582368},
title = {{Persistent neural activity: prevalence and mechanisms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15582368},
volume = {14},
year = {2004}
}
@article{Xulvi-Brunet|2004|,
abstract = {Many social networks exhibit assortative mixing so that the predictions
of uncorrelated models might be inadequate. To analyze the role of
assortativity we introduce an algorithm which changes correlations
in a network and produces assortative mixing to a desired degree.
This degree is governed by one parameter p. Changing this parameter
one can construct networks ranging from fully random (p = 0) to totally
assortative (p = 1). We apply the algorithm to a Barab{\^{A}}´asi-Albert
scale-free network and show that the degree of assortativity is an
important parameter governing geometrical and transport properties
of networks. Thus, the diameter of the network and the clustering
coefficient increase dramatically with the degree of assortativity.
Moreover, the concentration dependences of the size of the giant
component in the node percolation problem for uncorrelated and assortative
networks are strongly different.},
author = {Xulvi-Brunet, R and Sokolov, I M},
journal = {arXiv},
keywords = {assortative,networks,random networks,unread},
number = {0405095},
title = {{Construction and properties of assortative random networks}},
volume = {cond-mat}
}
@article{Yau1976,
abstract = {1. In segmental ganglia of the leech, the cutaneous mechanosensory neurones responding to to touch innervated the skin of their own segment and of part of the anterior and posterior adjacent segments. Each touch receptive field could be divided into three non-overlapping areas: a central part innervated by the branches of the cell which ran in the nerve roots of the ganglion containing the cell body, and anterior and posterior parts innervated by its branches which ran in the nerve roots of the anterior and posterior adjacent ganglia. 2. Impulses originating from the anterior and posterior parts of the receptive fields were susceptible to conduction block within the central nervous system when the touch cells fired repetitively at frequencies that could readily be elicited with weak mechanical stimulation. In contrast, impulses originating from the central part of the receptive fields were less susceptible to block. 3. The morphology of touch cells revealed by intracellular injection of horseradish peroxidase suggested that conduction block occurred at specific bifurcation points where small cell processes joined the main process. Different physiological experiments supported this conclusion. 4. In some touch cells, bifurcation points with particularly low safety margins of conduction operated as low-pass filters, limiting the frequency of impulses capable of invading certain branches. 5. The results suggest that mechanical stimuli which would likely be encountered by the animal can lead to conduction block within its central nervous system and as a result modify its integrative activities.
},
author = {Yau, K W},
journal = {Journal of Physiology},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
month = {dec},
number = {3},
pages = {513--538},
title = {{Receptive fields, geometry and conduction block of sensory neurones in the central nervous system of the leech.}},
url = {http://jp.physoc.org/cgi/content/abstract/263/3/513},
volume = {263},
year = {1976}
}
@article{Gibson2000,
author = {Gibson, MA and Bruck, J},
journal = {The journal of physical chemistry A},
pages = {1876--1889},
title = {{Efficient exact stochastic simulation of chemical systems with many species and many channels}},
url = {http://pubs.acs.org/doi/abs/10.1021/jp993732q},
volume = {2},
year = {2000}
}
@article{BM98,
author = {Berry, M and Meister, M},
journal = {J. Neurosci.},
pages = {2200--2211},
title = {{Refractoriness and neural precision}},
volume = {18},
year = {1998}
}
@misc{WormBase,
title = {http://www.wormbase.org}
}
@article{Nedjah2007,
author = {Nedjah, Nadia and {Macedo Mourelle}, Luiza},
doi = {10.1007/s00521-007-0086-x},
issn = {0941-0643},
journal = {Neural Computing and Applications},
keywords = {neural network hardware {\'{a}},stochastic computing},
month = {mar},
number = {3},
pages = {249--255},
title = {{Reconfigurable hardware for neural networks: binary versus stochastic}},
url = {http://link.springer.com/10.1007/s00521-007-0086-x},
volume = {16},
year = {2007}
}
@article{Gagvani|2006|,
abstract = {Skeletons are useful shape abstractions and have varied applications
in visualization. The density of the desired skeletal structure depends
on the application. Current techniques for extracting skeletons do
not allow control over the density. In this paper, we describe an
algorithm which uses a thinness parameter to control the density
of the skeleton. We apply our algorithm to skeletonize complex objects
from medical and CFD visualization. The skeleton of a medical dataset
is used as the centerline for surgical naviation and skeletons of
vortex structures are used to speed up tracking.},
annote = {Paper introduces distance-based skeletonization with parameter defining{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the thinness of the resulting skeleton.},
author = {Gagvani, N and Silver, D},
keywords = {centerline,computational,distance function,image processing,skeletonization,visualization,volume thinning},
title = {{Parameter controlled skeletons for 3D visualization}}
}
@article{Keysers2001,
abstract = {Macaque monkeys were presented with continuous rapid serial visual presentation (RSVP) sequences of unrelated naturalistic images at rates of 14--222 msec/image, while neurons that responded selectively to complex patterns (e.g., faces) were recorded in temporal cortex. Stimulus selectivity was preserved for 65{\%} of these neurons even at surprisingly fast presentation rates (14 msec/image or 72 images/sec). Five human subjects were asked to detect or remember images under equivalent conditions. Their performance in both tasks was above chance at all rates (14--111 msec/image). The performance of single neurons was comparable to that of humans and responded in a similar way to changes in presentation rate. The implications for the role of temporal cortex cells in perception are discussed.},
author = {Keysers, C and Xiao, D K and F{\"{o}}ldi{\'{a}}k, P and Perrett, D I},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Animals,Attention,Attention: physiology,Brain Mapping,Discrimination (Psychology),Discrimination (Psychology): physiology,Fixation,Humans,Macaca mulatta,Magnetic Resonance Imaging,Male,Memory,Memory: physiology,Models,Neurological,Neurons,Neurons: physiology,Ocular,Ocular: physiology,Pattern Recognition,Psychological,Psychophysics,Reaction Time,Reaction Time: physiology,Spike time neural coding,Temporal Lobe,Temporal Lobe: physiology,Vision,Visual,Visual Perception,Visual Perception: physiology,Visual: physiology},
mendeley-tags = {Spike time neural coding},
month = {jan},
number = {1},
pages = {90--101},
pmid = {11224911},
title = {{The speed of sight}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11224911},
volume = {13},
year = {2001}
}
@article{CB90,
author = {Clarke, B and Barron, A},
journal = {IEEE Transactions on Information Theory},
pages = {453--471},
title = {{Information-theoretic asymptotics of {\{}B{\}}ayes methods}},
volume = {36},
year = {1990}
}
@article{Horton|2005|,
abstract = {This year, the field of neuroscience celebrates the 50th anniversary
of Mountcastle{\"{i}}¾'s discovery of the cortical column. In this review,we
summarize half a century of research and come to the disappointing
realization that the column may have no function. Originally, it
was described as a discrete structure, spanning the layers of the
somatosensory cortex, which contains cells responsive to only a single
modality, such as deep joint receptors or cutaneous receptors. Subsequently,
examples of columns have been uncovered in numerous cortical areas,
expanding the original concept to embrace a variety of different
structures and principles. A {\"{i}}¾‘column{\"{i}}¾' now refers to cells in
any vertical cluster that share the same tuning for any given receptive
field attribute. In striate cortex, for example, cells with the same
eye preference are grouped into ocular dominance columns. Unaccountably,
ocular dominance columns are present in some species, but not others.
In principle, it should be possible to determine their function by
searching for species differences in visual performance that correlate
with their presence or absence. Unfortunately, this approach has
been to no avail; no visual faculty has emerged that appears to require
ocular dominance columns. Moreover, recent evidence has shown that
the expression of ocular dominance columns can be highly variable
among members of the same species, or even in different portions
of the visual cortex in the same individual. These observations deal
a fatal blow to the idea that ocular dominance columns serve a purpose.
More broadly, the term {\"{i}}¾‘column{\"{i}}¾' also denotes the periodic termination
of anatomical projections within or between cortical areas. In many
instances, periodic projections have a consistent relationship with
some architectural feature, such as the cytochrome oxidase patches
in V1 or the stripes in V2. These tissue compartments appear to divide
cells with different receptive field properties into distinct processing
streams. However, it is unclear what advantage, if any, is conveyed
by this form of columnar segregation. Although the column is an attractive
concept, it has failed as a unifying principle for understanding
cortical function. Unravelling the organization of the cerebral cortex
will require a painstaking description of the circuits, projections
and response properties peculiar to cells in each of its various
areas.},
author = {Horton, J C and Adams, D L},
journal = {Philosophical transactions of the royal society B},
keywords = {angioscotoma,barrel,cortical column,macaque,neurobiology,pinwheel,retinal wave,spandrel},
pages = {1},
title = {{The cortical column: a structrue without a function}}
}
@article{Yu-nips09,
author = {Yu, B M and Cunningham, J P and Santhanam, G and Ryu, S I and Shenoy, K V and Sahani, M},
journal = {Journal of Neurophysiology},
pages = {614--635},
title = {{Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity}},
volume = {102},
year = {2009}
}
@article{Katona2012,
abstract = {The understanding of brain computations requires methods that read out neural activity on different spatial and temporal scales. Following signal propagation and integration across a neuron and recording the concerted activity of hundreds of neurons posplose distinct challenges, and the design of imaging systems has been mostly focused on tackling one of the two operations. We developed a high-resolution, acousto-optic two-photon microscope with continuous three-dimensional (3D) trajectory and random-access scanning modes that reaches near-cubic-millimeter scan range and can be adapted to imaging different spatial scales. We performed 3D calcium imaging of action potential backpropagation and dendritic spike forward propagation at sub-millisecond temporal resolution in mouse brain slices. We also performed volumetric random-access scanning calcium imaging of spontaneous and visual stimulation-evoked activity in hundreds of neurons of the mouse visual cortex in vivo. These experiments demonstrate the subcellular and network-scale imaging capabilities of our system.},
author = {Katona, Gergely and Szalay, Gergely and Ma{\'{a}}k, P{\'{a}}l and Kasz{\'{a}}s, Attila and Veress, M{\'{a}}t{\'{e}} and Hillier, D{\'{a}}niel and Chiovini, Bal{\'{a}}zs and Vizi, E Sylvester and Roska, Botond and R{\'{o}}zsa, Bal{\'{a}}zs},
doi = {10.1038/nmeth.1851},
isbn = {1012011038},
issn = {1548-7091},
journal = {Nature methods},
number = {2},
pages = {201--208},
pmid = {22231641},
title = {{Fast two-photon in vivo imaging with three-dimensional random-access scanning in large tissue volumes}},
volume = {9},
year = {2012}
}
@article{Neher2003,
author = {Neher, E and Sakmann, B},
journal = {Nature},
pages = {799--802},
title = {{Single-channel currents recorded from membrane of denervated frog muscle fibres}},
year = {1976}
}
@book{RHC05,
author = {Kwon, Wook Hyun and Han, S},
publisher = {Springer},
title = {{Receding horizon control: model predictive control for state models}},
year = {2005}
}
@article{MaravallSvoboda00,
abstract = {We describe a method for determining intracellular free calcium concentration

([{\{}Ca{\}}{\^{}}{\{}2+{\}}]) from single-wavelength fluorescence signals. In

contrast to previous single-wavelength calibration methods, the proposed

method does not require independent estimates of resting [{\{}Ca{\}}{\^{}}{\{}2+{\}}]

but relies on the measurement of fluorescence close to indicator

saturation during an experiment. Consequently, it is well suited

to [{\{}Ca{\}}{\^{}}{\{}2+{\}}] indicators for which saturation can be achieved

under physiological conditions. In addition, the method requires

that the indicators have large dynamic ranges. Popular indicators

such as Calcium Green-1 or Fluo-3 fulfill these conditions. As a

test of the method, we measured [{\{}Ca{\}}{\^{}}{\{}2+{\}}] in CA1 pyramidal neurons

in rat hippocampal slices using Oregon Green BAPTA-1 and 2-photon

laser scanning microscopy (BAPTA: 1,2-bis(2-aminophenoxy)ethane-N,N,N',

N'-tetraacetic acid). Resting [{\{}Ca{\}}{\^{}}{\{}2+{\}}] was 32-59 nM in the

proximal apical dendrite. Monitoring action potential-evoked [{\{}Ca{\}}{\^{}}{\{}2+{\}}]

transients as a function of indicator loading yielded estimates of

endogenous buffering capacity (44-80) and peak [{\{}Ca{\}}{\^{}}{\{}2+{\}}] changes

at zero added buffer (178-312 nM). In young animals (postnatal days

14-17) our results were comparable to previous estimates obtained

by ratiometric methods (, Biophys. J. 70:1069-1081), and no significant

differences were seen in older animals (P24-28). We expect our method

to be widely applicable to measurements of [{\{}Ca{\}}{\^{}}{\{}2+{\}}] and [{\{}Ca{\}}{\^{}}{\{}2+{\}}]-dependent

processes in small neuronal compartments, particularly in the many

situations that do not permit wavelength ratio imaging.},
author = {Maravall, M and Mainen, Z F and Sabatini, B L and Svoboda, K},
journal = {Biophys J},
keywords = {Action Potentials; Animals; Biophysics; Buffers; C,Biological; Pyramidal Cells; Rats},
month = {may},
number = {5},
pages = {2655--2667},
pmid = {10777761},
title = {{Estimating intracellular calcium concentrations and buffering without wavelength ratioing.}},
volume = {78},
year = {2000}
}
@article{Wang2014,
abstract = {In this paper, adaptive synchronization of memristor-based neural networks (MNNs) with time-varying delays is investigated. The dynamical analysis here employs results from the theory of differential equations with discontinuous right-hand sides as introduced by Filippov. Sufficient conditions for the global synchronization of MNNs are established with a general adaptive controller. The update gain of the controller can be adjusted to control the synchronization speed. The obtained results complement and improve the previously known results. Finally, numerical simulations are carried out to demonstrate the effectiveness of the obtained results.},
author = {Wang, Leimin and Shen, Yi and Yin, Quan and Zhang, Guodong},
doi = {10.1109/TNNLS.2014.2361776},
issn = {2162-2388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
month = {nov},
number = {99},
pages = {1--10},
pmid = {25389244},
title = {{Adaptive Synchronization of Memristor-Based Neural Networks with Time-Varying Delays.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25389244},
year = {2014}
}
@article{Dziugaite2017,
abstract = {One of the defining properties of deep learning is that models are chosen to have many more parameters than available training data. In light of this capacity for overfitting, it is remarkable that simple algorithms like SGD reliably return solutions with low test error. One roadblock to explaining these phenomena in terms of implicit regularization, structural properties of the solution, and/or easiness of the data is that many learning bounds are quantitatively vacuous in this "deep learning" regime. In order to explain generalization, we need nonvacuous bounds. We return to an idea by Langford and Caruana (2001), who used PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization error for stochastic two-layer two-hidden-unit neural networks via a sensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples. We connect our findings to recent and old work on flat minima and MDL-based explanations of generalization.},
archivePrefix = {arXiv},
arxivId = {1703.11008},
author = {Dziugaite, Gintare Karolina and Roy, Daniel M.},
eprint = {1703.11008},
journal = {ArXiv},
title = {{Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data}},
url = {http://arxiv.org/abs/1703.11008},
year = {2017}
}
@article{Niu2010,
address = {New York, New York, USA},
author = {Niu, Dimin and Chen, Yiran and Xu, Cong and Xie, Yuan},
doi = {10.1145/1837274.1837495},
isbn = {9781450300025},
journal = {Design Automation Conference},
keywords = {memristor,nonvolatile memory,process variation},
pages = {877--882},
publisher = {ACM Press},
title = {{Impact of process variations on emerging memristor}},
url = {http://portal.acm.org/citation.cfm?doid=1837274.1837495 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5523499},
year = {2010}
}
@inproceedings{Le2011a,
author = {Le, Q V and Coates, A and Prochnow, B and Ng, A Y},
booktitle = {ICML '11},
pages = {265--272},
title = {{On optimization methods for deep learning}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:On+Optimization+Methods+for+Deep+Learning{\#}0},
year = {2011}
}
@article{RoordaMiesenbock04,
author = {Roorda, Robert D and Hohl, Tobias M and Toledo-Crow, Ricardo and Miesenbock, Gero},
journal = {Journal of Neurophysiology},
month = {jul},
number = {1},
pages = {609--621},
title = {{Video-rate nonlinear microscopy of neuronal membrane dynamics with genetically encoded probes}},
volume = {92},
year = {2004}
}
@article{dan2006spike,
annote = {2008num17},
author = {Dan, Y and Poo, M M},
journal = {Physiological Reviews},
number = {3},
pages = {1033},
publisher = {Am Physiological Soc},
title = {{Spike timing-dependent plasticity: from synapse to perception}},
volume = {86},
year = {2006}
}
@article{Claiborne|1986|,
abstract = {The axon collaterals of dentate granule cells have been analyzed with
the aid of a computerized microscope, following intracellular injections
of horseradish peroxidase in hippocampal slice preparations. The
axon of each granule cell gives rise to approximately seven primary
collaterals; these collaterals usually divide into secondary and
tertiary branches, which form an extensive plexus within the hilar
region of the dentate gyrus. Individual axon collaterals vary greatly
in length, but most have been found to be between 100 and 300 microns
long. On average, the summed lengths of the collaterals (exclusive
of the parent mossy fiber) are approximately 2,300 microns. Except
for an occasional collateral that is given off by a mossy fiber in
the proximal part of field CA3 of the hippocampus, the collaterals
of the granule cell axons are confined to the hilar region; they
are rarely seen in the granule cell layer itself and have never been
observed in the molecular layer. In the longitudinal dimension of
the dentate gyrus, most of the collaterals are contained within a
zone about 400 microns wide. The distribution of the collaterals
within the hilar region is correlated with the location of the granule
cell body. Those that arise from cells near the tip of the suprapyramidal
blade tend to be confined to the region above field CA3; those from
cells nearer the crest and from the infrapyramidal blade ramify widely
throughout the hilus. Two types of varicosities are present on the
collaterals. Numerous small (approximately 2 microns), round varicosities
are distributed unevenly along the collaterals; in electron micrographs
these varicosities can be seen to make asymmetric synaptic contacts
with dendritic shafts. On average, each granule cell collateral plexus
has about 160 of these varicosities. The second type of varicosity
is irregular in shape and ranges from 2 to 4 microns in diameter;
there is usually only one such varicosity per collateral. In all
respects except size, these varicosities resemble the expansions
found on the parent mossy fibers. Mossy fiber trajectories in the
proximal part of field CA3 were studied after extracellular injections
of HRP into localized regions of the granule cell layer. Granule
cells at different locations around the blade send their mossy fibers
to different depths within the pyramidal cell layer in the proximal
part of field CA3. However, further distally, mossy fibers from all
parts of the granule cell layer contribute to the suprapyramidal
bundle that occupies the stratum lucidum.},
annote = {NS-16980/NS/United States NINDS NS-20004/NS/United States NINDS Journal{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Article Research Support, Non-U.S. Gov{\&}{\#}039;t Research Support, U.S. Gov{\&}{\#}039;t,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}P.H.S. United states},
author = {Claiborne, B J and Amaral, D G and Cowan, W M},
journal = {J Comp Neurol},
keywords = {Animals Axons/ultrastructure *Brain Mapping Female,Electron Nerve Endings/ultrastructure Nerve Fiber,Inbred Strains},
number = {4},
pages = {435--458},
title = {{A light and electron microscopic analysis of the mossy fibers of the rat dentate gyrus}},
volume = {246}
}
@article{Fang1999,
author = {Fang, S C and Venkatesh, S S},
journal = {Random Structures {\&} Algorithms},
keywords = {at the ieee international,batch learning,binary perceptron,canada,correspondence to,directed drift,neural networks,neuron,on-line learning,parts of this paper,s,september 1995 and at,symposium on information,the international conference on,theory,venkatesh,were presented in part,whistler},
number = {November 1995},
pages = {345--381},
title = {{Learning finite binary sequences from half space data}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1098-2418(199907)14:4{\%}3C345::AID-RSA4{\%}3E3.0.CO;2-3/abstract},
year = {1999}
}
@article{Gilson2012,
abstract = {Spike-timing-dependent plasticity (STDP) has been observed in many brain areas such as sensory cortices, where it is hypothesized to structure synaptic connections between neurons. Previous studies have demonstrated how STDP can capture spiking information at short timescales using specific input configurations, such as coincident spiking, spike patterns and oscillatory spike trains. However, the corresponding computation in the case of arbitrary input signals is still unclear. This paper provides an overarching picture of the algorithm inherent to STDP, tying together many previous results for commonly used models of pairwise STDP. For a single neuron with plastic excitatory synapses, we show how STDP performs a spectral analysis on the temporal cross-correlograms between its afferent spike trains. The postsynaptic responses and STDP learning window determine kernel functions that specify how the neuron "sees" the input correlations. We thus denote this unsupervised learning scheme as 'kernel spectral component analysis' (kSCA). In particular, the whole input correlation structure must be considered since all plastic synapses compete with each other. We find that kSCA is enhanced when weight-dependent STDP induces gradual synaptic competition. For a spiking neuron with a "linear" response and pairwise STDP alone, we find that kSCA resembles principal component analysis (PCA). However, plain STDP does not isolate correlation sources in general, e.g., when they are mixed among the input spike trains. In other words, it does not perform independent component analysis (ICA). Tuning the neuron to a single correlation source can be achieved when STDP is paired with a homeostatic mechanism that reinforces the competition between synaptic inputs. Our results suggest that neuronal networks equipped with STDP can process signals encoded in the transient spiking activity at the timescales of tens of milliseconds for usual STDP.},
author = {Gilson, Matthieu and Fukai, T and Burkitt, Anthony N},
doi = {10.1371/journal.pcbi.1002584},
issn = {1553-7358},
journal = {PLoS computational biology},
month = {jul},
number = {7},
pages = {e1002584},
pmid = {22792056},
title = {{Spectral analysis of input spike trains by spike-timing-dependent plasticity.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3390410{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {8},
year = {2012}
}
@article{Lansky06,
author = {Lansky, P and Sanda, P and He, J},
journal = {Journal of Computational Neuroscience},
pages = {211--223},
title = {{The parameters of the stochastic leaky integrate-and-fire neuronal model}},
volume = {21},
year = {2006}
}
@article{Yu2008a,
abstract = {Stimulated exocytosis and endocytosis of post-synaptic alpha-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid subtype of glutamate receptors (AMPARs) have been proposed as primary mechanisms for the expression of hippocampal CA1 long-term potentiation (LTP) and long-term depression (LTD), respectively. LTP and LTD, the two most well characterized forms of synaptic plasticity, are thought to be important for learning and memory in behaving animals. Both LTP and LTD can also be induced in the lateral amygdala (LA), a critical structure involved in fear conditioning. However, the role of AMPAR trafficking in the expression of either LTP or LTD in this structure remains unclear. In this study, we show that NMDA receptor-dependent LTP and LTD can be reliably induced at the synapses of the auditory thalamic inputs to the LA in brain slices. The expression of LTP was prevented by post-synaptic blockade of vesicle-mediated exocytosis with application of a light chain of Clostridium tetanus neurotoxin and was associated with increased cell-surface AMPAR expression. In contrast, the expression of LTD was prevented by post-synaptic application of a glutamate receptor 2-derived interference peptide, which specifically blocks the stimulated clathrin-dependent endocytosis of AMPARs, and was correlated with a reduction in plasma membrane-surface expression of AMPARs. These results strongly suggest that regulated trafficking of post-synaptic AMPARs is also involved in the expression of LTP and LTD in the LA.},
author = {Yu, Shu Yan and Wu, Dong Chuan and Liu, Lidong and Ge, Yuan and Wang, Yu Tian},
doi = {10.1111/j.1471-4159.2008.05461.x},
issn = {1471-4159},
journal = {Journal of neurochemistry},
keywords = {2-Amino-5-phosphonovalerate,2-Amino-5-phosphonovalerate: pharmacology,Amygdala,Amygdala: cytology,Animals,Animals, Newborn,Bicuculline,Bicuculline: pharmacology,Biotinylation,Biotinylation: methods,Dose-Response Relationship, Radiation,Electric Stimulation,Electric Stimulation: methods,Endocytosis,Endocytosis: drug effects,Endocytosis: radiation effects,Excitatory Amino Acid Antagonists,Excitatory Amino Acid Antagonists: pharmacology,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: drug effects,Excitatory Postsynaptic Potentials: physiology,Excitatory Postsynaptic Potentials: radiation effe,GABA Antagonists,GABA Antagonists: pharmacology,Long-Term Potentiation,Long-Term Potentiation: drug effects,Long-Term Potentiation: physiology,Long-Term Potentiation: radiation effects,Male,Neurons,Neurons: drug effects,Neurons: metabolism,Neurons: radiation effects,Protein Transport,Protein Transport: drug effects,Protein Transport: radiation effects,Rats,Receptors, AMPA,Receptors, AMPA: metabolism,Receptors, N-Methyl-D-Aspartate,Receptors, N-Methyl-D-Aspartate: physiology,Synapses,Synapses: physiology,Synapses: radiation effects},
month = {jul},
number = {2},
pages = {889--99},
pmid = {18466342},
title = {{Role of AMPA receptor trafficking in NMDA receptor-dependent synaptic plasticity in the rat lateral amygdala.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19914186},
volume = {106},
year = {2008}
}
@article{Baldi1989,
author = {Baldi, Pierre},
journal = {Advances in Neural Information Processing Systems 1},
number = {1},
pages = {65--72},
title = {{Linear Learning: Landscapes and Algorithms}},
url = {http://papers.nips.cc/paper/123-linear-learning-landscapes-and-algorithms.pdf{\%}5Cnfiles/4658/Baldi - 1989 - Linear Learning Landscapes and Algorithms.pdf{\%}5Cnfiles/4659/123-linear-learning-landscapes-and-algorithms.html},
year = {1989}
}
@article{Michaeli2012,
author = {Mich{\`{e}}le, Thieullen and Eldar, Y C and Sapiro, G},
doi = {10.1093/imaiai/drn000},
journal = {arXiv preprint arXiv:1203.4422},
keywords = {bayesian estimation,bayesian networks,hidden,learning,minimum mean squared error,multi and single domain,partial knowledge,regression,relationships},
pages = {1--31},
title = {{Semi-supervised single-and multi-domain regression with multi-domain training}},
url = {http://arxiv.org/abs/1203.4422},
year = {2012}
}
@article{Dolev2011,
author = {Dolev, D and Schmid, U and Fugger, M and C, Lenzen},
doi = {10.1145/0000000.0000000},
number = {212},
pages = {1--54},
title = {{Fault-tolerant Algorithms for Tick-Generation in A synchronous Logic : Robust Pulse Generation}},
year = {2011}
}
@incollection{Andersen|1975|,
address = {New York},
author = {Andersen, P},
booktitle = {The hippocampus},
editor = {Isaacson, R L and Pribram, K H},
pages = {155--175},
publisher = {Plenum},
title = {{Organization of hippocampal neurons and their interconnections.}},
volume = {1}
}
@article{Hescheler1989,
abstract = {We measured the non-linear dynamics of cardiac action potentials by varying the stimulation frequency from 2 to 20 Hz and obtained the following results: (i) When the fast Na+ current initiated the action potentials ('fast action potentials') periodicity was maintained, i.e. the pattern of action potentials repeated after a finite number of stimuli. Chaotic sequences were absent. The transition from one sequence to the next occurred as a devil's staircase. (ii) When, however, the slow Ca2+ current initiated the action potentials ('slow action potentials'), we observed chaos, i.e. fully irregular behaviour, as well as bifurcations. (iii) Our results confirm the supposition that the global dynamics of cardiac cells can be well described by simple one-dimensional maps which predict these two kinds of behaviour.},
author = {Hescheler, J and Speicher, R},
issn = {0175-7571},
journal = {European biophysics journal : EBJ},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Calcium,Calcium: physiology,Electric Stimulation,Guinea Pigs,Heart,Heart: physiology,Sodium,Sodium: physiology},
month = {jan},
number = {5},
pages = {273--80},
pmid = {2636964},
title = {{Regular and chaotic behaviour of cardiac cells stimulated at frequencies between 2 and 20 Hz.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2636964},
volume = {17},
year = {1989}
}
@article{Meister1994,
author = {Meister, M and Pine, J and Baylor, D A},
journal = {J. Neuroscie. Methods},
pages = {95--106},
title = {{Multi-neuronal signals from the retina: acquisition and analysis}},
volume = {51},
year = {1994}
}
@article{Inoue2007,
abstract = {After the report of Softky and Koch [Softky, W.R., Koch, C., 1993. The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs. J. Neurosci. 13, 334-350], leaky integrate-and-fire models have been investigated to explain high coefficient of variation (CV) of interspike intervals (ISIs) at high firing rates observed in the cortex. The purpose of this paper is to study the effect of the position of a lower boundary of membrane potential on the possible value of CV of ISIs based on the diffusional leaky integrate-and-fire models with and without reversal potentials. Our result shows that the irregularity of ISIs for the diffusional leaky integrate-and-fire neuron significantly changes by imposing a lower boundary of membrane potential, which suggests the importance of the position of the lower boundary as well as that of the firing threshold when we study the statistical properties of leaky integrate-and-fire neuron models. It is worth pointing out that the mean-CV plot of ISIs for the diffusional leaky integrate-and-fire neuron with reversal potentials shows a close similarity to the experimental result obtained in Softky and Koch [Softky, W.R., Koch, C., 1993. The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs. J. Neurosci. 13, 334-350].},
annote = {2010IInum12.38},
author = {Inoue, Junko and Doi, Shinji},
doi = {10.1016/j.biosystems.2006.03.003},
issn = {0303-2647},
journal = {Bio Systems},
keywords = {Action Potentials,Models, Theoretical,Neurons,Neurons: physiology},
month = {jan},
number = {1},
pages = {49--57},
pmid = {16675100},
title = {{Sensitive dependence of the coefficient of variation of interspike intervals on the lower boundary of membrane potential for the leaky integrate-and-fire neuron model.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16675100},
volume = {87},
year = {2007}
}
@article{PAN05b,
author = {Paninski, L},
journal = {Journal of Computational Neuroscience},
pages = {71--87},
title = {{The most likely voltage path and large deviations approximations for integrate-and-fire neurons}},
volume = {21},
year = {2006}
}
@article{Teramae2012,
abstract = {The connectivity of complex networks and functional implications has been attracting much interest in many physical, biological and social systems. However, the significance of the weight distributions of network links remains largely unknown except for uniformly- or Gaussian-weighted links. Here, we show analytically and numerically, that recurrent neural networks can robustly generate internal noise optimal for spike transmission between neurons with the help of a long-tailed distribution in the weights of recurrent connections. The structure of spontaneous activity in such networks involves weak-dense connections that redistribute excitatory activity over the network as noise sources to optimally enhance the responses of individual neurons to input at sparse-strong connections, thus opening multiple signal transmission pathways. Electrophysiological experiments confirm the importance of a highly broad connectivity spectrum supported by the model. Our results identify a simple network mechanism for internal noise generation by highly inhomogeneous connection strengths supporting both stability and optimal communication.},
author = {Teramae, J N and Tsubo, Y and Fukai, T},
doi = {10.1038/srep00485},
issn = {2045-2322},
journal = {Scientific reports},
pages = {485},
pmid = {22761993},
title = {{Optimal spike-based communication in excitable networks with strong-sparse and weak-dense links.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3387577{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2},
year = {2012}
}
@article{196076,
address = {Philadelphia, PA, USA},
author = {Gu, M and Eisenstat, S},
doi = {http://dx.doi.org/10.1137/S089547989223924X},
issn = {0895-4798},
journal = {SIAM J. Matrix Anal. Appl.},
number = {4},
pages = {1266--1276},
publisher = {Society for Industrial and Applied Mathematics},
title = {{A Stable and Efficient Algorithm for the Rank-One Modification of the Symmetric Eigenproblem}},
volume = {15},
year = {1994}
}
@article{Starkman|1990|,
abstract = {We discuss the possibility that the dark matter consists of strongly
interacting massive particles (SIMP's) which have cross sections
with ordinary matter which are larger than characteristic weak-interaction
cross sections. We show that, while results from beta-beta decay,
cosmic-ray detectors, galactic-halo stability, the cooling of molecular
clouds, proton-decay detectors, and the existence of old neutron
stars and the Earth constain the interactions of the missing matter
with ordinary matter over a broad range of parameter space, there
still exist several windows for SIMP's. It is noteworthy that there
are two regions of less than geometric cross sections: one with masses
10{\^{}}5-10{\^{}}7 GeV and another with masses above 10{\^{}}10 GeV.},
annote = {This important paper discusses exclusion ranges on interacting dark{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}matter parameters.},
author = {Starkman, G D and Gould, A and Esmailazedeh, R and Dimopoulos, S},
journal = {Physical Review D},
keywords = {astrophysics,cross-section,dark matter,experimental,interaction,mass,physics,strongly interacting dark matter},
number = {12},
pages = {3594},
title = {{Opening the window on stronglt interacting dark matter}},
volume = {41}
}
@article{WiegrebeMeddis04,
author = {Wiegrebe, Lutz and Meddis, Ray},
journal = {Journal of The Acoustical Society Of America},
month = {mar},
number = {3},
pages = {1207--1218},
title = {{The representation of periodic sounds in simulated sustained chopper units of the ventral cochlear nucleus}},
volume = {115},
year = {2004}
}
@article{Gulrajani2017,
abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes significant progress toward stable training of GANs, but can still generate low-quality samples or fail to converge in some settings. We find that these training failures are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to pathological behavior. We propose an alternative method for enforcing the Lipschitz constraint: instead of clipping weights, penalize the norm of the gradient of the critic with respect to its input. Our proposed method converges faster and generates higher-quality samples than WGAN with weight clipping. Finally, our method enables very stable GAN training: for the first time, we can train a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data.},
archivePrefix = {arXiv},
arxivId = {1704.00028},
author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
eprint = {1704.00028},
pages = {1--19},
title = {{Improved Training of Wasserstein GANs}},
url = {http://arxiv.org/abs/1704.00028},
year = {2017}
}
@article{Ehrenstein1966,
author = {Ehrenstein, G},
doi = {10.1016/S0006-3495(66)86677-8},
issn = {00063495},
journal = {Biophysical Journal},
number = {5},
pages = {553--566},
publisher = {Elsevier},
title = {{Slow Changes of Potassium Permeability in the Squid Giant Axon}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349566866778},
volume = {6},
year = {1966}
}
@article{Chaudhari2017,
abstract = {We propose a new algorithm called Parle for parallel training of deep networks that converges 2-4x faster than a data-parallel implementation of SGD, while achieving significantly improved error rates that are nearly state-of-the-art on several benchmarks including CIFAR-10 and CIFAR-100, without introducing any additional hyper-parameters. We exploit the phenomenon of flat minima that has been shown to lead to improved generalization error for deep networks. Parle requires very infrequent communication with the parameter server and instead performs more computation on each client, which makes it well-suited to both single-machine, multi-GPU settings and distributed implementations.},
archivePrefix = {arXiv},
arxivId = {1707.00424},
author = {Chaudhari, Pratik and Baldassi, Carlo and Zecchina, Riccardo and Soatto, Stefano and Talwalkar, Ameet},
eprint = {1707.00424},
keywords = {deep neural networks,local entropy,non-convex optimization,parallelization of sgd,robust ensembles},
number = {2},
pages = {1--12},
title = {{Parle: parallelizing stochastic gradient descent}},
url = {http://arxiv.org/abs/1707.00424},
year = {2017}
}
@article{ReissYoung05,
author = {Reiss, Lina A J and Young, Eric D},
journal = {Journal of Neuroscience},
month = {apr},
number = {14},
pages = {3680--3691},
title = {{Spectral edge sensitivity in neural circuits of the dorsal cochlear nucleus}},
volume = {25},
year = {2005}
}
@article{Sohn|2006|,
abstract = {The contour tree has been used to compute the topology of isosurfaces,
generate a minimal seed set for accelerated isosurface extraction,
and provide a user interface to segment individual contour components
in a scalar field. In this paper, we extend the benefits of the contour
tree to time-varying data visualization. We define temporal correspondence
of contour components, and describe an algorithm to compute the correspondence
information in time dependent contour trees. A graph representing
the topology changes of time-varying isosurfaces is constructed in
real-time for any selected isovalue using the precomputed correspondence
information. Quantitative properties such as surface area and volume
of contour components are computed and labelled on the graph. This
topology change graph helps users to detect significant topological
and geometric changes in time-varying isosurfaces. The graph is also
used as an interactive user interface to segment, track and visualize
the evolution of any selected contour components over time.},
annote = {In this paper the authors propose a method for tracking set of contours{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}via contours overlap followed by a search in the adjucency matrix{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}(herein called contour tree).},
author = {Sohn, B.-S. and Bajaj, C},
keywords = {computational,contour tracking,contour tree,feature tracking,image processing,level set topology,time-varying volume visualization},
title = {{Time-varying contour topology}}
}
@article{Faisal2007,
abstract = {It is generally assumed that axons use action potentials (APs) to transmit information fast and reliably to synapses. Yet, the reliability of transmission along fibers below 0.5 microm diameter, such as cortical and cerebellar axons, is unknown. Using detailed models of rodent cortical and squid axons and stochastic simulations, we show how conduction along such thin axons is affected by the probabilistic nature of voltage-gated ion channels (channel noise). We identify four distinct effects that corrupt propagating spike trains in thin axons: spikes were added, deleted, jittered, or split into groups depending upon the temporal pattern of spikes. Additional APs may appear spontaneously; however, APs in general seldom fail ({\textless}1{\%}). Spike timing is jittered on the order of milliseconds over distances of millimeters, as conduction velocity fluctuates in two ways. First, variability in the number of Na channels opening in the early rising phase of the AP cause propagation speed to fluctuate gradually. Second, a novel mode of AP propagation (stochastic microsaltatory conduction), where the AP leaps ahead toward spontaneously formed clusters of open Na channels, produces random discrete jumps in spike time reliability. The combined effect of these two mechanisms depends on the pattern of spikes. Our results show that axonal variability is a general problem and should be taken into account when considering both neural coding and the reliability of synaptic transmission in densely connected cortical networks, where small synapses are typically innervated by thin axons. In contrast we find that thicker axons above 0.5 microm diameter are reliable.},
annote = {2010IIInum27},
author = {Faisal, A A and Laughlin, S B},
doi = {10.1371/journal.pcbi.0030079},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Axons: ultrastructure,Computer Simulation,Data Interpretation,Decapodiformes,Ion Channel Gating,Ion Channel Gating: physiology,Membrane Potentials,Membrane Potentials: physiology,Mice,Models,Neural Conduction,Neural Conduction: physiology,Neurological,Rats,Statistical,Stochastic Processes},
month = {may},
number = {5},
pages = {e79},
pmid = {17480115},
title = {{Stochastic simulations on the reliability of action potential propagation in thin axons.}},
volume = {3},
year = {2007}
}
@article{Yarrow2009,
abstract = {Events like the World Championships in athletics and the Olympic Games raise the public profile of competitive sports. They may also leave us wondering what sets the competitors in these events apart from those of us who simply watch. Here we attempt to link neural and cognitive processes that have been found to be important for elite performance with computational and physiological theories inspired by much simpler laboratory tasks. In this way we hope to inspire neuroscientists to consider how their basic research might help to explain sporting skill at the highest levels of performance.},
annote = {2010IIInum68},
author = {Yarrow, Kielan and Brown, Peter and Krakauer, John W},
doi = {10.1038/nrn2672},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
keywords = {Achievement,Brain,Brain: physiology,Cognition,Competitive Behavior,Competitive Behavior: physiology,Humans,Learning,Learning: physiology,Models, Biological,Motor Skills,Motor Skills: physiology,Sports,Sports: physiology,Sports: psychology},
month = {aug},
number = {8},
pages = {585--96},
pmid = {19571792},
publisher = {Nature Publishing Group},
title = {{Inside the brain of an elite athlete: the neural processes that support high achievement in sports.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19571792},
volume = {10},
year = {2009}
}
@article{BAIR97,
author = {Bair, W and Cavanaugh, J and Movshon, J},
journal = {NIPS},
pages = {34--40},
title = {{Reconstructing stimulus velocity from neuronal responses in area MT}},
volume = {9},
year = {1997}
}
@article{Histed2009,
abstract = {For over a century, electrical microstimulation has been the most direct method for causally linking brain function with behavior. Despite this long history, it is still unclear how the activity of neural populations is affected by stimulation. For example, there is still no consensus on where activated cells lie or on the extent to which neural processes such as passing axons near the electrode are also activated. Past studies of this question have proven difficult because microstimulation interferes with electrophysiological recordings, which in any case provide only coarse information about the location of activated cells. We used two-photon calcium imaging, an optical method, to circumvent these hurdles. We found that microstimulation sparsely activates neurons around the electrode, sometimes as far as millimeters away, even at low currents. Our results indicate that the pattern of activated neurons likely arises from the direct activation of axons in a volume tens of microns in diameter.},
annote = {2009num56},
author = {Histed, Mark H and Bonin, Vincent and Reid, R Clay},
doi = {10.1016/j.neuron.2009.07.016},
issn = {1097-4199},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cats,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Cerebral Cortex: ultrastructure,Electric Stimulation,Electric Stimulation: instrumentation,Electric Stimulation: methods,Inbred C57BL,Long-Evans,Memory,Memory: physiology,Mice,Microelectrodes,Neurons,Neurons: physiology,Neurons: ultrastructure,Rats},
month = {aug},
number = {4},
pages = {508--22},
pmid = {19709632},
publisher = {Elsevier Ltd},
title = {{Direct activation of sparse, distributed populations of cortical neurons by electrical microstimulation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19709632 http://dx.doi.org/10.1016/j.neuron.2009.07.016},
volume = {63},
year = {2009}
}
@article{Bartlett1998,
abstract = {Sample complexity results from computational learning theory, when applied to neural network learning for pattern classification problems, suggest that for good generalization performance the number of training examples should grow at least linearly with the number of adjustable parameters in the network. Results in this paper show that if a large neural network is used for a pattern classification problem and the learning algorithm finds a network with small weights that has small squared error on the training patterns, then the generalization performance depends on the size of the weights rather than the number of weights. For example, consider a two-layer feedforward network of sigmoid units, in which the sum of the magnitudes of the weights associated with each unit is bounded by A and the input dimension is n. We show that the misclassification probability is no more than a certain error estimate (that is related to squared error on the training set) plus A3 {\&}radic;((log n)/m) (ignoring log A and log m factors), where m is the number of training patterns. This may explain the generalization performance of neural networks, particularly when the number of training examples is considerably smaller than the number of weights. It also supports heuristics (such as weight decay and early stopping) that attempt to keep the weights small during training. The proof techniques appear to be useful for the analysis of other pattern classifiers: when the input domain is a totally bounded metric space, we use the same approach to give upper bounds on misclassification probability for classifiers with decision boundaries that are far from the training examples},
author = {Bartlett, Peter L.},
doi = {10.1109/18.661502},
isbn = {0018-9448},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Computational learning theory,Neural networks,Pattern recognition,Scale-sensitive dimensions,Weight decay},
number = {2},
pages = {525--536},
pmid = {233721207},
title = {{The sample complexity of pattern classification with neural networks: The size of the weights is more important than the size of the network}},
volume = {44},
year = {1998}
}
@article{Koopman93,
author = {Koopman, S},
journal = {Biometrika},
number = {1},
pages = {117--126},
title = {{Disturbance smoother for state space models}},
volume = {80},
year = {1993}
}
@article{Mishchenko2015a,
author = {Mishchenko, Y},
keywords = {calcium imaging,circuit reconstruction,functional connectivity,neuronal,neuronal population activity},
number = {324},
title = {{Consistent estimation of complete neuronal connectivity in large neuronal populations using sparse “ shotgun ” neuronal activity sampling}},
volume = {90},
year = {2015}
}
@article{Usher1995,
author = {Usher, M and Stemmler, M and Olami, Z},
journal = {Physical Review Letters},
title = {{Dynamic pattern formation leads to 1/f noise in neural populations}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.74.326},
year = {1995}
}
@article{Gray1990,
author = {Gray, R.M.},
doi = {10.1109/18.59924},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
number = {6},
pages = {1220--1244},
title = {{Quantization noise spectra}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=59924},
volume = {36},
year = {1990}
}
@article{Saad1990,
author = {Saad, D and Marom, E},
journal = {Complex Systems},
pages = {573--586},
title = {{Training Feed Forward Nets with Binary Weights Via a Modified CHIR Algorithm}},
url = {https://www.complex-systems.com/pdf/04-5-5.pdf},
volume = {4},
year = {1990}
}
@article{Meyer2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1004.3616v1},
author = {Meyer, Christian},
eprint = {arXiv:1004.3616v1},
journal = {arXiv preprint arXiv:1004.3616},
pages = {1--12},
title = {{Recursive Numerical Evaluation of the Cumulative Bivariate Normal Distribution}},
url = {http://arxiv.org/abs/1004.3616},
year = {2010}
}
@article{Schwarz1987,
author = {Schwarz, J.R. R and Eikhof, Gesa},
issn = {0031-6768},
journal = {Pfl$\backslash$$\backslash$"ugers Archiv European Journal of Physiology},
keywords = {action potential - body,current -,node of ranvier -,rat nerve - na,temperature - temperature},
number = {6},
pages = {569--577},
publisher = {Springer},
title = {{Na currents and action potentials in rat myelinated nerve fibres at 20 and 37 C}},
url = {http://www.springerlink.com/index/M50J760U66H82860.pdf},
volume = {409},
year = {1987}
}
@article{Johansson2004,
abstract = {It is generally assumed that primary sensory neurons transmit information by their firing rates. However, during natural object manipulations, tactile information from the fingertips is used faster than can be readily explained by rate codes. Here we show that the relative timing of the first impulses elicited in individual units of ensembles of afferents reliably conveys information about the direction of fingertip force and the shape of the surface contacting the fingertip. The sequence in which different afferents initially discharge in response to mechanical fingertip events provides information about these events faster than the fastest possible rate code and fast enough to account for the use of tactile signals in natural manipulation.},
annote = {2010IIInum59},
author = {Johansson, Roland S and Birznieks, Ingvars},
doi = {10.1038/nn1177},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adult,Afferent Pathways,Afferent Pathways: physiology,Female,Fingers,Fingers: physiology,Form Perception,Form Perception: physiology,Humans,Male,Mechanoreceptors,Mechanoreceptors: physiology,Physical Stimulation,Skin,Skin: innervation,Spike time neural coding,Touch,Touch: physiology},
mendeley-tags = {Spike time neural coding},
month = {mar},
number = {2},
pages = {170--7},
pmid = {14730306},
title = {{First spikes in ensembles of human tactile afferents code complex spatial fingertip events.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14730306},
volume = {7},
year = {2004}
}
@article{PR01,
author = {{Prakasa Rao}, B L S},
journal = {TEST},
pages = {105--120},
title = {{Cramer-Rao type integral inequalities for general loss functions}},
volume = {10},
year = {2001}
}
@article{PTSR99,
author = {{Panzeri S. Treves}, A and Schultz, S and Rolls, E},
journal = {Neural Computation},
pages = {1553--1577},
title = {{On decoding the responses of a population of neurons from short time windows}},
volume = {11},
year = {1999}
}
@article{Lowen1993a,
annote = {{\textless}m:note{\textgreater}2010num2.3{\textless}m:bold{\textgreater}          {\textless}m:linebreak/{\textgreater}        {\textless}/m:bold{\textgreater}        {\textless}m:linebreak/{\textgreater}        {\textless}m:linebreak/{\textgreater}        {\textless}m:linebreak/{\textgreater}      {\textless}/m:note{\textgreater}},
author = {Lowen, S B and Teich, M C},
journal = {Physical Review E},
number = {2},
pages = {992--1001},
publisher = {APS},
title = {{Fractal renewal processes generate 1/f noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.47.992 http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Fractal+renewal+processes+generate{\#}6},
volume = {47},
year = {1993}
}
@article{Kohn2014,
author = {Kohn, Robert and Ansley, Craig F},
keywords = {diffuse initial conditions,kalman filter,maximum likelihood,smoothing,state space},
number = {395},
pages = {751--761},
title = {{Estimation , Interpolation for ARIMA Models With Missing Data}},
volume = {81},
year = {2014}
}
@article{NevianHelmchen07,
abstract = {Studies of subcellular {\{}Ca{\}}{\^{}}{\{}2+{\}} signaling rely on methods for labeling

cells with fluorescent {\{}Ca{\}}{\^{}}{\{}2+{\}} indicator dyes. In this study,

we demonstrate the use of single-cell electroporation for {\{}Ca{\}}{\^{}}{\{}2+{\}}

indicator loading of individual neurons and small neuronal networks

in rat neocortex in vitro and in vivo. Brief voltage pulses were

delivered through glass pipettes positioned close to target cells.

This approach resulted in reliable and rapid (within seconds) loading

of somata and subsequent complete labeling of dendritic and axonal

arborizations. By using simultaneous whole-cell recordings in brain

slices, we directly addressed the effect of electroporation on neurons.

Cell viability was high (about 85{\%}) with recovery from the membrane

permeabilization occurring within a minute. Electrical properties

of recovered cells were indistinguishable before and after electroporation.

In addition, {\{}Ca{\}}{\^{}}{\{}2+{\}} transients with normal appearance could

be evoked in dendrites, spines, and axonal boutons of electroporated

cells. Using negative-stains of somata, targeted single-cell electroporation

was equally applicable in vivo. We conclude that electroporation

is a simple approach that permits {\{}Ca{\}}{\^{}}{\{}2+{\}} indicator loading of

multiple cells with low background staining within a short amount

of time, which makes it especially well suited for functional imaging

of subcellular {\{}Ca{\}}{\^{}}{\{}2+{\}} dynamics in small neuronal networks.},
author = {Nevian, Thomas and Helmchen, Fritjof},
doi = {10.1007/s00424-007-0234-2},
journal = {Pflugers Arch},
keywords = {Animals; Brain; Calcium; Cell Survival; Electropor,Wistar; Synaptic Transmission},
month = {jul},
number = {4},
pages = {675--688},
pmid = {17334778},
title = {{Calcium indicator loading of neurons using single-cell electroporation.}},
url = {http://dx.doi.org/10.1007/s00424-007-0234-2},
volume = {454},
year = {2007}
}
@article{Nykamp2007a,
author = {Nykamp, D Q},
journal = {SIAM Journal on Applied Mathematics},
keywords = {auto-,causality,correlations,maximum likelihood,neural networks,point process},
number = {2},
pages = {354--391},
title = {{Exploiting history-dependent effects to infer network connectivity}},
url = {http://epubs.siam.org/doi/abs/10.1137/070683350},
volume = {68},
year = {2007}
}
@article{Field2010,
abstract = {To understand a neural circuit requires knowledge of its connectivity. Here we report measurements of functional connectivity between the input and ouput layers of the macaque retina at single-cell resolution and the implications of these for colour vision. Multi-electrode technology was used to record simultaneously from complete populations of the retinal ganglion cell types (midget, parasol and small bistratified) that transmit high-resolution visual signals to the brain. Fine-grained visual stimulation was used to identify the location, type and strength of the functional input of each cone photoreceptor to each ganglion cell. The populations of ON and OFF midget and parasol cells each sampled the complete population of long- and middle-wavelength-sensitive cones. However, only OFF midget cells frequently received strong input from short-wavelength-sensitive cones. ON and OFF midget cells showed a small non-random tendency to selectively sample from either long- or middle-wavelength-sensitive cones to a degree not explained by clumping in the cone mosaic. These measurements reveal computations in a neural circuit at the elementary resolution of individual neurons.},
annote = {2011num41},
author = {Field, Greg D and Gauthier, Jeffrey L and Sher, Alexander and Greschner, Martin and Machado, Timothy a and Jepson, Lauren H and Shlens, Jonathon and Gunning, Deborah E and Mathieson, Keith and Dabrowski, Wladyslaw and Paninski, L and Litke, Alan M and Chichilnisky, E J},
doi = {10.1038/nature09424},
issn = {1476-4687},
journal = {Nature},
keywords = {Animals,Color,Color Perception,Color Perception: physiology,Color Vision,Color Vision: physiology,Light,Macaca,Macaca fascicularis,Macaca fascicularis: physiology,Macaca mulatta,Macaca mulatta: physiology,Macaca: physiology,Models,Neural Pathways,Neural Pathways: physiology,Neurological,Photic Stimulation,Retinal Cone Photoreceptor Cells,Retinal Cone Photoreceptor Cells: cytology,Retinal Cone Photoreceptor Cells: physiology,Retinal Ganglion Cells,Retinal Ganglion Cells: cytology,Retinal Ganglion Cells: physiology},
month = {oct},
number = {7316},
pages = {673--7},
pmid = {20930838},
title = {{Functional connectivity in the retina at the resolution of photoreceptors.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2953734{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {467},
year = {2010}
}
@article{Pan10,
abstract = {Optimal filtering of noisy voltage signals on dendritic trees is a key problem in computational cellular neuroscience. However, the state variable in this problem-the vector of voltages at every compartment-is very high-dimensional: realistic multicompartmental models often have on the order of N = 10(4) compartments. Standard implementations of the Kalman filter require O(N (3)) time and O(N (2)) space, and are therefore impractical. Here we take advantage of three special features of the dendritic filtering problem to construct an efficient filter: (1) dendritic dynamics are governed by a cable equation on a tree, which may be solved using sparse matrix methods in O(N) time; and current methods for observing dendritic voltage (2) provide low SNR observations and (3) only image a relatively small number of compartments at a time. The idea is to approximate the Kalman equations in terms of a low-rank perturbation of the steady-state (zero-SNR) solution, which may be obtained in O(N) time using methods that exploit the sparse tree structure of dendritic dynamics. The resulting methods give a very good approximation to the exact Kalman solution, but only require O(N) time and space. We illustrate the method with applications to real and simulated dendritic branching structures, and describe how to extend the techniques to incorporate spatially subsampled, temporally filtered, and nonlinearly transformed observations.},
author = {Paninski, L},
doi = {10.1007/s10827-009-0200-4},
issn = {1573-6873},
journal = {Journal of Computational Neuroscience},
keywords = {Algorithms,Automated,Calcium Channels,Calcium Channels: physiology,Computer Simulation,Dendrites,Dendrites: physiology,Markov Chains,Models,Neurological,Neurons,Neurons: physiology,Pattern Recognition,Voltage-Sensitive Dye Imaging},
month = {apr},
number = {2},
pages = {211--228},
pmid = {19943188},
title = {{Fast {\{}K{\}}alman filtering on quasilinear dendritic trees}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19943188},
volume = {28},
year = {2010}
}
@incollection{Strukov,
author = {Strukov, D B and Likharev, K K},
booktitle = {Nanoelectronics and Information Technology},
editor = {Waser, Rainer},
pages = {543--562},
publisher = {Wiley},
title = {{Reconfigurable nano-crossbar architectures}},
url = {http://rsfq1.physics.sunysb.edu/{~}likharev/nano/Was11.pdf http://www.ece.ucsb.edu/{~}strukov/papers/2012/Was2012.pdf},
year = {2012}
}
@article{POUZAT04,
author = {Pouzat, C and Delescluse, M and Viot, P and Diebolt, J},
journal = {Journal of Neurophysiology},
pages = {2910--2928},
title = {{Improved Spike-Sorting By Modeling Firing Statistics and Burst-Dependent Spike Amplitude Attenuation: A {\{}M{\}}arkov Chain {\{}M{\}}onte {\{}C{\}}arlo Approach}},
volume = {91},
year = {2004}
}
@article{BruceYoung03,
author = {Bruce, Ian C and Sachs, Murray B and Young, Eric D},
journal = {Journal of The Acoustical Society Of America},
month = {jan},
number = {1},
pages = {369--388},
title = {{An auditory-periphery model of the effects of acoustic trauma on auditory nerve responses}},
volume = {113},
year = {2003}
}
@phdthesis{KLI98,
author = {Klinger, A},
school = {University of Munich},
title = {{High-dimensional generalized linear models}},
year = {1998}
}
@article{Maaten2009,
author = {der Maaten, LJP Van},
journal = {Journal of Machine {\ldots}},
keywords = {dimensionality reduction,feature extraction,manifold learning},
number = {January},
title = {{Dimensionality reduction: A comparative review}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.125.6716{\&}rep=rep1{\&}type=pdf},
year = {2009}
}
@article{Sannuti1980,
author = {Sannuti, P and Puri, N N},
journal = {Circuits and Systems, IEEE Transactions},
title = {{Symbolic network analysis-an algebraic formulation}},
url = {http://cat.inist.fr/?aModele=afficheN{\&}cpsidt=4974659 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1084881},
year = {1980}
}
@article{Kaltenbach05_review,
author = {Kaltenbach, James A and Zhang, Jinsheng and Finlayson, Paul},
journal = {Hearing Research},
month = {aug},
number = {1-2},
pages = {200--226},
title = {{Tinnitus as a plastic phenomenon and its possible neural underpinnings in the dorsal cochlear nucleus}},
volume = {206},
year = {2005}
}
@article{Yasuda2004,
abstract = {Calcium and its regulation play central roles diverse physiologic

processes. Quantification of calcium concentrations ([{\{}Ca{\}}{\^{}}{\{}2+{\}}])

in small neuronal compartments is crucial to understanding {\{}Ca{\}}{\^{}}{\{}2+{\}}-dependent

signaling. Here, we describe techniques that are optimized for 2-photon

imaging of [{\{}Ca{\}}{\^{}}{\{}2+{\}}] dynamics in small compartments such as dendrites

and dendritic spines.},
author = {Yasuda, Ryohei and Nimchinsky, Esther A and Scheuss, Volker and Pologruto, Thomas A and Oertner, Thomas G and Sabatini, Bernardo L and Svoboda, Karel},
doi = {10.1126/stke.2192004pl5},
journal = {Sci STKE},
keywords = {Animals,Calcium Signaling,Cell Compartmentation,Computer-Assisted,Fluorescence,Lasers,Microscopy,Multiphoton,Neurons,Patch-Clamp Techniques,Rat},
month = {feb},
number = {219},
pages = {pl5},
pmid = {14872098},
title = {{Imaging calcium concentration dynamics in small neuronal compartments.}},
url = {http://dx.doi.org/10.1126/stke.2192004pl5},
volume = {2004},
year = {2004}
}
@article{Kubitscheck|2000|,
author = {Kubitscheck, U and K{\~{A}}¼ckmann, O and Kues, T and Peters, R},
journal = {Biophys. J.},
pages = {2170},
title = {{Imaging and tracking of single GFP molecules in solution.}},
volume = {78}
}
@article{BC06,
author = {Brincat, S and Connor, C},
journal = {Neuron},
pages = {17--24},
title = {{Dynamic Shape Synthesis in Posterior Interferotemporal Cortex}},
volume = {49},
year = {2006}
}
@article{BarHillel06,
author = {Bar-Hillel, A and Spiro, A and Stark, E},
journal = {Journal of Neuroscience Methods},
pages = {303--316},
title = {{Spike sorting: {\{}B{\}}ayesian clustering of non-stationary data}},
volume = {157},
year = {2006}
}
@article{Netzer2011,
author = {Netzer, Yuval and Wang, Tao},
journal = {{\ldots} Feature Learning},
pages = {1--9},
title = {{Reading digits in natural images with unsupervised feature learning}},
url = {http://research.google.com/pubs/archive/37648.pdf},
year = {2011}
}
@article{Mickus1999,
annote = {2009num11},
author = {Mickus, T},
doi = {10.1016/S0006-3495(99)77248-6},
issn = {00063495},
journal = {Biophysical Journal},
keywords = {slow sodium inactivation},
mendeley-tags = {slow sodium inactivation},
number = {2},
pages = {846--860},
publisher = {Elsevier},
title = {{Properties of Slow, Cumulative Sodium Channel Inactivation in Rat Hippocampal CA1 Pyramidal Neurons}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349599772486},
volume = {76},
year = {1999}
}
@article{Barmpoutis2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1108.2538v1},
author = {Barmpoutis, Dionysios and Murray, Richard M},
eprint = {arXiv:1108.2538v1},
journal = {arxiv},
title = {{Noise Propagation in Biological and Chemical Reaction Networks}},
year = {2011}
}
@article{Swanson|1977|,
author = {Swanson, L M and Cowan, W M},
journal = {J Comp Neurol},
pages = {49--84},
title = {{An autoradiographic study of the organization of the efferet connections}},
volume = {172}
}
@book{McLachlan2007,
author = {McLachlan, G and Krishnan, T},
file = {::},
publisher = {Wiley-Interscience},
title = {{The EM algorithm and extensions}},
year = {2007}
}
@article{KanoldYoung01,
author = {Kanold, P O and Young, E D},
journal = {Journal of Neuroscience},
month = {oct},
number = {19},
pages = {7848--7858},
title = {{Proprioceptive information from the pinna provides somatosensory input to cat dorsal cochlear nucleus}},
volume = {21},
year = {2001}
}
@article{Saad1998,
author = {Saad, D and Rattray, M},
journal = {On-line learning in neural networks},
title = {{Optimal on-line learning in multilayer neural networks}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=iu2v6C5nx4oC{\&}oi=fnd{\&}pg=PA135{\&}dq=optimal+online+learning+in+multilayer+neural+networks{\&}ots=oxLfQHhSO4{\&}sig=hXRJ1WZBnL{\_}AfJOU6J9Y3RLATYA},
year = {1998}
}
@article{Connors1990,
author = {Connors, B.W. and Gutnick, M.J.},
issn = {0166-2236},
journal = {Trends in Neurosciences},
number = {3},
pages = {99--104},
publisher = {Elsevier},
title = {{Intrinsic firing patterns of diverse neocortical neurons}},
url = {http://linkinghub.elsevier.com/retrieve/pii/016622369090185D},
volume = {13},
year = {1990}
}
@article{NagayamaChen07,
abstract = {A central question about the brain is how information is processed

by large populations of neurons embedded in intricate local networks.

Answering this question requires not only monitoring functional dynamics

of many neurons simultaneously, but also interpreting such activity

patterns in the context of neuronal circuitry. Here, we introduce

a versatile approach for loading {\{}Ca{\}}{\^{}}{\{}2+{\}} indicators in vivo by

local electroporation. With this method, {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging can

be performed both at neuron population level and with exquisite subcellular

resolution down to dendritic spines and axon boutons. This enabled

mitral cell odor-evoked ensemble activity to be analyzed simultaneously

with revealing their specific connectivity to different glomeruli.

Colabeling of Purkinje cell dendrites and intersecting parallel fibers

allowed {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging of both presynaptic boutons and postsynaptic

dendrites. This approach thus provides an unprecedented capability

for in vivo visualizing active cell ensembles and tracing their underlying

local neuronal circuits.},
author = {Nagayama, Shin and Zeng, Shaoqun and Xiong, Wenhui and Fletcher, Max L and Masurkar, Arjun V and Davis, Douglas J and Pieribone, Vincent A and Chen, Wei R},
doi = {10.1016/j.neuron.2007.02.018},
journal = {Neuron},
keywords = {Afferent Pathways; Animals; Brain; Calcium; Dendri},
month = {mar},
number = {6},
pages = {789--803},
pmid = {17359915},
title = {{In vivo simultaneous tracing and {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging of local neuronal circuits.}},
url = {http://dx.doi.org/10.1016/j.neuron.2007.02.018},
volume = {53},
year = {2007}
}
@article{BaldiP&Hornik1998,
abstract = {autoencoder; linearNN},
author = {{Baldi, P {\&} Hornik}, K},
journal = {Neural Networks},
keywords = {-neural networks,back propagation,learning,principal component analysis},
number = {10},
pages = {53--58},
title = {{Neural networks and principal component analysis: Learning from examples without local minima}},
volume = {2},
year = {1989}
}
@article{White1986,
author = {White, J G and Southgate, E and Thomson, J N and Brenner, S},
journal = {Philos. Trans. R. Soc. B},
pages = {1--340},
title = {{The structure of the nervous system of the nematode Caenorhabditis elegans}},
url = {http://rstb.royalsocietypublishing.org/content/314/1165/1.short},
volume = {314},
year = {1986}
}
@article{Stepanyants|2005|,
abstract = {The advent of high-quality 3D reconstructions of neuronal arbors has
revived the hope of inferring synaptic connectivity from the geometric
shapes of axons and dendrites, or {\"{i}}¾‘neurogeometry{\"{i}}¾'. A quantitative
description of connectivity must be built on a sound theoretical
framework. Here, we review recent developments in neurogeometry that
can provide such a framework. We base the geometric description of
connectivity on the concept of a {\"{i}}¾‘potential synapse{\"{i}}¾' {\^{A}}– the close
apposition between axons and dendrites necessary to form an actual
synapse. In addition to describing potential synaptic connectivity
in neuronal circuits, neurogeometry provides insight into basic features
of functional connectivity, such as specificity and plasticity.},
author = {Stepanyants, A and Chklovskii, D B},
journal = {TRENDS in Neuroscience},
keywords = {connectivity,cortical cirtuits,neurobiology,neurogeometry,optimization,plasticity,potential connectivity,synapse},
number = {7},
pages = {387},
title = {{Neurogeometry and potential synaptic connectivity}},
volume = {28}
}
@book{BOG98,
address = {New York},
author = {Bogachev, V},
publisher = {AMS},
title = {{Gaussian Measures}},
year = {1998}
}
@article{Treebushny05,
author = {Treebushny, Dimitri and Madsen, Henrik},
journal = {Future Gener. Comput. Syst.},
pages = {1047--1055},
title = {{On the construction of a reduced rank square-root {\{}K{\}}alman filter for efficient uncertainty propagation}},
volume = {21},
year = {2005}
}
@article{Chklovskii2012,
abstract = {We test the hypothesis that the neuronal spike generation mechanism is an analog-to-digital (AD) converter encoding rectified low-pass filtered summed synaptic currents into a spike train linearly decodable in post-synaptic neurons. Faithful encoding of an analog waveform by a binary signal requires that the spike generation mechanism has a sampling rate exceeding the Nyquist rate of the analog signal. Such oversampling is consistent with the experimental observation that the precision of the spike-generation mechanism is an order of magnitude greater than the cut-off frequency of low-pass filtering in dendrites. Additional improvement in the coding accuracy may be achieved by noise-shaping, a technique used in signal processing. If noise-shaping were used in neurons, it would reduce coding error relative to Poisson spike generator for frequencies below Nyquist by introducing correlations into spike times. By using experimental data from three different classes of neurons, we demonstrate that biological neurons utilize noise-shaping. Therefore, spike-generation mechanism can be viewed as an oversampling and noise-shaping AD converter.},
author = {Chklovskii, D.B. B and Soudry, D.},
isbn = {9781627480031},
issn = {10495258},
journal = {NIPS},
title = {{Neuronal spike generation mechanism as an oversampling, noise-shaping A-to-D converter}},
volume = {1},
year = {2012}
}
@article{Ceperley|1981|,
abstract = {We have carried out computer simulations of the statics and dynamics
of an isolated model polymer chain with excluded volume in a solvent
acting as a heat bath. We find that the distribution function for
the separation of a pair of beads scales as the number of beads N
to the power Y and that edge effects are small. The dynamical correlation
functions, such as that of the end-to-end vector, scale as Wy+{\"{i}}¾'
with Y N 0.6. The results of a dynamical lattice polymer model are
shown to be consistent with the present results if one adjusts the
time scales in such a way that the center of mass diffuses at the
same rate in the two models. The relaxation of the stress tensor
is shown to be quite similar to that of the Rouse model. Finally,
it is shown that edge effects are much more pronounced in the diffusive
motion of the individual beads, there being a skin comprising about
30{\%} of the total polymer, where bead motion is relatively quicker.},
author = {Ceperley, D and Kalos, M H and Lebowitz, J L},
journal = {Macromolecules},
keywords = {physics,polymer,quantum monte carlo},
pages = {1472},
title = {{Computer simulation of the static and dynamic properties of a polymer chain}},
volume = {14}
}
@article{Ahmadian2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1202.6670v2},
author = {Ahmadian, Yashar and Rubin, Daniel B and Miller, Kenneth D},
eprint = {arXiv:1202.6670v2},
title = {{Analysis of the stabilized supralinear network}},
year = {2012}
}
@article{Bengio2009a,
author = {Bengio, Y},
doi = {10.1561/2200000006},
isbn = {2200000006},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
keywords = {Deep Learning},
mendeley-tags = {Deep Learning},
number = {1},
pages = {1--127},
title = {{Learning Deep Architectures for AI}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000006},
volume = {2},
year = {2009}
}
@article{CallawayRoss95,
abstract = {The interaction between the excitatory climbing fiber (CF) response

and stellate cell inhibition was studied in guinea pig Purkinje cells

in sagittal slices from the cerebellar vermis. Sharp microelectrode

recordings from the soma or dendrites were combined with high-speed

fluorescence imaging of intracellularly injected fura-2. In this

way both the electrical responses and the associated [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i

changes could be monitored at the same time. Usually simultaneously

activated inhibition caused almost no change to the somatically recorded

CF response. However, the inhibition caused a strong reduction in

the CF-associated [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i increase which normally was widespread

in the dendrites. This effect was graded; stronger inhibition caused

a larger and more widespread reduction in the [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i change

that was greatest in the more distal dendrites. Sometimes the reduction

was over 90{\%} in the distal dendrites and occasionally it was localized

to only a single dendritic branch. Both the inhibitory postsynaptic

potential (IPSP) and the associated reduction in the CF-induced [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i

change were blocked by bicuculline, a GABAA receptor antagonist.

Dendritic recordings showed that each CF response evoked a 2-3 msec

wide action potential. The amplitude of this action potential was

reduced in a graded manner by the IPSP in parallel with the reduction

in the [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i change. Varying the time between the activation

of the IPSP and the CF response showed that both the reduction in

the [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i change and the action potential amplitude occurred

in a narrow time window of about 8-10 msec, about the rise time of

the IPSP. Together these results indicate that the CF response activates

a fast dendritic {\{}Ca{\}}{\^{}}{\{}2+{\}} spike that causes most of the [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i

increase, both of which can be blocked by an inhibitory shunting

conductance. This interaction provides a means whereby {\{}Ca{\}}{\^{}}{\{}2+{\}}-dependent

dendritic mechanisms can be modulated without affecting the immediate

output of the Purkinje cell.},
author = {Callaway, J C and Lasser-Ross, N and Ross, W N},
journal = {J Neurosci},
keywords = {Action Potentials; Animals; Bicuculline; Calcium;},
month = {apr},
number = {4},
pages = {2777--2787},
pmid = {7722628},
title = {{IPSPs strongly inhibit climbing fiber-activated [Ca{\^{}}{\{}2+{\}}]{\_}i increases in the dendrites of cerebellar Purkinje neurons.}},
volume = {15},
year = {1995}
}
@article{Liebovitch1987,
annote = {2009num31},
author = {Liebovitch, L S and Fisch, Karin and Koniarek, JP},
journal = {Mathematical biosciences},
title = {{Ion channel kinetic: a model based on fractal scaling rather than multistate Markov}},
url = {http://cat.inist.fr/?aModele=afficheN{\&}cpsidt=8312313},
year = {1987}
}
@article{Tabareau2010,
abstract = {THE FUNCTIONAL ROLE OF SYNCHRONIZATION HAS ATTRACTED MUCH INTEREST AND DEBATE: in particular, synchronization may allow distant sites in the brain to communicate and cooperate with each other, and therefore may play a role in temporal binding, in attention or in sensory-motor integration mechanisms. In this article, we study another role for synchronization: the so-called "collective enhancement of precision". We argue, in a full nonlinear dynamical context, that synchronization may help protect interconnected neurons from the influence of random perturbations-intrinsic neuronal noise-which affect all neurons in the nervous system. More precisely, our main contribution is a mathematical proof that, under specific, quantified conditions, the impact of noise on individual interconnected systems and on their spatial mean can essentially be cancelled through synchronization. This property then allows reliable computations to be carried out even in the presence of significant noise (as experimentally found e.g., in retinal ganglion cells in primates). This in turn is key to obtaining meaningful downstream signals, whether in terms of precisely-timed interaction (temporal coding), population coding, or frequency coding. Similar concepts may be applicable to questions of noise and variability in systems biology.},
author = {Tabareau, Nicolas and Slotine, Jean-Jacques and Pham, Quang-Cuong},
doi = {10.1371/journal.pcbi.1000637},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Algorithms,Computer Simulation,Membrane Potentials,Models, Biological,Neurons,Neurons: physiology,Nonlinear Dynamics,Systems Biology,Systems Biology: methods,Time Factors},
month = {jan},
number = {1},
pages = {e1000637},
pmid = {20090826},
title = {{How synchronization protects from noise.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20090826},
volume = {6},
year = {2010}
}
@book{Rosen,
author = {Rosen, Robert},
title = {{Life Itself}}
}
@book{Butler2007,
abstract = {Modern statistical methods use complex, sophisticated models that can lead to intractable computations. Saddlepoint approximations can be the answer. Written from the user's point of view, this book explains in clear language how such approximate probability computations are made, taking readers from the very beginnings to current applications. The core material is presented in chapters 1-6 at an elementary mathematical level. Chapters 7-9 then give a highly readable account of higher-order asymptotic inference. Later chapters address areas where saddlepoint methods have had substantial impact: multivariate testing, stochastic systems and applied probability, bootstrap implementation in the transform domain, and Bayesian computation and inference. No previous background in the area is required. Data examples from real applications demonstrate the practical value of the methods. Ideal for graduate students and researchers in statistics, biostatistics, electrical engineering, econometrics, and applied mathematics, this is both an entry-level text and a valuable reference.},
author = {Butler, Ronald W.},
booktitle = {Saddlepoint Approximations with Applications},
doi = {10.1017/CBO9780511619083},
isbn = {9780511619083},
pages = {1--564},
title = {{Saddlepoint Approximations with Applications}},
url = {https://www.google.com/books?hl=en{\&}lr={\&}id=jvlWV2aIk{\_}AC{\&}oi=fnd{\&}pg=PA12{\&}dq=Saddlepoint+approximations+and+applications{\&}ots=8fhDGr5Wt7{\&}sig=W7Ayzy9M7n-5pVQ9PdP6IwT6Oo8 http://www.scopus.com/inward/record.url?eid=2-s2.0-84925105968{\&}partnerID=tZOtx3y1},
year = {2007}
}
@article{Goldman2009,
abstract = {Memory storage on short timescales is thought to be maintained by neuronal activity that persists after the remembered stimulus is removed. Although previous work suggested that positive feedback is necessary to maintain persistent activity, here it is demonstrated how neuronal responses can instead be maintained by a purely feedforward mechanism in which activity is passed sequentially through a chain of network states. This feedforward form of memory storage is shown to occur both in architecturally feedforward networks and in recurrent networks that nevertheless function in a feedforward manner. The networks can be tuned to be perfect integrators of their inputs or to reproduce the time-varying firing patterns observed during some working memory tasks but not easily reproduced by feedback-based attractor models. This work illustrates a mechanism for maintaining short-term memory in which both feedforward and feedback processes interact to govern network behavior.},
annote = {

2010IInum11.2},
author = {Goldman, Mark S},
doi = {10.1016/j.neuron.2008.12.012},
issn = {1097-4199},
journal = {Neuron},
keywords = {Algorithms,Electrophysiology,Feedback,Linear Models,Memory,Memory: physiology,Models,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Psychological,Psychological: physiology,Short-Term,Short-Term: physiology,Statistical},
month = {feb},
number = {4},
pages = {621--34},
pmid = {19249281},
publisher = {Elsevier Ltd},
title = {{Memory without feedback in a neural network.}},
url = {http://dx.doi.org/10.1016/j.neuron.2008.12.012 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2674525{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pubmed/19249281},
volume = {61},
year = {2009}
}
@article{Vandenberg1991,
annote = {2010num3.6},
author = {Vandenberg, C. A.},
doi = {10.1016/S0006-3495(91)82186-5},
issn = {00063495},
journal = {Biophysical Journal},
number = {6},
pages = {1511--1533},
publisher = {Elsevier},
title = {{A sodium channel gating model based on single channel, macroscopic ionic, and gating currents in the squid giant axon}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349591821865},
volume = {60},
year = {1991}
}
@article{Orme2002,
author = {Orme, Chris D and Ruud, Paul A},
journal = {Economics Letters},
pages = {209--217},
title = {{On the uniqueness of the maximum likelihood estimator}},
volume = {75},
year = {2002}
}
@article{Ioannidis2006,
annote = {2010IInum12.6},
author = {Ioannidis, JPA},
journal = {NEONATAL INTENSIVE CARE},
title = {{Why most published research findings are false}},
url = {http://medicine.plosjournals.org/?request=get-document{\&}doi=10.1371/journal.pmed.0020124},
year = {2006}
}
@misc{rsblender3d,
keywords = {3D editor,blender 3D,manual,miscellaneous},
title = {{Blender 3D manual}}
}
@article{Meinshausen2010,
author = {Meinshausen, Nicolai and B{\"{u}}hlmann, Peter},
doi = {10.1111/j.1467-9868.2010.00740.x},
issn = {13697412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {high dimensional data,resampling,stability selection,structure estimation},
month = {jul},
number = {4},
pages = {417--473},
title = {{Stability selection}},
url = {http://doi.wiley.com/10.1111/j.1467-9868.2010.00740.x},
volume = {72},
year = {2010}
}
@article{Lapicque1907,
author = {Lapicque, L},
journal = {Physiol. Pathol. Gen},
pages = {620--635},
title = {{Recherches quantitatives sur l'excitation {\'{e}}lectrique des nerfs trait{\'{e}}e comme une polarisation}},
volume = {9},
year = {1907}
}
@article{Soltiz2013,
author = {Soltiz, Michael and Kudithipudi, Dhireesha and Merkel, Cory and Rose, G S and Pino, R E},
journal = {Computers, IEEE Transactions on},
month = {mar},
number = {8},
pages = {1597--1606},
title = {{Memristor-based neural logic blocks for non-linearly separable functions}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6489976},
volume = {62},
year = {2013}
}
@article{Miller2012a,
author = {Miller, Kai J. and Foster, Brett L. and Honey, Christopher J.},
doi = {10.3389/fncom.2012.00085},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
number = {October},
pages = {1--3},
title = {{Does rhythmic entrainment represent a generalized mechanism for organizing computation in the brain?}},
url = {http://www.frontiersin.org/Computational{\_}Neuroscience/10.3389/fncom.2012.00085/full},
volume = {6},
year = {2012}
}
@techreport{Xuru2006,
author = {Xuru},
keywords = {Fractional Calculus},
mendeley-tags = {Fractional Calculus},
pages = {1--19},
title = {{Introductory Notes on Fractional Calculus}},
url = {http://www.xuru.org/},
volume = {0},
year = {2006}
}
@article{TOWN06,
author = {Townsend, B and Paninski, L and Lemon, R},
journal = {Journal of Neurophysiology},
pages = {2578--2592},
title = {{Application of cascade analysis to simultaneously recorded motor cortical, cerebellar and EMG data}},
volume = {96},
year = {2006}
}
@article{Custers2010,
annote = {2010IInum12.48},
author = {Custers, R. and Aarts, H.},
doi = {10.1126/science.1188595},
issn = {0036-8075},
journal = {Science},
month = {jul},
number = {5987},
pages = {47--50},
title = {{The Unconscious Will: How the Pursuit of Goals Operates Outside of Conscious Awareness}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1188595},
volume = {329},
year = {2010}
}
@article{Nishiyama2007,
author = {Nishiyama, H and Fukaya, M and Watanabe, M},
journal = {Neuron},
number = {3},
pages = {472--487},
title = {{Axonal motility and its modulation by activity are branch-type specific in the intact adult cerebellum}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627307007088},
volume = {56},
year = {2007}
}
@article{Rybicki95,
author = {Rybicki, George B and Press, William H},
doi = {10.1103/PhysRevLett.74.1060},
journal = {Phys. Rev. Lett.},
month = {feb},
number = {7},
pages = {1060--1063},
publisher = {American Physical Society},
title = {{Class of Fast Methods for Processing Irregularly Sampled or Otherwise Inhomogeneous One-Dimensional Data}},
volume = {74},
year = {1995}
}
@article{Elston|2001|,
author = {Elston, G N},
journal = {Exp. Brain Res.},
number = {2},
pages = {141--152},
title = {{Interlaminar differences in the pyramidal cell phenotype in cortical areas 7 m and STP (the superior temporal polysensory area) of the macaque monkey.}},
volume = {138}
}
@article{Nevian2007,
author = {Nevian, T and Helmchen, F},
journal = {Pflugers Archiv Eur. J. Nerosci.},
pages = {675--688},
title = {{Calcium indicator loading of neurons using single-cell electroporation}},
volume = {454(4)},
year = {2007}
}
@article{Diba2006,
abstract = {We investigate the effects of the stochastic nature of ion channels on the faithfulness, precision and reproducibility of electrical signal transmission in weakly active, dendritic membrane under in vitro conditions. The properties of forward and backpropagating action potentials (BPAPs) in the dendritic tree of pyramidal cells are the subject of intense empirical work and theoretical speculation (Larkum et al., 1999; Zhu, 2000; Larkum et al., 2001; Larkum and Zhu, 2002; Schaefer et al., 2003; Williams, 2004; Waters et al., 2005). We numerically simulate the effects of stochastic ion channels on the forward and backward propagation of dendritic spikes in Monte-Carlo simulations on a reconstructed layer 5 pyramidal neuron. We report that in most instances there is little variation in timing or amplitude for a single BPAP, while variable backpropagation can occur for trains of action potentials. Additionally, we find that the generation and forward propagation of dendritic Ca(2+) spikes are susceptible to channel variability. This indicates limitations on computations that depend on the precise timing of Ca(2+) spikes.},
author = {Diba, K and Koch, C and Segev, I},
doi = {10.1007/s10870-006-4770-0},
issn = {0929-5313},
journal = {Journal of Computational Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Calcium,Calcium: metabolism,Computer Simulation,Dendrites,Dendrites: physiology,Excitatory Postsynaptic Potentials,Ion Channel Gating,Ion Channel Gating: physiology,Ion Channels,Ion Channels: classification,Ion Channels: physiology,Models,Neurological,Neuron Model,Neurons,Neurons: cytology,Rats,Somatosensory Cortex,Somatosensory Cortex: cytology,Stochastic Processes},
mendeley-tags = {Neuron Model},
month = {feb},
number = {1},
pages = {77--84},
pmid = {16649068},
title = {{Spike propagation in dendrites with stochastic ion channels.}},
url = {http://www.springerlink.com/content/a8h2728jx037363r http://www.ncbi.nlm.nih.gov/pubmed/16649068},
volume = {20},
year = {2006}
}
@article{Kvatinsky2012,
author = {Kvatinsky, S and Friedman, E G and Kolodny, A and Weiser, U C},
journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
month = {jan},
number = {1},
pages = {211--221},
title = {{TEAM: ThrEshold Adaptive Memristor Model}},
url = {http://webee.technion.ac.il/people/skva/Memristor Models/TEAM paper.pdf},
volume = {60},
year = {2013}
}
@article{Levy2002,
abstract = {Organisms evolve as compromises, and many of these compromises can be expressed in terms of energy efficiency. For example, a compromise between rate of information processing and the energy consumed might explain certain neurophysiological and neuroanatomical observations (e.g., average firing frequency and number of neurons). Using this perspective reveals that the randomness injected into neural processing by the statistical uncertainty of synaptic transmission optimizes one kind of information processing relative to energy use. A critical hypothesis and insight is that neuronal information processing is appropriately measured, first, by considering dendrosomatic summation as a Shannon-type channel (1948) and, second, by considering such uncertain synaptic transmission as part of the dendrosomatic computation rather than as part of axonal information transmission. Using such a model of neural computation and matching the information gathered by dendritic summation to the axonal information transmitted, H(p*), conditions are defined that guarantee synaptic failures can improve the energetic efficiency of neurons. Further development provides a general expression relating optimal failure rate, f, to average firing rate, p*, and is consistent with physiologically observed values. The expression providing this relationship, f approximately 4(-H(p*)), generalizes across activity levels and is independent of the number of inputs to a neuron.},
annote = {2010IIInum35},
author = {Levy, W B and Baxter, Robert a},
doi = {20026456},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Computer Simulation,Energy Metabolism,Energy Metabolism: physiology,Entropy,Information Theory,Mathematics,Models, Neurological,Neocortex,Neocortex: physiology,Neurons,Neurons: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {jun},
number = {11},
pages = {4746--55},
pmid = {12040082},
title = {{Energy-efficient neuronal computation via quantal synaptic failures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12040082},
volume = {22},
year = {2002}
}
@book{Feynman1963,
author = {Feynman, R.P.},
title = {{The Feynman lectures on physics}},
year = {1963}
}
@article{Simon2001,
abstract = {An expression for the cumulative distribution function evaluated at zero of the difference of two chi-square variates with different number of degrees of freedom is derived and applied to the outage probability computation of cellular mobile radio systems in fading channels. In particular, a generic result is developed for this probability which takes on several forms, the simplest of which, is a single integral with finite limits and an integrand composed of elementary (exponential and trigonometric) functions. The results are applicable to cellular systems that are subject to independent identically distributed (i.i.d.) interfering signals and that employ maximal-ratio combining reception over i.i.d. diversity paths. Various fading channel models are assumed for the desired signal and interferers. For each desired signal/interferer combination, the outage probability is expressed in closed form in terms of a set of parameters that characterize the particular scenario. A tabulation of these various scenarios and their associated parameters for channels of practical interest is included},
author = {Simon, Marvin K. and Alouini, Mohamed Slim},
doi = {10.1109/26.966071},
issn = {00906778},
journal = {IEEE Transactions on Communications},
keywords = {Cellular mobile radio systems,Central and noncentral chi-square distributions,Co-channel interference,Generalized Marcum Q-function,Maximal ratio combining,Nakagami fading,Outage probability,Rician fading},
number = {11},
pages = {1946--1954},
title = {{On the difference of two chi-square variates with application to outage probability computation}},
volume = {49},
year = {2001}
}
@book{di2008piecewise,
address = {London},
author = {{Di Bernardo}, M},
isbn = {1846280397},
publisher = {Springer Verlag},
title = {{Piecewise-smooth dynamical systems: theory and applications}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=mAMLF4YWszUC{\&}oi=fnd{\&}pg=PA1{\&}dq=Piecewise-smooth+dynamical+systems:+theory+and+applications{\&}ots=fsqkjHkU1z{\&}sig=3wrp7qgCL-TmGsMgY{\_}pPX0nLoE8},
volume = {163},
year = {2008}
}
@article{Jones2014,
author = {Jones, Richard H},
keywords = {missing observations,time series analysis},
number = {3},
pages = {389--395},
title = {{Maximum Likelihood of ARMA Models to Time Fitting Series With Observations Missing}},
volume = {22},
year = {2014}
}
@article{Solomon1975,
author = {Solomon, F.},
journal = {The annals of probability},
number = {1},
pages = {1--31},
publisher = {JSTOR},
title = {{Random walks in a random environment}},
url = {http://www.jstor.org/stable/2959260},
volume = {3},
year = {1975}
}
@article{Gammaitoni1998,
author = {Gammaitoni, L and Nazionale, I and Fisica, D and Perugia, S and Perugia, I and Augsburg, D and Jung, P and Marchesoni, F and Camerino, I},
journal = {Reviews of Modern Physics},
number = {1},
pages = {223--287},
title = {{Stochastic resonance}},
volume = {70},
year = {1998}
}
@phdthesis{Wallach2012,
author = {Wallach, A},
number = {March},
school = {Technion},
title = {{The Response Clamp : A Control Based Approach for the Study of Neural Systems ; Method and Applications}},
year = {2012}
}
@article{Rhode99,
author = {Rhode, W S},
journal = {Journal of Neurophysiology},
month = {aug},
number = {2},
pages = {1019--1032},
title = {{Vertical cell responses to sound in cat dorsal cochlear nucleus}},
volume = {82},
year = {1999}
}
@article{KoyamaShinomoto05,
author = {Koyama, S and Shinomoto, S},
journal = {J. Phys. A},
pages = {531--537},
title = {{Empirical {\{}B{\}}ayes interpretations of random point events}},
volume = {38},
year = {2005}
}
@article{smith2002modeling,
annote = {2009num24},
author = {Smith, Gordon C S},
journal = {Computational Cell Biology},
pages = {291--325},
publisher = {Springer},
title = {{Modeling the stochastic gating of ion channels}},
year = {2002}
}
@book{Slotine1991,
author = {Slotine, JJE and Li, W},
isbn = {0130408905},
title = {{Applied nonlinear control}},
url = {ftp://222.18.54.49/xiaomagecc/Applied Nonliear control [Slotin 1991--Prentice Hall].pdf},
year = {1991}
}
@article{Cox04,
author = {Cox, S},
journal = {Journal of Computational Neuroscience,},
pages = {225--243},
title = {{Estimating the Location and Time Course of Synaptic Input From Multi-Site Potential Recordings}},
volume = {17},
year = {2004}
}
@article{KS05,
author = {Kohn, A and Smith, M},
journal = {Journal of Neuroscience},
pages = {3661--3673},
title = {{Stimulus dependence of neuronal correlation in primary visual cortex of the macaque}},
volume = {25},
year = {2005}
}
@article{Manuscript2008a,
author = {Manuscript, Author},
number = {3},
pages = {472--487},
title = {specific in the intact adult cerebellum},
volume = {56},
year = {2008}
}
@misc{Svoboda2015,
author = {Svoboda, Karel},
booktitle = {Janelia Farm Campus, HHMI},
howpublished = {http://dx.doi.org/10.6080/K02R3PMN},
title = {{GENIE project}},
url = {http://dx.doi.org/10.6080/K02R3PMN},
year = {2015}
}
@article{Debanne2004,
abstract = {Axons link distant brain regions and are generally regarded as reliable transmission cables in which stable propagation occurs once an action potential has been generated. However, recent experimental and theoretical data indicate that the functional capabilities of axons are much more diverse than traditionally thought. Beyond axonal propagation, intrinsic voltage-gated conductances together with the intrinsic geometrical properties of the axon determine complex phenomena such as branch-point failures and reflected propagation. This review considers recent evidence for the role of these forms of axonal computation in the short-term dynamics of neural communication.},
annote = {2010IIInum71},
author = {Debanne, D},
doi = {10.1038/nrn1397},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Brain,Brain: cytology,Brain: physiology,Electrophysiology,Neural Conduction,Neural Conduction: physiology,Neuron Model,Potassium Channels,Potassium Channels: metabolism,Sodium Channels,Sodium Channels: metabolism,Synaptic Transmission,Synaptic Transmission: physiology},
mendeley-tags = {Neuron Model},
month = {apr},
number = {4},
pages = {304--16},
pmid = {15034555},
shorttitle = {Nat Rev Neurosci},
title = {{Information processing in the axon.}},
url = {http://dx.doi.org/10.1038/nrn1397},
volume = {5},
year = {2004}
}
@article{Caloyannides1974,
abstract = {Manyphysical occurrences are characterized by extremely low spectral variations, themeasurement and estimation of which has been invariably difficult. Anestimate of the density of the power spectrum of very-low-frequencysemiconductor 1/f noise is experimentally obtained from 10−6.3 to 1.0cps with a greater accuracy than that achieved in previoussimilar attempts; it is concluded that the spectrum is 1/f with approximately 1.3 over most of the frequency range,but appearing to have a value of about 1.0 inthe lowest decade. A peculiar form of stationarity seems todistinguish 1/f noise from other noise in semiconductors. Ten independent noise sources were time multiplexed and their spectral estimates were subsequently averaged. If the sources have similar spectra, this reducesthe necessary data-taking time by a factor of 10 fora given accuracy. An estimator is derived for optimal spectral estimation based on a number of statistically independent noise sources.Other related topics considered are non-equidistant sampling, and a plausible mathematical model of such flicker noise. Finally, the variance ofthe spectral estimate obtained through the Blackman/Tukey algorithm is analyzed in great detail; the variance is shown to diverge for 1.0 in an assumed power spectrum of k/|f|, unless the assumed spectrum is ``truncated''. {\textcopyright}1974 American Institute of Physics},
author = {Caloyannides, M. A. MA},
journal = {Journal of Applied Physics},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {jan},
number = {1},
pages = {307--316},
publisher = {AIP},
shorttitle = {J. Appl. Phys.},
title = {{Microcycle spectral estimates of 1/f noise in semiconductors}},
url = {http://link.aip.org/link/?JAPIAU/45/307/1 http://link.aip.org/link/?JAP/45/307/1},
volume = {45},
year = {1974}
}
@article{canepari1997experimental,
author = {Canepari, M and Bove, M and Maeda, E and Cappello, M and Kawana, A},
journal = {Biological Cybernetics},
keywords = {networks},
mendeley-tags = {networks},
number = {2},
pages = {153--162},
publisher = {Springer},
title = {{Experimental analysis of neuronal dynamics in cultured cortical networks and transitions between different patterns of activity}},
volume = {77},
year = {1997}
}
@article{Colquhoun1977a,
annote = {

2010num3.1},
author = {Colquhoun, D and Hawkes, A G},
journal = {Proceedings of the Royal Society of London. Series B, Biological Sciences},
number = {1135},
pages = {231--262},
publisher = {The Royal Society},
title = {{Relaxation and fluctuations of membrane currents that flow through drug-operated channels}},
url = {http://www.jstor.org/stable/77258},
volume = {199},
year = {1977}
}
@article{Soen1999,
annote = {2008num3},
author = {Soen, Yoav and Cohen, Netta and Lipson, Doron and Braun, E},
doi = {10.1103/PhysRevLett.82.3556},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {apr},
number = {17},
pages = {3556--3559},
title = {{Emergence of Spontaneous Rhythm Disorders in Self-Assembled Networks of Heart Cells}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.82.3556},
volume = {82},
year = {1999}
}
@article{Liu1996,
author = {Liu, Jun S.},
doi = {10.1007/BF00162521},
issn = {0960-3174},
journal = {Statistics and Computing},
keywords = {coupling,delta method,eigen analysis,importance ratio},
month = {jun},
number = {2},
pages = {113--119},
title = {{Metropolized independent sampling with comparisons to rejection sampling and importance sampling}},
url = {http://link.springer.com/10.1007/BF00162521},
volume = {6},
year = {1996}
}
@article{Harris|1995|,
author = {Harris, K M},
journal = {Trends Neurosci.},
pages = {365--369},
title = {{How Multiple Synapse Boutons Could Preserve Input Specificity During an Interneuronal Spread Of Long-term Potentiation.}},
volume = {18}
}
@article{Strukov2008,
author = {Strukov, D B and Snider, G S and Stewart, D R and Williams, R S},
journal = {Nature},
number = {7191},
pages = {80--83},
title = {{The missing memristor found}},
url = {http://www.nature.com/nature/journal/vaop/ncurrent/full/nature06932.html},
volume = {453},
year = {2008}
}
@book{Montavon2012,
abstract = {The twenty last years have been marked by an increase in available data and computing power. In parallel to this trend, the focus of neural network research and the practice of training neural networks has undergone a number of important changes, for example, use of deep learning machines. The second edition of the book augments the first edition with more tricks, which have resulted from 14 years of theory and experimentation by some of the world's most prominent neural network researchers. These tricks can make a substantial difference (in terms of speed, ease of implementation, and accuracy) when it comes to putting algorithms to work on real problems.},
author = {Montavon, Gr{\'{e}}goire and Orr, Genevi{\`{e}}ve and M{\"{u}}ller, Klaus-Robert},
booktitle = {Neural networks: tricks of the trade},
doi = {10.1007/978-3-642-35289-8},
edition = {2},
isbn = {978-3-642-35288-1},
keywords = {icle},
title = {{Neural Networks: Tricks of the Trade}},
url = {https://www.google.com/books?hl=iw{\&}lr={\&}id=VCKqCAAAQBAJ{\&}oi=fnd{\&}pg=PR5{\&}dq=neural+networks+tricks+of+the+trade{\&}ots=cBhuOELh2G{\&}sig=ITvyS{\_}U3tmvaiz0oaFPledMa2Ss http://link.springer.com/10.1007/978-3-642-35289-8},
year = {2012}
}
@article{Deco2011,
abstract = {A broad body of experimental work has demonstrated that apparently spontaneous brain activity is not random. At the level of large-scale neural systems, as measured with functional MRI (fMRI), this ongoing activity reflects the organization of a series of highly coherent functional networks. These so-called resting-state networks (RSNs) closely relate to the underlying anatomical connectivity but cannot be understood in those terms alone. Here we review three large-scale neural system models of primate neocortex that emphasize the key contributions of local dynamics, signal transmission delays and noise to the emerging RSNs. We propose that the formation and dissolution of resting-state patterns reflects the exploration of possible functional network configurations around a stable anatomical skeleton.},
author = {Deco, Gustavo and Jirsa, Viktor K and McIntosh, Anthony R},
doi = {10.1038/nrn2961},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Nerve Net,Nerve Net: physiology,Neural Pathways,Neural Pathways: physiology,Rest,Rest: physiology},
month = {jan},
number = {1},
pages = {43--56},
pmid = {21170073},
publisher = {Nature Publishing Group},
title = {{Emerging concepts for the dynamical organization of resting-state activity in the brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21170073},
volume = {12},
year = {2011}
}
@book{Briggs00,
author = {Briggs, William L and Henson, Van Emden and McCormick, Steve F},
publisher = {SIAM},
title = {{A multigrid tutorial (2nd ed.)}},
year = {2000}
}
@article{Dahl2012,
author = {Dahl, G E and Yu, D and Deng, L and Acero, A},
journal = {Audio, Speech, and Language Processing},
keywords = {Deep Learning},
mendeley-tags = {Deep Learning},
number = {1},
pages = {30--42},
title = {{Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5740583},
volume = {20},
year = {2012}
}
@phdthesis{Winther1998a,
author = {Winther, O},
booktitle = {Unpublished doctoral dissertation, University of {\ldots}},
title = {{Bayesian mean field algorithms for neural networks and gaussian processes}},
url = {http://isp.imm.dtu.dk/staff/winther/thesis.pdf},
year = {1998}
}
@techreport{HEN96,
author = {Henrion, M and Pradhan, M and del Favero, B and Huang, K and Provan, G and O'Rorke, P},
institution = {Stanford},
number = {SMI-96-0637},
title = {{Why is diagnosis using belief networks insensitive to imprecision in probabilities?}},
year = {1996}
}
@article{Madhavan:2006fk,
abstract = {We culture high-density cortical cultures on multi-electrode arrays
(MEAs), which allow us to stimulate and record from thousands of
neurons. One of the modes of activity in these high-density cultures
is dish-wide synchronized bursting. Unlike in vivo, these synchronized
patterns persist for the lifetime of the culture. Such aberrant patterns
of activity might be due to the fact that cortical cultures are sensory-deprived
and arrested in development. We have devised methods to control this
spontaneous activity by multi-electrode electrical stimulation and
to study long-term functional neural plasticity, on a background
of such burst-quieting stimulation. Here, we investigate whether
burst quieting reveals long-term plasticity induced by tetanic stimulation.
Spatio-temporal activity patterns (STAPs) that result from probe
pulses were clustered and quantified in quieted and non-quieted cultures.
Burst-quieted cultures show more tetanus-induced functional change
than cultures which are allowed to express spontaneous bursts. The
methods developed for this study will help in the understanding of
network dynamics and appreciation of their role in long-term plasticity
and information processing in the brain.},
author = {Madhavan, Radhika and Chao, Zenas C and Wagenaar, D A and Bakkum, Douglas J and Potter, S M},
doi = {10.1109/IEMBS.2006.260571},
journal = {Conf Proc IEEE Eng Med Biol Soc},
keywords = {networks},
mendeley-tags = {networks},
pages = {1593--1596},
pmid = {17946052},
title = {{Multi-site stimulation quiets network-wide spontaneous bursts and enhances functional plasticity in cultured cortical networks}},
volume = {1},
year = {2006}
}
@article{Nakai|2004|,
abstract = {An application of independent component analysis (ICA) was attempted
to develop a method of processing magnetic resonance (MR) images
to extract physiologically independent components representing tissue
relaxation times and achieve improved visualization of normal and
pathologic structures. Anatomical T1-weighted, T2- weighted and proton
density images were obtained from 10 normal subjects, 3 patients
with brain tumors and 1 patient with multiple sclerosis. The data
sets were analyzed using ICA based on the learning rule of Bell and
Sejnowski after prewhitening operations. The three independent components
obtained from the three original data sets corresponded to (1) short
T1 components representing myelin of white matter and lipids, (2)
relatively short T1 components representing gray matter and (3) long
T2 components representing free water. The involvement of gray or
white matter in brain tumor cases and the demyelination in the case
of multiple sclerosis were enhanced and visualized in independent
component images. ICA can potentially achieve separation of tissues
with different relaxation characteristics and generate new contrast
images of gray and white matter. With the proper choice of contrast
for the original images, ICA may be useful not only for extracting
subtle or hidden changes but also for preprocessing transformation
before clustering and segmenting the structure of the human brain.},
author = {Nakai, T and Muraki, S and Bagarinao, E and Miki, Y and Takehara, Y and Matsuo, K and Kato, C and Sakahara, H and Isoda, H},
journal = {NeuroImage},
keywords = {ICA,MRI,brain neoplasm,computational,image processing,independent component analysis,magnetic resonance imaging,mathematics,multiple sclerosis,neurobiology},
pages = {251},
title = {{Application of independent component analysis to magnetic resonance imaging for enhancing the contrast of gray and white matter}},
volume = {21}
}
@article{Calabrese10,
author = {Calabrese, A and Schumacher, J and Schneider, D and Woolley, S and Paninski, L},
journal = {COSYNE},
title = {{Predicting zebra finch MLd spiking responses to song and noise stimuli using a generalized linear model}},
year = {2010}
}
@article{Society2009,
author = {Society, Royal Statistical},
number = {3},
pages = {576--581},
title = {{On the Superposition of Point Processes Author ( s ): E . Cinlar and R . A . Agnew Source : Journal of the Royal Statistical Society . Series B ( Methodological ), Vol . 30 , No . 3 Published by : Blackwell Publishing for the Royal Statistical Society Sta}},
volume = {30},
year = {2009}
}
@inproceedings{NYK03b,
author = {Nykamp, D Q},
booktitle = {Neural Information Processing Systems},
pages = {309--316},
title = {{Reconstructing stimulus-driven neural networks from spike times}},
volume = {15},
year = {2003}
}
@article{SmithRhode85,
author = {Smith, P H and Rhode, W S},
journal = {Journal of Comparative Neurology},
month = {jul},
number = {1},
pages = {127--143},
title = {{Electron microscopic features of physiologically characterized, HRP-labeled fusiform cells in the cat dorsal cochlear nucleus}},
volume = {237},
year = {1985}
}
@article{CarpenterFearnhead99,
author = {Carpenter, J and Clifford, P and Fearnhead, P},
journal = {Radar, Sonar and Navigation, IEE Proceedings-},
number = {1},
pages = {2--7},
title = {{Improved particle filter for nonlinear problems}},
volume = {146},
year = {1999}
}
@article{Guo2014,
author = {Guo, Zhenyuan and Wang, Jun and Yan, Zheng},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
month = {mar},
number = {11},
pages = {2099--2109},
title = {{Passivity and Passification of Memristor-Based Recurrent Neural Networks With Time-Varying Delays}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6774460},
volume = {25},
year = {2014}
}
@article{Bean2007,
abstract = {The action potential of the squid giant axon is formed by just two voltage-dependent conductances in the cell membrane, yet mammalian central neurons typically express more than a dozen different types of voltage-dependent ion channels. This rich repertoire of channels allows neurons to encode information by generating action potentials with a wide range of shapes, frequencies and patterns. Recent work offers an increasingly detailed understanding of how the expression of particular channel types underlies the remarkably diverse firing behaviour of various types of neurons.},
annote = {2010IInum12.35},
author = {Bean, B P},
doi = {10.1038/nrn2148},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Calcium Channels,Calcium Channels: physiology,Cell Membrane,Cell Membrane: physiology,Central Nervous System,Central Nervous System: physiology,Humans,Ion Channels,Ion Channels: physiology,Neuron Model,Neurons,Neurons: physiology,Neurons: ultrastructure,Potassium Channels,Potassium Channels: physiology,Sodium Channels,Sodium Channels: physiology},
mendeley-tags = {Neuron Model},
month = {jun},
number = {6},
pages = {451--65},
pmid = {17514198},
title = {{The action potential in mammalian central neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17514198},
volume = {8},
year = {2007}
}
@article{Feigenbaum1978,
author = {Feigenbaum, M.J. J},
isbn = {5029078750957},
journal = {Journal of statistical physics},
keywords = {1,a variety of,attractor,bifurcation,f,i n t r,l,limit cycles,o d u c,population dynamics,provide a description for,recurrence,recursion equations xn,sality,scaling,t i o n,univer-,x},
number = {1},
pages = {25--52},
publisher = {Springer},
title = {{Quantitative universality for a class of nonlinear transformations}},
url = {http://www.springerlink.com/index/q555g62245040133.pdf},
volume = {19},
year = {1978}
}
@article{Anderson2001,
abstract = {The total length of cortical axons could be reduced if the parent axons maintained straight trajectories and simply connected to dendritic shafts via spine-like terminaux boutons and to dendritic spines via bead-like en passant boutons. Cortical axons from cat area 17 were reconstructed from serial electron micrographs and their bouton morphology was correlated with their synaptic targets. En passant or terminaux boutons did not differ in the proportion of synapses they formed with dendritic spines and shafts, and thus, the two morphological variants of synaptic bouton do not contribute directly to optimizing axon length.},
author = {Anderson, J C and Martin, K a},
doi = {10.1038/nn772},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Animals,Cats,Cell Size,Cell Size: physiology,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Image Processing, Computer-Assisted,Microscopy, Electron,Neural Pathways,Neural Pathways: growth {\&} development,Neural Pathways: physiology,Neural Pathways: ultrastructure,Neuronal Plasticity,Neuronal Plasticity: physiology,Presynaptic Terminals,Presynaptic Terminals: physiology,Presynaptic Terminals: ultrastructure,Synapses,Synapses: physiology,Synapses: ultrastructure,Synaptic Transmission,Synaptic Transmission: physiology,Visual Cortex,Visual Cortex: growth {\&} development,Visual Cortex: physiology,Visual Cortex: ultrastructure},
month = {dec},
number = {12},
pages = {1166--7},
pmid = {11713473},
title = {{Does bouton morphology optimize axon length?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11713473},
volume = {4},
year = {2001}
}
@article{BROWN09b,
author = {Brown, L and Cai, T and Zhou, H},
journal = {Annals of Statistics. To appear.},
title = {{Nonparametric Regression in Exponential Familie}},
year = {2009}
}
@article{ISR95,
author = {Inoue, J and Sato, S and Ricciardi, L},
journal = {Biological Cybernetics},
pages = {209--221},
title = {{On the parameter estimation for diffusion models of single neuron's activities: {\{}I{\}}. Application to spontaneous activities of mesencephalic reticular formation cells in sleep and waking states}},
volume = {73},
year = {1995}
}
@article{Dodt03,
author = {Dodt, H U and Schierloh, A and Eder, M and Zieglgansberger, W},
journal = {Neuroreport},
number = {4},
pages = {623--627},
title = {{Circuitry of rat barrel cortex investigated by infrared-guided laser stimulation}},
volume = {14},
year = {2003}
}
@article{Canepari07,
abstract = {The non-linear and spatially inhomogeneous interactions of dendritic
membrane potential signals that represent the first step in the induction
of activity-dependent long-term synaptic plasticity are not fully
understood, particularly in dendritic regions which are beyond the
reach of electrode measurements. We combined voltage-sensitive-dye
recordings and Ca2+ imaging of hippocampal CA1 pyramidal neurons
to study large regions of the dendritic arbor, including branches
of small diameter (distal apical and oblique dendrites). Dendritic
membrane potential transients were monitored at high spatial resolution
and correlated with supra-linear [Ca2+]i changes during one cycle
of a repetitive patterned stimulation protocol that typically results
in the induction of long-term potentiation (LTP). While the increase
in the peak membrane depolarization during coincident pre- and post-synaptic
activity was required for the induction of supra-linear [Ca2+]i signals
shown to be necessary for LTP, the change in the baseline-to-peak
amplitude of the backpropagating dendritic action potential (bAP)
was not critical in this process. At different dendritic locations,
the baseline-to-peak amplitude of the bAP could be either increased,
decreased or unaltered at sites where EPSP-AP pairing evoked supra-linear
summation of [Ca2+]i transients. We suggest that modulations in the
bAP baseline-to-peak amplitude by local EPSPs act as a mechanism
that brings the membrane potential into the optimal range for Ca2+
influx through NMDA receptors (0 to -15 mV); this may require either
boosting or the reduction of the bAP, depending on the initial size
of both signals.},
author = {Canepari, Marco and Djurisic, Maja and Zecevic, Dejan},
doi = {10.1113/jphysiol.2006.125005},
journal = {J Physiol},
number = {2},
pages = {463--484},
title = {{Dendritic signals from rat hippocampal CA1 pyramidal neurons during coincident pre- and post-synaptic activity: a combined voltage- and calcium-imaging study}},
url = {http://jp.physoc.org/cgi/content/abstract/580/2/463},
volume = {580},
year = {2007}
}
@article{RR01,
author = {Roberts, G and Rosenthal, J},
journal = {Statistical Science},
pages = {351--367},
title = {{Optimal Scaling for Various Metropolis-Hastings Algorithms}},
volume = {16},
year = {2001}
}
@article{Daliot2003,
author = {Daliot, A and Dolev, D and Parnas, H},
journal = {Self-Stabilizing Systems},
title = {{Self-stabilizing pulse synchronization inspired by biological pacemaker networks}},
url = {http://www.springerlink.com/index/VM3V336362604573.pdf},
year = {2003}
}
@article{Implement,
author = {Zurada, JM},
journal = {Circuits and Devices Magazine, IEEE},
title = {{Analog implementation of neural networks}},
url = {http://www.sciencedirect.com/science/article/pii/S092523121000216X http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=158511},
year = {1992}
}
@book{bremaud1981point,
author = {Bremaud, P},
publisher = {Springer},
title = {{Point Processes and Queues, Martingale Dynamics: Martingale Dynamics}},
year = {1981}
}
@article{Grothe2010,
author = {Grothe, Benedikt and Pecka, Michael},
doi = {10.1152/physrev.00026.2009.},
journal = {Physiological reviews},
pages = {983--1012},
title = {{Mechanisms of sound localization in mammals}},
url = {http://physrev.physiology.org/content/90/3/983.short},
year = {2010}
}
@article{Sadeghi12,
author = {Sadeghi, K and Gauthier, J L and Field, G D and Greschner, M and Agne, M and Chichilnisky, E J and Paninski, L},
journal = {Network},
number = {1},
pages = {27--51},
title = {{Monte Carlo methods for localization of cones given multielectrode retinal ganglion cell recordings}},
volume = {24},
year = {2013}
}
@article{Stevenson2010,
abstract = {Neurons in the sensory system exhibit changes in excitability that unfold over many time scales. These fluctuations produce noise and could potentially lead to perceptual errors. However, to prevent such errors, postsynaptic neurons and synapses can adapt and counteract changes in the excitability of presynaptic neurons. Here we ask how neurons could optimally adapt to minimize the influence of changing presynaptic neural properties on their outputs. The resulting model, based on Bayesian inference, explains a range of physiological results from experiments which have measured the overall properties and detailed time-course of sensory tuning curve adaptation in the early visual cortex. We show how several experimentally measured short term plasticity phenomena can be understood as near-optimal solutions to this adaptation problem. This framework provides a link between high level computational problems, the properties of cortical neurons, and synaptic physiology.},
annote = {2010IIInum73},
author = {Stevenson, I H and Cronin, Beau and Sur, Mriganka and Kording, Konrad P},
doi = {10.1371/journal.pone.0012436},
issn = {1932-6203},
journal = {PloS one},
month = {jan},
number = {8},
pages = {e12436},
pmid = {20865056},
title = {{Sensory adaptation and short term plasticity as bayesian correction for a changing brain.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2928744{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2010}
}
@article{KellemsCox09,
author = {Kellems, Anthony and Roos, Derrick and Xiao, Nan and Cox, Steven},
journal = {Journal of Computational Neuroscience},
title = {{Low-dimensional, morphologically accurate models of subthreshold membrane potential}},
year = {2009}
}
@article{Cook2007,
abstract = {We examined how hippocamal CA1 neurons process complex time-varying inputs that dendrites are likely to receive in vivo. We propose a functional model of the dendrite-to-soma input/output relationship that combines temporal integration and static-gain control mechanisms. Using simultaneous dual whole cell recordings, we injected 50 s of subthreshold and suprathreshold zero-mean white-noise current into the primary dendritic trunk along the proximal 2/3 of stratum radiatum and measured the membrane potential at the soma. Applying a nonlinear system-identification analysis, we found that a cascade of a linear filter followed by an adapting static-gain term fully accounted for the nonspiking input/output relationship between the dendrite and soma. The estimated filters contained a prominent band-pass region in the 1- to 10-Hz frequency range that remained constant as a function of stimulus variance. The gain of the dendrite-to-soma input/output relationship, in contrast, varied as a function of stimulus variance. When the contribution of the voltage-dependent current I(h) was eliminated, the estimated filters lost their band-pass properties and the gain regulation was substantially altered. Our findings suggest that the dendrite-to-soma input/output relationship for proximal apical inputs to CA1 pyramidal neurons is well described as a band-pass filter in the theta frequency range followed by a gain-control nonlinearity that dynamically adapts to the statistics of the input signal.},
author = {Cook, Erik P and Guest, Jennifer a and Liang, Yong and Masse, Nicolas Y and Colbert, Costa M},
doi = {10.1152/jn.00414.2007},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Action Potentials: radiation effects,Animals,Axons,Axons: physiology,Dendrites,Dendrites: physiology,Dose-Response Relationship,Electric Stimulation,Electric Stimulation: methods,Hippocampus,Hippocampus: cytology,Male,Models,Neurological,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: cytology,Radiation,Rats,Sprague-Dawley,Time Factors},
month = {nov},
number = {5},
pages = {2943--55},
pmid = {17881486},
title = {{Dendrite-to-soma input/output function of continuous time-varying signals in hippocampal CA1 pyramidal neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17881486},
volume = {98},
year = {2007}
}
@article{DeWeese2006,
abstract = {Many models of cortical dynamics have focused on the high-firing regime, in which neurons are driven near their maximal rate. Here we consider the responses of neurons in auditory cortex under typical low-firing rate conditions, when stimuli have not been optimized to drive neurons maximally. We used whole-cell patch-clamp recording in vivo to measure subthreshold membrane potential fluctuations in rat primary auditory cortex in both the anesthetized and awake preparations. By analyzing the subthreshold membrane potential dynamics on single trials, we made inferences about the underlying population activity. We found that, during both spontaneous and evoked responses, membrane potential was highly non-Gaussian, with dynamics consisting of occasional large excursions (sometimes tens of millivolts), much larger than the small fluctuations predicted by most random walk models that predict a Gaussian distribution of membrane potential. Thus, presynaptic inputs under these conditions are organized into quiescent periods punctuated by brief highly synchronous volleys, or "bumps." These bumps were typically so brief that they could not be well characterized as "up states" or "down states." We estimate that hundreds, perhaps thousands, of presynaptic neurons participate in the largest volleys. These dynamics suggest a computational scheme in which spike timing is controlled by concerted firing among input neurons rather than by small fluctuations in a sea of background activity.},
author = {DeWeese, M and Zador, A M},
doi = {10.1523/JNEUROSCI.2813-06.2006},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Anesthetics,Animals,Auditory Cortex,Auditory Cortex: cytology,Cortical Synchronization,Electric Stimulation,Electric Stimulation: methods,Lidocaine,Lidocaine: analogs {\&} derivatives,Lidocaine: pharmacology,Local,Local: pharmacology,Membrane Potentials,Membrane Potentials: drug effects,Membrane Potentials: physiology,Membrane Potentials: radiation effects,Models,Neural Inhibition,Neural Inhibition: physiology,Neurological,Neurons,Neurons: physiology,Newborn,Nonlinear Dynamics,Patch-Clamp Techniques,Rats,Sprague-Dawley,Tetrodotoxin,Tetrodotoxin: pharmacology,Time Factors,Wakefulness},
month = {nov},
number = {47},
pages = {12206--18},
pmid = {17122045},
title = {{Non-Gaussian membrane potential dynamics imply sparse, synchronous activity in auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17122045},
volume = {26},
year = {2006}
}
@article{RB90,
author = {Ritov, Y and Bickel, P},
journal = {Annals of Statistics},
pages = {925--938},
title = {{Achieving information bounds in non- and semi-parametric models}},
volume = {18},
year = {1990}
}
@article{RuB94,
author = {Ruderman, D and Bialek, W},
journal = {Physics Review Letters},
pages = {814--817},
title = {{Statistics of natural images: scaling in the woods}},
volume = {73},
year = {1994}
}
@article{Querlioz2013,
author = {Querlioz, D and Bichler, Olivier and Dollfus, Philippe and Gamrat, Christian},
doi = {10.1109/TNANO.2013.2250995},
issn = {1536-125X},
journal = {IEEE Transactions on Nanotechnology},
month = {may},
number = {3},
pages = {288--295},
title = {{Immunity to Device Variations in a Spiking Neural Network With Memristive Nanodevices}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6508962},
volume = {12},
year = {2013}
}
@article{PAN03e,
author = {Paninski, L},
journal = {Advances in Neural Information Processing Systems},
title = {{Design of experiments via information theory}},
volume = {16},
year = {2003}
}
@article{Chang2009,
author = {Chang, H S and Weiss, Y and Freeman, W T},
journal = {IEEE International Conference on Image Processing},
number = {November},
pages = {3025--3028},
title = {{Informative sensing of natural images}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5414426},
year = {2009}
}
@article{Serr03,
author = {Serruya, M and Hatsopoulos, N and Paninski, L and Fellows, M and Donoghue, J},
journal = {Biological Cybernetics},
pages = {219--228},
title = {{Robustness of neuroprosthetic decoding algorithms}},
volume = {88},
year = {2003}
}
@article{Schaefer2003,
abstract = {Neurons display a variety of complex dendritic morphologies even within the same class. We examined the relationship between dendritic arborization and the coupling between somatic and dendritic action potential (AP) initiation sites in layer 5 (L5) neocortical pyramidal neurons. Coupling was defined as the relative reduction in threshold for initiation of a dendritic calcium AP due to a coincident back-propagating AP. Simulations based on reconstructions of biocytin-filled cells showed that addition of oblique branches of the main apical dendrite in close proximity to the soma (d {\textless} 140 microm) increases the coupling between the apical and axosomatic AP initiation zones, whereas incorporation of distal branches decreases coupling. Experimental studies on L5 pyramids in acute brain slices revealed a highly significant (n = 28, r = 0.63, P {\textless} 0.0005) correlation: increasing the fraction of proximal oblique dendrites (d {\textless} 140 microm), e.g., from 30 to 60{\%} resulted on average in an increase of the coupling from approximately 35{\%} to almost 60{\%}. We conclude that variation in dendritic arborization may be a key determinant of variability in coupling (49 +/- 17{\%}; range 19-83{\%}; n = 37) and is likely to outweigh the contribution made by variations in active membrane properties. Thus coincidence detection of inputs arriving from different cortical layers is strongly regulated by differences in dendritic arborization.},
author = {Schaefer, AT Andreas T and Larkum, Matthew E and Sakmann, Bert and Roth, Arnd},
doi = {10.1152/jn.00046.2003},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Animals,Biological,Dendrites,Dendrites: physiology,Electrophysiology,Membrane Potentials,Models,Neuron Model,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Somatosensory Cortex,Somatosensory Cortex: physiology,Wistar},
mendeley-tags = {Neuron Model},
month = {jun},
number = {6},
pages = {3143--54},
pmid = {12612010},
title = {{Coincidence detection in pyramidal neurons is tuned by their dendritic branching pattern.}},
url = {http://jn.physiology.org/content/89/6/3143.short http://www.ncbi.nlm.nih.gov/pubmed/12612010},
volume = {89},
year = {2003}
}
@article{MilbrandtCaspary00,
abstract = {Pharmacological studies of the inferior colliculus (IC) suggest that

the inhibitory amino acid neurotransmitter gamma-aminobutyric acid

(GABA) plays an important role in shaping responses to simple and

complex acoustic stimuli. Several models of auditory dysfunction,

including age-related hearing loss, tinnitus, and peripheral deafferentation,

suggest an alteration of normal GABA neurotransmission in central

auditory pathways. The present study attempts to further characterize

noise-induced changes in GABA markers in the IC. Four groups (unexposed

control, 0 h post-exposure, 42 h post-exposure, and 30 days post-exposure)

of 3-month-old male Fischer 344 rats were exposed to a high intensity

sound (12 kHz, 106 dB) for 10 h. Observed hair cell damage was primarily

confined to the basal half of the cochlea. There was a significant

decrease in glutamic acid decarboxylase (GAD(65)) immunoreactivity

in the IC membrane fraction compared to controls (P{\textless}0.05) at 0 h

(-41{\%}) and 42 h (-28{\%}) post-exposure, with complete recovery by

30 days post-exposure (P{\textgreater}0.98). Observed decreases in cytosolic levels

of GAD(65) were not significant. Quantitative muscimol receptor binding

revealed a significant increase (+20{\%}) in IC 30 days after sound

exposure (P{\textless}0.05). These data suggest that changes in GABA neurotransmission

occur in the IC of animals exposed to intense sound. Additional studies

are needed to determine whether these changes are a result of protective/compensatory

mechanisms or merely peripheral differentiation, as well as whether

these changes preserve or diminish central auditory system function.},
author = {Milbrandt, J C and Holder, T M and Wilson, M C and Salvi, R J and Caspary, D M},
journal = {Hearing Research},
keywords = {Animals; Cochlea; Glutamate Decarboxylase; Hair Ce,GABA-A; Research Support,Inbred F344; Receptors,Noise-Induced; Inferior Colliculus; Male; Muscimo,P.H.S.; Synaptic Transmission; gamma-Aminobutyric,U.S. Gov't},
month = {sep},
number = {1-2},
pages = {251--260},
pmid = {10962189},
title = {{GAD levels and muscimol binding in rat inferior colliculus following acoustic trauma.}},
volume = {147},
year = {2000}
}
@misc{AXEL01,
author = {Axelrod, Scott and Fine, Shai and Gilad-Bachrach, Ran and Mendelson, Shahar and Tishby, Naftali},
howpublished = {Available at citeseer.nj.nec.com/axelrod01information.html},
title = {{The Information Of Observations And Application For Active Learning With Uncertainty}},
year = {2001}
}
@article{Mazumder2010a,
author = {Mazumder, Rahul and Hastie, Trevor and Tibshirani, Robert},
journal = {The Journal of Machine Learning Research},
keywords = {collaborative filtering,large scale,netflix prize,nuclear norm,spectral regularization},
pages = {2287--2322},
title = {{Spectral regularization algorithms for learning large incomplete matrices}},
url = {http://dl.acm.org/citation.cfm?id=1859931},
volume = {11},
year = {2010}
}
@article{Gori1992,
abstract = {The authors propose a theoretical framework for backpropagation (BP) in order to identify some of its limitations as a general learning procedure and the reasons for its success in several experiments on pattern recognition. The first important conclusion is that examples can be found in which BP gets stuck in local minima. A simple example in which BP can get stuck during gradient descent without having learned the entire training set is presented. This example guarantees the existence of a solution with null cost. Some conditions on the network architecture and the learning environment that ensure the convergence of the BP algorithm are proposed. It is proven in particular that the convergence holds if the classes are linearly separable. In this case, the experience gained in several experiments shows that multilayered neural networks (MLNs) exceed perceptrons in generalization to new examples},
author = {Gori, Marco and Tesi, Alberto},
doi = {10.1109/34.107014},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {1},
pages = {76--86},
pmid = {18267788},
title = {{On the problem of local minima in backpropagation}},
volume = {14},
year = {1992}
}
@article{Rudelson2009,
abstract = {We prove an optimal estimate on the smallest singular value of a random subgaussian matrix, valid for all fixed dimensions. For an N by n matrix A with independent and identically distributed subgaussian entries, the smallest singular value of A is at least of the order $\backslash$sqrt{\{}N{\}} - $\backslash$sqrt{\{}n-1{\}} with high probability. A sharp estimate on the probability is also obtained.},
archivePrefix = {arXiv},
arxivId = {0802.3956},
author = {Rudelson, Mark and Vershynin, Roman},
doi = {10.1002/cpa.20294},
eprint = {0802.3956},
issn = {00103640},
journal = {Communications on Pure and Applied Mathematics},
number = {12},
pages = {1707--1739},
title = {{Smallest singular value of a random rectangular matrix}},
volume = {62},
year = {2009}
}
@article{Diamond2002,
annote = {2010IIInum20},
author = {Diamond, Jeffrey S},
doi = {10.1038/nn0402-291},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Glutamic Acid,Glutamic Acid: metabolism,Hippocampus,Hippocampus: cytology,Hippocampus: metabolism,Long-Term Potentiation,Long-Term Potentiation: physiology,Neurons,Neurons: metabolism,Neurotransmitter Agents,Neurotransmitter Agents: metabolism,Receptors, AMPA,Receptors, AMPA: metabolism,Receptors, N-Methyl-D-Aspartate,Receptors, N-Methyl-D-Aspartate: metabolism,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
month = {apr},
number = {4},
pages = {291--2},
pmid = {11914716},
title = {{A broad view of glutamate spillover.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11914716},
volume = {5},
year = {2002}
}
@article{Paulin93,
author = {Paulin, M G},
journal = {Biological Cybernetics},
number = {1},
pages = {67--76},
title = {{A method for constructing data-based models of spiking neurons using a dynamic linear-static nonlinear cascade}},
volume = {69},
year = {1993}
}
@article{FM99,
address = {Cambridge, MA, USA},
author = {Fusi, Stefano and Mattia, Maurizio},
doi = {http://dx.doi.org/10.1162/089976699300016601},
issn = {0899-7667},
journal = {Neural Computation},
number = {3},
pages = {633--652},
publisher = {MIT Press},
title = {{Collective behavior of networks with linear {\{}(VLSI){\}} integrate-and-fire neurons}},
volume = {11},
year = {1999}
}
@article{Bushong|2002|,
author = {Bushong, E A and Martone, M E and Jones, Y Z and Ellisman, M H},
journal = {J Neurosci},
pages = {183--92.},
title = {{Protoplasmic astrocytes in CA1 stratum radiatum occupy separate anatomical domains.}},
volume = {22}
}
@article{Henze2011,
annote = {In this paper they show experimentally the claim that extracellular voltage is proprtional to dV/dt of the membrane, at least at the AP rise.},
author = {Henze, D A and Borhegyi, Z and Csicsvari, J and Mamiya, A and Harris, K D and Buzs{\'{a}}ki, G},
journal = {Journal of Neurophysiology},
number = {1},
pages = {390},
publisher = {Am Physiological Soc},
title = {{Intracellular features predicted by extracellular recordings in the hippocampus in vivo}},
url = {http://jn.physiology.org/content/84/1/390.short},
volume = {84},
year = {2000}
}
@article{dBK68,
author = {de Boer, E and Kuyper, P},
journal = {IEEE Transactions on Biomedical Engineering},
pages = {159--179},
title = {{Triggered Correlation}},
volume = {15},
year = {1968}
}
@techreport{Paugam-Moisy2006,
author = {Paugam-Moisy, H},
booktitle = {Raport Technique RR11},
title = {{Spiking neuron networks a survey}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0129065709002002?url{\_}ver=Z39.88-2003{\&}rfr{\_}id=ori:rid:crossref.org{\&}rfr{\_}dat=cr{\_}pub=pubmed http://citeseerx.ist.psu.edu/viewdoc/download?rep=rep1{\&}type=pdf{\&}doi=10.1.1.132.516},
year = {2006}
}
@article{Hinton2006a,
author = {Hinton, G E and Salakhutdinov, R R},
journal = {Science},
number = {July},
pages = {504--507},
title = {{Reducing the dimensionality of data with neural networks}},
url = {http://www.sciencemag.org/content/313/5786/504.short},
volume = {313},
year = {2006}
}
@article{Lukosevicius2009,
author = {Lukosevicius, M and Jaeger, H and Luko, M},
journal = {Computer Science Review},
keywords = {Reservoir Computing,computational intelligence,connectionist,echo state network,liquid state machine,machine learning,recurrent neural network},
mendeley-tags = {Reservoir Computing},
number = {3},
pages = {127--149},
publisher = {Elsevier},
title = {{Reservoir computing approaches to recurrent neural network training}},
url = {http://www.sciencedirect.com/science/article/pii/S1574013709000173},
volume = {3},
year = {2009}
}
@article{Rusu2016,
abstract = {Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.},
archivePrefix = {arXiv},
arxivId = {1606.04671},
author = {Rusu, Andrei A. and Rabinowitz, Neil C. and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
eprint = {1606.04671},
journal = {CoRR. arXiv:1606.04671},
title = {{Progressive Neural Networks}},
url = {http://arxiv.org/abs/1606.04671},
year = {2016}
}
@article{Trust2010,
author = {Trust, Applied Probability and Probability, Applied},
number = {3},
pages = {439--468},
title = {{THE INTRINSIC RANDOM FUNCTIONS}},
volume = {5},
year = {2010}
}
@article{LeMasson1993,
annote = {2010IIInum9},
author = {LeMasson, G. and Marder, E and Abbott, L F},
journal = {SCIENCE-NEW YORK THEN WASHINGTON-},
pages = {1915--1915},
publisher = {American Association for the Advancement of Science},
title = {{Activity-dependent regulation of conductances in model neurons}},
url = {http://stg.rutgers.edu/stgrefs/stg{\_}library/LeMasson{\_}Marder{\_}Abbott{\_}1993.pdf},
volume = {259},
year = {1993}
}
@article{SIR03,
author = {Sirovich, L},
journal = {Network: Computation in Neural Systems},
pages = {249--272},
title = {{Dynamics of Neuronal Populations: Eigenfunction Theory, Part 1, Some Solvable Cases}},
volume = {14},
year = {2003}
}
@article{Lu,
archivePrefix = {arXiv},
arxivId = {arXiv:0904.0602v1},
author = {Lu, Wei and Vaswani, Namrata},
eprint = {arXiv:0904.0602v1},
pages = {1--4},
title = {{The Wiener-Khinchin Theorem for Non-wide Sense stationary Random Processes}}
}
@article{Cooper|1981|,
abstract = {We derive from the path integral a continuum strong-coupling expansion
for QED in d-dimensional Euclidean space-time. It is a double expansion
in the fermion and boson kinetic energy (inverse free propagators),
which leads to a double power series for the Green's functions of
the cutoff theory in terms of 1/e{\^{}}2 and Lambda{\^{}}2/M{\^{}}2. Lambda is a
smooth cutoff in Euclidean momentum space, and M is an infrared regulator
mass for the photons needed to define the local part of the path
integral. We demonstrate how dimensional continuation is necessary
to control the broken gauge invariance of the cutoff theory. Restricting
to d=2 (the Schwinger model) we show how to remove the cutoff using
Pade approximants. We find some evidence that as Lambda{\^{}}2/M{\^{}}2-{\textgreater}infty
gauge invariance is restored and we calculate the vector-meson mass,
keeping the first three terms in the expansion in powers of the bare
photon inverse propagator.},
annote = {The paper works out details of the strong coupling expansion by treating{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}kinetic term in Lagrangian as perturbation in QED.},
author = {Cooper, F and Kenway, R},
journal = {Physical Review D},
keywords = {derivatives expansion,hopping expansion,physics,quantum electrodynamics,quantum field theory,strong coupling expansion},
number = {10},
pages = {2706},
title = {{Continuum strong-coupling expansion for quantum electrodynamics}},
volume = {24}
}
@article{Bruno2012,
author = {Bruno, Randy M and Sakmann, B},
doi = {10.1126/science.1124593},
number = {2006},
title = {{Cortex Is Driven by Weak but}},
volume = {1622},
year = {2012}
}
@inproceedings{julier97new,
author = {Julier, S and Uhlmann, J},
booktitle = {Int. Symp. Aerospace/Defense Sensing, Simul. and Controls, Orlando, FL},
title = {{A new extension of the {\{}Kalman{\}} filter to nonlinear systems}},
url = {citeseer.ist.psu.edu/julier97new.html},
year = {1997}
}
@article{Rockafellarf1979,
author = {Rockafellarf, R T},
doi = {10.1112/plms/s3-39.2.331},
issn = {0024-6115},
journal = {Proceedings of the London Mathematical Society},
number = {77},
pages = {331--355},
title = {{Directionally Lipschitzian Functions and Subdifferential Calculus}},
volume = {39},
year = {1979}
}
@article{Gruning2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1112.0213v1},
author = {Gr{\"{u}}ning, A and Sporea, Ioana},
eprint = {arXiv:1112.0213v1},
journal = {Neural processing letters},
keywords = {logical operation,spike trains,spiking neural networks,supervised learning},
pages = {1--15},
title = {{Supervised learning of logical operations in layered spiking neural networks with spike train encoding}},
url = {http://link.springer.com/article/10.1007/s11063-012-9225-1},
year = {2012}
}
@article{Rifai2012,
author = {Rifai, Salah and Bengio, Y and Dauphin, YN and Vincent, P},
journal = {arXiv preprint arXiv:1206.6434},
number = {1},
title = {{A generative process for sampling contractive auto-encoders}},
url = {http://arxiv.org/abs/1206.6434},
year = {2012}
}
@article{Romano2014,
abstract = {We consider the problem of predicting the spin states in a kinetic Ising model when spin trajectories are observed for only a finite fraction of sites. In a Bayesian setting, where the probabilistic model of the spin dynamics is assumed to be known, the optimal prediction can be computed from the conditional (posterior) distribution of unobserved spins given the observed ones. Using the replica method, we compute the error of the Bayes optimal predictor for parallel discrete time dynamics in a fully connected spin system with non symmetric random couplings. The results, exact in the thermodynamic limit, agree very well with simulations of finite spin systems.},
archivePrefix = {arXiv},
arxivId = {1405.4164},
author = {Romano, LB and Opper, M},
eprint = {1405.4164},
journal = {arXiv preprint arXiv:1405.4164},
month = {may},
title = {{Inferring hidden states in a random kinetic Ising model: replica analysis}},
url = {http://arxiv.org/abs/1405.4164},
year = {2014}
}
@article{Douglas1989,
author = {Douglas, RJ J and Martin, KAC A C and Whitteridge, David},
journal = {Neural Computation},
pages = {480--488},
title = {{A canonical microcircuit for neocortex}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.480},
volume = {488},
year = {1989}
}
@article{MaMay06,
author = {Ma, Wei-Li Diana and Hidaka, Hiroshi and May, Bradford J},
journal = {Hearing Research},
month = {feb},
number = {1-2},
pages = {9--21},
title = {{Spontaneous activity in the inferior colliculus of CBA/J mice after manipulations that induce tinnitus}},
volume = {212},
year = {2006}
}
@article{Gustafsson|2000|,
author = {Gustafsson, M G L},
journal = {J. Microsc.},
pages = {82},
title = {{Surpassing the lateral resolution limit by a factor of two using structured illumination microscopy.}},
volume = {198}
}
@article{Levy18042012,
abstract = {The role of local cortical activity in shaping neuronal responses is controversial. Among other questions, it is unknown how the diverse response patterns reported in vivo—lateral inhibition in some cases, approximately balanced excitation and inhibition (co-tuning) in others—compare to the local spread of synaptic connectivity. Excitatory and inhibitory activity might cancel each other out, or, whether one outweighs the other, receptive field properties might be substantially affected. As a step toward addressing this question, we used multiple intracellular recording in mouse primary auditory cortical slices to map synaptic connectivity among excitatory pyramidal cells and the two broad classes of inhibitory cells, fast-spiking (FS) and non-FS cells in the principal input layer. Connection probability was distance-dependent; the spread of connectivity, parameterized by Gaussian fits to the data, was comparable for all cell types, ranging from 85 to 114 $\mu$m. With brief stimulus trains, unitary synapses formed by FS interneurons were stronger than other classes of synapses; synapse strength did not correlate with distance between cells. The physiological data were qualitatively consistent with predictions derived from anatomical reconstruction. We also analyzed the truncation of neuronal processes due to slicing; overall connectivity was reduced but the spatial pattern was unaffected. The comparable spatial patterns of connectivity and relatively strong excitatory-inhibitory interconnectivity are consistent with a theoretical model where either lateral inhibition or co-tuning can predominate, depending on the structure of the input.},
author = {Levy, Robert B and Reyes, Alex D},
doi = {10.1523/JNEUROSCI.5158-11.2012},
journal = {The Journal of Neuroscience},
number = {16},
pages = {5609--5619},
title = {{Spatial Profile of Excitatory and Inhibitory Synaptic Connectivity in Mouse Primary Auditory Cortex}},
url = {http://www.jneurosci.org/content/32/16/5609.abstract},
volume = {32},
year = {2012}
}
@article{Morita,
annote = {undefined},
author = {Morita, S and Yasumatsu, N and Noguchi, J and Kasai, H},
journal = {landesbioscience.com},
keywords = {binding,biology,bioscience,calcium,cancer,cell,cycle,landes,organogenesis,proteins},
title = {{Generation, elimination and weight fluctuations of synapses in the cerebral cortex}},
url = {http://www.landesbioscience.com/journals/cib/article/9564}
}
@article{Astman2006,
abstract = {In addition to the well described fast-inactivating component of the Na+ current [transient Na+ current (INaT)], neocortical neurons also exhibit a low-voltage-activated, slowly inactivating "persistent" Na+ current (INaP), which plays a role in determining neuronal excitability and synaptic integration. We investigated the Na+ channels responsible for INaP in layer 5 pyramidal cells using cell-attached and whole-cell recordings in neocortical slices. In simultaneous cell-attached and whole-cell somatic recordings, no persistent Na+ channel activity was detected at potentials at which whole-cell INaP operates. Detailed kinetic analysis of late Na+ channel activity in cell-attached patches at 36 degrees C revealed that somatic Na+ channels do not demonstrate "modal gating" behavior and that the probability of single late openings is extremely low ({\textless}1.4 x 10(-4) or {\textless}0.02{\%} of maximal open probability of INaT). Ensemble averages of these currents did not reveal a sustained component whose amplitude and voltage dependence could account for INaP as seen in whole-cell recordings. Local application of TTX to the axon blocked somatically recorded INaP, whereas somatic and dendritic application had little or no effect. Finally, simultaneous current-clamp recordings from soma and apical dendrite revealed that Na+ plateau potentials originate closer to the axon. Our data indicate that the primary source of INaP is in the spike initiation zone in the proximal axon. The focal axonal presence of regenerative subthreshold conductance with voltage and time dependence optimal to manipulate integration of synaptic input, spike threshold, and the pattern of repetitive firing provides the layer 5 pyramidal neuron with a mechanism for dynamic control of its gain.},
author = {Astman, N and Gutnick, M J and Fleidervish, I A},
doi = {10.1523/JNEUROSCI.4907-05.2006},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Cells,Cultured,Long-Term Potentiation,Long-Term Potentiation: physiology,Membrane Potentials,Membrane Potentials: physiology,Mice,Neocortex,Neocortex: physiology,Nerve Net,Nerve Net: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Synaptic Transmission,Synaptic Transmission: physiology,Wistar},
month = {mar},
number = {13},
pages = {3465--73},
pmid = {16571753},
title = {{Persistent sodium current in layer 5 neocortical neurons is primarily generated in the proximal axon.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16571753},
volume = {26},
year = {2006}
}
@article{Hochreiter1997,
abstract = {Learning to store information over extended time intervals via recurrent backpropagation takes a very long time, mostly due to insufficient, decaying error back flow. We briefly review Hochreiter's 1991 analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called "Long Short-Term Memory" (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete time steps by enforcing constant error flow through "constant error carrousels" within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with RTRL, BPTT, Recurrent Cascade-Correlation, Elman nets, and Neural Sequence Chunking, LSTM leads to many more successful...},
author = {Hochreiter, Sepp and Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen and Schmidhuber, J{\"{u}}rgen},
doi = {10.1.1.56.7752},
issn = {0899-7667},
journal = {Neural Computation},
number = {8},
pages = {1735--1780},
title = {{Long Short-term Memory}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7752},
volume = {9},
year = {1997}
}
@article{Escola2011,
author = {Escola, S and Fontanini, A and Katz, D and Paninski, L},
journal = {In press, Neural Computation},
title = {{Hidden {\{}M{\}}arkov models for the stimulus-response relationships of multi-state neural systems}},
year = {2011}
}
@article{EICH04,
author = {Eichhorn, J and Tolias, A and Zien, A and Kuss, M and Rasmussen, C and Weston, J and Logothetis, N and Schoelkopf, B},
journal = {NIPS},
title = {{Prediction on spike data using kernel algorithms}},
volume = {16},
year = {2004}
}
@article{Giudicet2000,
author = {Fusi, S and Giudice, P Del and Amit, DJ},
isbn = {0769506194},
journal = {Neural Networks, 2000. IJCNN {\ldots}},
title = {{Neurophysiology of a VLSI spiking neural network: LANN21}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=861291},
year = {2000}
}
@article{Wang1993,
author = {Wang, X J},
journal = {Physica D: Nonlinear Phenomena},
pages = {263--274},
title = {{Genesis of bursting oscillations in the Hindmarsh-Rose model and homoclinicity to a chaotic saddle}},
url = {http://www.sciencedirect.com/science/article/pii/016727899390286A},
volume = {62},
year = {1993}
}
@article{Fiala|2002|,
author = {Fiala, J C and Harris, K M},
journal = {Miscoscopy and Analysis},
pages = {5--8},
title = {{Computer-based alignment and reconstruction of serial sections.}},
volume = {87}
}
@article{Gillijns06,
author = {Gillijns, S and Bernstein, D and {De Moor}, B},
journal = {Proc. of the 14th IFAC Symposium on System Identification},
title = {{The Reduced Rank Transform Square Root Filter for Data Assimilation}},
year = {2006}
}
@article{Chalasani2007,
author = {Chalasani, S H and Chronis, N and Tsunozaki, M and Gray, J M and Ramot, D and Goodman, M B and Bargmann, C I},
journal = {Nature},
pages = {35},
title = {{Dissecting a circuit for olfactory behaviour in Caenorhabditis elegans}},
volume = {450},
year = {2007}
}
@article{Soudry2017,
abstract = {We examine a multilayer neural network with piecewise linear units, input of dimension {\$}d{\_}{\{}0{\}}{\$}, one hidden layer of width {\$}d{\_}{\{}1{\}}{\$}, a single output, and a quadratic loss, trained on {\$}N{\$} datapoints. We prove that in the limit that {\$}N\backslashrightarrow\backslashinfty{\$}, the volume of differentiable regions of the loss containing sub-optimal differentiable local minima is exponentially vanishing in comparison with the same volume of global minima, given standard normal input, {\$}d{\_}{\{}0{\}}\backslashleft(N\backslashright)=\backslashtilde{\{}\backslashOmega{\}}\backslashleft(\backslashsqrt{\{}N{\}}\backslashright){\$} and an asymptotically "mild" over-parameterization: {\$}\backslash{\#}\backslashmathrm{\{}parameters=\backslash,{\}}\backslashtilde{\{}\backslashOmega{\}}\backslashleft(N\backslashright){\$}. Previous results on vanishing local minima so far required many more parameters: {\$}\backslash{\#}\backslashmathrm{\{}parameters=\backslash,{\}}\backslashOmega\backslashleft(Nd{\_}{\{}0{\}}\backslashleft(N\backslashright)\backslashright){\$}, which is typically worse.},
archivePrefix = {arXiv},
arxivId = {1702.05777},
author = {Soudry, D. and Hoffer, Elad},
eprint = {1702.05777},
journal = {ArXiv},
title = {{Exponentially vanishing sub-optimal local minima in multilayer neural networks}},
url = {http://arxiv.org/abs/1702.05777},
year = {2017}
}
@article{KW04,
author = {Koerding, K and Wolpert, D},
journal = {Nature},
pages = {244--247},
title = {{Bayesian Integration in Sensorimotor Learning}},
volume = {427},
year = {2004}
}
@article{Forsgren2002,
author = {Forsgren, Anders},
doi = {10.1016/S0168-9274(02)00119-8},
issn = {01689274},
journal = {Applied Numerical Mathematics},
keywords = {inertia control,optimization,sparse matrix factorization,symmetric indefinite factorization},
number = {1-2},
pages = {91--107},
title = {{Inertia-controlling factorizations for optimization algorithms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168927402001198},
volume = {43},
year = {2002}
}
@article{Bittner2017,
abstract = {Learning is primarily mediated by activity-dependent modifications of synaptic strength within neuronal circuits. Here we report that hippocampal CA1 place fields are produced by a synaptic potentiation that is starkly different from the Hebbian-style plasticity cur-rently thought to control learning. Analyses of in vivo data indicate that place field firing can be produced in a single trial by potentiation of synaptic input that arrived seconds before and after a complex spike event. In addition, the synaptic input that becomes po-tentiated was not initially coincident with any significant action potential firing or mem-brane depolarization. Thus, the plasticity rule we discovered, named behavioral timescale synaptic plasticity, abruptly modifies inputs that were neither causal nor close in time to postsynaptic activation. The existence of such plasticity was confirmed in slice record-ings, where only five pairings of subthreshold presynaptic activity and dendritic Ca 2+ plateau potentials produces a large magnitude potentiation ({\~{}}3X) that decreases with for-ward and backward time constants of 1.3s and 0.7s, respectively. Both the in vitro plas-ticity and in vivo place field formation exhibited a similar pharmacology. Because this novel plasticity efficiently stores entire behavioral sequences within synaptic weights, it appears more suitable for supporting hippocampal-dependent forms of learning than tra-ditional Hebbian-style mechanisms.},
author = {Bittner, Katie C. and Milstein, Aaron D. and Grienberger, Christine and Romani, Sandro and Magee, Jeffrey C. and Magee, Jeffrey C.},
doi = {10.1126/science.aan3846},
issn = {0036-8075},
journal = {Science},
number = {6355},
title = {{Behavioral timescale synaptic plasticity underlies CA1 place fields}},
url = {http://science.sciencemag.org/content/357/6355/1033.full},
volume = {357},
year = {2017}
}
@article{Laughlin1998,
abstract = {We derive experimentally based estimates of the energy used by neural mechanisms to code known quantities of information. Biophysical measurements from cells in the blowfly retina yield estimates of the ATP required to generate graded (analog) electrical signals that transmit known amounts of information. Energy consumption is several orders of magnitude greater than the thermodynamic minimum. It costs 10(4) ATP molecules to transmit a bit at a chemical synapse, and 10(6)-10(7) ATP for graded signals in an interneuron or a photoreceptor, or for spike coding. Therefore, in noise-limited signaling systems, a weak pathway of low capacity transmits information more economically, which promotes the distribution of information among multiple pathways.},
annote = {2010IIInum17 },
author = {Laughlin, S B and {de Ruyter van Steveninck}, R R and Anderson, J C},
doi = {10.1038/236},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adenosine Triphosphate,Adenosine Triphosphate: metabolism,Animals,Diptera,Electrophysiology,Models, Neurological,Neurons,Neurons: metabolism,Neurons: physiology,Photoreceptor Cells, Invertebrate,Photoreceptor Cells, Invertebrate: metabolism,Photoreceptor Cells, Invertebrate: physiology,Retina,Retina: cytology,Retina: metabolism,Retina: physiology,Signal Transduction,Signal Transduction: physiology,Synapses,Synapses: physiology},
month = {may},
number = {1},
pages = {36--41},
pmid = {10195106},
title = {{The metabolic cost of neural information.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1698034{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {1},
year = {1998}
}
@article{Gjorgjieva2016,
abstract = {Despite advances in experimental and theoretical neuroscience, we are still trying to identify key biophysical details that are important for characterizing the operation of brain circuits. Biological mechanisms at the level of single neurons and synapses can be combined as 'building blocks' to generate circuit function. We focus on the importance of capturing multiple timescales when describing these intrinsic and synaptic components. Whether inherent in the ionic currents, the neuron's complex morphology, or the neurotransmitter composition of synapses, these multiple timescales prove crucial for capturing the variability and richness of circuit output and enhancing the information-carrying capacity observed across nervous systems.},
author = {Gjorgjieva, J and Drion, G and Marder, E},
doi = {10.1016/j.conb.2015.12.008},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
number = {Table 1},
pages = {44--52},
pmid = {26774694},
publisher = {Elsevier Ltd},
title = {{Computational implications of biophysical diversity and multiple timescales in neurons and synapses for circuit performance}},
url = {http://dx.doi.org/10.1016/j.conb.2015.12.008},
volume = {37},
year = {2016}
}
@article{Morris1981,
abstract = {Barnacle muscle fibers subjected to constant current stimulation produce a variety of types of oscillatory behavior when the internal medium contains the Ca++ chelator EGTA. Oscillations are abolished if Ca++ is removed from the external medium, or if the K+ conductance is blocked. Available voltage-clamp data indicate that the cell's active conductance systems are exceptionally simple. Given the complexity of barnacle fiber voltage behavior, this seems paradoxical. This paper presents an analysis of the possible modes of behavior available to a system of two noninactivating conductance mechanisms, and indicates a good correspondence to the types of behavior exhibited by barnacle fiber. The differential equations of a simple equivalent circuit for the fiber are dealt with by means of some of the mathematical techniques of nonlinear mechanics. General features of the system are (a) a propensity to produce damped or sustained oscillations over a rather broad parameter range, and (b) considerable latitude in the shape of the oscillatory potentials. It is concluded that for cells subject to changeable parameters (either from cell to cell or with time during cellular activity), a system dominated by two noninactivating conductances can exhibit varied oscillatory and bistable behavior.},
author = {Morris, C and Lecar, H},
doi = {10.1016/S0006-3495(81)84782-0},
issn = {0006-3495},
journal = {Biophysical Journal},
keywords = {Action Potentials,Animals,Calcium,Calcium: physiology,Electric Conductivity,Models, Biological,Muscles,Muscles: physiology,Potassium,Potassium: physiology,Sarcolemma,Sarcolemma: physiology,Thoracica,Thoracica: physiology},
month = {jul},
number = {1},
pages = {193--213},
pmid = {7260316},
title = {{Voltage oscillations in the barnacle giant muscle fiber.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1327511{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {35},
year = {1981}
}
@article{Baraniuk2007,
author = {Baraniuk, RG},
journal = {Signal Processing Magazine, IEEE},
pages = {1--49},
title = {{Compressive sensing}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4286571},
year = {2007}
}
@article{BP06,
author = {Butts, D and Paninski, L},
journal = {CNS*06 Meeting, Edinburgh},
title = {{Contrast adaptation in descriptions of visual neurons that incorporate spike-history dependence}},
year = {2006}
}
@article{Mishchenko2009b,
author = {Mishchenko, Y and Spacek, J and Mendenhall, J and Chklovskii, D and Harris, K M},
journal = {Submitted},
title = {{Reconstruction of hippocampal {\{}CA1{\}} neuropil at nanometer resolution reveals disordered packing of processes and dependence of synaptic connectivity on local environment and dendritic caliber.}},
year = {2009}
}
@article{Mezard2002a,
abstract = {We study the satisfiability of random Boolean expressions built from many clauses with K variables per clause (K-satisfiability). Expressions with a ratio alpha of clauses to variables less than a threshold alphac are almost always satisfiable, whereas those with a ratio above this threshold are almost always unsatisfiable. We show the existence of an intermediate phase below alphac, where the proliferation of metastable states is responsible for the onset of complexity in search algorithms. We introduce a class of optimization algorithms that can deal with these metastable states; one such algorithm has been tested successfully on the largest existing benchmark of K-satisfiability.},
author = {M{\'{e}}zard, M and Parisi, G and Zecchina, R},
doi = {10.1126/science.1073287},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Message passing},
mendeley-tags = {Message passing},
month = {aug},
number = {5582},
pages = {812--5},
pmid = {12089451},
title = {{Analytic and algorithmic solution of random satisfiability problems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12089451},
volume = {297},
year = {2002}
}
@article{RT96,
author = {Rodriguez, R and Tuckwell, H},
journal = {Physical Review E},
pages = {5585--5590},
title = {{Statistical properties of stochastic nonlinear dynamical models of single spiking neurons and neural networks}},
volume = {54},
year = {1996}
}
@article{Zeng2013,
author = {Zeng, HL and Alava, Mikko and Aurell, Erik and Hertz, J and Roudi, Y},
doi = {10.1103/PhysRevLett.110.210601},
issn = {0031-9007},
journal = {Physical review letters},
month = {may},
number = {21},
pages = {210601},
title = {{Maximum likelihood reconstruction for Ising models with asynchronous updates}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.110.210601 http://prl.aps.org/abstract/PRL/v110/i21/e210601},
volume = {110},
year = {2013}
}
@article{CallawayYuste02,
author = {Callaway, E and Yuste, R},
journal = {Current Opinion in Neurobiology},
pages = {587--592},
title = {{Stimulating neurons with light}},
volume = {12},
year = {2002}
}
@article{Satel2009,
abstract = {Synaptic plasticity is an underlying mechanism of learning and memory in neural systems, but it is controversial whether synaptic efficacy is modulated in a graded or binary manner. It has been argued that binary synaptic weights would be less susceptible to noise than graded weights, which has impelled some theoretical neuroscientists to shift from the use of graded to binary weights in their models. We compare retrieval performance of models using both binary and graded weight representations through numerical simulations of stochastic attractor networks. We also investigate stochastic attractor models using multiple discrete levels of weight states, and then investigate the optimal threshold for dilution of binary weight representations. Our results show that a binary weight representation is not less susceptible to noise than a graded weight representation in stochastic attractor models, and we find that the load capacities with an increasing number of weight states rapidly reach the load capacity with graded weights. The optimal threshold for dilution of binary weight representations under stochastic conditions occurs when approximately 50{\%} of the smallest weights are set to zero.},
author = {Satel, Jason and Trappenberg, Thomas and Fine, Alan},
doi = {10.1007/s11571-009-9083-3},
issn = {1871-4080},
journal = {Cognitive neurodynamics},
keywords = {associative memory {\'{a}} point,attractor networks,synaptic plasticity {\'{a}} binary,versus graded {\'{a}}},
month = {sep},
number = {3},
pages = {243--50},
pmid = {19424822},
title = {{Are binary synapses superior to graded weight representations in stochastic attractor networks?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2727164{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2009}
}
@article{Kolston92,
author = {Kolston, J and Osen, K K and Hackney, C M and Ottersen, O P and Storm-Mathisen, J},
journal = {Anatomy and Embryology},
number = {5},
pages = {443--465},
publisher = {Springer},
title = {{An atlas of glycine-and GABA-like immunoreactivity and colocalization in the cochlear nuclear complex of the guinea pig}},
volume = {186},
year = {1992}
}
@article{GilbertWiesel79,
author = {Gilbert, C and Wiesel, T},
journal = {Nature},
pages = {120--125},
title = {{Morphology and intracortical projections of functionally characterised neurons in the cat visual cortex}},
volume = {280},
year = {1979}
}
@article{Knight72,
author = {Knight, B},
journal = {J. Gen. Physiol.},
pages = {734--766},
title = {{Dynamics of encoding in a population of neurons}},
volume = {59},
year = {1972}
}
@article{Sinai1982,
author = {Sinai, Y A G},
journal = {Theory of Probability and Its Applications},
number = {27},
pages = {256--268},
title = {{The Limiting Behavior of a One-Dimensional Random Walk in a Random Medium}},
year = {1982}
}
@article{Amit91,
author = {Amit, D J and Tsodyks, M V},
journal = {Network},
pages = {259--273},
title = {{Quantitative study of attractor neural networks retrieving at low spike rates. I: Substrate --- spikes, rates, and neuronal gain.}},
volume = {2},
year = {1991}
}
@article{Spruston2008,
abstract = {Pyramidal neurons are characterized by their distinct apical and basal dendritic trees and the pyramidal shape of their soma. They are found in several regions of the CNS and, although the reasons for their abundance remain unclear, functional studies--especially of CA1 hippocampal and layer V neocortical pyramidal neurons--have offered insights into the functions of their unique cellular architecture. Pyramidal neurons are not all identical, but some shared functional principles can be identified. In particular, the existence of dendritic domains with distinct synaptic inputs, excitability, modulation and plasticity appears to be a common feature that allows synapses throughout the dendritic tree to contribute to action-potential generation. These properties support a variety of coincidence-detection mechanisms, which are likely to be crucial for synaptic integration and plasticity.},
annote = {2010IInum12.29},
author = {Spruston, Nelson},
doi = {10.1038/nrn2286},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Dendrites,Dendrites: physiology,Hippocampus,Hippocampus: cytology,Models,Neocortex,Neocortex: cytology,Neurological,Neuron Model,Pyramidal Cells,Pyramidal Cells: physiology,Pyramidal Cells: ultrastructure,Synapses,Synapses: physiology,Synapses: ultrastructure},
mendeley-tags = {Neuron Model},
month = {mar},
number = {3},
pages = {206--21},
pmid = {18270515},
title = {{Pyramidal neurons: dendritic structure and synaptic integration.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18270515},
volume = {9},
year = {2008}
}
@article{Trommald|1997|,
author = {Trommald, M and Hulleberg, G},
journal = {J. Comp. Neurol.},
pages = {15--28},
title = {{Dimensions and density of dendritic spines from rat dentate granule cells based on reconstructions from serial electron micrographs.}},
volume = {377}
}
@article{PAN05c,
author = {Paninski, L},
journal = {Advances in Neural Information Processing Systems},
title = {{Variational minimax estimation of discrete distributions under {\{}KL{\}} loss}},
volume = {17},
year = {2005}
}
@article{Rangarajan2000,
annote = {2010num2.8},
author = {Rangarajan, Govindan and Ding, M},
journal = {Physical Review E},
number = {5},
pages = {4991--5001},
title = {{Integrated approach to the assessment of long range correlation in time series data}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.61.4991},
volume = {61},
year = {2000}
}
@article{Grubb2010,
author = {Grubb, M S and Burrone, J},
doi = {10.1038/nature09160},
issn = {0028-0836},
journal = {Nature},
month = {jun},
number = {7301},
pages = {1070--1074},
publisher = {Nature Publishing Group},
title = {{Activity-dependent relocation of the axon initial segment fine-tunes neuronal excitability}},
url = {http://www.nature.com/doifinder/10.1038/nature09160},
volume = {465},
year = {2010}
}
@article{Ikegaya2005,
author = {Ikegaya, Y and {Le Bon-Jego}, M and Yuste, R},
journal = {Neuroscience Research},
pages = {132--138},
title = {{Large-scale imaging of cortical network activity with calcium indicators.}},
volume = {52},
year = {2005}
}
@article{Hurlimann02,
author = {Hurlimann, F and Kiper, D and Carandini, M},
journal = {Vision Research},
pages = {2253--2257},
title = {{Testing the Bayesian model of perceived speed}},
volume = {42},
year = {2002}
}
@article{Magleby1986,
author = {Magleby, K L and Box, P O},
number = {1986},
pages = {141--174},
title = {{of Phy8iology}},
year = {1986}
}
@article{Hogan2007,
author = {Hogan, S.J. and Higham, L. and Griffin, T.C.L.},
doi = {10.1098/rspa.2006.1735},
issn = {1364-5021},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
month = {jan},
number = {2077},
pages = {49--65},
title = {{Dynamics of a piecewise linear map with a gap}},
url = {http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.2006.1735},
volume = {463},
year = {2007}
}
@article{Schoenauer1998,
author = {Schoenauer, T and Jahnke, A and Roth, U and Klar, H},
journal = {Proceedings of Neuronal {\ldots}},
keywords = {neuro-accelerators,neurochips,neurocomputer,parallel processing},
pages = {101--106},
title = {{Digital neurohardware: principles and perspectives}},
url = {https://www.fer.unizg.hr/{\_}download/repository/schoenauer98digital.pdf},
year = {1998}
}
@article{Meyer02,
author = {Meyer, Axel H and Katona, Istvan and Blatow, Maria and Rozov, Andrei and Monyer, Hannah},
journal = {J. Neurosci.},
pages = {7055--7064},
title = {{In Vivo Labeling of Parvalbumin-Positive Interneurons and Analysis of Electrical Coupling in Identified Neurons}},
volume = {22},
year = {2002}
}
@article{Keener1980,
annote = {2011num21},
author = {Keener, J P},
issn = {0002-9947},
journal = {Transactions of the American Mathematical Society},
number = {2},
pages = {589--604},
publisher = {American Mathematical Society},
title = {{Chaotic behavior in piecewise continuous difference equations}},
url = {http://www.ams.org/journals/tran/1980-261-02/S0002-9947-1980-0580905-3/S0002-9947-1980-0580905-3.pdf},
volume = {261},
year = {1980}
}
@incollection{Rinzel1998,
annote = {2011num51},
author = {Rinzel, J and Ermentrout, B},
booktitle = {Methods},
title = {analysis of neural excitabiilty and oscillations},
year = {1998}
}
@article{Lewicki98,
author = {Lewicki, M},
journal = {Network: Computation in Neural Systems},
pages = {R53----R78},
title = {{A review of methods for spike sorting: the detection and classification of neural action potentials}},
volume = {9},
year = {1998}
}
@article{Badoni1995,
author = {Badoni, Davide and Bertazzoni, Stefano},
journal = {Network: {\ldots}},
pages = {1--46},
title = {{Electronic implementation of an analogue attractor neural network with stochastic learning}},
url = {http://informahealthcare.com/doi/abs/10.1088/0954-898X{\_}6{\_}2{\_}002},
year = {1995}
}
@article{delaRocha07,
author = {de la Rocha, J and Doiron, B and Shea-Brown, E and Josic, K and Reyes, A},
journal = {Nature},
pages = {802--806},
title = {{Correlation between neural spike trains increases with firing rate}},
volume = {448},
year = {2007}
}
@article{RS99,
author = {Reyes, A and Sakmann, B},
journal = {Journal of Neuroscience},
pages = {3827--3835},
title = {{Developmental switch in the short-term modification of unitary EPSPs evoked in layer 2/3 and layer 5 pyramidal neurons of rat neocortex}},
volume = {19},
year = {1999}
}
@article{Spergel|2000|,
abstract = {Cosmological models with cold dark matter composed of weakly interacting
particles predict overly dense cores in the centers of galaxies and
clusters and an overly large number of halos within the Local Group
compared to actual observations. We propose that the conflict can
be resolved if the cold dark matter particles are self-interacting
with a large scattering cross section but negligible annihilation
or dissipation. In this scenario, astronomical observations may enable
us to study dark matter properties that are inaccessible in the laboratory.},
annote = {This paper puts forward a survey of medim-scale inconsistencies in{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}CDM model and suggests SIMP as explanation for galaxy-scale deviations.},
author = {Spergel, D N and Steinhardt, P J},
journal = {Physical Review Letters},
keywords = {CDM,astrophysics,cold dark matter,cusp,dark matter,evidence,halo,interaction,observational,physics,profile,strongly interacting dark matter},
number = {17},
pages = {3760},
title = {{Observational Evidence for Self-Interacting Cold Dark Matter}},
volume = {84}
}
@misc{MB02,
author = {Mascaro, M and Bradley, D},
howpublished = {Unpublished abstract at http://www.compscipreprints.com/},
title = {{Optimized neuronal tuning algorithm for multichannel recording}},
year = {2002}
}
@article{Komlosi2012,
abstract = {Selective serotonin reuptake inhibitors are the most widely prescribed drugs targeting the CNS with acute and chronic effects in cognitive, emotional and behavioral processes. This suggests that microcircuits of the human cerebral cortex are powerfully modulated by selective serotonin reuptake inhibitors, however, direct measurements of serotonergic regulation on human synaptic interactions are missing. Using multiple whole-cell patch-clamp recordings from neurons in acute cortical slices derived from nonpathological human samples of the prefrontal cortex, we show that neuronal assemblies triggered by single action potentials of individual neurons in the human cortex are suppressed by therapeutic doses of fluoxetine (Prozac). This effect is boosted and can be mimicked by physiological concentrations of serotonin through 5HT-2A and 5HT-1A receptors. Monosynaptic excitatory connections from pyramidal cells to interneurons were suppressed by application of serotonin leaving the monosynaptic output of GABAergic cells unaffected. Changes in failure rate, in paired-pulse ratio, and in the coefficient of variation of the amplitude of EPSPs suggest a presynaptic action of serotonin. In conclusion, activation of neuronal assemblies, which were suggested as building blocks of high order cognitive processes, are effectively downregulated by the acute action of selective serotonin reuptake inhibitors or serotonin at the site of pyramidal output in human microcircuits.},
author = {Koml{\'{o}}si, Gergely and Moln{\'{a}}r, G{\'{a}}bor and R{\'{o}}zsa, M{\'{a}}rton and Ol{\'{a}}h, Szabolcs and Barz{\'{o}}, P{\'{a}}l and Tam{\'{a}}s, G{\'{a}}bor},
doi = {10.1523/JNEUROSCI.2618-12.2012},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Adult,Aged,Brain Neoplasms,Brain Neoplasms: surgery,Excitatory Amino Acids,Excitatory Amino Acids: physiology,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: drug effects,Female,Fluoxetine,Fluoxetine: pharmacology,Glutamic Acid,Glutamic Acid: physiology,Humans,Male,Middle Aged,Nerve Net,Nerve Net: cytology,Nerve Net: drug effects,Nerve Net: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: drug effects,Prefrontal Cortex: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Receptor, Serotonin, 5-HT1A,Receptor, Serotonin, 5-HT1A: drug effects,Receptor, Serotonin, 5-HT2A,Receptor, Serotonin, 5-HT2A: drug effects,Serotonin,Serotonin Uptake Inhibitors,Serotonin Uptake Inhibitors: pharmacology,Serotonin: pharmacology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {nov},
number = {46},
pages = {16369--78},
pmid = {23152619},
title = {{Fluoxetine (prozac) and serotonin act on excitatory synaptic transmission to suppress single layer 2/3 pyramidal neuron-triggered cell assemblies in the human prefrontal cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3752144{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {32},
year = {2012}
}
@article{MART00,
author = {Martignon, L and Deco, G and Laskey, K and Diamond, M and Freiwald, W and Vaadia, E},
journal = {Neural Computation},
pages = {2621--2653},
title = {{Neural coding: higher-order temporal patterns in the neuro-statistics of cell assemblies}},
volume = {12},
year = {2000}
}
@article{carroll2001role,
annote = {2010num5.1},
author = {Carroll, R C and Beattie, E C and von Zastrow, M and Malenka, R C},
journal = {Nature Reviews Neuroscience},
number = {5},
pages = {315--324},
title = {{Role of AMPA receptor endocytosis in synaptic plasticity}},
volume = {2},
year = {2001}
}
@article{Nodelman2003,
annote = {2010IIInum52},
author = {Nodelman, U and Shelton, CR R and Koller, D},
journal = {Proceedings of the Nineteenth {\ldots}},
keywords = {ion channel,math},
mendeley-tags = {ion channel,math},
title = {{Learning continuous time Bayesian networks}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.1934{\&}rep=rep1{\&}type=pdf},
year = {2003}
}
@misc{Johnson|2006|,
annote = {This presentation deals with edge detection using wavelets and scale{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}determination using wavelets},
author = {Johnson, B D},
keywords = {computational,edge detection,image processing,multiscale,wavelets},
title = {{Wavelets and Multiscale Edge Detection}}
}
@article{Parnas1979,
abstract = {1. A mathematical model based on the Hodgkin-Huxley equations is derived to describe quantitatively the propagation of action potentials in a branching axon. 2. The model treats the case of a bifurcating axon with branches of different diameters. The solution takes into account the changes in space constant in the different regions. 3. The model allows for investigating parameters leading to preferential conduction of action potentials in one daughter branch as seen experimentally. 4. Assuming that the only difference between the various daughter branches is in their diameters, conduction blocks should occur simultaneously rather than differentially into all daughter branches when the geometrical ratio is greater than 10. 5. In order to obtain differential conduction into the two branches changes in ionic concentrations due to the repetitive action potentials had to be introduced into the equations. 6. We find that conditions which allow differential buildup of K concentration around the two branches, produce differential conduction block. These conditions may be different periaxonal spaces around the branches or different time constant for recovery processes that eliminate K from the periaxonal space. 7. The effects of an inexcitable branch on conduction of action potentials in the second branch are described. 8. We find that the membrane current which is associated with the action potential is much more sensitive than the action potential itself and shows more distinct changes near regions of inhomogeneity such as a branch point, a step increase in diameter or an inexcitable branch.},
author = {Parnas, I and Segev, I},
journal = {Journal of Physiology},
month = {oct},
number = {1},
pages = {323--343},
title = {{A mathematical model for conduction of action potentials along bifurcating axons.}},
url = {http://jp.physoc.org/cgi/content/abstract/295/1/323},
volume = {295},
year = {1979}
}
@article{Singh|2005|,
abstract = {In this paper, we present a new approach to edge detection. We see
edges as delineators of local, photometrically coherent clusters
of pixels. We are concerned with edges at a given pair of photometric
and spatial scales. We first define the Similarity Region (SR) of
a pixel as the set of pixels in it's neighborhood that form a local
cluster with the pixel. The SR is discovered by using an affinity
measure at the given spatial and photometric scales. It follows then
that the SR's for two adjacent pixels within a region will be similar
and they will be different for pixels across a region boundary. This
property is used to determine if there is an edge between any two
pixels. SR's of a pixel pair are evaluated for similarity in two
ways - by comparing their geometric properties and by comparing the
affinity distributions of pixels within them. This leads to two edge
operators. The first uses Normalized difference of Moments (NdM)
of the two SR's, while the second uses a $\chi${\^{}}2-measure of the two
affinity distributions. These edge operators are fast, they respond
to local edge freatures like corners faithfully and they do not introduce
bias or localization errors for images with ESNR (Edge Strength to
Noise Ratio) greater than 10dB. For higher noise, the methods respond
to edges of regions formed by noise. For robustness, we propose a
preprocessing step that clusters data. To this end, we present two
clustering algorithms based on cost function optimization. The first
algorithm is an Iterated Mode algorithm that uses the histogram of
pixel values in a local window to replace each pixel value with a
value that has higher probability of occurrence at that pixel. The
second algoruthm minimizes a Soft Clustering Evaluation Function
(SCEF) to partition the image into clusters such that the mutual
information between these clusters is minimized. This work is closely
related to Rosenfeld et al.'s iterative smoothing algoruthms, histogram-based
techniques and pyramid linking shcmes; these relationships are pointed
out. We present the responses of edge operators on synthetic and
real images. The integration of these operators to define coherent
edge detectors will be reported in the near future.},
annote = {The paper deals with edge detection as interface between homogeneous{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}regions. It is related to hierarchical clustering and multiscale{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}clustering/smoothing in a way. No doubt applicable to segmentation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of different grayscale level/color regions, but uncertain in applicability{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}for narrow dark edges detection.},
author = {Singh, M K and Ahuja, N},
keywords = {computational,edge-detection,hierarchical clustering,image processing,multiscale filtering,pyramid linking,segmentation},
title = {{Edge measures using similarity regions}}
}
@article{RyugoMay93,
abstract = {The cochlear nucleus receives incoming auditory nerve discharges,

preserves or transforms the signals, and distributes outgoing activity

to higher centers. The organization of auditory nerve input to the

cochlear nucleus will heavily influence the mechanisms by which acoustic

information is processed. In order to study structure-function relationships

between auditory nerve and cochlear nucleus, the axonal arborizations

of type I spiral ganglion cells were labeled with intracellular injections

of horseradish peroxidase after first being electrophysiologically

characterized by recording with a micropipette inserted into the

axon. For each auditory nerve fiber, spontaneous discharge rate (SR)

and a frequency tuning curve were determined. The tuning curve yielded

the characteristic frequency (CF, that frequency to which the fiber

is most sensitive) and CF threshold in dB SPL. Individual axonal

arborizations including all terminal swellings were reconstructed

through serial sections with the aid of a light microscope and drawing

tube. On average, 13.4 +/- 8.1{\%} of the terminal swellings were found

in the dorsal cochlear nucleus (DCN) and the remaining terminal swellings

were located in the ventral cochlear nucleus. In the DCN, the terminal

fields of auditory nerve fibers were restricted to layer III, contributed

to cytoarchitectonic striations, and exhibited a systematic relationship

between fiber CF and position along the strial (or long) axis of

the nucleus. Computer-aided rotations revealed that the terminal

fields were anisotropic, being flattened within the trans-strial

axis. The maximal width of the terminal fields along the strial axis

ranged from 31-321 microns and was inversely related to fiber CF

and SR. Variation in the number of terminals or depth of the terminal

field within layer III was not related to SR grouping or CF of the

fiber.},
author = {Ryugo, D K and May, S K},
doi = {10.1002/cne.903290103},
journal = {J Comp Neurol},
keywords = {Afferent; Pons; Vestibulocochlear Nerve,Animals; Auditory Pathways; Brain Mapping; Cats; C},
month = {mar},
number = {1},
pages = {20--35},
pmid = {8454724},
title = {{The projections of intracellularly labeled auditory nerve fibers to the dorsal cochlear nucleus of cats.}},
url = {http://dx.doi.org/10.1002/cne.903290103},
volume = {329},
year = {1993}
}
@article{Ingber,
abstract = {This paper focuses on how bottom-up neocortical models can be developed
into eigenfunction expansions of probability distributions appropriate
to describe short-term memory in the context of scalp EEG. The mathematics
of eigenfunctions are similar to the top-down eigenfunctions developed
by Nunez, albeit they hav e different physical manifestations. The
bottom-up eigenfunctions are at the local mesocolumnar scale, whereas
the top-down eigenfunctions are at the global regional scale. However,
as described in several joint papers, our approaches have regions
of substantial overlap, and future studies may expand top-down eigenfunctions
into the bottom-up eigenfunctions, yielding a model of scalp EEG
that is ultimately expressed in terms of columnar states of neocortical
processing of attention and short-term memory.},
author = {Ingber, L and LLC, D R W Investments},
keywords = {eigenfunctions,electroencyphalogram,imaging,neurobiology,nonlinear,short-term memory,statistical},
title = {{Statistical mechanics of neocortical interactions: EEG eigenfunctions of short-term memory}}
}
@article{Shalev-Shwartz2017,
abstract = {Exploiting the great expressive power of Deep Neural Network architectures, relies on the ability to train them. While current theoretical work provides, mostly, results showing the hardness of this task, empirical evidence usually differs from this line, with success stories in abundance. A strong position among empirically successful architectures is captured by networks where extensive weight sharing is used, either by Convolutional or Recurrent layers. Additionally, characterizing specific aspects of different tasks, making them "harder" or "easier", is an interesting direction explored both theoretically and empirically. We consider a family of ConvNet architectures, and prove that weight sharing can be crucial, from an optimization point of view. We explore different notions of the frequency, of the target function, proving necessity of the target function having some low frequency components. This necessity is not sufficient - only with weight sharing can it be exploited, thus theoretically separating architectures using it, from others which do not. Our theoretical results are aligned with empirical experiments in an even more general setting, suggesting viability of examination of the role played by interleaving those aspects in broader families of tasks.},
archivePrefix = {arXiv},
arxivId = {1706.00687},
author = {Shalev-Shwartz, Shai and Shamir, Ohad and Shammah, Shaked},
eprint = {1706.00687},
month = {jun},
title = {{Weight Sharing is Crucial to Succesful Optimization}},
url = {http://arxiv.org/abs/1706.00687},
year = {2017}
}
@article{GordonSmith93,
author = {Gordon, N J and Salmond, D J and Smith, A F M},
journal = {Radar and Signal Processing, IEE Proceedings F},
number = {2},
pages = {107--113},
title = {{Novel approach to nonlinear/non-Gaussian Bayesian state estimation}},
volume = {140},
year = {1993}
}
@book{Sra2012,
author = {Sra, S and Nowozin, S and Wright, SJ},
isbn = {9780262016469},
title = {{Optimization for machine learning}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=JPQx7s2L1A8C{\&}oi=fnd{\&}pg=PR5{\&}dq=Optimization+for+Machine+Learning{\&}ots=vce7wkh3D9{\&}sig=RUvM8{\_}bApdXrkgyZ4d2Nyxq1iQ0},
year = {2012}
}
@article{Farrar|1984|,
abstract = {A light gluino is not presently excluded experimentally if the lightest
of the gluino-containing R-hadrons are long lived. In this case the
properties of R-hadrons are very different than has been previously
assumed. Strategies for their detection are suggested.},
author = {Farrar, G R},
journal = {Physical Review Letters},
keywords = {SUSY,astrophysics,physics,quantum field theory,supersymmetry},
number = {11},
pages = {1029},
title = {{Light Gluinos}},
volume = {53}
}
@article{Meltzer2009,
author = {Meltzer, Talya and Globerson, Amir and Weiss, Y},
journal = {{\ldots} of the Twenty-Fifth Conference on {\ldots}},
keywords = {Message passing},
mendeley-tags = {Message passing},
title = {{Convergent message passing algorithms: a unifying view}},
url = {http://dl.acm.org/citation.cfm?id=1795160},
year = {2009}
}
@article{Pillow2008,
abstract = {Statistical dependencies in the responses of sensory neurons govern both the amount of stimulus information conveyed and the means by which downstream neurons can extract it. Although a variety of measurements indicate the existence of such dependencies, their origin and importance for neural coding are poorly understood. Here we analyse the functional significance of correlated firing in a complete population of macaque parasol retinal ganglion cells using a model of multi-neuron spike responses. The model, with parameters fit directly to physiological data, simultaneously captures both the stimulus dependence and detailed spatio-temporal correlations in population responses, and provides two insights into the structure of the neural code. First, neural encoding at the population level is less noisy than one would expect from the variability of individual neurons: spike times are more precise, and can be predicted more accurately when the spiking of neighbouring neurons is taken into account. Second, correlations provide additional sensory information: optimal, model-based decoding that exploits the response correlation structure extracts 20{\%} more information about the visual scene than decoding under the assumption of independence, and preserves 40{\%} more visual information than optimal linear decoding. This model-based approach reveals the role of correlated activity in the retinal coding of visual stimuli, and provides a general framework for understanding the importance of correlated activity in populations of neurons.},
author = {Pillow, J W and Shlens, J and Paninski, L and Sher, A and Litke, A M and Chichilnisky, E J and Simoncelli, E P},
doi = {10.1038/nature07140},
issn = {1476-4687},
journal = {Nature},
keywords = {Action Potentials,Animals,Macaca mulatta,Macaca mulatta: physiology,Models,Neurological,Ocular,Ocular: physiology,Photic Stimulation,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,Time Factors,Vision},
month = {aug},
number = {7207},
pages = {995--9},
pmid = {18650810},
title = {{Spatio-temporal correlations and visual signalling in a complete neuronal population.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2684455{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {454},
year = {2008}
}
@book{Mountcastle95,
author = {Mountcastle, Vernon},
publisher = {Harvard University Press},
title = {{Perceptual Neuroscience: The Cerebral Cortex}},
year = {1995}
}
@article{Akemann2010,
author = {Akemann, Walther and Mutoh, Hiroki and Perron, Amelie and Rossier, Jean and Knopfel, Thomas},
journal = {Nature Methods},
pages = {643--649},
title = {{Imaging brain electric signals with genetically targeted voltage-sensitive fluorescent proteins.}},
volume = {7},
year = {2010}
}
@article{DombeckTank07,
abstract = {We report a technique for two-photon fluorescence imaging with cellular
resolution in awake, behaving mice with minimal motion artifact.
The apparatus combines an upright, table-mounted two-photon microscope
with a spherical treadmill consisting of a large, air-supported Styrofoam
ball. Mice, with implanted cranial windows, are head restrained under
the objective while their limbs rest on the ball's upper surface.
Following adaptation to head restraint, mice maneuver on the spherical
treadmill as their heads remain motionless. Image sequences demonstrate
that running-associated brain motion is limited to approximately
2-5 microm. In addition, motion is predominantly in the focal plane,
with little out-of-plane motion, making the application of a custom-designed
Hidden-Markov-Model-based motion correction algorithm useful for
postprocessing. Behaviorally correlated calcium transients from large
neuronal and astrocytic populations were routinely measured, with
an estimated motion-induced false positive error rate of {\textless}5{\%}.},
author = {Dombeck, Daniel A and Khabbaz, Anton N and Collman, Forrest and Adelman, Thomas L and Tank, David W},
doi = {10.1016/j.neuron.2007.08.003},
journal = {Neuron},
month = {oct},
number = {1},
pages = {43--57},
pmid = {17920014},
title = {{Imaging large-scale neural activity with cellular resolution in awake, mobile mice.}},
url = {http://dx.doi.org/10.1016/j.neuron.2007.08.003},
volume = {56},
year = {2007}
}
@incollection{BROW05,
author = {Brown, E},
booktitle = {Methods and Models in Neurophysics},
editor = {Chow, C and Gutkin, B and Hansel, D and Meunier, C and Dalibard, J},
pages = {691--726},
publisher = {Elsevier},
title = {{The theory of point processes for neural systems}},
year = {2005}
}
@article{Sotiropoulos2009,
abstract = {Two very important characteristics of biological reaction networks need to be considered carefully when modeling these systems. First, models must account for the inherent probabilistic nature of systems far from the thermodynamic limit. Often, biological systems cannot be modeled with traditional continuous-deterministic models. Second, models must take into consideration the disparate spectrum of time scales observed in biological phenomena, such as slow transcription events and fast dimerization reactions. In the last decade, significant efforts have been expended on the development of stochastic chemical kinetics models to capture the dynamics of biomolecular systems, and on the development of robust multiscale algorithms, able to handle stiffness. In this paper, the focus is on the dynamics of reaction sets governed by stiff chemical Langevin equations, i.e., stiff stochastic differential equations. These are particularly challenging systems to model, requiring prohibitively small integration step sizes. We describe and illustrate the application of a semianalytical reduction framework for chemical Langevin equations that results in significant gains in computational cost.},
author = {Sotiropoulos, Vassilios and Contou-Carrere, Marie-Nathalie and Daoutidis, Prodromos and Kaznessis, Yiannis N},
doi = {10.1109/TCBB.2009.23},
isbn = {2008050084},
issn = {1557-9964},
journal = {IEEE/ACM transactions on computational biology and bioinformatics / IEEE, ACM},
keywords = {Algorithms,Bacteria,Bacteria: chemistry,Cataract,Cataract: enzymology,L-Iditol 2-Dehydrogenase,L-Iditol 2-Dehydrogenase: metabolism,Markov Chains,Models, Biological,Models, Chemical,Systems Biology},
number = {3},
pages = {470--82},
pmid = {19644174},
title = {{Model reduction of multiscale chemical langevin equations: a numerical case study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19644174},
volume = {6},
year = {2009}
}
@book{Goodwin1977,
address = {New York, New York, USA},
author = {Goodwin, G C and Payne, R L},
publisher = {Academic Press New York},
title = {{Dynamic system identification: Experiment design and data analysis}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=oUY0bKa3WToC{\&}oi=fnd{\&}pg=PP2{\&}dq=Dynamic+system+identification:+Experiment+design+and+data+analysis{\&}ots=jugU9di0jE{\&}sig=z1UEtNS35WUOR7nhsiIYOhCxmIw},
year = {1977}
}
@article{Chains1978,
author = {Kurtz, TG},
journal = {Stochastic Processes and Their Applications},
pages = {223--240},
title = {{Strong approximation theorems for density dependent Markov chains}},
url = {http://www.sciencedirect.com/science/article/pii/0304414978900200},
volume = {6},
year = {1978}
}
@article{Josic,
author = {Josic, K.},
journal = {caam.rice.edu},
pages = {1--12},
title = {{Point processes and elements of neural coding}},
url = {http://www.caam.rice.edu/{~}cox/reu/probtut.pdf}
}
@article{Kolka2006,
author = {Kolka, Zden{\v{e}}k},
journal = {on System science and simulation in},
number = {4},
pages = {377--380},
title = {{Numerical algorithms for symbolic analysis of large circuits}},
url = {http://www.wseas.us/e-library/conferences/2006tenerife/papers/541-362.pdf},
year = {2006}
}
@article{Zhu2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1212.5860v1},
author = {Zhu, Shenghuo},
eprint = {arXiv:1212.5860v1},
journal = {arXiv preprint arXiv:1212.5860},
number = {6},
pages = {1--5},
title = {{A short note on the tail bound of Wishart distribution}},
url = {http://arxiv.org/abs/1212.5860},
volume = {1},
year = {2012}
}
@article{WENN04,
author = {Wennekers, T},
journal = {Journal of Computational Neuroscience},
pages = {27--38},
title = {{Separation of spatio-temporal receptives fields into sums of {\{}G{\}}aussians component}},
volume = {16},
year = {2004}
}
@article{SmithOtis05,
author = {Smith, Spencer Lavere and Otis, Thomas Stephen},
journal = {Proceedings of The National Academy Of Sciences Of The United States Of America},
month = {oct},
number = {41},
pages = {14901--14906},
title = {{Pattern-dependent, simultaneous plasticity differentially transforms the input-output relationship of a feedforward circuit}},
volume = {102},
year = {2005}
}
@article{DAR53,
author = {Darling, D},
journal = {Annals of Mathematical Statistics},
pages = {239--253},
title = {{On a class of problems related to the random division of an interval}},
volume = {24},
year = {1953}
}
@article{Maclean06,
author = {MacLean, J and Fenstermaker, V and Watson, B and Yuste, R},
journal = {Nature Methods},
pages = {129--134},
title = {{A visual thalamocortical slice}},
volume = {3},
year = {2006}
}
@article{Polsky2009,
abstract = {Bursts of action potentials are important information-bearing signals in the brain, although the neuronal specializations underlying burst generation and detection are only partially understood. In apical dendrites of neocortical pyramidal neurons, calcium spikes are known to contribute to burst generation, but a comparable understanding of basal dendritic mechanisms is lacking. Here we show that NMDA spikes in basal dendrites mediate both detection and generation of bursts through a postsynaptic mechanism. High-frequency inputs to basal dendrites markedly facilitated NMDA spike initiation compared with low-frequency activation or single inputs. Unlike conventional temporal summation effects based on voltage, however, NMDA spike facilitation depended mainly on residual glutamate bound to NMDA receptors from previous activations. Once triggered by an input burst, we found that NMDA spikes in turn reliably trigger output bursts under in vivo-like stimulus conditions. Through their unique biophysical properties, NMDA spikes are thus ideally suited to promote the propagation of bursts through the cortical network.},
annote = {2010IInum12.39},
author = {Polsky, A and Mel, B and Schiller, J},
doi = {10.1523/JNEUROSCI.5250-08.2009},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Animals,Calcium Channel Blockers,Calcium Channel Blockers: pharmacology,Cerebral Cortex,Cerebral Cortex: drug effects,Cerebral Cortex: physiology,Computer Simulation,Dendrites,Dendrites: drug effects,Dendrites: physiology,Electric Stimulation,Glutamic Acid,Glutamic Acid: metabolism,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: metabolism,N-Methylaspartate,N-Methylaspartate: metabolism,Neuronal Plasticity,Neuronal Plasticity: drug effects,Neuronal Plasticity: physiology,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: drug effects,Pyramidal Cells: physiology,Rats,Receptors,Sodium Channel Blockers,Sodium Channel Blockers: pharmacology,Synapses,Synapses: drug effects,Synapses: physiology,Time Factors,Wistar},
month = {sep},
number = {38},
pages = {11891--903},
pmid = {19776275},
title = {{Encoding and decoding bursts by NMDA spikes in basal dendrites of layer 5 pyramidal neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19776275},
volume = {29},
year = {2009}
}
@article{Berkes2011,
author = {Berkes, P and Lengyel, M},
journal = {Science},
number = {January},
title = {{Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment}},
url = {http://www.sciencemag.org/content/331/6013/83.short},
year = {2011}
}
@article{Vogels2005,
abstract = {Transmission of signals within the brain is essential for cognitive function, but it is not clear how neural circuits support reliable and accurate signal propagation over a sufficiently large dynamic range. Two modes of propagation have been studied: synfire chains, in which synchronous activity travels through feedforward layers of a neuronal network, and the propagation of fluctuations in firing rate across these layers. In both cases, a sufficient amount of noise, which was added to previous models from an external source, had to be included to support stable propagation. Sparse, randomly connected networks of spiking model neurons can generate chaotic patterns of activity. We investigate whether this activity, which is a more realistic noise source, is sufficient to allow for signal transmission. We find that, for rate-coded signals but not for synfire chains, such networks support robust and accurate signal reproduction through up to six layers if appropriate adjustments are made in synaptic strengths. We investigate the factors affecting transmission and show that multiple signals can propagate simultaneously along different pathways. Using this feature, we show how different types of logic gates can arise within the architecture of the random network through the strengthening of specific synapses.},
annote = {2010IInum9.10},
author = {Vogels, Tim P and Abbott, L F},
doi = {10.1523/JNEUROSCI.3508-05.2005},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Ion Channel Gating,Ion Channel Gating: physiology,Logic,Models, Neurological,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Signal Transduction,Signal Transduction: physiology},
number = {46},
pages = {10786--95},
pmid = {16291952},
title = {{Signal propagation and logic gating in networks of integrate-and-fire neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16291952},
volume = {25},
year = {2005}
}
@misc{Godel|1956|,
author = {Godel, K},
keywords = {complexity,mathematics},
title = {{Letter to Von Neumann: Computational Complexity}}
}
@article{Corson2012,
abstract = {Developmental signaling networks are composed of dozens of components whose interactions are very difficult to quantify in an embryo. Geometric reasoning enumerates a discrete hierarchy of phenotypic models with a few composite variables whose parameters may be defined by in vivo data. Vulval development in the nematode Caenorhabditis elegans is a classic model for the integration of two signaling pathways; induction by EGF and lateral signaling through Notch. Existing data for the relative probabilities of the three possible terminal cell types in diverse genetic backgrounds as well as timed ablation of the inductive signal favor one geometric model and suffice to fit most of its parameters. The model is fully dynamic and encompasses both signaling and commitment. It then predicts the correlated cell fate probabilities for a cross between any two backgrounds/conditions. The two signaling pathways are combined additively, without interactions, and epistasis only arises from the nonlinear dynamical flow in the landscape defined by the geometric model. In this way, the model quantitatively fits genetic experiments purporting to show mutual pathway repression. The model quantifies the contributions of extrinsic vs. intrinsic sources of noise in the penetrance of mutant phenotypes in signaling hypomorphs and explains available experiments with no additional parameters. Data for anchor cell ablation fix the parameters needed to define Notch autocrine signaling.},
author = {Corson, Francis and Siggia, Eric Dean},
doi = {10.1073/pnas.1201505109},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {mar},
number = {15},
pmid = {22434912},
title = {{Geometry, epistasis, and developmental patterning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22434912},
volume = {109},
year = {2012}
}
@article{Clauset2009,
archivePrefix = {arXiv},
arxivId = {arXiv:0706.1062v2},
author = {Clauset, A and Shalizi, CR and Newman, MEJ},
eprint = {arXiv:0706.1062v2},
journal = {SIAM review},
keywords = {62-07,62f99,62p99,65c05,ams subject classifications,heavy-tailed distribu-,likelihood ratio test,maximum likelihood,model selection,pareto,power-law distributions,tions,zipf},
title = {{Power-law distributions in empirical data}},
url = {http://epubs.siam.org/doi/pdf/10.1137/070710111},
year = {2009}
}
@article{deFeo05,
author = {Makarov, Valeri A and Panetsos, Fivos and de Feo, Oscar},
journal = {Journal of Neuroscience Methods},
month = {jun},
number = {2},
pages = {265--279},
title = {{A method for determining neural connectivity and inferring the underlying network dynamics using extracellular spike recordings}},
volume = {144},
year = {2005}
}
@article{Dickman1998a,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/9712115v1},
author = {Dickman, Ronald and Vespignani, Alessandro and Zapperi, Stefano},
eprint = {9712115v1},
journal = {Physical Review E},
primaryClass = {arXiv:cond-mat},
title = {{Self-organized criticality as an absorbing-state phase transition}},
url = {http://pre.aps.org/abstract/PRE/v57/i5/p5095{\_}1},
year = {1998}
}
@article{Foy2004,
author = {Foy, J},
doi = {10.1016/j.tcs.2004.05.001},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {correctness,dynamical systems,hybrid systems,piecewise a ne systems,stability},
month = {sep},
number = {00},
pages = {355 -- 361},
title = {{A dynamical system which must be stable whose stability cannot be proved}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397504003639},
volume = {328},
year = {2004}
}
@article{SEE04,
author = {Seeger, M},
journal = {International Journal of Neural Systems},
pages = {1--38},
title = {{Gaussian Processes for Machine Learning}},
volume = {14},
year = {2004}
}
@inproceedings{MM54,
author = {Miller, G},
booktitle = {Information theory in psychology II-B},
pages = {95--100},
title = {{Note on the bias of information estimates}},
year = {1955}
}
@article{tichavsk?1998posterior,
annote = {2008num24},
author = {Tichavsky, P and Muravchik, C H and Nehorai, A},
journal = {IEEE Transactions on Signal Processing},
number = {5},
pages = {1386--1396},
title = {{Posterior Cramer-Rao bounds for discrete-time nonlinear filtering}},
volume = {46},
year = {1998}
}
@article{Gillespie2000,
author = {Gillespie, D T},
doi = {10.1063/1.481811},
issn = {00219606},
journal = {The Journal of Chemical Physics},
number = {1},
pages = {297},
title = {{The chemical Langevin equation}},
url = {http://link.aip.org/link/JCPSA6/v113/i1/p297/s1{\&}Agg=doi},
volume = {113},
year = {2000}
}
@article{Goldman2001,
abstract = {The electrical characteristics of many neurons are remarkably robust in the face of changing internal and external conditions. At the same time, neurons can be highly sensitive to neuromodulators. We find correlates of this dual robustness and sensitivity in a global analysis of the structure of a conductance-based model neuron. We vary the maximal conductance parameters of the model neuron and, for each set of parameters tested, characterize the activity pattern generated by the cell as silent, tonically firing, or bursting. Within the parameter space of the five maximal conductances of the model, we find directions, representing concerted changes in multiple conductances, along which the basic pattern of neural activity does not change. In other directions, relatively small concurrent changes in a few conductances can induce transitions between these activity patterns. The global structure of the conductance-space maps implies that neuromodulators that alter a sensitive set of conductances will have powerful, and possibly state-dependent, effects. Other modulators that may have no direct impact on the activity of the neuron may nevertheless change the effects of such direct modulators via this state dependence. Some of the results and predictions arising from the model studies are replicated and verified in recordings of stomatogastric ganglion neurons using the dynamic clamp.},
author = {Goldman, M S and Golowasch, J and Marder, E and Abbott, L F},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Animals,Brachyura,Ganglia, Invertebrate,Models, Neurological,Nephropidae,Neural Conduction,Neural Conduction: drug effects,Neural Conduction: physiology,Neurons,Neurons: classification,Neurons: drug effects,Neurons: metabolism,Neurotransmitter Agents,Neurotransmitter Agents: metabolism,Neurotransmitter Agents: pharmacology,Patch-Clamp Techniques,Predictive Value of Tests,Reproducibility of Results,Sensitivity and Specificity},
month = {jul},
number = {14},
pages = {5229--38},
pmid = {11438598},
title = {{Global structure, robustness, and modulation of neuronal models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11438598},
volume = {21},
year = {2001}
}
@article{MAC92,
author = {MacKay, D J C},
journal = {Neural Computation},
pages = {589--603},
title = {{Information-based objective functions for active data selection}},
volume = {4},
year = {1992}
}
@article{ST86,
author = {Steele, J},
journal = {Annals of Statistics},
pages = {753--758},
title = {{An {\{}E{\}}fron-{\{}S{\}}tein inequality for nonsymmetric statistics}},
volume = {14},
year = {1986}
}
@article{Grewe2009,
author = {Grewe, B and Helmchen, F},
journal = {Current Opinion in Neurobiology},
pages = {520--529},
title = {{Optical probing of neuronal ensemble activity}},
year = {2009}
}
@article{FR02,
author = {Field, G and Rieke, F},
journal = {Neuron},
pages = {733--747},
title = {{Mechanisms regulating variability of the single photon responses of mammalian rod photoreceptors}},
volume = {35},
year = {2002}
}
@article{Miller2012,
author = {Miller, Greg},
doi = {10.1126/science.338.6103.30-b},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
month = {oct},
number = {6103},
pages = {30--1},
pmid = {23042864},
title = {{How are memories retrieved?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23042864},
volume = {338},
year = {2012}
}
@article{KP06,
abstract = {Recent developments in multi-electrode recordings enable the simultaneous

measurement of the spiking activity of many neurons. Analysis of

such multineuronal data is one of the key challenge in computational

neuroscience today. In this work, we develop a multivariate point-process

model in which the observed activity of a network of neurons depends

on three terms: (1) the experimentally-controlled stimulus; (2) the

spiking history of the observed neurons; and (3) a hidden term that

corresponds, for example, to common input from an unobserved population

of neurons that is presynaptic to two or more cells in the observed

population. We consider two models for the network firing-rates,

one of which is computationally and analytically tractable but can

lead to unrealistically high firing-rates, while the other with reasonable

firing-rates imposes a greater computational burden. We develop an

expectation-maximization algorithm for fitting the parameters of

both the models. For the analytically tractable model the expectation

step is based on a continuous-time implementation of the extended

Kalman smoother, and the maximization step involves two concave maximization

problems which may be solved in parallel. The other model that we

consider necessitates the use of Monte Carlo methods for the expectation

as well as maximization step. We discuss the trade-off involved in

choosing between the two models and the associated methods. The techniques

developed allow us to solve a variety of inference problems in a

straightforward, computationally efficient fashion; for example,

we may use the model to predict network activity given an arbitrary

stimulus, infer a neuron's ring rate given the stimulus and the activity

of the other observed neurons, and perform optimal stimulus decoding

and prediction. We present several detailed simulation studies which

explore the strengths and limitations of our approach.},
author = {Kulkarni, Jayant E and Paninski, Liam},
doi = {10.1080/09548980701625173},
journal = {Network: Computation in Neural Systems},
month = {dec},
number = {4},
pages = {375--407},
pmid = {17943613},
title = {{Common-input models for multiple neural spike-train data}},
url = {http://dx.doi.org/10.1080/09548980701625173},
volume = {18},
year = {2007}
}
@article{Conti1976,
abstract = {Single myelinated nerve fibres of Rana esculenta were investigated under voltage clamp conditions at 13 degrees C. Fluctuations of steady-state membrane current were measured during the last 152 msec of 190-225 msec pulses depolarizing the membrane by 8-48 mV. Noise power spectral densities were calculated in the frequency range of 6-6-6757 Hz. 2. External application of 150 nM tetrodotoxin (TTX) and/or 10 mM tetraethylammonium (TEA) ion reduced the current fluctuations. The difference of current noise spectra measured in the presence and absence of TTX (TEA) was not changed by the presence of TEA (TTX) during both measurements, and was taken as the spectrum of the Na (K) current fluctuations. 3. Residual current noise during application of both TTX and TEA was, except for some excess noise at the low and high frequency ends of the spectrum, similar to the noise measured from a passive nerve model and could be understood in terms of Nyquist noise of the known resistances and the amplifier noise. 4. Na current fluctuation spectra were interpreted as the sum N/f+SNa(f) where SNa(F) represents the spectrum expected for a set of equal, independent Na channels with only two conductance states (open or closed) which follow Hodgkin-Huxley kinetics. With values of hinfinity, tauh and minfinity measured from macroscopic Na currents, the measured spectra were fitted well by optimizing N, SNa(0) and taum. Values of taum obtained by this method were in fair agreement with values found from macroscopic currents. 5. The 1/f component of Na current noise was roughly proportional to the square of the steady-state Na current, I2. The mean value of N/I2 was (1-1 +/- 0-3) X 10(-4). 6. The current carried by a single Na channel was calculated from fitted spectra and steady-state Na currents measured simultaneously with the current fluctuations. The single channel conductance gamma normalized to zero absolute membrane potential was calculated. The average gamma from twelve measurements at depolarizations of 8-40 mV was 7-9 +/- 0-9 pS (S.E. of mean). The apparent value of gamma was smallest with small depolarizations. Variations of the assumed kinetic properties of the model did not drastically affect the single channel conductance. 7. External application of 0-1 mM-Ni ion lengthened taum in the macroscopic currents and in the fluctuation spectra and enhanced both the steady-state Na current and the current fluctuations. In Ni-treated nodes gamma was smaller than in normal nodes.},
author = {Conti, F and Hille, B and Neumcke, B and Nonner, W and St{\"{a}}mpfli, R},
issn = {0022-3751},
journal = {The Journal of physiology},
keywords = {Animals,Electric Conductivity,Kinetics,Membrane Potentials,Membrane Potentials: drug effects,Nerve Fibers, Myelinated,Nerve Fibers, Myelinated: metabolism,Rana esculenta,Ranvier's Nodes,Ranvier's Nodes: metabolism,Sodium,Sodium: metabolism,Tetraethylammonium Compounds,Tetraethylammonium Compounds: pharmacology,Tetrodotoxin,Tetrodotoxin: pharmacology},
month = {nov},
number = {3},
pages = {699--727},
pmid = {1087643},
title = {{Measurement of the conductance of the sodium channel from current fluctuations at the node of Ranvier.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1307668{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {262},
year = {1976}
}
@article{BrusteinKonnerth03,
abstract = {The zebrafish larva is a powerful model for the analysis of behaviour and the underlying neuronal network activity during early stages of development. Here we employ a new approach of "in vivo" {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging in this preparation. We demonstrate that bolus injection of membrane-permeable {\{}Ca{\}}{\^{}}{\{}2+{\}} indicator dyes into the spinal cord of zebrafish larvae results in rapid staining of essentially the entire spinal cord. Using two-photon imaging, we could monitor {\{}Ca{\}}{\^{}}{\{}2+{\}} signals simultaneously from a large population of spinal neurons with single-cell resolution. To test the method, {\{}Ca{\}}{\^{}}{\{}2+{\}} transients were produced by iontophoretic application of glutamate and, as observed for the first time in a living preparation, of GABA or glycine. Glycine-evoked {\{}Ca{\}}{\^{}}{\{}2+{\}} transients were blocked by the application of strychnine. Sensory stimuli that trigger escape reflexes in mobile zebrafish evoked {\{}Ca{\}}{\^{}}{\{}2+{\}} transients in distinct neurons of the spinal network. Moreover, long-term recordings revealed spontaneous {\{}Ca{\}}{\^{}}{\{}2+{\}} transients in individual spinal neurons. Frequently, this activity occurred synchronously among many neurons in the network. In conclusion, the new approach permits a reliable analysis with single-cell resolution of the functional organisation of developing neuronal networks.},
author = {Brustein, E and Marandi, N and Kovalchuk, Y and Drapeau, P and Konnerth, A},
doi = {10.1007/s00424-003-1138-4},
journal = {Pflugers Arch},
keywords = {Animals,Calcium,Calcium Signaling,Coloring Agen},
month = {sep},
number = {6},
pages = {766--773},
pmid = {12883893},
title = {{Monitoring of neuronal network activity in zebrafish by two-photon {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging.}},
url = {http://dx.doi.org/10.1007/s00424-003-1138-4},
volume = {446},
year = {2003}
}
@article{Kim2009,
author = {Kim, A J and Lazar, A A},
doi = {10.1186/1471-2202-10-S1-P102},
issn = {1471-2202},
journal = {BMC Neuroscience},
number = {Suppl 1},
pages = {P102},
title = {{Recovery of stimuli encoded with a Hodgkin-Huxley neuron using conditional PRCs}},
url = {http://www.biomedcentral.com/1471-2202/10/S1/P102},
volume = {10},
year = {2009}
}
@article{RB97,
author = {Rudd, M and Brown, L},
journal = {Neural Computation},
pages = {1047--1069},
title = {{Noise adaptation in integrate-and-fire neurons}},
volume = {9},
year = {1997}
}
@article{klaas_current_06,
author = {Stephan, K E and Harrison, L M and Kiebel, S J and David, O and Penny, W D and Friston, K J},
journal = {Journal of Biosciences},
number = {1},
pages = {411--416},
title = {{Dynamic causal models of neural system dynamics: current state and future extensions}},
volume = {32},
year = {2007}
}
@article{Lin2009,
annote = {2011num15},
author = {Lin, Hai and Antsaklis, Panos J.},
doi = {10.1109/TAC.2008.2012009},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
month = {feb},
number = {2},
pages = {308--322},
title = {{Stability and Stabilizability of Switched Linear Systems: A Survey of Recent Results}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4782010},
volume = {54},
year = {2009}
}
@article{Cessac2008b,
author = {Cessac, B and Vi{\'{e}}ville, T},
doi = {10.3389/neuro.10.002.2008},
journal = {Front. Comput. Neurosci.},
keywords = {generalized integrate and fi,neural code,neural networks dynamics,re models,spiking network},
pages = {1--20},
title = {{On dynamics of integrate-and-fire neural networks with conductance based synapses}},
volume = {2},
year = {2008}
}
@article{Melamed-Frank1999,
abstract = {Hyperkalemic periodic paralysis (HyperPP) is a hereditary disorder characterized by alternate episodic attacks of muscle weakness and muscle myotonia. The most common mutation associated with HyperPP is a T704M substitution in the skeletal-muscle sodium channel. This mutation increases sodium persistent currents, alters voltage dependence of activation and impairs slow inactivation. The present study shows experimental evidence in support of a potentially important global defect caused by the T704M mutation. While the effective rate of recovery from slow inactivation, in both normal and mutated channels, is related to the duration of past activity by a power law function, the scaling power of the mutated channel is significantly greater. This difference between the channels offers a clue for an explanation to the wide range of time scales, history dependence, and the mixed myotonic/paralysis effect, which mark the clinical picture of HyperPP.},
annote = {2009num14},
author = {Melamed-Frank, M and Marom, S},
issn = {0031-6768},
journal = {Pfl{\"{u}}gers Archiv : European journal of physiology},
keywords = {Cell Line,Electrophysiology,Familial Periodic,Familial Periodic: physiopathology,Humans,Ion Channel Gating,Kinetics,Muscle,Mutation,Paralyses,Plasmids,Skeletal,Skeletal: physiopathology,Sodium Channels,Sodium Channels: genetics,Sodium Channels: physiology},
month = {jul},
number = {2},
pages = {213--217},
pmid = {10370108},
title = {{A global defect in scaling relationship between electrical activity and availability of muscle sodium channels in hyperkalemic periodic paralysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10370108},
volume = {438},
year = {1999}
}
@article{Schrauwen,
author = {Schrauwen, B. and {Van Campenhout}, J.},
doi = {10.1109/IJCNN.2004.1379954},
isbn = {0-7803-8359-1},
journal = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},
pages = {471--475},
publisher = {Ieee},
title = {{Extending SpikeProp}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1379954}
}
@article{Strogatz2000,
annote = {2010num7.1},
author = {Strogatz, S H},
doi = {10.1016/S0167-2789(00)00094-4},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
keywords = {coupled oscillators,kinetic theory,kuramoto model,plasma physics},
month = {sep},
number = {1-4},
pages = {1--20},
title = {{From Kuramoto to Crawford: exploring the onset of synchronization in populations of coupled oscillators}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167278900000944},
volume = {143},
year = {2000}
}
@article{Mattia2000,
author = {Mattia, Maurizio and Giudice, P Del},
journal = {Neural Computation},
pages = {2305--2329},
title = {{Efficient event-driven simulation of large networks of spiking neurons and dynamical synapses}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976600300014953},
volume = {2329},
year = {2000}
}
@inproceedings{Prodromakis2010,
abstract = {Recent discovery of the memristor has sparked a new wave of enthusiasm and optimism in revolutionising circuit design, marking a new era for the advancement of neuromorphic and analogue applications. In this work, we consider practical applications in which the highly non-linear dynamic response of the memristor can be employed. It is shown that the device can be utilised as a non-volatile memory element and/or a programmable dynamic load, with particular emphasis given into bio-inspired analog implementations that typically exploit the ability of the memristor to support both logic and memory simultaneously. Finally, a novel concept is presented demonstrating the capacity of memristive networks in realising demanding image processing algorithms and more specifically edge detection.},
author = {Prodromakis, T. and Toumazou, C.},
booktitle = {2010 17th IEEE International Conference on Electronics, Circuits and Systems},
doi = {10.1109/ICECS.2010.5724666},
isbn = {978-1-4244-8155-2},
month = {dec},
pages = {934--937},
publisher = {IEEE},
title = {{A review on memristive devices and applications}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=5724666},
year = {2010}
}
@article{Chow2012,
author = {Chow, B Y and Han, X and Bernstein, J G and Monahan, P E and Boyden, E S},
doi = {10.1007/7657},
journal = {Neuromethods},
keywords = {archaerhodopsin,channelrhodopsin,halorhodopsin,light-sensitive cation channel,light-sensitive chloride pump,light-sensitive pro-,optogenetics,photocontrol of behavior,photosensitive proteins,retinal,ton pump},
number = {December 2011},
pages = {305--338},
title = {{Light-activated ion pumps and channels for temporally precise optical control of activity in genetically targeted neurons}},
url = {http://link.springer.com/protocol/10.1007/7657{\_}2011{\_}10},
volume = {67},
year = {2012}
}
@article{Wehr1996,
author = {Wehr, M and Laurent, G},
journal = {Nature},
keywords = {Spike time neural coding},
mendeley-tags = {Spike time neural coding},
title = {{Odour encoding by temporal sequences of firing in oscillating neural assemblies}},
url = {http://zadorlab.cshl.edu/wehr/wehr-laurent1996.pdf},
year = {1996}
}
@article{Huys2006,
abstract = {Biophysically accurate multicompartmental models of individual neurons have significantly advanced our understanding of the input-output function of single cells. These models depend on a large number of parameters that are difficult to estimate. In practice, they are often hand-tuned to match measured physiological behaviors, thus raising questions of identifiability and interpretability. We propose a statistical approach to the automatic estimation of various biologically relevant parameters, including 1) the distribution of channel densities, 2) the spatiotemporal pattern of synaptic input, and 3) axial resistances across extended dendrites. Recent experimental advances, notably in voltage-sensitive imaging, motivate us to assume access to: i) the spatiotemporal voltage signal in the dendrite and ii) an approximate description of the channel kinetics of interest. We show here that, given i and ii, parameters 1-3 can be inferred simultaneously by nonnegative linear regression; that this optimization problem possesses a unique solution and is guaranteed to converge despite the large number of parameters and their complex nonlinear interaction; and that standard optimization algorithms efficiently reach this optimum with modest computational and data requirements. We demonstrate that the method leads to accurate estimations on a wide variety of challenging model data sets that include up to about 10(4) parameters (roughly two orders of magnitude more than previously feasible) and describe how the method gives insights into the functional interaction of groups of channels.},
annote = {

2010IIInum18
2011num35

},
author = {Huys, Q J M and Ahrens, M B and Paninski, L},
doi = {10.1152/jn.00079.2006.},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Algorithms,Biophysical Phenomena,Biophysics,Cell Membrane,Cell Membrane: physiology,Data Interpretation,Dendrites,Dendrites: physiology,Electrophysiology,Ion Channel Gating,Ion Channel Gating: physiology,Ion Channels,Kinetics,Ligands,Likelihood Functions,Models,Monte Carlo Method,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: physiology,Neurological,Neurons,Neurons: physiology,Patch-Clamp Techniques,Receptors,Statistical,Synapses,Synapses: physiology},
number = {2},
pages = {872},
pmid = {16624998},
publisher = {Am Physiological Soc},
title = {{Efficient estimation of detailed single-neuron models}},
url = {http://jn.physiology.org/cgi/content/abstract/96/2/872 http://jn.physiology.org/content/96/2/872.short},
volume = {96},
year = {2006}
}
@article{NakaiImoto01,
abstract = {Recently, several groups have developed green fluorescent protein

(GFP)-based Ca(2+) probes. When applied in cells, however, these

probes are difficult to use because of a low signal-to-noise ratio.

Here we report the development of a high-affinity Ca(2+) probe composed

of a single GFP (named G-CaMP). G-CaMP showed an apparent K(d) for

Ca(2+) of 235 nM. Association kinetics of Ca(2+) binding were faster

at higher Ca(2+) concentrations, with time constants decreasing from

230 ms at 0.2 microM Ca(2+) to 2.5 ms at 1 microM Ca(2+). Dissociation

kinetics (tau approximately 200 ms) are independent of Ca(2+) concentrations.

In HEK-293 cells and mouse myotubes expressing G-CaMP, large fluorescent

changes were observed in response to application of drugs or electrical

stimulations. G-CaMP will be a useful tool for visualizing intracellular

Ca2+ in living cells. Mutational analysis, together with previous

structural information, suggests the residues that may alter the

fluorescence of GFP.},
author = {Nakai, J and Ohkura, M and Imoto, K},
doi = {10.1038/84397},
journal = {Nat Biotechnol},
keywords = {Adenosine Triphosphate; Amino Acid Sequence; Anima,Site-Directed; Myosin-Light-Chain Kinase; Myosins},
month = {feb},
number = {2},
pages = {137--141},
pmid = {11175727},
title = {{A high signal-to-noise {\{}Ca{\}}{\^{}}{\{}2+{\}} probe composed of a single green fluorescent protein.}},
url = {http://dx.doi.org/10.1038/84397},
volume = {19},
year = {2001}
}
@article{Anemuller|2003|,
abstract = {Independent component analysis (ICA) has proven useful for modeling
brain and electroencephalographic (EEG) data. Here, we present a
new, generalized method to better capture the dynamics of brain signals
than previous ICA algorithms. We regard EEG sources as eliciting
spatio-temporal activity patterns, corresponding to, e.g. trajectories
of activation propagating across cortex. This leads to a model of
convolutive signal superposition, in contrast with the commonly used
instantaneous mixing model. In the frequency-domain, convolutive
mixing is equivalent to multiplicative mixing of complex signal sources
within distinct spectral bands. We decompose the recorded spectraldomain
signals into independent components by a complex infomax ICA algorithm.
First results from a visual attention EEG experiment exhibit: (1)
sources of spatio-temporal dynamics in the data, (2) links to subject
behavior, (3) sources with a limited spectral extent, and (4) a higher
degree of independence compared to sources derived by standard ICA.},
author = {Anemuller, J and Sejnowski, T J and Makeig, S},
journal = {Neural Networks},
keywords = {ICA,biomedical signal analysis,computational,convolutive mixing,electroencephalogram,event-related potential,frequency-domain,independent component analysis,mathematics,neurobiology,visual selective attention},
pages = {1311},
title = {{Complex independent component analysis of frequency-domain electroencephalographic data}},
volume = {16}
}
@article{PAN03b,
author = {Paninski, L and Lau, B and Reyes, A},
journal = {Neurocomputing},
pages = {877--883},
title = {{Noise-driven adaptation: in vitro and mathematical analysis}},
volume = {52},
year = {2003}
}
@article{Broome2006,
author = {Broome, B M and Jayaraman, V and Laurent, G},
journal = {Neuron},
pages = {467--482},
title = {{Encoding and decoding of overlapping odor sequences}},
volume = {51},
year = {2006}
}
@article{Fiala|2001|,
abstract = {OBJECTIVE: Analysis of brain ultrastructure is needed to reveal how
neurons communicate with one another via synapses and how disease
processes alter this communication. In the past, such analyses have
usually been based on single or paired sections obtained by electron
microscopy. Reconstruction from multiple serial sections provides
a much needed, richer representation of the three-dimensional organization
of the brain. This paper introduces a new reconstruction system and
new methods for analyzing in three dimensions the location and ultrastructure
of neuronal components, such as synapses, which are distributed non-randomly
throughout the brain. DESIGN AND MEASUREMENTS: Volumes are reconstructed
by defining transformations that align the entire area of adjacent
sections. Whole-field alignment requires rotation, translation, skew,
scaling, and second-order nonlinear deformations. Such transformations
are implemented by a linear combination of bivariate polynomials.
Computer software for generating transformations based on user input
is described. Stereological techniques for assessing structural distributions
in reconstructed volumes are the unbiased bricking, disector, unbiased
ratio, and per-length counting techniques. A new general method,
the fractional counter, is also described. This unbiased technique
relies on the counting of fractions of objects contained in a test
volume. A volume of brain tissue from stratum radiatum of hippocampal
area CA1 is reconstructed and analyzed for synaptic density to demonstrate
and compare the techniques. RESULTS AND CONCLUSIONS: Reconstruction
makes practicable volume-oriented analysis of ultrastructure using
such techniques as the unbiased bricking and fractional counter methods.
These analysis methods are less sensitive to the section-to-section
variations in counts and section thickness, factors that contribute
to the inaccuracy of other stereological methods. In addition, volume
reconstruction facilitates visualization and modeling of structures
and analysis of three-dimensional relationships such as synaptic
connectivity.},
annote = {R01 MH/DA 57351/MH/United States NIMH Journal Article Research Support,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}U.S. Gov{\&}{\#}039;t, Non-P.H.S. Research Support, U.S. Gov{\&}{\#}039;t, P.H.S. United{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}states Jamia},
author = {Fiala, J C and Harris, K M},
journal = {J Am Med Inform Assoc},
keywords = {Algorithms Animals Brain/*ultrastructure Dendrites,Computer-Assisted/*methods Microscopy,Electron Neurons/ultrastructure Neuropil/ultrastr},
number = {1},
pages = {1--16},
title = {{Extending unbiased stereology of brain ultrastructure to three-dimensional volumes}},
volume = {8}
}
@article{Wang2010,
annote = {2011num43},
author = {Wang, X J},
doi = {10.1152/physrev.00035.2008.},
journal = {Physiological Reviews},
number = {3},
pages = {1195},
publisher = {Am Physiological Soc},
title = {{Neurophysiological and computational principles of cortical rhythms in cognition}},
url = {http://physrev.physiology.org/content/90/3/1195.short},
volume = {90},
year = {2010}
}
@misc{CarlBianco,
author = {{Carl Bianco}},
title = {{How Vision Works}},
url = {http://health.howstuffworks.com/mental-health/human-nature/perception/eye2.htm}
}
@article{AD99,
author = {Abbott, L F and Dayan, P},
journal = {Neural Computation},
pages = {91--101},
title = {{The Effect of Correlated Variability on the Accuracy of a Population Code}},
volume = {11},
year = {1999}
}
@article{Guler2013,
author = {G{\"{u}}ler, M},
doi = {10.1162/NECO},
journal = {Neural computation},
pages = {2355--2372},
title = {{An Investigation of the Stochastic Hodgkin-Huxley Models Under Noisy Rate Functions}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/NECO{\_}a{\_}00487},
volume = {25},
year = {2013}
}
@article{Ishizuka|1995|,
abstract = {The three dimensional organization of the dendritic trees of pyramidal
cells in the rat hippocampus was investigated using intracellular
injection of horseradish peroxidase in the in vitro hippocampal slice
preparation and computer-aided reconstruction. The total dendritic
length, dendritic length in each of the hippocampal laminae, and
the number of dendritic branches were measured in 20 CA1 pyramidal
cells, 7 neurons in CA2 and 20 CA3 pyramidal cells. The total dendritic
length of CA3 pyramidal cells varied in a consistent fashion depending
on their position within the field. Cells located close to the dentate
gyrus had the smallest dendritic trees which averaged 9,300 microns
in total length. Cells in the distal part of CA3 (near CA2) had the
largest dendritic trees, averaging 15,800 microns. The CA2 field
contained cells which resembled CA3 pyramidal cells in most respects
except for the absence of thorny excrescences on their proximal dendrites.
There were also smaller pyramidal cells that resembled CA1 neurons.
CA1 pyramidal cells tended to be more homogeneous. Pyramidal neurons
throughout the transverse extent of CA1 had a total dendritic length
on the order of 13,500 microns. The quantitative analysis of the
laminar distribution of dendrites demonstrated that the stratum oriens
and stratum radiatum contained significant portions of the pyramidal
cell dendritic trees. In Ca3, for example, 42-51{\%} of the total dendritic
length was located in stratum oriens; about 34{\%} of the dendritic
tree was located in stratum radiatium. The amount of dendritic length
in stratum lacunosum-moleculare of CA3 varied depending on the location
of the cell. Many CA3 cells located within the limbs of the dentate
gyrus, for example, had no dendrites extending into stratum lacunosum-moleculare
whereas those located distally in CA3 had about the same percentage
of their dendritic tree in stratum lacunosum-moleculare as in stratum
radiatum. In CA1, nearly half of the dendritic length was located
in stratum radiatum, 34{\%} was in stratum oriens and 18{\%} was in stratum
lacunosum-moleculare. These studies identified distinctive dendritic
branching patterns, in the stratum radiatum and stratum lacunosum-moleculare,
which clearly distinguished CA3 from CA1 neurons.},
annote = {NS 16980/NS/United States NINDS Journal Article Research Support,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Non-U.S. Gov{\&}{\#}039;t Research Support, U.S. Gov{\&}{\#}039;t, P.H.S. United states},
author = {Ishizuka, N and Cowan, W M and Amaral, D G},
journal = {J Comp Neurol},
keywords = {Animals Cell Size/physiology Dendrites/*physiology,Computer-Assisted Pyramidal Cells/physiology/*ult,Sprague-Dawley/*physiology Terminology as Topic},
number = {1},
pages = {17--45},
title = {{A quantitative analysis of the dendritic organization of pyramidal cells in the rat hippocampus}},
volume = {362}
}
@misc{Navarro,
annote = {This presentation addresses CDM scenario for galaxy formation by{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}one of the creators of NFW model.},
author = {Navarro, J F},
keywords = {astrophysics,cold dark matter,disk galaxy,galaxy formation,physics},
title = {{Disk Galaxy Formation in a Cold Dark Matter Universe: A Test of the Paradigm}}
}
@book{KNNL05,
author = {Kutner, M and Nachtsheim, C and Neter, J and Li, W},
publisher = {McGraw-Hill},
title = {{Applied Linear Statistical Models}},
year = {2005}
}
@article{Pearson2007,
author = {Pearson, Keir},
doi = {10.1152/jn.00065.2005},
pages = {4256--4268},
title = {{Computer Simulation of Stepping in the Hind Legs of the Cat : An Examination of Mechanisms Regulating the Stance-to-Swing Transition}},
year = {2007}
}
@article{Loh,
author = {Loh, Po-ling and Bruck, J},
title = {{The Robustness of Stochastic Switching Networks}},
year = {2009}
}
@article{JohnstonMagee96,
author = {Johnston, D and Magee, J C and Colbert, C M and Cristie, B R},
journal = {Ann. Rev. Neurosci.},
pages = {165--186},
title = {{Active properties of neuronal dendrites.}},
volume = {19},
year = {1996}
}
@book{Gorenflo2000,
archivePrefix = {arXiv},
arxivId = {arXiv:0805.3823v1},
author = {Gorenflo, Rudolf and Mainardi, Francesco},
eprint = {arXiv:0805.3823v1},
isbn = {321182913X},
number = {378},
pages = {223--276},
title = {{No Title}},
year = {2000}
}
@article{Higham01,
author = {Higham, D},
journal = {SIAM Review},
pages = {525--546},
title = {{An Algorithmic Introduction to Numerical Simulation of Stochastic Differential Equations}},
volume = {43},
year = {2001}
}
@article{Amari1987,
author = {Amari, S I and Barndorff-Nielsen, O E and Kass, R E and Lauritzen, S L and Rao, C R},
isbn = {0940600129},
journal = {Lecture Notes - Monograph Series},
title = {{Differential geometry in statistical inference}},
url = {http://www.jstor.org/stable/4355557},
volume = {10},
year = {1987}
}
@article{Zeitouni2006,
author = {ZEiTOUNi, O.},
doi = {10.1088/0305-4470/39/40/R01},
issn = {0305-4470},
journal = {Journal of Physics A: Mathematical and General},
month = {oct},
number = {40},
pages = {R433--R464},
title = {{Random walks in random environments}},
url = {http://stacks.iop.org/0305-4470/39/i=40/a=R01?key=crossref.a9e17fd824e939431f5e5f173d0da860 http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:LECTURE+NOTES+ON+RANDOM+WALKS+in+random+enviroments{\#}0},
volume = {39},
year = {2006}
}
@article{Hoffman2013,
author = {Hoffman, M and Others},
journal = {MLRG},
pages = {1303--1347},
title = {{Stochastic Variational Inference}},
volume = {14},
year = {2013}
}
@article{Krauth1987,
author = {Krauth, W and M{\'{e}}zard, M},
journal = {Journal of Physics A: Mathematical and {\ldots}},
title = {{Learning algorithms with optimal stability in neural networks}},
url = {http://iopscience.iop.org/0305-4470/20/11/013},
volume = {20},
year = {1987}
}
@article{KULK07,
author = {Kulkarni, J and Paninski, L},
journal = {In press, IEEE Signal Processing Magazine (special issue on brain-computer interfaces)},
title = {{A Numerically Efficient Approach for Constructing Reach- Trajectories Conditioned on Target}},
year = {2007}
}
@article{Truccolo2010,
author = {Truccolo, Wilson},
journal = {Analysis of Parallel Spike Trains},
keywords = {networks},
mendeley-tags = {networks},
pages = {321--341},
publisher = {Springer},
title = {{Stochastic models for multivariate neural point processes: Collective dynamics and neural decoding}},
url = {http://www.springerlink.com/index/K0115255863M7459.pdf},
year = {2010}
}
@article{Wu04,
author = {Wu, W and Black, M J and Mumford, D and Gao, Y and Bienenstock, E and Donoghue, J P},
journal = {IEEE Transactions on Biomedical Engineering},
number = {6},
pages = {933--942},
publisher = {Citeseer},
title = {{Modeling and decoding motor cortical activity using a switching {\{}K{\}}alman filter}},
volume = {51},
year = {2004}
}
@article{Scharf1995a,
author = {Scharf, Rainer and Meesmann, Malte and Boese, Jan and Chialvo, Dante R and Kniflki, Klaus-d},
pages = {255--263},
title = {{Biological Cybernetics}},
volume = {263},
year = {1995}
}
@article{Migliore2006,
abstract = {The NEURON simulation environment has been extended to support parallel network simulations. Each processor integrates the equations for its subnet over an interval equal to the minimum (interprocessor) presynaptic spike generation to postsynaptic spike delivery connection delay. The performance of three published network models with very different spike patterns exhibits superlinear speedup on Beowulf clusters and demonstrates that spike communication overhead is often less than the benefit of an increased fraction of the entire problem fitting into high speed cache. On the EPFL IBM Blue Gene, almost linear speedup was obtained up to 100 processors. Increasing one model from 500 to 40,000 realistic cells exhibited almost linear speedup on 2,000 processors, with an integration time of 9.8 seconds and communication time of 1.3 seconds. The potential for speed-ups of several orders of magnitude makes practical the running of large network simulations that could otherwise not be explored.},
author = {Migliore, M and Cannia, C and Lytton, W W and Markram, H and Hines, M L},
doi = {10.1007/s10827-006-7949-5},
isbn = {1082700679495},
issn = {0929-5313},
journal = {Journal of computational neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Cerebral Cortex,Cerebral Cortex: physiology,Humans,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Software,Synaptic Transmission,Synaptic Transmission: physiology},
month = {oct},
number = {2},
pages = {119--29},
pmid = {16732488},
title = {{Parallel network simulations with NEURON.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2655137{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {21},
year = {2006}
}
@article{Stepanyants|2004|,
abstract = {Brain function relies on specificity of synaptic connectivity patterns
among different classes of neurons. Yet, the substrates of specificity
in complex neuropil remain largely unknown. We search for imprints
of specificity in the layout of axonal and dendritic arbors from
the rat neocortex. An analysis of 3D reconstructions of pairs consisting
of pyramidal cells (PCs) and GABAergic interneurons (GIs) revealed
that the layout of GI axons is specific. This specificity is manifested
in a relatively high tortuosity, small branch length of these axons,
and correlations of their trajectories with the positions of postsynaptic
neuron dendrites. Axons of PCs show no such specificity, usually
taking a relatively straight course through neuropil. However, wiring
patterns among PCs hold a large potential for circuit remodeling
and specificity through growth and retraction of dendritic spines.
Our results define distinct class-specific rules in establishing
synaptic connectivity, which could be crucial in formulating a canonical
cortical circuit.},
annote = {MH69838/MH/United States NIMH NS047138/NS/United States NINDS In{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Vitro Journal Article Research Support, Non-U.S. Gov{\&}{\#}039;t Research Support,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}U.S. Gov{\&}{\#}039;t, P.H.S. United States},
author = {Stepanyants, A and Tamas, G and Chklovskii, D B},
journal = {Neuron},
keywords = {Animals Axons/*physiology/ultrastructure Dendrites,Computer-Assisted Imaging,Three-Dimensional Interneurons/metabolism/ultrast,Wistar Synapses/physiology gamma-Aminobutyric Aci},
number = {2},
pages = {251--259},
title = {{Class-specific features of neuronal wiring}},
volume = {43}
}
@misc{Mishchenko2015,
author = {Mishchenko, Y},
booktitle = {In prep.},
howpublished = {In prep.},
title = {{Consistency of the complete neuronal population connectivity reconstructions using shotgun imaging}},
year = {2015}
}
@article{Fairhall2001,
abstract = {We examine the dynamics of a neural code in the context of stimuli whose statistical properties are themselves evolving dynamically. Adaptation to these statistics occurs over a wide range of timescales-from tens of milliseconds to minutes. Rapid components of adaptation serve to optimize the information that action potentials carry about rapid stimulus variations within the local statistical ensemble, while changes in the rate and statistics of action-potential firing encode information about the ensemble itself, thus resolving potential ambiguities. The speed with which information is optimized and ambiguities are resolved approaches the physical limit imposed by statistical sampling and noise.},
annote = {2009num21},
author = {Fairhall, a L and Lewen, G.D. D and Bialek, W and van Steveninck, R.R.R. and {de Ruyter Van Steveninck}, R R},
doi = {10.1038/35090500},
issn = {0028-0836},
journal = {Nature},
keywords = {Adaptation,Animals,Data Interpretation,Diptera,Physiological,Reaction Time,Statistical,Synaptic Transmission,Visual Pathways,Visual Pathways: physiology},
month = {aug},
number = {6849},
pages = {787--792},
pmid = {11518957},
publisher = {Nature Publishing Group},
title = {{Efficiency and ambiguity in an adaptive neural code}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11518957 http://www.nature.com/nature/journal/v412/n6849/abs/412787a0.html},
volume = {412},
year = {2001}
}
@article{Lowen1991,
annote = {2010num2.4},
author = {Lowen, S B and Teich, M C},
journal = {Physical Review A},
title = {{Doubly stochastic Poisson point process driven by fractal shot noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevA.43.4192},
year = {1991}
}
@article{Feldt2011,
abstract = {Structure-function studies of neuronal networks have recently benefited from considerable progress in different areas of investigation. Advances in molecular genetics and imaging have allowed for the dissection of neuronal connectivity with unprecedented detail whereas in vivo recordings are providing much needed clues as to how sensory, motor and cognitive function is encoded in neuronal firing. However, bridging the gap between the cellular and behavioral levels will ultimately require an understanding of the functional organization of the underlying neuronal circuits. One way to unravel the complexity of neuronal networks is to understand how their connectivity emerges during brain maturation. In this review, we will describe how graph theory provides experimentalists with novel concepts that can be used to describe and interpret these developing connectivity schemes.},
annote = {2011num47},
author = {Feldt, Sarah and Bonifazi, Paolo and Cossart, Rosa},
doi = {10.1016/j.tins.2011.02.007},
issn = {1878-108X},
journal = {Trends in Neurosciences},
keywords = {networks},
mendeley-tags = {networks},
month = {may},
number = {5},
pages = {225--36},
pmid = {21459463},
publisher = {Elsevier Ltd},
title = {{Dissecting functional connectivity of neuronal microcircuits: experimental and theoretical insights.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21459463},
volume = {34},
year = {2011}
}
@phdthesis{Chua|1999|,
abstract = {A fundamental activity common to many image processing, pattern classification
and clustering algorithms involves searching a set of n, k-dimensional
data of the one which is nearest to a given target item with respect
to a distance function. Our goal is to find fast search algorithms
which are full-search equivalent - that is, the resulting match is
as good as what we could obtain if we were to search the set exhaustively.
We propose a framework made up of three components, namely (i) a
technique for obtaining a good initial match, (ii) an inexpensive
method for determining whether the current match is a full-search
equivalent match, and (iii) an effective technique for improving
the current match. Our approach is to consider good solutions for
each component in order to find an algorithm which balances the overall
complexity of the search. We also propose a technique for hierarchical
ordering and cluster elimination using a minimal cost spanning tree.
Our experiments on vector quantisation coding of images show that
the framework and techniques we proposed can be used to construct
suitable algorithms for most of our data sets which require full-search
equivalent matches at an average arithmetic cost of less than O(k
log n) while using only O(n) space.},
author = {Chua, J J},
keywords = {computational,nearest neighbor search},
title = {{Fast full-search equivalent nearest-neighbour search algorithms}}
}
@article{Itzkovitz|2004|,
abstract = {Many real-world networks describe systems in which interactions decay
with the distance between nodes. Examples include systems constrained
in real space such as transportation and communication networks,
as well as systems constrained in abstract spaces such as multivariate
biological or economic datasets and models of social networks. These
networks often display network motifs: subgraphs that recur in the
network much more often than in randomized networks. To understand
the origin of the network motifs in these networks, it is important
to study the subgraphs and network motifs that arise solely from
geometric constraints. To address this, we analyze geometric network
models, in which nodes are arranged on a lattice and edges are formed
with a probability that decays with the distance between nodes. We
present analytical solutions for the numbers of all 3 and 4-node
subgraphs, in both directed and non-directed geometric networks.
We also analyze geometric networks with arbitrary degree sequences,
and models with a field that biases for directed edges in one direction.
Scaling rules for scaling of subgraph numbers with system size, lattice
dimension and interaction range are given. Several invariant measures
are found, such as the ratio of feedback and feed-forward loops,
which do not depend on system size, dimension or connectivity function.
We find that network motifs in many real-world networks, including
social networks and neuronal networks, are not captured solely by
these geometric models. This is in line with recent evidence that
biological network motifs were selected as basic circuit elements
with defined information-processing functions.},
annote = {The paper introduces "geometric networks" which are random networks{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}embedded in metric "geometrical" space such that probability of connection{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}between nodes also depends on the metric distance between nodes in{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}this space. Distribution of network motifs is studied and it is shown{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}that many "short-range" connection patterns are boosted relative{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to random Erdos-Renyi networks and become motifs},
author = {Itzkovitz, S and Alon, U},
journal = {arXiv},
keywords = {continuous networks,geometric networks,network metrics,network motifs,networks},
number = {0409163},
title = {{Subgraphs and network motifs in geometric networks}},
volume = {cond=mat}
}
@article{Ardalan1987,
author = {Ardalan, S and Paulos, J},
journal = {Circuits and Systems, IEEE Transactions on},
number = {6},
pages = {593--603},
title = {{An analysis of nonlinear behavior in delta-sigma modulators}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1086187},
volume = {34},
year = {1987}
}
@article{SK03,
author = {Sergio, L and Kalaska, J},
journal = {Journal of Neurophysiology},
pages = {212--228},
title = {{Systematic changes in motor cortex activity with arm posture during directional isometric force generation}},
volume = {89},
year = {2003}
}
@article{Frieden1993,
author = {Frieden, B.Roy R},
doi = {10.1016/0378-4371(93)90194-9},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
month = {sep},
number = {1-2},
pages = {262--338},
title = {{Estimation of distribution laws, and physical laws, by a principle of extremized physical information}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0378437193901949},
volume = {198},
year = {1993}
}
@article{Ly,
author = {Ly, Bu},
title = {x}
}
@inproceedings{Friedrich2015,
author = {Friedrich, Johannes and Soudry, D. and Mu, Yu and Freeman, Jeremy and Ahrens, Misha and Paninski, Liam},
booktitle = {NIPS workshop on statistical methods for understanding neural systems},
file = {::},
title = {{Fast Constrained Non-negative Matrix Factorization for Whole-Brain Calcium Imaging Data}},
url = {http://www.stat.columbia.edu/{~}johannes/docs/nips2015.pdf},
year = {2015}
}
@article{Harris|1994|,
author = {Harris, K M and Kater, S B},
journal = {Annu. Rev. Neurosci.},
pages = {341--371},
title = {{Dendritic spines: cellular specializations imparting both stability and flexibility to synaptic function}},
volume = {17}
}
@article{SunneyXie2002,
author = {{Sunney Xie}, X.},
doi = {10.1063/1.1521159},
issn = {00219606},
journal = {The Journal of Chemical Physics},
number = {24},
pages = {11024},
title = {{Single-molecule approach to dispersed kinetics and dynamic disorder: Probing conformational fluctuation and enzymatic dynamics}},
url = {http://link.aip.org/link/JCPSA6/v117/i24/p11024/s1{\&}Agg=doi},
volume = {117},
year = {2002}
}
@article{OSZ03,
author = {Orlitsky, A and Santhanam, N and Zhang, J},
journal = {Science},
pages = {427--431},
title = {{Always {\{}G{\}}ood {\{}T{\}}uring: Asymptotically Optimal Probability Estimation}},
volume = {302},
year = {2003}
}
@book{BrockwellDavis91,
author = {Brockwell, P and Davis, R},
publisher = {Springer},
title = {{Time Series: Theory and Methods}},
year = {1991}
}
@article{Bernstein|1988|,
abstract = {The authors present a simplified model of helium synthesis in the
early universe. The purpose of the model is to explain clearly the
physical ideas relevant to teh cosmological helium synthesis in a
manner that does not overlay these ideas with complex computer calculations.
The model closely follows the standard calculation, except that it
neglects the small effect of Fermi-Dirac statistics for the leptons.
The temperature difference between photons and neutrinos during the
period in which neurtons and protons interconvert is also neglected.
These approximations permit the expression of neutron-proton conversion
rates in a closed form, which agrees to 10{\%} accuracy or better with
the exact rates. Using these analytic expressions for the rates,
the authors reduce the calculation of the neutron-proton ratio as
a function of temperature to a simple numerical integral. They also
estimate the effect of neutron decay on the helium abundance. Their
result for this quantity agrees well with precise computer calculations.
Their semianalytic formulas are used to determine how the preducted
helium abundance varies with such parameters as the neutron lifetime,
the baryon-to-photon ratio, the number of neutrino species, and a
possible electron-neutrino chemical potential.},
author = {Bernstein, J and Brown, L S and Feinberg, G},
journal = {Reviews of Modern Physics},
keywords = {astrophysics,cosmology,early universe,helium production,physics,synthesis},
number = {1},
pages = {25},
title = {{Cosmological Helium Production Simplified}},
volume = {61}
}
@article{Real2017,
abstract = {Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Evolutionary algorithms provide a technique to discover such networks automatically. Despite significant computational requirements, we show that evolving models that rival large, hand-designed architectures is possible today. We employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions. To do this, we use novel and intuitive mutation operators that navigate large search spaces. We stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.},
archivePrefix = {arXiv},
arxivId = {1703.01041},
author = {Real, Esteban and Moore, Sherry and Selle, Andrew and Saxena, Saurabh and Suematsu, Yutaka Leon and Le, Quoc and Kurakin, Alex},
eprint = {1703.01041},
title = {{Large-Scale Evolution of Image Classifiers}},
year = {2017}
}
@article{Paninski2010,
abstract = {State space methods have proven indispensable in neural data analysis. However, common methods for performing inference in state-space models with non-Gaussian observations rely on certain approximations which are not always accurate. Here we review direct optimization methods that avoid these approximations, but that nonetheless retain the computational efficiency of the approximate methods. We discuss a variety of examples, applying these direct optimization techniques to problems in spike train smoothing, stimulus decoding, parameter estimation, and inference of synaptic properties. Along the way, we point out connections to some related standard statistical methods, including spline smoothing and isotonic regression. Finally, we note that the computational methods reviewed here do not in fact depend on the state-space setting at all; instead, the key property we are exploiting involves the bandedness of certain matrices. We close by discussing some applications of this more general point of view, including Markov chain Monte Carlo methods for neural decoding and efficient estimation of spatially-varying firing rates.},
author = {Paninski, L and Ahmadian, Yashar and Ferreira, Daniel Gil and Koyama, Shinsuke and {Rahnama Rad}, Kamiar and Vidne, Michael and Vogelstein, Joshua and Wu, Wei},
doi = {10.1007/s10827-009-0179-x},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {1 introduction,Action Potentials,Action Potentials: physiology,Animals,Computer Simulation,Estimation,Models,Neurological,Neurons,Neurons: physiology,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,Statistical,Synapses,Synapses: physiology,for inference in state-space,forward-backward methods,hidden markov model,models,neural coding,state-space models,tridiagonal matrix},
mendeley-tags = {Estimation},
month = {aug},
number = {1-2},
pages = {107--26},
pmid = {19649698},
title = {{A new look at state-space models for neural data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19649698 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3712521{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {29},
year = {2010}
}
@article{Jelenkovic1997,
author = {Jelenkovic, P R and Lazar, A A and Semret, N},
journal = {IEEE Journal on Selected Areas in Communications},
number = {6},
pages = {1052--1071},
title = {{The effect of multiple time scales and subexponentiality in MPEGvideo streams on queueing behavior}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:The+Effect+of+Multiple+Time+Scales+and+Subexponentiality+in+MPEG{\#}0},
volume = {15},
year = {1997}
}
@article{Cotton2013,
abstract = {Great progress has been made toward understanding the properties of single neurons, yet the principles underlying interactions between neurons remain poorly understood. Given that connectivity in the neocortex is locally dense through both horizontal and vertical connections, it is of particular importance to characterize the activity structure of local populations of neurons arranged in three dimensions. However, techniques for simultaneously measuring microcircuit activity are lacking. We developed an in vivo 3D high-speed, random-access two-photon microscope that is capable of simultaneous 3D motion tracking. This allows imaging from hundreds of neurons at several hundred Hz, while monitoring tissue movement. Given that motion will induce common artifacts across the population, accurate motion tracking is absolutely necessary for studying population activity with random-access based imaging methods. We demonstrate the potential of this imaging technique by measuring the correlation structure of large populations of nearby neurons in the mouse visual cortex, and find that the microcircuit correlation structure is stimulus-dependent. Three-dimensional random access multiphoton imaging with concurrent motion tracking provides a novel, powerful method to characterize the microcircuit activity in vivo.},
author = {Cotton, R. J. and Froudarakis, E. and Storer, P. and Saggau, P. and Tolias, A. S.},
doi = {10.3389/fncir.2013.00151},
isbn = {1662-5110 (Electronic)$\backslash$r1662-5110 (Linking)},
journal = {Frontiers in neural circuits},
keywords = {Animals,Fluorescence,Imaging,Mice,Microscopy,Multiphoton,Multiphoton: methods,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Three-Dimensional,Three-Dimensional: methods,Visual Cortex,Visual Cortex: physiology},
pages = {151},
pmid = {24133414},
title = {{Three-dimensional mapping of microcircuit correlation structure.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3794294{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@article{RVK98,
author = {Reich, D and Victor, J and Knight, B},
journal = {The Journal of Neuroscience},
pages = {10090--10104},
title = {{The Power Ratio and the Interval Map: Spiking Models and Extracellular Recordings}},
volume = {18},
year = {1998}
}
@article{Rosenblatt1956,
author = {Rosenblatt, M},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {jan},
number = {1},
pages = {43--7},
pmid = {16589813},
title = {{a Central Limit Theorem and a Strong Mixing Condition.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=534230{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {42},
year = {1956}
}
@incollection{GKO04,
author = {Garthwaite, P and Kadane, J and O'Hagan, A},
chapter = {Elicitatio},
title = {{Handbook of Statistics}},
year = {2004}
}
@article{Hauser2012,
abstract = {The control of compliant robots is, due to their often nonlinear and complex dynamics, inherently difficult. The vision of morphological computation proposes to view these aspects not only as problems, but rather also as parts of the solution. Non-rigid body parts are not seen anymore as imperfect realizations of rigid body parts, but rather as potential computational resources. The applicability of this vision has already been demonstrated for a variety of complex robot control problems. Nevertheless, a theoretical basis for understanding the capabilities and limitations of morphological computation has been missing so far. We present a model for morphological computation with compliant bodies, where a precise mathematical characterization of the potential computational contribution of a complex physical body is feasible. The theory suggests that complexity and nonlinearity, typically unwanted properties of robots, are desired features in order to provide computational power. We demonstrate that simple generic models of physical bodies, based on mass-spring systems, can be used to implement complex nonlinear operators. By adding a simple readout (which is static and linear) to the morphology such devices are able to emulate complex mappings of input to output streams in continuous time. Hence, by outsourcing parts of the computation to the physical body, the difficult problem of learning to control a complex body, could be reduced to a simple and perspicuous learning task, which can not get stuck in local minima of an error function.},
author = {Hauser, Helmut and Ijspeert, Auke J and F{\"{u}}chslin, Rudolf M and Pfeifer, Rolf and Maass, W},
doi = {10.1007/s00422-012-0471-0},
issn = {1432-0770},
journal = {Biological cybernetics},
keywords = {Reservoir Computing,analog computation,embodiment,morphological computation,nonlinear mass-spring systems,volterra series},
mendeley-tags = {Reservoir Computing},
month = {jan},
number = {2011},
pages = {355--370},
pmid = {22290137},
title = {{Towards a theoretical foundation for morphological computation with compliant bodies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22290137},
year = {2012}
}
@article{GW92,
author = {Gilks, W and Wild, P},
journal = {Applied Statistics},
pages = {337--348},
title = {{Adaptive rejection sampling for {\{}G{\}}ibbs sampling}},
volume = {41},
year = {1992}
}
@article{Korattikara2015,
abstract = {We consider the problem of Bayesian parameter estimation for deep neural networks, which is important in problem settings where we may have little data, and/ or where we need accurate posterior predictive densities, e.g., for applications involving bandits or active learning. One simple approach to this is to use online Monte Carlo methods, such as SGLD (stochastic gradient Langevin dynamics). Unfortunately, such a method needs to store many copies of the parameters (which wastes memory), and needs to make predictions using many versions of the model (which wastes time). We describe a method for "distilling" a Monte Carlo approximation to the posterior predictive density into a more compact form, namely a single deep neural network. We compare to two very recent approaches to Bayesian neural networks, namely an approach based on expectation propagation [Hernandez-Lobato and Adams, 2015] and an approach based on variational Bayes [Blundell et al., 2015]. Our method performs better than both of these, is much simpler to implement, and uses less computation at test time.},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.04416v2},
author = {Korattikara, Anoop and Rathod, Vivek and Murphy, Kevin and Welling, Max},
eprint = {arXiv:1506.04416v2},
journal = {arXiv},
pages = {1--9},
title = {{Bayesian Dark Knowledge}},
year = {2015}
}
@article{Vogelstein2009,
abstract = {As recent advances in calcium sensing technologies facilitate simultaneously imaging action potentials in neuronal populations, complementary analytical tools must also be developed to maximize the utility of this experimental paradigm. Although the observations here are fluorescence movies, the signals of interest--spike trains and/or time varying intracellular calcium concentrations--are hidden. Inferring these hidden signals is often problematic due to noise, nonlinearities, slow imaging rate, and unknown biophysical parameters. We overcome these difficulties by developing sequential Monte Carlo methods (particle filters) based on biophysical models of spiking, calcium dynamics, and fluorescence. We show that even in simple cases, the particle filters outperform the optimal linear (i.e., Wiener) filter, both by obtaining better estimates and by providing error bars. We then relax a number of our model assumptions to incorporate nonlinear saturation of the fluorescence signal, as well external stimulus and spike history dependence (e.g., refractoriness) of the spike trains. Using both simulations and in vitro fluorescence observations, we demonstrate temporal superresolution by inferring when within a frame each spike occurs. Furthermore, the model parameters may be estimated using expectation maximization with only a very limited amount of data (e.g., approximately 5-10 s or 5-40 spikes), without the requirement of any simultaneous electrophysiology or imaging experiments.},
author = {Vogelstein, Joshua T and Watson, Brendon O and Packer, Adam M and Yuste, R and Jedynak, Bruno and Paninski, L},
doi = {10.1016/j.bpj.2008.08.005},
issn = {1542-0086},
journal = {Biophysical journal},
keywords = {Animals,Calcium,Calcium: metabolism,Estimation,Fluorescence,Intracellular Space,Intracellular Space: metabolism,Mice,Mice, Inbred C57BL,Models, Biological,Monte Carlo Method,Neurons,Neurons: cytology,Neurons: metabolism,Probability,Time Factors},
mendeley-tags = {Estimation},
month = {jul},
number = {2},
pages = {636--55},
pmid = {19619479},
publisher = {Biophysical Society},
title = {{Spike inference from calcium imaging using sequential Monte Carlo methods.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2711341{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {97},
year = {2009}
}
@article{Moore2002,
author = {Moore, SC},
journal = {Unpublished master's thesis, University {\ldots}},
title = {{BACK-PROPAGATION IN SPIKING NEURAL NETWORKS}},
url = {http://emmanuellebeart.ndirect.co.uk/scm/Thesis4.pdf},
year = {2002}
}
@article{Blondel2001a,
author = {Blondel, V D and Bournez, O and Koiran, P and Tsitsiklis, J N},
doi = {10.1006/jcss.2000.1737},
issn = {0022-0000},
journal = {Journal of Computer and System Sciences},
keywords = {decidability,dynamical systems,hybrid systems,mortality,piecewise affine,saturated linear systems,stability,systems},
month = {may},
number = {3},
pages = {442--462},
publisher = {Elsevier},
title = {{The stability of saturated linear dynamical systems is undecidable}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022000000917379},
volume = {62},
year = {2001}
}
@article{SAH03,
author = {Sahani, M and Linden, J},
journal = {NIPS},
title = {{Evidence optimization techniques for estimating stimulus-response functions}},
volume = {15},
year = {2003}
}
@article{Thomas2012,
author = {Thomas, Philipp and Grima, Ramon and Straube, Arthur},
doi = {10.1103/PhysRevE.86.041110},
issn = {1539-3755},
journal = {Physical Review E},
month = {oct},
number = {4},
pages = {1--9},
title = {{Rigorous elimination of fast stochastic variables from the linear noise approximation using projection operators}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.86.041110},
volume = {86},
year = {2012}
}
@book{Bishop2006,
address = {Singapore},
author = {Bishop, C M},
isbn = {9780387310732},
publisher = {Springer},
title = {{Pattern recognition and machine learning}},
url = {http://soic.iupui.edu/syllabi/semesters/4142/INFO{\_}B529{\_}Liu{\_}s.pdf},
year = {2006}
}
@book{Tulino2004,
author = {Tulino, AM A.M. and Verd{\'{u}}, S.},
booktitle = {Communications},
number = {1},
publisher = {Now Publishers Inc},
title = {{Random matrix theory and wireless communications}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=quQKOz1QhjcC{\&}oi=fnd{\&}pg=PA1{\&}dq=Random+Matrix+Theory+and+Wireless+Communications{\&}ots=IpJS0Ozqti{\&}sig=e{\_}yyXDMAby4e652XQ57IS8BdZnA http://books.google.com/books?hl=en{\&}lr={\&}id=quQKOz1QhjcC{\&}oi=fnd{\&}pg=PA1{\&}dq=Random+matrix+theory+and+wireless+communications{\&}ots=IpMS-Kzlpp{\&}sig=sTvqn0x9kZkk{\_}SkmeC0U-ZMNXjg},
volume = {1},
year = {2004}
}
@article{RKFS08,
author = {Reddy, G D and Kelleher, K and Fink, R and Saggau, P},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {6},
pages = {713--720},
publisher = {Nature Publishing Group},
title = {{Three-dimensional random access multiphoton microscopy for functional imaging of neuronal activity}},
volume = {11},
year = {2008}
}
@article{Kabashima2004,
author = {Kabashima, Yoshiyuki and Uda, Shinsuke},
journal = {Algorithmic Learning Theory},
number = {2},
pages = {479--493},
title = {{A BP-based algorithm for performing Bayesian inference in large perceptron-type networks}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-30215-5{\_}36},
year = {2004}
}
@article{Baldassarre|2005|,
abstract = {An important goal of collective robotics is the design of control
systems that allow groups of robots to accomplish common tasks by
coordinating without centralized control. In this paper, we study
how a group of physically assembled robots can display coherent behavior
on the basis of a simple neural controller that has access only to
local sensory information. This controller is synthesized through
artificial evolution in a simulated environment, in order to let
the robots display coordinated motion behaviors. The evolved controller
proves to be robust enough to allow a smooth transfer from simulation
to reality. Additionally, it generalizes to new experimental conditions,
such as different sizes/shapes of the group and/or different connection
mechanisms. The performance of the neural controller downloaded},
annote = {This paper is rather primitive study of how a directed motion may{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}originate in a system of rigidly-conneted mobile robots. A neural{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}network was trained to control motor to achieve max-displacement{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of the group of robots at given time. The network found to follow{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}simple intuitively clear prescription - pull randomly at first, then{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}pull in the direction of overall motion.},
author = {Baldassarre, Gianluca and Trianni, Vito and Bonani, Michael and Mondada, Francesco and Dorigo, Marco and Nolfi, Stefano},
journal = {IEEE},
keywords = {complex systems,distributed control,evolutionary algorithms,intelligent mobile robots,neural networks,swarm intellingence,swarm robots},
title = {{Self-organized coordinated motion in groups of physically connected robots}}
}
@article{YusteKatz92,
abstract = {The mammalian neocortex consists of a mosaic of columnar units whose

development is poorly understood. Optical recordings of brain slices

labeled with the fluorescent calcium indicator fura-2 revealed that

the neonatal rat cortex was partitioned into distinct domains of

spontaneously coactive neurons. In tangential slices, these domains

were 50 to 120 micrometers in diameter; in coronal slices they spanned

several cortical layers and resembled columns found in the adult

cortex. In developing somatosensory cortex, domains were smaller

than, and distinct from, the barrels, which represent sensory input

from a single vibrissa. The neurons within each domain were coupled

by gap junctions. Thus, nonsynaptic communication during cortical

development defines discrete multicellular patterns that could presage

adult functional architecture.},
author = {Yuste, R and Peinado, A and Katz, L C},
journal = {Science},
keywords = {Action Potentials; Animals; Brain Mapping; Calcium,Computer-Assisted; Intercellular Junctions; Neuro},
month = {jul},
number = {5070},
pages = {665--669},
pmid = {1496379},
title = {{Neuronal domains in developing neocortex.}},
volume = {257},
year = {1992}
}
@article{OHKI05,
author = {Ohki, K and Chung, S and Ch'ng, Y and Kara, P and Reid, C},
journal = {Nature},
pages = {597--603},
title = {{Functional imaging with cellular resolution reveals precise micro-architecture in visual cortex}},
volume = {433},
year = {2005}
}
@article{Kiefer|1998|,
abstract = {This review gives an introduction to various attempts to understand
the quantum nature of black holes. The first part focuses on thermodynamics
of black holes, Hawking radiation, and the interpretation of entropy.
The second part is devoted to the detailed treatment of black holes
within canonical quantum gravity. The last part adds a brief discussion
of black holes in string theory and quantum cosmology.},
author = {Kiefer, C},
journal = {arXiv},
keywords = {astrophysics,black holes,physics,quantum gravity,unread},
pages = {9803049},
title = {{Towards a full quantum theory of black holes}},
volume = {gr-qc}
}
@article{Schneider1991a,
author = {Schneider, C and Card, H},
journal = {Electronics letters},
number = {9},
pages = {785--786},
title = {{Analogue CMOS Hebbian Synapses}},
url = {http://digital-library.theiet.org/content/journals/10.1049/el{\_}19910489},
volume = {27},
year = {1991}
}
@article{Chang2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1207.3563v1},
author = {Chang, Joshua C and Brennan, K C and He, Dongdong and Huang, Huaxiong and Miura, Robert M and Phillip, L and Wylie, Jonathan J},
eprint = {arXiv:1207.3563v1},
pages = {1--21},
title = {cortical spreading depression}
}
@article{AK01,
author = {Antos, A and Kontoyiannis, I},
journal = {Random Structures and Algorithms},
pages = {163--193},
title = {{Convergence properties of functional estimates for discrete distributions}},
volume = {19},
year = {2001}
}
@article{Cantley2011,
author = {Cantley, KD},
journal = {IEEE Transactions on Nanotechnology},
number = {5},
pages = {1066--1073},
title = {{Hebbian learning in spiking neural networks with nanocrystalline silicon TFTs and memristive synapses}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5686944},
volume = {10},
year = {2011}
}
@article{Chen2010,
abstract = {BACKGROUND: How living neural networks retain information is still incompletely understood. Two prominent ideas on this topic have developed in parallel, but have remained somewhat unconnected. The first of these, the "synaptic hypothesis," holds that information can be retained in synaptic connection strengths, or weights, between neurons. Recent work inspired by statistical mechanics has suggested that networks will retain the most information when their weights are distributed in a skewed manner, with many weak weights and only a few strong ones. The second of these ideas is that information can be represented by stable activity patterns. Multineuron recordings have shown that sequences of neural activity distributed over many neurons are repeated above chance levels when animals perform well-learned tasks. Although these two ideas are compelling, no one to our knowledge has yet linked the predicted optimum distribution of weights to stable activity patterns actually observed in living neural networks. RESULTS: Here, we explore this link by comparing stable activity patterns from cortical slice networks recorded with multielectrode arrays to stable patterns produced by a model with a tunable weight distribution. This model was previously shown to capture central features of the dynamics in these slice networks, including neuronal avalanche cascades. We find that when the model weight distribution is appropriately skewed, it correctly matches the distribution of repeating patterns observed in the data. In addition, this same distribution of weights maximizes the capacity of the network model to retain stable activity patterns. Thus, the distribution that best fits the data is also the distribution that maximizes the number of stable patterns. CONCLUSIONS: We conclude that local cortical networks are very likely to use a highly skewed weight distribution to optimize information retention, as predicted by theory. Fixed distributions impose constraints on learning, however. The network must have mechanisms for preserving the overall weight distribution while allowing individual connection strengths to change with learning.},
author = {Chen, Wei and Hobbs, Jon P and Tang, Aonan and Beggs, John M},
doi = {10.1186/1471-2202-11-3},
issn = {1471-2202},
journal = {BMC neuroscience},
keywords = {Algorithms,Animals,Cells,Cultured,Information Theory,Microelectrodes,Models,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Probability,Rats,Somatosensory Cortex,Somatosensory Cortex: physiology,Sprague-Dawley,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,networks},
mendeley-tags = {networks},
month = {jan},
pages = {3},
pmid = {20053290},
title = {{A few strong connections: optimizing information retention in neuronal avalanches.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2824798{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {11},
year = {2010}
}
@article{Jacobs|2001|,
author = {Jacobs, B and Schall, M and Prather, M and Kapler, E and Driscoll, L and Baca, S and Jacobs, J and Ford, K and Wainwright, M and Treml, M},
journal = {Cereb Cortex},
number = {6},
pages = {558--571},
title = {{Regional dendritic and spine variation in human cerebral cortex: a quantitative golgi study.}},
volume = {11}
}
@article{DL91,
author = {Donoho, D and Liu, R},
journal = {Annals of Statistics},
pages = {633--701},
title = {{Geometrizing rates of convergence}},
volume = {19},
year = {1991}
}
@article{Reynolds|1999|,
abstract = {For purposes of this review, we will define the binding problem as
the problem of how the visual system cor- rectly links up all the
different features of complex objects. For example, when viewing
a person seated in a blue car, one effortlessly sees that the person{\"{i}}¾'s
nose belongs to his face and not to the car, and that the car, but
not the nose, is blue. To fully understand the solution to this problem
requires a good neurobiological theory of object recognition, which
does not exist. We will therefore follow the lead of the computer
engineer, who, when asked to describe how he would write a computer
program to recognize a chicken, replied, {\"{i}}¾“first, assume spherical
chicken.{\"{i}}¾” Thus, in this review we will make some assumptions that
simplify the binding problem in order to appreciate how neural mechanisms
of attention provide a partial solution.},
author = {Reynolds, J H and Desimone, R},
journal = {Neuron},
keywords = {attention,decision making,neurobiology,psychology,unread,visual salience},
pages = {19},
title = {{The role of neural mechanisms of attention in solving the binding problem}},
volume = {24}
}
@article{CohenKeynes71,
author = {Cohen, L B and Keynes, R D},
journal = {J. Physiol.},
pages = {259--275},
title = {{Changes in light scattering associated with the action potential in crab nerves.}},
volume = {212},
year = {1971}
}
@article{DT97,
author = {Ditzian, Z and Lubinsky, D},
journal = {Constructive Approximation},
pages = {99--152},
title = {{Jackson and smoothness theorems for {\{}F{\}}reud weights in {\{}L{\_}p{\}} (0 {\textless} p $\backslash$leq $\backslash$infty)}},
volume = {13},
year = {1997}
}
@article{Ciresan2010,
author = {Ciresan, D and Meier, U},
journal = {Neural Computation},
number = {12},
pages = {3207--3220},
title = {{Deep, big, simple neural nets for handwritten digit recognition}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/NECO{\_}a{\_}00052},
volume = {22},
year = {2010}
}
@article{Tong2011,
author = {Tong, H},
journal = {Statistics {\&} Its Interface},
keywords = {bi-modality,canadian lynx,chaos,conditional least squares,drift criterion,ecol-,ergodicity,heteroscedasticity,indicator time series,invertibility,limit cycles,markov chain,markov switching,nonlinear oscillations,ogy,piecewise linearity,river-flow,s pea-shooter,seiche record,skeleton,stability,test for linearity,threshold models,threshold principle,volatility,yule},
pages = {107--136},
title = {{Threshold models in time series analysis - 30 years on}},
url = {http://lx2.saas.hku.hk/research/research-report-471.pdf},
year = {2011}
}
@article{Paninski2012,
abstract = {We discuss methods for optimally inferring the synaptic inputs to an electrotonically compact neuron, given intracellular voltage-clamp or current-clamp recordings from the postsynaptic cell. These methods are based on sequential Monte Carlo techniques ("particle filtering"). We demonstrate, on model data, that these methods can recover the time course of excitatory and inhibitory synaptic inputs accurately on a single trial. Depending on the observation noise level, no averaging over multiple trials may be required. However, excitatory inputs are consistently inferred more accurately than inhibitory inputs at physiological resting potentials, due to the stronger driving force associated with excitatory conductances. Once these synaptic input time courses are recovered, it becomes possible to fit (via tractable convex optimization techniques) models describing the relationship between the sensory stimulus and the observed synaptic input. We develop both parametric and nonparametric expectation-maximization (EM) algorithms that consist of alternating iterations between these synaptic recovery and model estimation steps. We employ a fast, robust convex optimization-based method to effectively initialize the filter; these fast methods may be of independent interest. The proposed methods could be applied to better understand the balance between excitation and inhibition in sensory processing in vivo.},
author = {Paninski, L and Vidne, Michael and DePasquale, Brian and Ferreira, Daniel Gil},
doi = {10.1007/s10827-011-0371-7},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Animals,Biophysics,Electric Stimulation,Estimation,Membrane Potentials,Membrane Potentials: physiology,Models, Neurological,Monte Carlo Method,Neurons,Neurons: physiology,Patch-Clamp Techniques,Stochastic Processes,Synapses,Synapses: physiology},
mendeley-tags = {Estimation},
month = {aug},
number = {1},
pages = {1--19},
pmid = {22089473},
title = {{Inferring synaptic inputs given a noisy voltage trace via sequential Monte Carlo methods.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22089473},
volume = {33},
year = {2012}
}
@article{PrinzEa03,
author = {Prinz, A and Billimoria, C and Marder, E},
journal = {J. Neurophysiol.},
number = {6},
pages = {3998--4015},
title = {{Hand-Tuning Conductance-Based Models: Construction and Analysis of Databases of Model Neurons}},
volume = {90},
year = {2003}
}
@article{Chazelle2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1204.3946v1},
author = {Chazelle, Bernard},
eprint = {arXiv:1204.3946v1},
pages = {1--51},
title = {{The Dynamics of Influence Systems}},
url = {http://www.sns.ias.edu/pitp/2012files/Influence{\_}Systems.pdf},
year = {2008}
}
@article{Clay2005,
abstract = {The original papers of Hodgkin and Huxley (J. Physiol. 116 (1952a) 449, J. Physiol. 116 (1952b) 473, J. Physiol. 116 (1952c) 497, J. Physiol. 117 (1952d) 500) have provided a benchmark in our understanding of cellular excitability. Not surprisingly, their model of the membrane action potential (AP) requires revisions even for the squid giant axon, the preparation for which it was originally formulated. The mechanisms they proposed for the voltage-gated potassium and sodium ion currents, IK, and INa, respectively, have been superceded by more recent formulations that more accurately describe voltage-clamp measurements of these components. Moreover, the current-voltage relation for IK has a non-linear dependence upon driving force that is well described by the Goldman-Hodgkin-Katz (GHK) relation, rather than the linear dependence on driving force found by Hodgkin and Huxley. Furthermore, accumulation of potassium ions in the extracellular space adjacent to the axolemma appears to be significant even during a single AP. This paper describes the influence of these various modifications in their model on the mathematically reconstructed AP. The GHK and K+ accumulation results alter the shape of the AP, whereas the modifications in IK and INa gating have surprisingly little effect. Perhaps the most significant change in their model concerns the amplitude of INa, which they appear to have overestimated by a factor of two. This modification together with the GHK and the K+ accumulation results largely remove the discrepancies between membrane excitability of the squid giant axon and the Hodgkin and Huxley (J. Physiol. 117 (1952d) 500) model previously described (Clay, J. Neurophysiol. 80 (1998) 903).},
author = {Clay, J R},
doi = {10.1016/j.pbiomolbio.2003.12.004},
issn = {0079-6107},
journal = {Progress in biophysics and molecular biology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Decapodiformes,Decapodiformes: physiology,Ion Channel Gating,Ion Channel Gating: physiology,Models,Neurological,Potassium,Potassium Channels,Potassium Channels: physiology,Potassium: physiology,Sodium,Sodium: physiology},
month = {may},
number = {1},
pages = {59--90},
pmid = {15561301},
title = {{Axonal excitability revisited.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15561301},
volume = {88},
year = {2005}
}
@article{GPD03,
author = {Gedeon, T and Parker, A and Dimitrov, A},
journal = {Canadian Applied Math Quarterly},
pages = {33--70},
title = {{Information distortion and neural coding}},
volume = {10},
year = {2003}
}
@article{vanPelt05,
author = {{Van Pelt}, J and Vajda, I and Wolters, P and Corner, M and Ramakers, G},
journal = {Progress in Brain Research},
pages = {173--188},
title = {{Dynamics and plasticity in developing neuronal networks in vitro.}},
volume = {147},
year = {2005}
}
@article{Tsien88,
author = {Tsien, R Y},
journal = {Trends In Neurosciences},
month = {oct},
number = {10},
pages = {419--424},
title = {{Fluorescence measurement and photochemical manipulation of cytosolic free calcium}},
volume = {11},
year = {1988}
}
@article{YuDavis03,
abstract = {Camgaroos are yellow fluorescent protein derivatives that hold promise

as transgenically encoded calcium sensors in behaving animals. We

expressed two versions of camgaroo in Drosophila mushroom bodies

using the galactosidase-4 (GAL4) system. Potassium depolarization

of brains expressing the reporters produces a robust increase in

fluorescence that is blocked by removing extracellular calcium or

by antagonists of voltage-dependent calcium channels. The fluorescence

increase is not attributable to cytoplasmic alkalization; depolarization

induces a slight acidification of the cytoplasm of mushroom body

neurons. Acetylcholine applied near the dendrites of the mushroom

body neurons induces a rapid and ipsilateral-specific fluorescence

increase in the mushroom body axons that is blocked by antagonists

of calcium channels or nicotinic acetylcholine receptors. Fluorescence

was observed to increase in all three classes of mushroom body neurons,

indicating that all types respond to cholinergic innervation.},
author = {Yu, Dinghui and Baird, Geoffrey S and Tsien, Roger Y and Davis, Ronald L},
journal = {J Neurosci},
keywords = {Acetylcholine; Animals; Bacterial Proteins; Calciu,Cultured; Drosophila; Green Fluorescent Proteins;,Fluorescence; Mushroom Bodies; Neurons; Potassium},
month = {jan},
number = {1},
pages = {64--72},
pmid = {12514202},
title = {{Detection of calcium transients in Drosophila mushroom body neurons with camgaroo reporters.}},
volume = {23},
year = {2003}
}
@article{Hunter2000,
author = {Hunter, J J and Campus, A},
keywords = {stationary distribution},
mendeley-tags = {stationary distribution},
pages = {25--36},
title = {{A Survey of Generalized Inverses and their Use in Stochastic Modelling}},
year = {2000}
}
@article{SH95,
author = {Shao, Y and Hahn, M},
journal = {Statistics and Probability Letters},
pages = {121--132},
title = {{Limit theorems for the logarithm of sample spacings}},
volume = {24},
year = {1995}
}
@inproceedings{burak09,
author = {Burak, Y and Rokini, U and Sompolinsky, H and Meister, M},
booktitle = {Frontiers in Systems Neuroscience. Conference abstract: Computational and systems neuroscience.},
title = {{Compensating fixational eye movements: A network model.}},
year = {2009}
}
@article{Holtmaat2009,
abstract = {Synaptic plasticity in adult neural circuits may involve the strengthening or weakening of existing synapses as well as structural plasticity, including synapse formation and elimination. Indeed, long-term in vivo imaging studies are beginning to reveal the structural dynamics of neocortical neurons in the normal and injured adult brain. Although the overall cell-specific morphology of axons and dendrites, as well as of a subpopulation of small synaptic structures, are remarkably stable, there is increasing evidence that experience-dependent plasticity of specific circuits in the somatosensory and visual cortex involves cell type-specific structural plasticity: some boutons and dendritic spines appear and disappear, accompanied by synapse formation and elimination, respectively. This Review focuses on recent evidence for such structural forms of synaptic plasticity in the mammalian cortex and outlines open questions.},
annote = {2010IIInum24},
author = {Holtmaat, Anthony and Svoboda, K},
doi = {10.1038/nrn2699},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Brain,Brain: cytology,Brain: growth {\&} development,Brain: physiology,Humans,Nerve Net,Nerve Net: cytology,Nerve Net: growth {\&} development,Nerve Net: physiology,Neurogenesis,Neurogenesis: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Synapses,Synapses: physiology},
month = {sep},
number = {9},
pages = {647--658},
pmid = {19693029},
title = {{Experience-dependent structural synaptic plasticity in the mammalian brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19693029},
volume = {10},
year = {2009}
}
@article{Hornik1991,
author = {Hornik, K},
journal = {Neural networks},
keywords = {--multilayer feedforward networks,1,activation function,approximation,d,distance between functions,environment measure,i n t r,input,measured by the uniform,o d u c,p,smooth approximation,sobolev spaces,t i o n,uniform approximation,universal approximation capabilities},
number = {1989},
pages = {251--257},
title = {{Approximation capabilities of multilayer feedforward networks}},
url = {http://www.sciencedirect.com/science/article/pii/089360809190009T},
volume = {4},
year = {1991}
}
@incollection{OsenMugnaini81,
author = {K, Osen K and Mugnaini, E},
chapter = {Neuronal c},
editor = {J., Syka and Aitkin, L},
pages = {119--125},
publisher = {Plenum},
title = {{Neuronal Mechanisms of Hearing}},
year = {1981}
}
@article{Shlens06,
author = {Shlens, Jonathon and Field, Greg D and Gauthier, Jeffrey L and Grivich, Matthew I and Petrusca, Dumitru and Sher, Alexander and Litke, Alan M and Chichilnisky, E J},
journal = {J. Neurosci.},
pages = {8254--8266},
title = {{The Structure of Multi-Neuron Firing Patterns in Primate Retina}},
volume = {26},
year = {2006}
}
@article{Petersen03,
author = {Petersen, C and Hahn, T and Mehta, M and Grinvald, A and Sakmann, B},
journal = {PNAS},
pages = {13638--13643},
title = {{Interaction of sensory responses with spontaneous depolarization in layer 2/3 barrel cortex}},
volume = {100},
year = {2003}
}
@phdthesis{BatuPhd,
author = {Batu, T},
school = {Cornell},
title = {{Testing Properties of Distributions}},
year = {2001}
}
@article{Fiala|2005|,
author = {Fiala, J C},
journal = {J. Microsc.},
pages = {52--61},
title = {{Reconstruct: a free editor for serial section microscopy}},
volume = {218}
}
@article{Guckenheimer2002,
author = {Guckenheimer, J and Oliva, R A},
doi = {10.1137/S1111111101394040},
issn = {15360040},
journal = {SIAM Journal on Applied Dynamical Systems},
keywords = {1,15,37g35,92c20,action potential,ams subject classifications,chaos,for the action potential,hodgkin,horseshoe,huxley,huxley model,introduction,of a space-,pii,s1111111101394040,the hodgkin},
number = {1},
pages = {105},
title = {{Chaos in the Hodgkin--Huxley Model}},
url = {http://link.aip.org/link/SJADAY/v1/i1/p105/s1{\&}Agg=doi},
volume = {1},
year = {2002}
}
@article{LaCamera2006a,
abstract = {Neural dynamic processes correlated over several time scales are found in vivo, in stimulus-evoked as well as spontaneous activity, and are thought to affect the way sensory stimulation is processed. Despite their potential computational consequences, a systematic description of the presence of multiple time scales in single cortical neurons is lacking. In this study, we injected fast spiking and pyramidal (PYR) neurons in vitro with long-lasting episodes of step-like and noisy, in-vivo-like current. Several processes shaped the time course of the instantaneous spike frequency, which could be reduced to a small number (1-4) of phenomenological mechanisms, either reducing (adapting) or increasing (facilitating) the neuron's firing rate over time. The different adaptation/facilitation processes cover a wide range of time scales, ranging from initial adaptation ({\textless}10 ms, PYR neurons only), to fast adaptation ({\textless}300 ms), early facilitation (0.5-1 s, PYR only), and slow (or late) adaptation (order of seconds). These processes are characterized by broad distributions of their magnitudes and time constants across cells, showing that multiple time scales are at play in cortical neurons, even in response to stationary stimuli and in the presence of input fluctuations. These processes might be part of a cascade of processes responsible for the power-law behavior of adaptation observed in several preparations, and may have far-reaching computational consequences that have been recently described.},
annote = {

2009num47},
author = {{La Camera}, Giancarlo and Rauch, Alexander and Thurbon, David and L{\"{u}}scher, Hans-r and Senn, Walter and Fusi, Stefano and Camera, Giancarlo La and Lu, Hans-r and Camera, La},
doi = {10.1152/jn.00453.2006},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Adaptation,Algorithms,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Electric Stimulation,Electrophysiology,Female,Male,Models,Neurological,Neurons,Neurons: physiology,Patch-Clamp Techniques,Physiological,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Statistical},
month = {dec},
number = {6},
pages = {3448--64},
pmid = {16807345},
title = {{Multiple time scales of temporal response in pyramidal and fast spiking cortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16807345},
volume = {96},
year = {2006}
}
@article{Remy2009a,
abstract = {Neurons possess elaborate dendritic arbors which receive and integrate excitatory synaptic signals. Individual dendritic subbranches exhibit local membrane potential supralinearities, termed dendritic spikes, which control transfer of local synaptic input to the soma. Here, we show that dendritic spikes in CA1 pyramidal cells are strongly regulated by specific types of prior input. While input in the linear range is without effect, supralinear input inhibits subsequent spikes, causing them to attenuate and ultimately fail due to dendritic Na(+) channel inactivation. This mechanism acts locally within the boundaries of the input branch. If an input is sufficiently strong to trigger axonal action potentials, their back-propagation into the dendritic tree causes a widespread global reduction in dendritic excitability which is prominent after firing patterns occurring in vivo. Together, these mechanisms control the capability of individual dendritic branches to trigger somatic action potential output. They are invoked at frequencies encountered during learning, and impose limits on the storage and retrieval rates of information encoded as branch excitability.},
author = {Remy, Stefan and Csicsvari, Jozsef and Beck, Heinz},
doi = {10.1016/j.neuron.2009.01.032},
issn = {1097-4199},
journal = {Neuron},
keywords = {4-Aminopyridine,4-Aminopyridine: pharmacology,Action Potentials,Action Potentials: physiology,Animals,Biophysics,Dendrites,Dendrites: physiology,Electric Stimulation,Electric Stimulation: methods,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: drug effects,Excitatory Postsynaptic Potentials: physiology,Hippocampus,Hippocampus: cytology,Isoquinolines,Isoquinolines: metabolism,Linear Models,Newborn,Potassium Channel Blockers,Potassium Channel Blockers: pharmacology,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Rats,Sodium Channels,Sodium Channels: physiology,Wistar},
month = {mar},
number = {6},
pages = {906--916},
pmid = {19323999},
publisher = {Elsevier Ltd},
title = {{Activity-dependent control of neuronal output by local and global dendritic spike attenuation.}},
url = {http://dx.doi.org/10.1016/j.neuron.2009.01.032 http://www.sciencedirect.com/science/article/pii/S0896627309001561 http://www.ncbi.nlm.nih.gov/pubmed/19323999},
volume = {61},
year = {2009}
}
@article{shahaf2001learning,
annote = {2008num9},
author = {Shahaf, G and Marom, S},
journal = {Journal of Neuroscience},
number = {22},
pages = {8782},
publisher = {Soc Neuroscience},
title = {{Learning in networks of cortical neurons}},
volume = {21},
year = {2001}
}
@article{Feigenbaum1979,
author = {Feigenbaum, M.J.},
journal = {Physics Letters A},
number = {6},
pages = {375--378},
publisher = {Elsevier},
title = {{The onset spectrum of turbulence}},
url = {http://www.sciencedirect.com/science/article/pii/0375960179902275},
volume = {74},
year = {1979}
}
@article{Tasdizen|2005|,
abstract = {Transmission electron microscopy (TEM) is an important modality for
the analysis of cellular structures in neurobiology. The computational
analysis of neurons entail their segmentation and reconstruction
from TEM images. This problem is complicated by the heavily textured
nature of cellular TEM images and typically low signal-to-noise ratios.
In this paper, we propose a new partial differential equation for
enhancing the contrast and continuity of cell membranes in TEM images.},
annote = {The paper uses anisotropic diffusion to filter images while preserving{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}extended linear features. Hessian of given size is computed, and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}diffusion in the direction of smaller eigenvalue is performed. Gives{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}pretty good results.},
author = {Tasdizen, T and Whitaker, R and Marc, R and Jones, B},
journal = {IEEE},
keywords = {computational,diffusion,electron microscopy,filtering,image processing,nonlinear filter},
title = {{Enhancement of cell boundaries in transmission electron microscopy images}}
}
@book{MW04,
author = {Moeller, J and Waagepetersen, R},
publisher = {Chapman Hall},
title = {{Statistical inference and simulation for spatial point processes}},
year = {2004}
}
@book{VW98,
address = {Cambridge},
author = {van der Vaart, A},
publisher = {Cambridge University Press},
title = {{Asymptotic statistics}},
year = {1998}
}
@article{Almeida1996,
author = {Almeida, AP and Franca, JE},
journal = {Neural Networks, IEEE Transactions {\ldots}},
number = {2},
pages = {506--514},
title = {{Digitally programmable analog building blocks for the implementation of artificial neural networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=485684},
volume = {7},
year = {1996}
}
@inproceedings{SmalMeijering07,
abstract = {Modern live cell fluorescence microscopy imaging systems, used abundantly

for studying intra-cellular processes in vivo, generate vast amounts

of noisy image data that cannot be processed efficiently and accurately

by means of manual or current computerized techniques. We propose

an improved tracking method, built within a Bayesian probabilistic

framework, which better exploits temporal information and prior knowledge.

Experiments on simulated and real fluorescence microscopy image data

acquired for microtubule dynamics studies show that the technique

is more robust to noise, photobleaching, and object interaction than

common tracking methods and yields results that are in good agreement

with expert cell biologists.},
author = {Smal, I and Draegestein, K and Galjart, N and Niessen, W J and Meijering, E},
booktitle = {Information Processing in Medical Imaging - IPMI 2007},
title = {{Rao-Blackwellized Marginal Particle Filtering for Multiple Object Tracking in Molecular Bioimaging}},
year = {2007}
}
@article{Schmidt00,
author = {Schmidt, David M},
doi = {10.1103/PhysRevE.61.1052},
journal = {Phys. Rev. E},
month = {feb},
number = {2},
pages = {1052--1055},
publisher = {American Physical Society},
title = {{Continuous probability distributions from finite data}},
volume = {61},
year = {2000}
}
@article{Kondgen2008,
abstract = {Cortical neurons are often classified by current-frequency relationship. Such a static description is inadequate to interpret neuronal responses to time-varying stimuli. Theoretical studies suggested that single-cell dynamical response properties are necessary to interpret ensemble responses to fast input transients. Further, it was shown that input-noise linearizes and boosts the response bandwidth, and that the interplay between the barrage of noisy synaptic currents and the spike-initiation mechanisms determine the dynamical properties of the firing rate. To test these model predictions, we estimated the linear response properties of layer 5 pyramidal cells by injecting a superposition of a small-amplitude sinusoidal wave and a background noise. We characterized the evoked firing probability across many stimulation trials and a range of oscillation frequencies (1-1000 Hz), quantifying response amplitude and phase-shift while changing noise statistics. We found that neurons track unexpectedly fast transients, as their response amplitude has no attenuation up to 200 Hz. This cut-off frequency is higher than the limits set by passive membrane properties (approximately 50 Hz) and average firing rate (approximately 20 Hz) and is not affected by the rate of change of the input. Finally, above 200 Hz, the response amplitude decays as a power-law with an exponent that is independent of voltage fluctuations induced by the background noise.},
author = {Ko, Harold and Geisler, Caroline and Fusi, Stefano and Wang, Jing and Lu, Hans-rudolf and K{\"{o}}ndgen, Harold and Wang, Xiao-Jing J and L{\"{u}}scher, Hans-Rudolf and Giugliano, Michele},
doi = {10.1093/cercor/bhm235},
issn = {1460-2199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Artifacts,Electric Stimulation,Evoked Potentials,Evoked Potentials: physiology,Linear Models,Models,Neocortex,Neocortex: cytology,Neocortex: physiology,Neurological,Organ Culture Techniques,Periodicity,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Reaction Time,Reaction Time: physiology,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology,Wistar},
month = {sep},
number = {9},
pages = {2086--97},
pmid = {18263893},
title = {{The dynamical response properties of neocortical neurons to temporally modulated noisy inputs in vitro.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3140196{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pubmed/18263893},
volume = {18},
year = {2008}
}
@article{Ballo2009,
abstract = {We studied the peripheral motor axons of the two pyloric dilator (PD) neurons of the stomatogastric ganglion in the lobster, Homarus americanus. Intracellular recordings from the motor nerve showed both fast and slow voltage- and activity-dependent dynamics. During rhythmic bursts, the PD axons displayed changes in spike amplitude and duration. Pharmacological experiments and the voltage dependence of these phenomena suggest that inactivation of sodium and A-type potassium channels are responsible. In addition, the "resting" membrane potential was dependent on ongoing spike or burst activity, with more hyperpolarized values when activity was strong. Nerve stimulations, pharmacological block and current clamp experiments suggest that this is due to a functional antagonism between a slow after-hyperpolarization (sAHP) and inward rectification through hyperpolarization-activated current (IH). Dopamine application resulted in modest depolarization and "ectopic" peripheral spike initiation in the absence of centrally generated activity. This effect was blocked by CsCl and ZD7288, consistent with a role of IH. High frequency nerve stimulation inhibited peripheral spike initiation for several seconds, presumably due to the sAHP. Both during normal bursting activity and antidromic nerve stimulation, the conduction delay over the length of the peripheral nerve changed in a complex manner. This suggests that axonal membrane dynamics can have a substantial effect on the temporal fidelity of spike patterns propagated from a spike initiation site to a synaptic target, and that neuromodulators can influence the extent to which spike patterns are modified.},
annote = {2010IInum12.33},
author = {Ballo, Aleksander W and Bucher, D},
doi = {10.1523/JNEUROSCI.0716-09.2009},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Dopamine,Dopamine: physiology,Membrane Potentials,Membrane Potentials: physiology,Motor Neurons,Motor Neurons: physiology,Nephropidae,Neuron Model},
mendeley-tags = {Neuron Model},
month = {apr},
number = {16},
pages = {5062--74},
pmid = {19386902},
title = {{Complex intrinsic membrane properties and dopamine shape spiking activity in a motor axon.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19386902},
volume = {29},
year = {2009}
}
@article{DB00,
author = {Denzler, J and Brown, C},
journal = {U. Rochester Technical Reports},
title = {{Optimal Selection of Camera Parameters for State Estimation of Static Systems: An Information Theoretic Approach}},
volume = {732},
year = {2000}
}
@book{Golub1996,
author = {Golub, G.H. and {Van Loan}, C.F.},
publisher = {Johns Hopkins Univ Pr},
title = {{Matrix Computations}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=mlOa7wPX6OYC{\&}oi=fnd{\&}pg=PR11{\&}dq=Matrix+Computations{\&}ots=lcbrh3Obl{\_}{\&}sig=8aIKQt6jMaFMAt5qyCxlIizKZz4},
volume = {3},
year = {1996}
}
@article{Matsuzaki08,
author = {Matsuzaki, Masanori and Ellis-Davies, Graham C R and Kasai, Haruo},
journal = {J Neurophysiol},
number = {3},
pages = {1535--1544},
title = {{Three-Dimensional Mapping of Unitary Synaptic Connections by Two-Photon Macro Photolysis of Caged Glutamate}},
volume = {99},
year = {2008}
}
@article{Choi|1999|,
abstract = {Both the mass spectra and the wave functions of the light pseudoscalar
(p,K,h ,h 8) and vector(r ,K*,v,f) mesons are analyzed within the
framework of the light-cone constituent quark model. A Gaussian radial
wave function is used as a trial function of the variational principle
for a QCD-motivated Hamiltonian which includes not only the Coulomb
plus confining potential but also the hyperfine interaction to obtain
the correct r -p splitting. For the confining potential, we use the
{\~{}}1! harmonic oscillator potential and {\~{}}2! linear potential and compare
the numerical results for these two cases. The mixing angles of v-f
and h -h 8 are predicted and various physical observables such as
decay constants, charge radii, and radiative decay rates, etc., are
calculated. Our numerical results in the two cases {\~{}}1! and {\~{}}2! are
overall not much different from each other and are in good agreement
with the available experimental data.},
annote = {This paper introduces form-factors calculations using fairly simple{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}LF constituent quarks model for mesons.},
author = {Choi, H.-M. and Ji, C.-R.},
journal = {Physical Review D},
keywords = {constituent model,form-factors,light front dynamics,mesons,physics,quantum chromodynamics},
pages = {74015},
title = {{Mixing angles and electromagnetic properties of ground state pseudoscalar and vector meson nonets in the light-cone quark model}},
volume = {59}
}
@incollection{WF02,
author = {Weiss, Y and Fleet, D},
chapter = {Velocity l},
pages = {77--96},
publisher = {MIT Press},
title = {{Statistical Theories of the Cortex}},
year = {2002}
}
@article{Koch84,
author = {Koch, C},
journal = {Biological Cybernetics},
pages = {15--33},
title = {{Cable theory in neurons with active, linearized membranes}},
volume = {50},
year = {1984}
}
@article{CAR05,
author = {Carandini et al.},
journal = {Journal of Neuroscience},
pages = {10577--10597},
title = {{Do we know what the early visual system does?}},
volume = {25},
year = {2005}
}
@article{Review1998,
author = {Review, Topical},
keywords = {conducted a series of,deactivation,environments,excitabil-,hodgkin-huxley,inactivation,ion channel,ity,membrane,modulation,relations between the ionic,studies aimed at uncovering,the},
pages = {105--113},
title = {{Membrane Biology Topical Review of Excitable Membranes}},
volume = {113},
year = {1998}
}
@phdthesis{HAITH04,
author = {Haith, A},
school = {University of Edinburgh},
title = {{Estimating the Parameters of a Stochastic Integrate-and-Fire Neural Model}},
year = {2004}
}
@book{Murray2002,
author = {Murray, J D},
edition = {3rd},
isbn = {0387952233},
publisher = {Springer, New York},
title = {{Mathematical Biology}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=XbCuqjePs0MC{\&}oi=fnd{\&}pg=PR2{\&}dq=Mathematical+Biology{\&}ots=Z1t1glCooG{\&}sig=PafzgWptTzVQGfQ8722OH9tRgfc},
year = {2002}
}
@book{jacob2003limit,
author = {Jacob, J and Shiryaev, A N},
publisher = {Berlin: Springer-Verlag},
title = {{Limit Theorems for Stochastic Processes, ser. A Series of Comprehensive Studies in Mathematics}},
year = {2003}
}
@article{Buesing2011,
abstract = {The organization of computations in networks of spiking neurons in the brain is still largely unknown, in particular in view of the inherently stochastic features of their firing activity and the experimentally observed trial-to-trial variability of neural systems in the brain. In principle there exists a powerful computational framework for stochastic computations, probabilistic inference by sampling, which can explain a large number of macroscopic experimental data in neuroscience and cognitive science. But it has turned out to be surprisingly difficult to create a link between these abstract models for stochastic computations and more detailed models of the dynamics of networks of spiking neurons. Here we create such a link and show that under some conditions the stochastic firing activity of networks of spiking neurons can be interpreted as probabilistic inference via Markov chain Monte Carlo (MCMC) sampling. Since common methods for MCMC sampling in distributed systems, such as Gibbs sampling, are inconsistent with the dynamics of spiking neurons, we introduce a different approach based on non-reversible Markov chains that is able to reflect inherent temporal processes of spiking neuronal activity through a suitable choice of random variables. We propose a neural network model and show by a rigorous theoretical analysis that its neural activity implements MCMC sampling of a given distribution, both for the case of discrete and continuous time. This provides a step towards closing the gap between abstract functional models of cortical computation and more detailed models of networks of spiking neurons.},
author = {Buesing, L and Bill, J and Nessler, B and Maass, W},
doi = {10.1371/journal.pcbi.1002211},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Computer Simulation,Humans,Markov Chains,Models,Monte Carlo Method,Neurological,Neurons,Neurons: physiology,Primates,Stochastic Processes},
month = {nov},
number = {11},
pages = {e1002211},
pmid = {22096452},
title = {{Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3207943{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2011}
}
@techreport{Petersen2007,
author = {Petersen, K B and Pedersen, M S},
doi = {10.1111/j.1365-294X.2006.03161.x},
isbn = {0962-1083 (Print)$\backslash$r0962-1083 (Linking)},
issn = {09621083},
pmid = {17284204},
title = {{The Matrix Cookbook}},
url = {http://matrixcookbook.com},
year = {2012}
}
@article{Healthcare1992,
author = {Healthcare, Publisher Informa},
doi = {10.1088/0954-898X/3/3/002},
number = {906391986},
title = {{Network : Computation in Neural Systems Dynamic properties of neural networks with adapting synapses}},
year = {1992}
}
@article{Gritsun2010b,
abstract = {One of the most specific and exhibited features in the electrical activity of dissociated cultured neural networks (NNs) is the phenomenon of synchronized bursts, whose profiles vary widely in shape, width and firing rate. On the way to understanding the organization and behavior of biological NNs, we reproduced those features with random connectivity network models with 5,000 neurons. While the common approach to induce bursting behavior in neuronal network models is noise injection, there is experimental evidence suggesting the existence of pacemaker-like neurons. In our simulations noise did evoke bursts, but with an unrealistically gentle rising slope. We show that a small subset of 'pacemaker' neurons can trigger bursts with a more realistic profile. We found that adding pacemaker-like neurons as well as adaptive synapses yield burst features (shape, width, and height of the main phase) in the same ranges as obtained experimentally. Finally, we demonstrate how changes in network connectivity, transmission delays, and excitatory fraction influence network burst features quantitatively.},
author = {Le, T A Gritsun J and Stegenga, Feber J and Rutten, Wim L C and Gritsun, T a and {Le Feber}, J and Stegenga, J},
doi = {10.1007/s00422-010-0366-x},
issn = {1432-0770},
journal = {Biological cybernetics},
keywords = {Action Potentials,Adaptation,Animals,Biological Clocks,Cells,Cultured,Cybernetics,Electrophysiological Phenomena,Models,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurological,Physiological,Rats,Synapses,Synapses: physiology,cultured neuronal,network bursts,networks,pacemaker cells,recurrent neural networks},
month = {apr},
number = {4},
pages = {293--310},
pmid = {20157725},
title = {{Network bursts in cortical cultures are best simulated using pacemaker neurons and adaptive synapses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20157725},
volume = {102},
year = {2010}
}
@article{hodgkin1949effect,
author = {Hodgkin, A L and Katz, B.},
issn = {0022-3751},
journal = {The Journal of physiology},
number = {1},
pages = {37},
publisher = {Physiological Soc},
title = {{The effect of sodium ions on the electrical activity of the giant axon of the squid}},
url = {http://jp.physoc.org/content/108/1/37.full.pdf},
volume = {108},
year = {1949}
}
@article{Takahashi2010,
abstract = {Spike synchronization underlies information processing and storage in the brain. But how can neurons synchronize in a noisy network? By exploiting a high-speed (500-2,000 fps) multineuron imaging technique and a large-scale synapse mapping method, we directly compared spontaneous activity patterns and anatomical connectivity in hippocampal CA3 networks ex vivo. As compared to unconnected pairs, synaptically coupled neurons shared more common presynaptic neurons, received more correlated excitatory synaptic inputs, and emitted synchronized spikes with approximately 10(7) times higher probability. Importantly, common presynaptic parents per se synchronized more than unshared upstream neurons. Consistent with this, dynamic-clamp stimulation revealed that common inputs alone could not account for the realistic degree of synchronization unless presynaptic spikes synchronized among common parents. On a macroscopic scale, network activity was coordinated by a power-law scaling of synchronization, which engaged varying sets of densely interwired (thus highly synchronized) neuron groups. Thus, locally coherent activity converges on specific cell assemblies, thereby yielding complex ensemble dynamics. These segmentally synchronized pulse packets may serve as information modules that flow in associatively parallel network channels.},
annote = {2010IInum12.43},
author = {Takahashi, Naoya and Sasaki, Takuya and Matsumoto, Wataru and Matsuki, Norio and Ikegaya, Y},
doi = {10.1073/pnas.0914594107},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {networks},
mendeley-tags = {networks},
month = {may},
number = {22},
pages = {10244--10249},
pmid = {20479225},
title = {{Circuit topology for synchronizing neurons in spontaneously active networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20479225},
volume = {107},
year = {2010}
}
@article{Sorra|1998|a,
author = {Sorra, K E and Fiala, J C and Harris, K M},
journal = {J Comp Neurol},
pages = {225--240},
title = {{Critical assessment of the involvement of perforations, spinules, and spine branching in hippocampal synapse formation.}},
volume = {398}
}
@article{KVC03,
author = {Kass, R and Ventura, V and Cai, C},
journal = {Network: Computation in Neural Systems},
pages = {5--15},
title = {{Statistical smoothing of neuronal data}},
volume = {14},
year = {2003}
}
@article{Shewchuk1994,
author = {Shewchuk, JR},
keywords = {1,2,5,agonizing pain,conjugate gradient method,convergence analysis,eigen do it if,eigenvalues,i try,jacobi iterations,preconditioning,thinking with eigenvectors and},
title = {{An introduction to the conjugate gradient method without the agonizing pain}},
url = {http://reference.kfupm.edu.sa/content/i/n/an{\_}introduction{\_}to{\_}the{\_}conjugate{\_}gradien{\_}55475.pdf},
year = {1994}
}
@article{Englitz2008,
abstract = {Pharmacologically isolated GABAergic irregular spiking and stuttering interneurons in the mouse visual cortex display highly irregular spike times, with high coefficients of variation approximately 0.9-3, in response to a depolarizing, constant current input. This is in marked contrast to cortical pyramidal cells, which spike quite regularly in response to the same current injection. We applied time-series analysis methods to show that the irregular behavior of the interneurons was not a consequence of low-dimensional, deterministic processes. These methods were also applied to the Hindmarsh and Rose neuronal model to confirm that the methods are adequate for the types of data under investigation. This result has important consequences for the origin of fluctuations observed in the cortex in vivo.},
author = {Englitz, Bernhard and Stiefel, Klaus M and Sejnowski, T J},
doi = {10.1162/neco.2008.20.1.44},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Computer Simulation,Cortical Synchronization,Interneurons,Interneurons: physiology,Mice,Models, Neurological,Neural Inhibition,Neural Inhibition: physiology,Nonlinear Dynamics,Periodicity,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Stochastic Processes,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors,Visual Cortex,Visual Cortex: physiology},
month = {jan},
number = {1},
pages = {44--64},
pmid = {18045000},
title = {{Irregular firing of isolated cortical interneurons in vitro driven by intrinsic stochastic mechanisms.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2730502{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {20},
year = {2008}
}
@article{Poznanski2004,
author = {Poznanski, R.R.},
journal = {Journal of integrative neuroscience},
number = {3},
pages = {267},
title = {{Analytical solutions of the Frankenhaeuser-Huxley equations I: minimal model for backpropagation of action potentials in sparsely excitable dendrites.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15366097},
volume = {3},
year = {2004}
}
@article{Wawrzkiewicz2012,
author = {Wawrzkiewicz, Agata and Pawelek, Krzysztof},
doi = {10.1007/s00249-012-0806-8},
isbn = {0024901208068},
journal = {European Biophysics {\ldots}},
keywords = {analysis {\'{a}},bk channels {\'{a}} activation,conformational diffusion {\'{a}} hurst,gate,random walk process {\'{a}}},
pages = {505--526},
title = {{On the simple random-walk models of ion-channel gate dynamics reflecting long-term memory}},
url = {http://www.springerlink.com/index/6050620866433411.pdf},
year = {2012}
}
@article{WILSON72,
author = {Wilson, H R and Cowan, J D},
journal = {Biophys J},
month = {jan},
number = {1},
pages = {1--24},
title = {{{\{}E{\}}xcitatory and inhibitory interactions in localized populations of model neurons}},
volume = {12},
year = {1972}
}
@article{Rubin1976,
author = {Rubin, Donald B.},
doi = {10.2307/2335739},
issn = {00063444},
journal = {Biometrika},
month = {dec},
number = {3},
pages = {581},
title = {{Inference and Missing Data}},
url = {http://www.jstor.org/stable/2335739?origin=crossref},
volume = {63},
year = {1976}
}
@article{Destexhe2004a,
annote = {2009num49},
author = {Destexhe, A and Marder, E},
journal = {Nature},
number = {October},
pages = {789--795},
title = {{Plasticity in single neuron and circuit computations}},
url = {http://www.nature.com/nature/journal/v431/n7010/full/nature03011.html?lang=en},
volume = {431},
year = {2004}
}
@article{Matsumoto1987,
author = {Matsumoto, G. and Aihara, K. and Hanyu, Y. and Takahashi, N. and Yoshizawa, S. and Nagumo, J.},
issn = {0375-9601},
journal = {Physics letters A},
number = {4},
pages = {162--166},
publisher = {Elsevier},
title = {{Chaos and phase locking in normal squid axons}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0375960187906967},
volume = {123},
year = {1987}
}
@article{Stein67,
author = {Stein, R},
journal = {Biophysical Journal},
pages = {797--826},
title = {{The information capacity of nerve cells using a frequency code}},
volume = {7},
year = {1967}
}
@article{Gilbert83,
author = {Gilbert, C},
journal = {Annu Rev Neurosci},
pages = {217--247},
title = {{Microcircuitry of visual cortex}},
volume = {6},
year = {1983}
}
@article{Vergassola2007,
abstract = {Chemotactic bacteria rely on local concentration gradients to guide them towards the source of a nutrient. Such local cues pointing towards the location of the source are not always available at macroscopic scales because mixing in a flowing medium breaks up regions of high concentration into random and disconnected patches. Thus, animals sensing odours in air or water detect them only intermittently as patches sweep by on the wind or currents. A macroscopic searcher must devise a strategy of movement based on sporadic cues and partial information. Here we propose a search algorithm, which we call 'infotaxis', designed to work under such conditions. Any search process can be thought of as acquisition of information on source location; for infotaxis, information plays a role similar to concentration in chemotaxis. The infotaxis strategy locally maximizes the expected rate of information gain. We demonstrate its efficiency using a computational model of odour plume propagation and experimental data on mixing flows. Infotactic trajectories feature 'zigzagging' and 'casting' paths similar to those observed in the flight of moths. The proposed search algorithm is relevant to the design of olfactory robots, but the general idea of infotaxis can be applied more broadly in the context of searching with sparse information.},
annote = {2009num41},
author = {Vergassola, Massimo and Villermaux, Emmanuel and Shraiman, Boris I},
doi = {10.1038/nature05464},
issn = {1476-4687},
journal = {Nature},
keywords = {Algorithms,Animals,Biological,Biomimetics,Biomimetics: methods,Chemotaxis,Chemotaxis: physiology,Computer Simulation,Entropy,Models,Moths,Moths: physiology,Odors,Odors: analysis,Pheromones,Pheromones: analysis,Robotics,Robotics: methods,Smell,Smell: physiology},
number = {7126},
pages = {406--409},
pmid = {17251974},
title = {{'Infotaxis' as a strategy for searching without gradients.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17251974},
volume = {445},
year = {2007}
}
@inproceedings{Safran2015,
abstract = {Over the past few years, artificial neural networks have seen a dramatic resurgence in popularity as a tool for solving hard learning problems in AI applications. While it is widely known that neural networks are computationally hard to train in the worst case, in practice, neural networks are trained efficiently using SGD methods and a variety of techniques which accelerate the learning process. One mechanism which has been suggested to explain this is overspecification, which is the training of a network larger than what would be needed with unbounded computational power. Empirically, despite worst-case NP-hardness results, large networks tend to achieve a smaller error over the training set. In this work, we aspire to understand this phenomenon. In particular, we wish to better understand the behavior of the error over the sample as a function of the weights of the network, where we focus mostly on neural nets comprised of 2 layers, although we will also consider single neuron nets and nets of arbitrary depth, investigating properties such as the number of local minima the function has, and the probability of initializing from a basin with a given minimal value, with the goal of finding reasonable conditions under which efficient learning of the network is possible.},
archivePrefix = {arXiv},
arxivId = {1511.04210},
author = {Safran, Itay and Shamir, Ohad},
booktitle = {ICML},
eprint = {1511.04210},
title = {{On the Quality of the Initial Basin in Overspecified Neural Networks}},
url = {http://arxiv.org/abs/1511.04210},
year = {2016}
}
@article{Shadlen1998a,
annote = {2010IInum12.12},
author = {Shadlen, MN N and Newsome, WT T},
journal = {Journal of Neuroscience},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
pages = {3870--3896},
title = {{The variable discharge of cortical neurons: implications for connectivity, computation, and information coding}},
url = {http://www.jneurosci.org/cgi/content/abstract/18/10/3870},
volume = {18},
year = {1998}
}
@article{Tipireddy09,
author = {Tipireddy, R and Nasrellah, H and Manohar, C},
journal = {Probabilistic Engineering Mechanics},
pages = {60--74},
title = {{A {\{}K{\}}alman filter based strategy for linear structural system identification based on multiple static and dynamic test data}},
volume = {24},
year = {2009}
}
@article{Paglieroni|1992|,
abstract = {Distance transforms are shown to be useful for a variety of existing
and newly proposed machine vision applications. Their utility is
established and reviewed in the context of applications for newly
derived distance transform properties. These properties state the
effects of binary function geometrical transforms on their distance
transforms, quantify effects of translation and rotation on binary
function-to-distance transform cross-correlations and identify the
role of distance transforms in adaptive matching of one set of points
to another. Several application examples that involve pattern matching,
morphology, and interpolation are provided.},
annote = {This paper describes a variety of approximate distance transforms{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}used to reproduce Euclidean distance in computations and some of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}their applications as well as algorithms for scan-based fast computation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of such transforms.},
author = {Paglieroni, D W},
journal = {Graphical models and image processing},
keywords = {algorithm,chess-board,city-block,computational,distance transform,euclidean,image processing},
number = {1},
pages = {56},
title = {{Distance transforms: properties and machine vision applications}},
volume = {54}
}
@article{Solo04,
author = {Solo, V},
journal = {ICASSP},
pages = {685--688},
title = {{State estimation from high-dimensional data}},
volume = {2},
year = {2004}
}
@article{Card1994,
author = {Card, H and Schneider, C. R. and Schneider, R. S.},
doi = {10.1007/BF02106447},
issn = {0922-5773},
journal = {Journal of VLSI Signal Processing},
month = {oct},
number = {3},
pages = {209--225},
title = {{Learning capacitive weights in analog CMOS neural networks}},
url = {http://link.springer.com/10.1007/BF02106447},
volume = {8},
year = {1994}
}
@inproceedings{AhrensSahani06,
author = {Ahrens, M B and Paninski, L and Petersen, R and Sahani, M},
booktitle = {Computational Neuroscience Meeting, Edinburgh},
title = {{Input nonlinearity models of barrel cortex responses.}},
year = {2006}
}
@article{HOLTMAAT06,
author = {Holtmaat, A and Wilbrecht, L and Knott, G and Welker, E and Svoboda, K},
journal = {Nature},
pages = {979--983},
title = {{Experience-dependent and cell-type-specific spine growth in the neocortex}},
volume = {441},
year = {2006}
}
@article{BMC05,
author = {Bonin, V and Mante, V and Carandini, M},
journal = {Journal of Neuroscience},
pages = {10844--10856},
title = {{The Suppressive Field of Neurons in Lateral Geniculate Nucleus}},
volume = {25},
year = {2005}
}
@article{Small2009a,
author = {Small, Michael and Robinson, Hugh P C and Kleppe, Ingo C and Tse, Chi Kong},
doi = {10.1007/s00285-009-0312-5},
isbn = {0028500903},
keywords = {2000,bifurcation and chaos,cortical synaptic transmission,mathematics subject classification,modelling,nonlinear time,series analysis},
title = {{Mathematical Biology}},
year = {2009}
}
@article{White2000,
abstract = {The probabilistic gating of voltage-dependent ion channels is a source of electrical 'channel noise' in neurons. This noise has long been implicated in limiting the reliability (repeatability) of neuronal responses to repeated presentations of identical stimuli. More recently, it has been shown to increase the range of spiking behaviors exhibited in some neural populations. Channel numbers are tied to metabolic efficiency and the stability of resting potential, and channel noise might be exploited by future cochlear implants in order to improve the temporal representation of sound.},
annote = {2010IInum12.37},
author = {White, JA A and Rubinstein, JT T and Kay, AR R},
issn = {0166-2236},
journal = {Trends in Neurosciences},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Cochlear Implants,Electric Stimulation,Humans,Ion Channel Gating,Ion Channel Gating: physiology,Ion Channels,Ion Channels: physiology,Models,Neurological,Neurons,Neurons: cytology,Neurons: physiology,Reproducibility of Results,Stochastic Processes,Synaptic Transmission,Synaptic Transmission: physiology},
month = {mar},
number = {3},
pages = {131--7},
pmid = {10675918},
title = {{Channel noise in neurons}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19113157 http://www.ncbi.nlm.nih.gov/pubmed/10675918 http://www.sciencedirect.com/science/article/pii/S0166223699015210},
volume = {23},
year = {2000}
}
@book{Braitenberg1998,
address = {Berlin},
author = {Braitenberg, V and Schuz, A},
publisher = {Springer},
title = {{Cortex: statistics and geometry of neuronal connectivity.}},
year = {1998}
}
@article{Chen2016,
author = {Chen, Yingtong and Peng, Jigen},
doi = {10.1080/03081087.2015.1116495},
issn = {0308-1087},
journal = {Linear and Multilinear Algebra},
number = {9},
pages = {1750--1759},
publisher = {Taylor {\&} Francis},
title = {{Influences of preconditioning on the mutual coherence and the restricted isometry property of Gaussian/Bernoulli measurement matrices}},
url = {http://www.tandfonline.com/doi/full/10.1080/03081087.2015.1116495},
volume = {64},
year = {2016}
}
@article{BR88,
author = {Bickel, P and Ritov, Y},
journal = {Sankhya A},
pages = {381--393},
title = {{Estimating integrated squared density derivatives: sharp best order of convergence estimates}},
volume = {50},
year = {1988}
}
@article{Lowen1995,
author = {Lowen, S B and Teich, M C},
journal = {Fractals},
number = {1},
pages = {183--210},
title = {{Estimation and simulation of fractal stochastic point processes}},
url = {http://128.197.153.21/teich/pdfs/FRAC-03-183-1995.pdf},
volume = {3},
year = {1995}
}
@article{Shu2003,
abstract = {The vast majority of synaptic connections onto neurons in the cerebral cortex arise from other cortical neurons, both excitatory and inhibitory, forming local and distant 'recurrent' networks. Although this is a basic theme of cortical organization, its study has been limited largely to theoretical investigations, which predict that local recurrent networks show a proportionality or balance between recurrent excitation and inhibition, allowing the generation of stable periods of activity. This recurrent activity might underlie such diverse operations as short-term memory, the modulation of neuronal excitability with attention, and the generation of spontaneous activity during sleep. Here we show that local cortical circuits do indeed operate through a proportional balance of excitation and inhibition generated through local recurrent connections, and that the operation of such circuits can generate self-sustaining activity that can be turned on and off by synaptic inputs. These results confirm the long-hypothesized role of recurrent activity as a basic operation of the cerebral cortex.},
author = {Shu, Yousheng and Hasenstaub, Andrea and McCormick, David A},
doi = {10.1038/nature01616},
journal = {Nature},
keywords = {Action Potentials,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Electric Stimulation,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Ferrets,Ferrets: physiology,In Vitro Techniques,Interneurons,Interneurons: physiology,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurons,Neurons: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Synapses,Synapses: physiology},
month = {may},
number = {6937},
pages = {288--293},
pmid = {12748642},
shorttitle = {Nature},
title = {{Turning on and off recurrent balanced cortical activity.}},
url = {http://dx.doi.org/10.1038/nature01616},
volume = {423},
year = {2003}
}
@article{Gerhard2013,
abstract = {Identifying the structure and dynamics of synaptic interactions between neurons is the first step to understanding neural network dynamics. The presence of synaptic connections is traditionally inferred through the use of targeted stimulation and paired recordings or by post-hoc histology. More recently, causal network inference algorithms have been proposed to deduce connectivity directly from electrophysiological signals, such as extracellularly recorded spiking activity. Usually, these algorithms have not been validated on a neurophysiological data set for which the actual circuitry is known. Recent work has shown that traditional network inference algorithms based on linear models typically fail to identify the correct coupling of a small central pattern generating circuit in the stomatogastric ganglion of the crab Cancer borealis. In this work, we show that point process models of observed spike trains can guide inference of relative connectivity estimates that match the known physiological connectivity of the central pattern generator up to a choice of threshold. We elucidate the necessary steps to derive faithful connectivity estimates from a model that incorporates the spike train nature of the data. We then apply the model to measure changes in the effective connectivity pattern in response to two pharmacological interventions, which affect both intrinsic neural dynamics and synaptic transmission. Our results provide the first successful application of a network inference algorithm to a circuit for which the actual physiological synapses between neurons are known. The point process methodology presented here generalizes well to larger networks and can describe the statistics of neural populations. In general we show that advanced statistical models allow for the characterization of effective network structure, deciphering underlying network dynamics and estimating information-processing capabilities.},
author = {Gerhard, F and Kispersky, Tilman and Gutierrez, Gabrielle J and Marder, E and Kramer, Mark and Eden, Uri},
doi = {10.1371/journal.pcbi.1003138},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Estimation},
mendeley-tags = {Estimation},
month = {jul},
number = {7},
pages = {e1003138},
pmid = {23874181},
title = {{Successful reconstruction of a physiological circuit with known connectivity from spiking activity alone.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3708849{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2013}
}
@article{TsienRink82,
abstract = {A new, fluorescent, highly selective {\{}Ca{\}}{\^{}}{\{}2+{\}} indicator , "quin2",

has been trapped inside intact mouse and pig lymphocytes, to measure

and manipulate cytoplasmic free {\{}Ca{\}}{\^{}}{\{}2+{\}} concentrations, [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i.

Quin2 is a tetracarboxylic acid which binds {\{}Ca{\}}{\^{}}{\{}2+{\}} with 1:1

stoichiometry and an effective dissociation constant of 115 nM in

a cationic background mimicking cytoplasm. Its fluorescence signal

(excitation 339 nm, emission 492 nm) increases about fivefold going

from Ca-free to CA-saturated forms. Cells are loaded with quin2 by

incubation with its acetoxymethyl ester, which readily permeates

the membrane and is hydrolyzed in the cytoplasm, thus trapping the

impermeant quin2 there. The intracellular quin2 appears to be free

in cytoplasm, not bound to membranes and not sequestered inside organelles.

The fluorescence signal from resting cells indicates a [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i

of near 120 nM. The millimolar loadings of quin2 needed for accurately

calibrated signals do not seem to perturb steady-state [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i,

but do somewhat slow or blunt [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i transients. Loadings

of up to 2mM are without serious toxic effects, though above this

level some lowering of cellular ATP is observed. [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i

was well stabilized in the face of large changes in external {\{}Ca{\}}{\^{}}{\{}2+{\}}.

Alterations of Na+ gradients, membrane potential, or intracellular

pH had little effect. Mitochondrial poisons produced a small increase

in [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i, probably due mostly to the effects of severe

ATP depletion on the plasma membrane. Thus intracellulary trapped

chelators like quin2 offer a method to measure or buffer [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i

in hitherto intractable cell types.},
author = {Tsien, R and Pozzan, T and Rink, T},
journal = {J Cell Biol},
keywords = {Aminoquinolines; Animals; B-Lymphocytes; Calcium;},
month = {aug},
number = {2},
pages = {325--334},
pmid = {6980885},
title = {{Calcium homeostasis in intact lymphocytes: cytoplasmic free calcium monitored with a new, intracellularly trapped fluorescent indicator.}},
volume = {94},
year = {1982}
}
@article{Kim2003,
abstract = {The retina adapts to the temporal contrast of the light inputs. One component of contrast adaptation is intrinsic to retinal ganglion cells: temporal contrast affects the variance of the synaptic inputs to ganglion cells, which alters the gain of spike generation. Here we show that slow Na+ inactivation is sufficient to produce the observed variance adaptation. Slow inactivation caused the Na+ current available for spike generation to depend on the past history of activity, both action potentials and subthreshold voltage variations. Recovery from slow inactivation required several hundred milliseconds. Increased current variance caused the threshold for spike generation to increase, presumably because of the decrease in available Na+ current. Simulations indicated that slow Na+ inactivation could account for the observed decrease in excitability. This suggests a simple picture of how ganglion cells contribute to contrast adaptation: (1) increasing contrast causes an increase in input current variance that raises the spike rate, and (2) the increased spike rate reduces the available Na+ current through slow inactivation, which feeds back to reduce excitability. Cells throughout the nervous system face similar problems of accommodating a large range of input signals; furthermore, the Na+ currents of many cells exhibit slow inactivation. Thus, adaptation mediated by feedback modulation of the Na+ current through slow inactivation could serve as a general mechanism to control excitability in spiking neurons.},
author = {Kim, Kerry J and Rieke, Fred},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Adaptation,Animals,Cells,Computer Simulation,Cultured,Electric Conductivity,Kinetics,Patch-Clamp Techniques,Physiological,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,Sodium Channels,Sodium Channels: physiology,Urodela},
month = {feb},
number = {4},
pages = {1506--1516},
pmid = {12598639},
title = {{Slow Na+ inactivation and variance adaptation in salamander retinal ganglion cells.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12598639},
volume = {23},
year = {2003}
}
@article{Araya06a,
author = {Araya, Roberto and Jiang, Jiang and Eisenthal, Kenneth B and Yuste, R},
doi = {10.1073/pnas.0608755103},
journal = {PNAS},
number = {47},
pages = {17961--17966},
title = {{The spine neck filters membrane potentials}},
volume = {103},
year = {2006}
}
@article{Buckwar2011,
author = {Buckwar, E. and Riedler, M.G. G},
doi = {10.1007/s00285-010-0395-z},
journal = {Journal of Mathematical Biology},
keywords = {1,60j75,65c20,65l99,almost sure convergence,ams subject classifications,b,buckwar,cable equation,channel noise,e,g,hybrid algorithm,hybrid stochastic,in recent years the,introduction,m,neuron,neuron model,number of applications of,piecewise deterministic markov process,riedler,spatio-temporal dynamics,stochastic hybrid system,stochastic simulation},
mendeley-tags = {neuron},
number = {3},
pages = {1--43},
publisher = {Springer},
title = {{An exact stochastic hybrid model of excitable membranes including spatio-temporal evolution}},
url = {http://www.ma.hw.ac.uk/{~}mgr2/riedler{\_}thesis{\_}final{\_}onesided.pdf http://projecteuclid.org/euclid.aap/1282924062 http://www.springerlink.com/index/BT1W9GQVV223R785.pdf},
volume = {42},
year = {2011}
}
@article{Glorot2010,
author = {Glorot, Xavier and Bengio, Yoshua},
journal = {AISTATS10},
pages = {249--256},
title = {{Understanding the difficulty of training deep feedforward neural networks}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/AISTATS2010{\_}GlorotB10.pdf},
volume = {9},
year = {2010}
}
@article{Losonczy2006,
abstract = {Although radial oblique dendrites are a major synaptic input site in CA1 pyramidal neurons, little is known about their integrative properties. We have used multisite two-photon glutamate uncaging to deliver different spatiotemporal input patterns to single branches while simultaneously recording the uncaging-evoked excitatory postsynaptic potentials and local Ca2+ signals. Asynchronous input patterns sum linearly in spite of the spatial clustering and produce Ca2+ signals that are mediated by NMDA receptors (NMDARs). Appropriately timed and sized input patterns ( approximately 20 inputs within approximately 6 ms) produce a supralinear summation due to the initiation of a dendritic spike. The Ca2+ signals associated with synchronous input were larger and mediated by influx through both NMDARs and voltage-gated Ca2+ channels (VGCCs). The oblique spike is a fast Na+ spike whose duration is shaped by the coincident activation of NMDAR, VGCCs, and transient K+ currents. Our results suggest that individual branches can function as single integrative compartments.},
author = {Losonczy, Attila and Magee, Jeffrey C},
doi = {10.1016/j.neuron.2006.03.016},
issn = {0896-6273},
journal = {Neuron},
keywords = {Animals,Calcium Channels,Calcium Channels: metabolism,Dendrites,Dendrites: physiology,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Glutamic Acid,Glutamic Acid: metabolism,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: metabolism,Neuron Model,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Receptors,Sprague-Dawley,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
mendeley-tags = {Neuron Model},
month = {apr},
number = {2},
pages = {291--307},
pmid = {16630839},
title = {{Integrative properties of radial oblique dendrites in hippocampal CA1 pyramidal neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16630839},
volume = {50},
year = {2006}
}
@article{FM97,
author = {Fohlmeister, J and Miller, R},
journal = {Journal of Neurophysiology},
pages = {1948--1964},
title = {{Mechanisms by Which Cell Geometry Controls Repetitive Impulse Firing in Retinal Ganglion Cells}},
volume = {78},
year = {1997}
}
@article{Cunningham07,
author = {Cunningham, J and Yu, B and Shenoy, K and Sahani, M},
journal = {NIPS},
title = {{Inferring Neural Firing Rates from Spike Trains Using {\{}G{\}}aussian Processes}},
year = {2007}
}
@article{Min2012,
abstract = {Research in the last two decades has made clear that astrocytes play a crucial role in the brain beyond their functions in energy metabolism and homeostasis. Many studies have shown that astrocytes can dynamically modulate neuronal excitability and synaptic plasticity, and might participate in higher brain functions like learning and memory. With the plethora of astrocyte mediated signaling processes described in the literature today, the current challenge is to identify, which of these processes happen under what physiological condition, and how this shapes information processing and, ultimately, behavior. To answer these questions will require a combination of advanced physiological, genetical, and behavioral experiments. Additionally, mathematical modeling will prove crucial for testing predictions on the possible functions of astrocytes in neuronal networks, and to generate novel ideas as to how astrocytes can contribute to the complexity of the brain. Here, we aim to provide an outline of how astrocytes can interact with neurons. We do this by reviewing recent experimental literature on astrocyte-neuron interactions, discussing the dynamic effects of astrocytes on neuronal excitability and short- and long-term synaptic plasticity. Finally, we will outline the potential computational functions that astrocyte-neuron interactions can serve in the brain. We will discuss how astrocytes could govern metaplasticity in the brain, how they might organize the clustering of synaptic inputs, and how they could function as memory elements for neuronal activity. We conclude that astrocytes can enhance the computational power of neuronal networks in previously unexpected ways.},
author = {Min, Rogier and Santello, Mirko and Nevian, Thomas},
doi = {10.3389/fncom.2012.00093},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {astrocytes,astrocytes represent the largest,astrocytes, synaptic plasticity, spike-timing-depe,calcium,cellular population in the,computation,heterosynaptic,human,metaplasticity,plasticity,spike-timing-dependent plasticity,stdp,synaptic plasticity},
month = {jan},
number = {November},
pages = {93},
pmid = {23125832},
title = {{The computational power of astrocyte mediated synaptic plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23125832},
volume = {6},
year = {2012}
}
@article{KochPoggio85,
author = {Koch, Christof and Poggio, Tomaso},
journal = {Journal of Neuroscience Methods},
pages = {303--315},
title = {{A simple algorithm for solving the cable equation in dendritic trees of arbitrary geometry}},
volume = {12},
year = {1985}
}
@book{Neumann1976,
address = {New Haven, CT},
author = {Neumann, J Von},
publisher = {Yale Univ. Press},
title = {{The computer and the brain}},
url = {http://gicl.cs.drexel.edu/people/regli/Classes/Honors/papers/neumann.pdf},
year = {1958}
}
@article{YoungConley95,
author = {Young, E D and Nelken, I and Conley, R A},
journal = {Journal of Neurophysiology},
month = {feb},
number = {2},
pages = {743--765},
title = {{Somatosensory effects on neurons in dorsal cochlear nucleus}},
volume = {73},
year = {1995}
}
@article{Rosenfeld|1996|,
abstract = {The relative merits of performing local operations on {\~{}} digitized
picture in parallel or sequentially are discussed. Sequential local
operations are described which l{\~{}}bel the connected components of
a given subset of the picture and compute u "distance" from every
picture element to the subset. In terms of the "distance" function,
{\~{}} "skeleton" subset is defined which, in a certain sense, minimally
determines the original subset. Some applications of the connected
component and distance functions are also presented.},
author = {Rosenfeld, A and Pfaltz, J L},
keywords = {computational,distance transform,image processing,labeling,sequential operations,unread},
pages = {472},
title = {{Sequential operations in digital picture processing}}
}
@article{Ganguli2009a,
abstract = {Two studies in this issue of Neuron challenge widely held assumptions about the role of positive feedback in recurrent neuronal networks. Goldman shows that such feedback is not necessary for memory maintenance in a neural integrator, and Murphy and Miller show that it is not necessary for amplification of orientation patterns in V1. Both suggest that seemingly recurrent networks can be feedforward in disguise.},
annote = {2010IInum11.1
},
author = {Ganguli, Surya and Latham, Peter E},
doi = {10.1016/j.neuron.2009.02.006},
issn = {1097-4199},
journal = {Neuron},
keywords = {Animals,Feedback,Humans,Memory,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Psychological,Psychological: physiology,Short-Term,Short-Term: physiology},
month = {feb},
number = {4},
pages = {499--501},
pmid = {19249270},
title = {{Feedforward to the past: the relation between neuronal connectivity, amplification, and short-term memory.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19249270},
volume = {61},
year = {2009}
}
@article{Zbinden2011,
abstract = {In this paper, we highlight the topological properties of leader neurons whose existence is an experimental fact. Several experimental studies show the existence of leader neurons in population bursts of activity in 2D living neural networks (Eytan and Marom, J Neurosci 26(33):8465-8476, 2006; Eckmann et al., New J Phys 10(015011), 2008). A leader neuron is defined as a neuron which fires at the beginning of a burst (respectively network spike) more often than we expect by chance considering its mean firing rate. This means that leader neurons have some burst triggering power beyond a chance-level statistical effect. In this study, we characterize these leader neuron properties. This naturally leads us to simulate neural 2D networks. To build our simulations, we choose the leaky integrate and fire (lIF) neuron model (Gerstner and Kistler 2002; Cessac, J Math Biol 56(3):311-345, 2008), which allows fast simulations (Izhikevich, IEEE Trans Neural Netw 15(5):1063-1070, 2004; Gerstner and Naud, Science 326:379-380, 2009). The dynamics of our lIF model has got stable leader neurons in the burst population that we simulate. These leader neurons are excitatory neurons and have a low membrane potential firing threshold. Except for these two first properties, the conditions required for a neuron to be a leader neuron are difficult to identify and seem to depend on several parameters involved in the simulations themselves. However, a detailed linear analysis shows a trend of the properties required for a neuron to be a leader neuron. Our main finding is: A leader neuron sends signals to many excitatory neurons as well as to few inhibitory neurons and a leader neuron receives only signals from few other excitatory neurons. Our linear analysis exhibits five essential properties of leader neurons each with different relative importance. This means that considering a given neural network with a fixed mean number of connections per neuron, our analysis gives us a way of predicting which neuron is a good leader neuron and which is not. Our prediction formula correctly assesses leadership for at least ninety percent of neurons.},
author = {Zbinden, Cyrille},
doi = {10.1007/s10827-010-0308-6},
issn = {1573-6873},
journal = {Journal of Computational Neuroscience},
keywords = {burst,integrate and fire,leader,model,neuron,simulation},
month = {jan},
pmid = {21234795},
title = {{Leader neurons in leaky integrate and fire neural network simulations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21234795},
year = {2011}
}
@article{AR86,
author = {Akman, V and Raftery, A},
journal = {Annals of Statistics},
pages = {1583--1590},
title = {{Asymptotic inference for a change-point Poisson process}},
volume = {14},
year = {1986}
}
@article{Sjostrom2008,
abstract = {Most synaptic inputs are made onto the dendritic tree. Recent work has shown that dendrites play an active role in transforming synaptic input into neuronal output and in defining the relationships between active synapses. In this review, we discuss how these dendritic properties influence the rules governing the induction of synaptic plasticity. We argue that the location of synapses in the dendritic tree, and the type of dendritic excitability associated with each synapse, play decisive roles in determining the plastic properties of that synapse. Furthermore, since the electrical properties of the dendritic tree are not static, but can be altered by neuromodulators and by synaptic activity itself, we discuss how learning rules may be dynamically shaped by tuning dendritic function. We conclude by describing how this reciprocal relationship between plasticity of dendritic excitability and synaptic plasticity has changed our view of information processing and memory storage in neuronal networks.
},
annote = {

2010IIInum7},
author = {Sj{\"{o}}str{\"{o}}m, PJ J and Rancz, Ede A EA A and Roth, Arnd and H{\"{a}}usser, M and Sjostrom, P Jesper and Hausser, Michael},
doi = {10.1152/physrev.00016.2007.},
journal = {Physiological Reviews},
keywords = {dendrites,synapse},
mendeley-tags = {dendrites,synapse},
number = {2},
pages = {769 -- 840},
title = {{Dendritic excitability and synaptic plasticity}},
url = {http://physrev.physiology.org/cgi/content/abstract/88/2/769 http://physrev.physiology.org/content/88/2/769.short},
volume = {88},
year = {2008}
}
@article{Sutskever2013,
abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.},
author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
doi = {10.1109/ICASSP.2013.6639346},
isbn = {978-1-4799-0356-6},
journal = {ICML '13},
number = {2010},
pages = {1139--1147},
title = {{On the importance of initialization and momentum in deep learning}},
volume = {28},
year = {2013}
}
@article{YL99,
author = {Yamada, W and Lewis, E},
journal = {Hearing Research},
pages = {155--170},
title = {{Predicting the temporal responses of non-phase-locking bullfrog auditory units to complex acoustic waveforms}},
volume = {130},
year = {1999}
}
@article{Wong1965,
annote = {2010num1.1},
author = {Wong, E and Zakai, M},
journal = {J. Engng. Sci},
title = {{On the relation between ordinary and stochastic differential equations,  {\ldots}}},
url = {http://scholar.google.com/scholar?hl=en{\&}q=zakai+wong+1965+relation+between+{\&}btnG=Search{\&}as{\_}sdt=2000{\&}as{\_}ylo={\&}as{\_}vis=0{\#}0},
year = {1965}
}
@article{Krumin2009,
abstract = {Emerging evidence indicates that information processing, as well as learning and memory processes, in both the network and single-neuron levels are highly dependent on the correlation structure of multiple spike trains. Contemporary experimental as well as theoretical studies that involve quasi-realistic neuronal stimulation thus require a method for controlling spike train correlations. This letter introduces a general new strategy for generating multiple spike trains with exactly controlled mean firing rates and correlation structure (defined in terms of auto- and cross-correlation functions). Our approach nonlinearly transforms random gaussian-distributed processes with a predistorted correlation structure into nonnegative rate processes, which are then used to generate doubly stochastic Poisson point processes with the required correlation structure. We show how this approach can be used to generate stationary or nonstationary spike trains from small or large groups of neurons with diverse auto- and cross-correlation structures. We analyze and derive analytical formulas for the high-order correlation structure of generated spike trains and discuss the limitations of this approach.},
author = {Krumin, Michael and Shoham, Shy},
doi = {10.1162/neco.2009.08-08-847},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Humans,Learning,Learning: physiology,Models, Neurological,Neural Networks (Computer),Neurons,Neurons: physiology,Nonlinear Dynamics,Signal Processing, Computer-Assisted,Time Factors},
month = {jul},
number = {6},
pages = {1642--64},
pmid = {19191596},
title = {{Generation of spike trains with controlled auto- and cross-correlation functions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19191596},
volume = {21},
year = {2009}
}
@article{Driscoll2010,
author = {Driscoll, T. and Quinn, J. and Klein, S. and Kim, H. T. and Kim, B. J. and Pershin, Yu. V. and {Di Ventra}, M. and Basov, D. N.},
doi = {10.1063/1.3485060},
issn = {00036951},
journal = {Applied Physics Letters},
number = {9},
pages = {093502},
title = {{Memristive adaptive filters}},
url = {http://link.aip.org/link/APPLAB/v97/i9/p093502/s1{\&}Agg=doi},
volume = {97},
year = {2010}
}
@article{Caviglia1990,
author = {Caviglia, DD and Valle, M and Bisio, GM},
journal = {Neural Networks},
title = {{Effects of weight discretization on the back propagation learning method: Algorithm design and hardware realization}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5726915},
year = {1990}
}
@article{Spruston2004,
annote = {2010IInum12.14},
author = {Spruston, Nelson and Kath, William L},
doi = {10.1038/nn0604-567},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Dendrites,Dendrites: physiology,Neural Networks (Computer)},
month = {jun},
number = {6},
pages = {567--569},
pmid = {15162161},
title = {{Dendritic arithmetic.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15162161},
volume = {7},
year = {2004}
}
@article{SmithJarvis06,
abstract = {Determining how information flows along anatomical brain pathways

is a fundamental requirement for understanding how animals perceive

their environments, learn, and behave. Attempts to reveal such neural

information flow have been made using linear computational methods,

but neural interactions are known to be nonlinear. Here, we demonstrate

that a dynamic Bayesian network (DBN) inference algorithm we originally

developed to infer nonlinear transcriptional regulatory networks

from gene expression data collected with microarrays is also successful

at inferring nonlinear neural information flow networks from electrophysiology

data collected with microelectrode arrays. The inferred networks

we recover from the songbird auditory pathway are correctly restricted

to a subset of known anatomical paths, are consistent with timing

of the system, and reveal both the importance of reciprocal feedback

in auditory processing and greater information flow to higher-order

auditory areas when birds hear natural as opposed to synthetic sounds.

A linear method applied to the same data incorrectly produces networks

with information flow to non-neural tissue and over paths known not

to exist. To our knowledge, this study represents the first biologically

validated demonstration of an algorithm to successfully infer neural

information flow networks.},
author = {Smith, V Anne and Yu, Jing and Smulders, Tom V and Hartemink, Alexander J and Jarvis, Erich D},
doi = {10.1371/journal.pcbi.0020161},
journal = {PLoS Comput Biol},
month = {nov},
number = {11},
pages = {e161},
pmid = {17121460},
title = {{Computational inference of neural information flow networks.}},
url = {http://dx.doi.org/10.1371/journal.pcbi.0020161},
volume = {2},
year = {2006}
}
@phdthesis{Barker|1998|,
abstract = {The development of a fully unsupervised algorithm to achieve image
segmentation is the central theme of this dissertation},
author = {Barker, S A},
title = {{Image segmentation using Markov Random Fields Models}}
}
@article{LANCK04,
author = {Lanckriet, G and Cristianini, N and Bartlett, P and {El Ghaoui}, L and Jordan, M},
journal = {Journal of Machine Learning Research},
pages = {27--72},
title = {{Learning the kernel matrix with semidefinite programming}},
volume = {5},
year = {2004}
}
@article{Aramuni2013,
abstract = {Neuronal circuits develop, adjust to experience and degenerate in response to injury or disease in the course of weeks and months. Available recording techniques, however, typically sample physiological properties of identified neurons on the time scale of minutes and hours. Thus, in order to obtain a full understanding of a long term physiological process data need to be extrapolated from numerous experimental sessions and animals, often collected blindly and under variable conditions. The generation and ongoing engineering of genetically encoded calcium indicators creates an opportunity to repeatedly record activity from the same individual neurons in vivo over weeks, months and potentially the entire lifetime of a model organism. Chronic calcium imaging with genetically encoded indicators thus may allow to establish functional biographies of identified neuronal cell types in the brain and to reveal the physiological relevance of structural changes as they occur under natural and pathological conditions.},
author = {Aramuni, Gayane and Griesbeck, Oliver},
doi = {10.1016/j.expneurol.2012.02.008},
file = {::},
journal = {Experimental neurology},
keywords = {Animals,Brain,Brain Diseases,Brain Diseases: metabolism,Brain Diseases: pathology,Brain Diseases: physiopathology,Brain: cytology,Brain: physiopathology,Calcium,Calcium: metabolism,Humans,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Optical Imaging,Time Factors},
month = {apr},
pages = {50--56},
pmid = {22374357},
title = {{Chronic calcium imaging in neuronal development and disease.}},
url = {http://www.sciencedirect.com/science/article/pii/S0014488612000672},
volume = {242},
year = {2013}
}
@article{Eikenberry2012,
abstract = {We propose a new variant of Volterra-type model with a nonlinear auto-regressive (NAR) component that is a suitable framework for describing the process of AP generation by the neuron membrane potential, and we apply it to input-output data generated by the Hodgkin-Huxley (H-H) equations. Volterra models use a functional series expansion to describe the input-output relation for most nonlinear dynamic systems, and are applicable to a wide range of physiologic systems. It is difficult, however, to apply the Volterra methodology to the H-H model because is characterized by distinct subthreshold and suprathreshold dynamics. When threshold is crossed, an autonomous action potential (AP) is generated, the output becomes temporarily decoupled from the input, and the standard Volterra model fails. Therefore, in our framework, whenever membrane potential exceeds some threshold, it is taken as a second input to a dual-input Volterra model. This model correctly predicts membrane voltage deflection both within the subthreshold region and during APs. Moreover, the model naturally generates a post-AP afterpotential and refractory period. It is known that the H-H model converges to a limit cycle in response to a constant current injection. This behavior is correctly predicted by the proposed model, while the standard Volterra model is incapable of generating such limit cycle behavior. The inclusion of cross-kernels, which describe the nonlinear interactions between the exogenous and autoregressive inputs, is found to be absolutely necessary. The proposed model is general, non-parametric, and data-derived.},
author = {Eikenberry, Steffen E and Marmarelis, Vasilis Z},
doi = {10.1007/s10827-012-0412-x},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {autoregressive model,laguerre expansions,neuronal modeling,nonlinear modeling,nonparametric model,volterra kernels},
month = {aug},
pmid = {22878687},
title = {{A nonlinear autoregressive Volterra model of the Hodgkin-Huxley equations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22878687},
year = {2012}
}
@article{Hahnloser2002,
abstract = {Sequences of motor activity are encoded in many vertebrate brains by complex spatio-temporal patterns of neural activity; however, the neural circuit mechanisms underlying the generation of these pre-motor patterns are poorly understood. In songbirds, one prominent site of pre-motor activity is the forebrain robust nucleus of the archistriatum (RA), which generates stereotyped sequences of spike bursts during song and recapitulates these sequences during sleep. We show that the stereotyped sequences in RA are driven from nucleus HVC (high vocal centre), the principal pre-motor input to RA. Recordings of identified HVC neurons in sleeping and singing birds show that individual HVC neurons projecting onto RA neurons produce bursts sparsely, at a single, precise time during the RA sequence. These HVC neurons burst sequentially with respect to one another. We suggest that at each time in the RA sequence, the ensemble of active RA neurons is driven by a subpopulation of RA-projecting HVC neurons that is active only at that time. As a population, these HVC neurons may form an explicit representation of time in the sequence. Such a sparse representation, a temporal analogue of the 'grandmother cell' concept for object recognition, eliminates the problem of temporal interference during sequence generation and learning attributed to more distributed representations.},
annote = {2010IIInum61},
author = {Hahnloser, Richard H R and Kozhevnikov, Alexay a and Fee, Michale S},
doi = {10.1038/nature00974},
issn = {0028-0836},
journal = {Nature},
keywords = {Action Potentials,Animal,Animal: physiology,Animals,Brain,Brain: anatomy {\&} histology,Brain: cytology,Brain: physiology,Electrophysiology,Interneurons,Interneurons: physiology,Male,Neurons,Neurons: physiology,Sleep,Sleep: physiology,Songbirds,Songbirds: anatomy {\&} histology,Songbirds: physiology,Spike time neural coding,Vocalization},
mendeley-tags = {Spike time neural coding},
month = {sep},
number = {6902},
pages = {65--70},
pmid = {12214232},
title = {{An ultra-sparse code underlies the generation of neural sequences in a songbird.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12214232},
volume = {419},
year = {2002}
}
@article{Ellerkmann2001a,
annote = {2009num7},
author = {Ellerkmann, R K and Riazanski, V and Elger, C E and Urban, B W and Beck, H},
journal = {The Journal of Physiology},
number = {2},
pages = {385},
publisher = {Physiological Soc},
title = {{Slow recovery from inactivation regulates the availability of voltage-dependent Na+ channels in hippocampal granule cells, hilar neurons and basket cells}},
url = {http://jp.physoc.org/content/532/2/385.full},
volume = {532},
year = {2001}
}
@article{Candes2006,
author = {Candes, E J and Romberg, J and Tao, T},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {489--509},
title = {{Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information}},
volume = {52},
year = {2006}
}
@article{Boukhobza2008,
author = {Boukhobza, T},
journal = {Recherche},
keywords = {Reservoir Computing,generic uniform observability,graph theory,structured bilinear systems},
mendeley-tags = {Reservoir Computing},
pages = {3133--3138},
title = {{Generic uniform observability analysis for bilinear systems}},
volume = {12},
year = {2008}
}
@article{Rousson|2005|,
abstract = {Extraction of structures of interest in medical images is often an
arduous task because of noisy or incomplete data. However, handsegmented
data are often available and most of the structures to be extracted
have a similar shape from one subject to an other. Then, the possibility
of modeling a family of shapes and restricting the new structure
to be extracted within this class is of particular interest. This
approach is commonly implemented using active shape models [2] and
the definition of the image term is the most challenging component
of such an approach. In parallel, level set methods [8] define a
powerful optimization framework, that can be used to recover objects
of interest by the propagation of curves or surfaces. They can support
complex topologies, considered in higher dimensions, are implicit,
intrinsic and parameter free. In this paper we re-visit active shape
models and introduce a level set variant of them. Such an approach
can account for prior shape knowledge quite efficiently as well as
use data/image terms of various form and complexity. Promising results
on the extraction of brain ventricles in MR images demonstrate the
potential of our approach.},
annote = {This interesting paper introduces a variant of active shape approach{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}in terms of level set equations. Solution in terms of level set function{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}defined via a number of principal shape components is proposed.},
author = {Rousson, M and Paragios, N and Deriche, R},
keywords = {active contour,active shape,computational,image processing,level set,segmentation},
title = {{Implicit active shape models for 3D segmentation in MR imaging}}
}
@inproceedings{Turaga2013a,
author = {Turaga, S and Buesing, L and Packer, A M and Dalgleish, H and Pettit, N and Hausser, M and Macke, J},
booktitle = {Neural Information Processing Systems},
pages = {1--9},
title = {{Inferring neural population dynamics from multiple partial recordings of the same neural circuit}},
year = {2013}
}
@article{Cortes1995,
author = {Cortes, C and Vapnik, V},
journal = {Machine learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
pages = {273--297},
title = {{Support-vector networks}},
url = {http://www.springerlink.com/index/K238JX04HM87J80G.pdf},
volume = {297},
year = {1995}
}
@inproceedings{Andoni2014,
author = {Andoni, A and Panigrahy, R and Valiant, G and Zhang, L},
booktitle = {ICML},
title = {{Learning Polynomials with Neural Networks}},
year = {2014}
}
@article{Mascagni1989,
author = {Mascagni, MV V},
journal = {Methods in Neuronal Modeling},
keywords = {neuron},
mendeley-tags = {neuron},
title = {{Numerical methods for neuronal modeling}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Numerical+Methods+for+Neuronal+Modeling{\#}0},
year = {1989}
}
@article{Liberty2007,
abstract = {We describe two recently proposed randomized algorithms for the construction of low-rank approximations to matrices, and demonstrate their application (inter alia) to the evaluation of the singular value decompositions of numerically low-rank matrices. Being probabilistic, the schemes described here have a finite probability of failure; in most cases, this probability is rather negligible (10(-17) is a typical value). In many situations, the new procedures are considerably more efficient and reliable than the classical (deterministic) ones; they also parallelize naturally. We present several numerical examples to illustrate the performance of the schemes.},
author = {Talmon, R and Coifman, RR},
doi = {10.1073/pnas.0709640104},
issn = {1091-6490},
journal = {Proc. Nat. Acad. Sci},
month = {dec},
number = {51},
pages = {20167--72},
pmid = {18056803},
title = {{Differential stochastic sensing: Intrinsic modeling of random time series with applications to nonlinear tracking}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2154402{\&}tool=pmcentrez{\&}rendertype=abstract http://www.cs.yale.edu/publications/techreports/tr1451.pdf},
volume = {104},
year = {2012}
}
@article{Koulakov2009,
abstract = {Two recent experimental observations pose a challenge to many cortical models. First, the activity in the auditory cortex is sparse, and firing rates can be described by a lognormal distribution. Second, the distribution of nonzero synaptic strengths between nearby cortical neurons can also be described by a lognormal distribution. Here we use a simple model of cortical activity to reconcile these observations. The model makes the experimentally testable prediction that synaptic efficacies onto a given cortical neuron are statistically correlated, i.e., it predicts that some neurons receive stronger synapses than other neurons. We propose a simple Hebb-like learning rule that gives rise to such correlations and yields both lognormal firing rates and synaptic efficacies. Our results represent a first step toward reconciling sparse activity and sparse connectivity in cortical networks.},
author = {Koulakov, Alexei a and Hrom{\'{a}}dka, Tom{\'{a}}s and Zador, Anthony M},
doi = {10.1523/JNEUROSCI.4500-08.2009},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Animals,Models, Neurological,Neocortex,Neocortex: physiology,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Synapses,Synapses: physiology},
month = {mar},
number = {12},
pages = {3685--94},
pmid = {19321765},
title = {{Correlated connectivity and the distribution of firing rates in the neocortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2784918{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {29},
year = {2009}
}
@article{Hanes1996,
author = {Hanes, DP and Schall, JD},
journal = {Science},
number = {October},
pages = {427--430},
title = {{Neural control of voluntary movement initiation}},
url = {http://www.sciencemag.org/content/274/5286/427.short},
volume = {274},
year = {1996}
}
@article{Amunts2013,
abstract = {Reference brains are indispensable tools in human brain mapping, enabling integration of multimodal data into an anatomically realistic standard space. Available reference brains, however, are restricted to the macroscopic scale and do not provide information on the functionally important microscopic dimension. We created an ultrahigh-resolution three-dimensional (3D) model of a human brain at nearly cellular resolution of 20 micrometers, based on the reconstruction of 7404 histological sections. "BigBrain" is a free, publicly available tool that provides considerable neuroanatomical insight into the human brain, thereby allowing the extraction of microscopic data for modeling and simulation. BigBrain enables testing of hypotheses on optimal path lengths between interconnected cortical regions or on spatial organization of genetic patterning, redefining the traditional neuroanatomy maps such as those of Brodmann and von Economo.},
author = {Amunts, Katrin and Lepage, Claude and Borgeat, Louis and Mohlberg, Hartmut and Dickscheid, Timo and Rousseau, Marc-{\'{E}}tienne and Bludau, Sebastian and Bazin, Pierre-Louis and Lewis, Lindsay B and Oros-Peusquens, Ana-Maria and Shah, Nadim J and Lippert, Thomas and Zilles, Karl and Evans, Alan C},
doi = {10.1126/science.1235381},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Aged,Brain,Brain Mapping,Brain: anatomy {\&} histology,Brain: cytology,Cerebral Cortex,Cerebral Cortex: anatomy {\&} histology,Cerebral Cortex: cytology,Female,Humans,Image Processing, Computer-Assisted,Imaging, Three-Dimensional,Magnetic Resonance Imaging,Microtomy},
month = {jun},
number = {6139},
pages = {1472--5},
pmid = {23788795},
title = {{BigBrain: an ultrahigh-resolution 3D human brain model.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23788795},
volume = {340},
year = {2013}
}
@article{vasilaki2009correction,
annote = {2008num16},
author = {Vasilaki, E and Fr{\'{e}}maux, N and Urbanczik, R and Senn, W and Gerstner, W},
publisher = {Public Library of Science},
title = {{Correction: Spike-Based Reinforcement Learning in Continuous State and Action Space: When Policy Gradient Methods Fail}},
year = {2009}
}
@article{PetersenSakmann00,
abstract = {Sensory whiskers are mapped to rodent layer 4 somatosensory cortex
as discrete units termed barrels, which can be visualized at high
resolution in living brain slices. Both anatomical and physiological
properties of the layer 4 neuronal network can thus be investigated
in the context of the functional boundaries of this sensory map.
Large- scale confinement of neuronal arbors to single barrels was
suggested by restricted lateral diffusion of DiI across septa between
barrels. Morphological analysis of dendritic and axonal arborizations
of individual excitatory neurons showed that neuronal processes remain
within the barrel of origin through polarization toward the center
of the barrel. Functionally, the large-scale properties of the neuronal
network were investigated through mapping the spatial extent of field
EPSPs, which were found to attenuate at barrel borders. This ensemble
property of a layer 4 barrel was further investigated by analyzing
the connectivity of pairs of excitatory neurons with respect to the
locations of the somata. Approximately one-third of the excitatory
neurons within the same barrel were synaptically coupled. At the
septum between adjacent barrels the connectivity dropped rapidly,
and very few connections were found between neurons located in adjacent
barrels. Each layer 4 barrel is thus composed of an excitatory neuronal
network, which to a first order approximation, acts independently
of its neighbors.},
author = {Petersen, C C and Sakmann, B},
journal = {J Neurosci},
keywords = {Animal Axons/physiology/ultrastructure Brain Mappi,Non-U.S. Gov't Synaptic Transmission/physiology T,Wistar Somatosensory Cortex/cytology/*physiology},
number = {20},
pages = {7579--86.},
title = {{The excitatory neuronal network of rat layer 4 barrel cortex}},
volume = {20},
year = {2000}
}
@article{Bhalla08,
author = {Bhalla, U},
journal = {PLOS Comput. Biol.},
pages = {e1000098},
title = {{How To Record a Million Synaptic Weights in a Hippocampal Slice}},
volume = {4},
year = {2008}
}
@article{Zhong2017,
abstract = {In this paper, we consider regression problems with one-hidden-layer neural networks (1NNs). We distill some properties of activation functions that lead to local strong convexity in the neighborhood of the ground-truth parameters for the 1NN squared-loss objective. Most popular nonlinear activation functions satisfy the distilled properties, including rectified linear units (ReLUs), leaky ReLUs, squared ReLUs and sigmoids. For activation functions that are also smooth, we show local linear convergence guarantees of gradient descent under a resampling rule. For homogeneous activations, we show tensor methods are able to initialize the parameters to fall into the local strong convexity region. As a result, tensor initialization followed by gradient descent is guaranteed to recover the ground truth with sample complexity d {\textperiodcentered} log(1//) {\textperiodcentered} poly(k, $\lambda$) and computational complexity n {\textperiodcentered} d {\textperiodcentered} poly(k, $\lambda$) for smooth homogeneous activations with high probability, where d is the dimension of the input, k (k ≤ d) is the number of hidden nodes, $\lambda$ is a conditioning property of the ground-truth parameter matrix between the input layer and the hidden layer, is the targeted precision and n is the number of samples. To the best of our knowledge, this is the first work that provides recovery guarantees for 1NNs with both sample complexity and computational complexity linear in the input dimension and logarithmic in the precision.},
archivePrefix = {arXiv},
arxivId = {arXiv:1706.03175v1},
author = {Zhong, Kai and {Zhao Song}, Ut-Austin and Jain, Prateek and Bartlett, Peter L. and Dhillon, Inderjit S.},
eprint = {arXiv:1706.03175v1},
journal = {ICML},
month = {jun},
title = {{Recovery Guarantees for One-hidden-layer Neural Networks}},
url = {http://arxiv.org/abs/1706.03175 https://arxiv.org/pdf/1706.03175.pdf},
year = {2017}
}
@article{Shepherd|2003|,
abstract = {Sensory deprivation during a critical period reduces motility and
disrupts receptive field structure of layer 2/3 neurons in rat barrel
cortex. To determine the locus of plasticity, we used laser scanning
photo stimulation, allowing us to rapidly map intracortical synaptic
connectivity in brain slices. Layer 2/3 neuronsdiffered in their
spatial distributions of presynaptic partners: neurons directly above
barrels received, on average, significantly more layer 4 input than
those above the septa separating barrels. Complementary connectivity
was found in deprived cortex: neurons above septa were now strongly
coupled to septal regions, while connectivity between barrel regions
and layer 2/3 was reduced. These results reveal competitive interactions
between barrel and septal circuits in the establishment of precise
intracortical circuits.},
author = {Shepherd, G M G and Pologruto, T A and Svoboda, K},
journal = {Neuron},
keywords = {barrel,circuitry,cortical column,development,glutamate uncaging,neurobiology,photostimulation,rat,two-photon,whisker},
number = {2},
pages = {277--289},
title = {{Circuit Analysis of Experience-Dependent Plasticity in the Developing Rat Barrel Cortex}},
volume = {38},
year = {2003}
}
@article{Roudi,
archivePrefix = {arXiv},
arxivId = {arXiv:0902.2885v1},
author = {Roudi, Y and Tyrcha, J and Hertz, J},
eprint = {arXiv:0902.2885v1},
pages = {1--12},
title = {{The Ising Model for Neural Data: Model Quality and Approximate Methods for Extracting Functional Connectivity}}
}
@article{Ryan2009,
abstract = {Understanding the evolutionary origins of behaviour is a central aim in the study of biology and may lead to insights into human disorders. Synaptic transmission is observed in a wide range of invertebrate and vertebrate organisms and underlies their behaviour. Proteomic studies of the molecular components of the highly complex mammalian postsynaptic machinery point to an ancestral molecular machinery in unicellular organisms--the protosynapse--that existed before the evolution of metazoans and neurons, and hence challenges existing views on the origins of the brain. The phylogeny of the molecular components of the synapse provides a new model for studying synapse diversity and complexity, and their implications for brain evolution.},
annote = {2010IIInum45},
author = {Ryan, Tom{\'{a}}s J and Grant, Seth G N},
doi = {10.1038/nrn2717},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Brain,Brain: cytology,Brain: physiology,Cell Communication,Cell Communication: physiology,Evolution,Humans,Models, Biological,Nerve Tissue Proteins,Nerve Tissue Proteins: metabolism,Neurons,Neurons: cytology,Neurons: physiology,Signal Transduction,Signal Transduction: physiology,Synapses,Synapses: physiology},
month = {oct},
number = {10},
pages = {701--12},
pmid = {19738623},
title = {{The origin and evolution of synapses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19738623},
volume = {10},
year = {2009}
}
@inproceedings{Eguchi1991,
address = {Seattle, WA},
author = {Eguchi, H and Furuta, T and Horiguchi, H},
booktitle = {Neural Networks},
isbn = {0780301641},
month = {jul},
pages = {453--456},
title = {{Neural network LSI chip with on-chip learning}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=155220},
year = {1991}
}
@article{Assaf2009,
archivePrefix = {arXiv},
arxivId = {arXiv:0907.0070v2},
author = {Assaf, Michael and Meerson, Baruch and Garbaczewski, P and Stephanovich, V. and Odor, G. and Dickman, R. and Diederix, JM M and Gubbels, KB B and Stoof, HTC T C and Ajisaka, S. and Others},
eprint = {arXiv:0907.0070v2},
journal = {Scenario},
number = {3},
title = {{Extinction of metastable stochastic populations}},
url = {http://physics.technion.ac.il/{~}steady/Meerson.pdf},
volume = {0},
year = {2009}
}
@article{Kleinert|2005|,
abstract = {We extend field theoretic variational perturbation theory by self-similar
approximation theory, which greatly accelerates convergence. This
is illustrated by recalculating the critical exponents of O(N)-symmetric
phi{\^{}}4 theory. From only three-loop perturbation expansions in 4{\^{a}}ˆ'e
dimensions, we obtain analytic results for the exponents, which are
close to those derived recently from ordinary field-theoretic variational
perturbational theory to seventh order. In particular, the specific-heat
exponent is found to be in good agreement with best-measured exponent
alpha{\textless}{\^{a}}ˆ'0.0127 of the specific-heat peak in superfluid helium, found
in a satellite experiment. In addition, our analytic expressions
reproduce also the exactly known large-N behavior of the exponents.},
author = {Kleinert, H and Yukalov, V I},
journal = {Physical review E},
keywords = {analytic continuation,phi-4,physics,quantum field theory,resummation,strong coupling,unread},
pages = {26131},
title = {{Self-similar variational perturbation theory for critical exponents}},
volume = {71}
}
@article{Hestenes|2002|,
abstract = {The connection between physics teaching and research at its deepest
level can be illuminated by Physics Education Research (PER). For
students and scientists alike, what they know and learn about physics
is profoundly shaped by the conceptual tools at their command. Physicists
employ a miscellaneous assortment of mathematical tools in ways that
contribute to a fragmentation of knowledge. We can do better! Research
on the design and use of mathematical systems provides a guide for
designing a uni{\^{A}}¯ed mathematical language for the whole of physics
that facilitates learning and enhances physical insight. This has
produced a comprehensive language called Geometric Algebra, which
I introduce with emphasis on how it simpli{\^{A}}¯es and integrates classical
and quantum physics. Introducing research-based reform into a conservative
physics curriculum is a challenge for the emerging PER community.
Join the fun!},
author = {Hestenes, D},
keywords = {geometric algebra,geometric calculus,mathematics,physics,unread},
title = {{Oersted medal lecture 2002: Reforming the mathematical language of physics}}
}
@article{David07,
author = {David, S and Mesgarani, N and Shamma, S},
journal = {Network},
pages = {191--212},
title = {{Estimating sparse spectro-temporal receptive fields with natural stimuli}},
volume = {18},
year = {2007}
}
@article{KS86,
author = {Kaplan, E and Shapley, R},
journal = {PNAS},
pages = {2755--2757},
title = {{The primate retina contains two types of ganglion cells, with high and low contrast sensitivity}},
volume = {83},
year = {1986}
}
@article{Alijani2011,
author = {Alijani, A and Richardson, M J E},
doi = {10.1103/PhysRevE.84.011919},
issn = {1539-3755},
journal = {Physical Review E},
month = {jul},
number = {1},
pages = {1--9},
title = {{Rate response of neurons subject to fast or frozen noise: From stochastic and homogeneous to deterministic and heterogeneous populations}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.84.011919},
volume = {84},
year = {2011}
}
@article{Afek2011,
annote = {2010IIInum75},
author = {Afek, Y. and Alon, N. and Barad, O. and Hornstein, E. and Barkai, N. and Bar-Joseph, Z.},
doi = {10.1126/science.1193210},
issn = {0036-8075},
journal = {Science},
month = {jan},
number = {6014},
pages = {183--185},
title = {{A Biological Solution to a Fundamental Distributed Computing Problem}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1193210},
volume = {331},
year = {2011}
}
@article{Scharf1995,
author = {Scharf, Rainer and Meesmann, Malte and Boese, Jan and Chialvo, DR R},
journal = {Biological},
pages = {255--263},
title = {{General relation between variance-time curve and power spectral density for point processes exhibiting 1/f $\beta$-fluctuations, with special reference to heart rate variability}},
url = {http://www.springerlink.com/index/Q25868H846402RK8.pdf},
volume = {263},
year = {1995}
}
@article{Fortet43,
author = {Fortet, R},
journal = {J. Math Pures Appl.},
pages = {177--243},
title = {{Les fonctions aleatoires du type de Markoff associees a certaines equations lineaires aux derivees partielles du type paraboliques}},
volume = {22},
year = {1943}
}
@article{Voytas2002,
abstract = {The ratio of L- to K-shell electron captures in light nuclei is particularly
sensitive to electron overlap and exchange effects. Calculations
of these effects in 7{\^{}}Be disagree by more than 20{\%}. We report a measurement
of the L/K ratio in 7{\^{}}Be, using a cryogenic microcalorimeter which
clearly separates Land K-shell captures. The obtained L/K ratio of
0.040(6) is less than half that of existing predictions for free
7{\^{}}Be. The discrepancy is likely due to in-medium effects distorting
the L-shell electron orbitals.},
annote = {This paper from McCammon about power of his microcalorimeter spectrometer},
author = {Voytas, P A and Ternovan, C and Galeazzi, M and McCammon, D and Kolata, J J and Santi, P and Peterson, D and Guimaraes, V and Becchetti, F D and Lee, M Y and O'Donnell, T W and Roberts, D A and Shaheen, S},
journal = {Physical Review Letters},
keywords = {X-ray,calorimeter,criogenic,detector,electron capture,microcalorimeter,nuclear,particle,physics,spectrometer},
number = {1},
pages = {12501},
title = {{Direct Measurement of the L/K Ratio in 7{\^{}}Be Electron Capture}},
volume = {88},
year = {2002}
}
@article{Gaba2013,
abstract = {Nanoscale resistive switching devices (memristive devices or memristors) have been studied for a number of applications ranging from non-volatile memory, logic to neuromorphic systems. However a major challenge is to address the potentially large variations in space and time in these nanoscale devices. Here we show that in metal-filament based memristive devices the switching can be fully stochastic. While individual switching events are random, the distribution and probability of switching can be well predicted and controlled. Rather than trying to force high switching probabilities using excess voltage or time, the inherent stochastic nature of resistive switching allows these binary devices to be used as building blocks for novel error-tolerant computing schemes such as stochastic computing and provides the needed "analog" feature for neuromorphic applications. To verify such potential, we demonstrated memristor-based stochastic bitstreams in both time and space domains, and show that an array of binary memristors can act as a multi-level "analog" device for neuromorphic applications.},
author = {Gaba, S and Sheridan, P and Zhou, J and Choi, S and Lu, W},
doi = {10.1039/c3nr01176c},
issn = {2040-3372},
journal = {Nanoscale},
month = {jul},
number = {13},
pages = {5872--8},
pmid = {23698627},
title = {{Stochastic memristive devices for computing and neuromorphic applications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23698627},
volume = {5},
year = {2013}
}
@article{BRK04,
author = {Brockwell, A and Rojas, A and Kass, R},
journal = {Journal of Neurophysiology},
pages = {1899--1907},
title = {{Recursive {\{}B{\}}ayesian Decoding of Motor Cortical Signals by Particle Filtering}},
volume = {91},
year = {2004}
}
@article{Portilla03,
author = {Portilla, J and Strela, V and Wainwright, M J and Simoncelli, E P},
doi = {10.1109/TIP.2003.818640},
journal = {IEEE Trans Image Processing},
month = {nov},
number = {11},
pages = {1338--1351},
title = {{Image denoising using scale mixtures of {\{}Gaussians{\}} in the wavelet domain}},
volume = {12},
year = {2003}
}
@article{Kotter05,
author = {Kotter, R and Schubert, D and Dyhrfjeld-Johnsen, J and Luhmann, H J and Staiger, J F},
journal = {J Biomed Opt},
number = {1},
pages = {11003},
title = {{Optical release of caged glutamate for stimulation of neurons in the in vitro slice preparation}},
volume = {10},
year = {2005}
}
@article{Kaulakys2004a,
author = {Kaulakys, B. and Ruseckas, J.},
doi = {10.1103/PhysRevE.70.020101},
issn = {1539-3755},
journal = {Physical Review E},
month = {aug},
number = {2},
pages = {020101},
title = {{Stochastic nonlinear differential equation generating 1∕f noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.70.020101},
volume = {70},
year = {2004}
}
@article{KEAT01,
author = {Keat, J and Reinagel, P and Reid, R and Meister, M},
journal = {Neuron},
pages = {803--817},
title = {{Predicting every spike: a model for the responses of visual neurons}},
volume = {30},
year = {2001}
}
@article{Harada|1997|,
abstract = {We investigate the mesonic light-front bound-state equations of the
{\"{i}}¾'t Hooft and Schwinger model in the two-particle, i.e. valence
sector, for small fermion mass. We perform a high precision determination
of the mass and light-cone wave function of the lowest lying meson
by combining fermion mass perturbation theory with a variational
approach. All calculations are done entirely in the fermionic representation
without using any bosonization scheme. In a step-by-step procedure
we enlarge the space of variational parameters. We achieve good convergence
so that the calculation of the meson mass squared can be extended
to third order in the fermion mass. Within a numerical treatment
we include higher Fock states up to six particles. Our results are
consistent with all previous numerical investigations, in particular
lattice calculations. For the massive Schwinger model, we find a
small discrepancy ({\textless}2{\%}) in comparison with known results. Possible
resolutions of this discrepancy are discussed.},
author = {Harada, K and Heinzl, T and Stern, C},
journal = {arXiv},
keywords = {bound state,constituent model,light front dynamics,mesons,physics,quantum chromodynamics,unread,variational perturbation theory},
pages = {9705159},
title = {{Variational mass perturbation theory for light-front bound state equations}},
volume = {hep-th}
}
@article{Bouchaud1992,
annote = {2010num1.6},
author = {Bouchaud, J P},
journal = {J. Phys. I France},
title = {{Weak ergodicity breaking and aging in disordered systems}},
url = {http://www.edpsciences.org/articles/jp1/abs/1992/09/jp1v2p1705/jp1v2p1705.html},
year = {1992}
}
@article{Rajapakse2012,
author = {Rajapakse, Indika and Groudine, Mark and Mesbahi, Mehran},
doi = {10.1371/journal.pcbi.1002543},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Cell Differentiation,Cell Differentiation: physiology,Complex Networks,Computational Biology,Humans,Models, Biological,Signal Transduction,Systems Theory},
mendeley-tags = {Complex Networks},
month = {jan},
number = {6},
pages = {e1002543},
pmid = {22761554},
title = {{What can systems theory of networks offer to biology?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3386158{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {8},
year = {2012}
}
@article{Csi67,
author = {Csiszar, I},
journal = {Studia Sci. Math. Hungar.},
pages = {299--317},
title = {{Information-type measures of difference of probability distributions and indirect observations}},
volume = {2},
year = {1967}
}
@article{Geffen09,
author = {Geffen, Maria N and Broome, Bede M and Laurent, Gilles and Meister, Markus},
journal = {Neuron},
pages = {570--586},
title = {{Neural Encoding of Rapidly Fluctuating Odors}},
volume = {61},
year = {2009}
}
@misc{Candes2005,
author = {Candes, E J and Romberg, J},
title = {{Practical signal recovery from random projections.}},
volume = {5914},
year = {2005}
}
@article{Buzsaki2014,
author = {Buzs{\'{a}}ki, Gy{\"{o}}rgy and Mizuseki, Kenji},
doi = {10.1038/nrn3687},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
month = {feb},
number = {February},
pages = {1--15},
title = {{The log-dynamic brain: how skewed distributions affect network operations}},
url = {http://www.nature.com/doifinder/10.1038/nrn3687},
year = {2014}
}
@article{Modha2011,
author = {Modha, Dharmendra S. and Ananthanarayanan, Rajagopal and Esser, Steven K. and Ndirango, Anthony and Sherbondy, Anthony J. and Singh, Raghavendra},
doi = {10.1145/1978542.1978559},
issn = {00010782},
journal = {Communications of the ACM},
month = {aug},
number = {8},
pages = {62},
title = {{Cognitive computing}},
url = {http://portal.acm.org/citation.cfm?doid=1978542.1978559},
volume = {54},
year = {2011}
}
@article{GreenbergKerr08,
abstract = {It is unclear how the complex spatiotemporal organization of ongoing
cortical neuronal activity recorded in anesthetized animals relates
to the awake animal. We therefore used two-photon population calcium
imaging in awake and subsequently anesthetized rats to follow action
potential firing in populations of neurons across brain states, and
examined how single neurons contributed to population activity. Firing
rates and spike bursting in awake rats were higher, and pair-wise
correlations were lower, compared with anesthetized rats. Anesthesia
modulated population-wide synchronization and the relationship between
firing rate and correlation. Overall, brain activity during wakefulness
cannot be inferred using anesthesia.},
author = {Greenberg, David S and Houweling, Arthur R and Kerr, Jason N D},
doi = {10.1038/nn.2140},
institution = {These authors contributed equally to this work.},
journal = {Nat Neurosci},
month = {jun},
pmid = {18552841},
title = {{Population imaging of ongoing neuronal activity in the visual cortex of awake rats.}},
url = {http://dx.doi.org/10.1038/nn.2140},
year = {2008}
}
@article{Repp2004,
author = {Repp, Bruno H and Keller, PE},
journal = {Quarterly Journal of Experimental {\ldots}},
title = {{Adaptation to tempo changes in sensorimotor synchronization: Effects of intention, attention, and awareness}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02724980343000369},
year = {2004}
}
@article{Gilles2010,
abstract = {The assessment of the variability of neuronal spike timing is fundamental to gain understanding of latency coding. Based on recent mathematical results, we investigate theoretically the impact of channel noise on latency variability. For large numbers of ion channels, we derive the asymptotic distribution of latency, together with an explicit expression for its variance. Consequences in terms of information processing are studied with Fisher information in the Morris-Lecar model. A competition between sensitivity to input and precision is responsible for favoring two distinct regimes of latencies.},
author = {Gilles, Wainrib and Mich{\`{e}}le, Thieullen and Khashayar, Pakdaman},
doi = {10.1007/s00422-010-0384-8},
isbn = {0042201003848},
issn = {1432-0770},
journal = {Biological cybernetics},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cell Membrane,Cell Membrane: physiology,Central Nervous System,Central Nervous System: physiology,Humans,Ion Channel Gating,Ion Channel Gating: physiology,Neurons,Neurons: physiology,Reaction Time,Reaction Time: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {jul},
number = {1},
pages = {43--56},
pmid = {20372920},
publisher = {Springer},
title = {{Intrinsic variability of latency to first-spike}},
url = {http://www.springerlink.com/index/G47384K537731R4R.pdf http://www.ncbi.nlm.nih.gov/pubmed/20372920},
volume = {103},
year = {2010}
}
@article{Kataeva2015,
author = {Kataeva, Irina and Merrikh-Bayat, Famood and Zamanidoost, Elham and Strukov, Dmitri},
file = {:C$\backslash$:/Users/Daniel/Downloads/07280785.pdf:pdf},
isbn = {9781479919598},
journal = {IJCNN},
title = {{Efficient Training Algorithms for Neural Networks Based on Memristive Crossbar Circuits}},
year = {2015}
}
@article{Sik|1993|,
author = {Sik, A and Tamamaki, N and Freund, T F},
journal = {Eur. J. Nerosci.},
pages = {1719--1728},
title = {{Complete axon arborization of a single CA3 pyramidal cell in the rat hippocampus, and its relationship with postsynaptic parvalbumin-containing interneurons.}},
volume = {5}
}
@article{Bohland2009,
author = {{Bohland, J. et al}},
journal = {arXiv},
pages = {0901.4598},
title = {{A proposal for a coordinated effort for the determination of brainwide neuroanatomical connectivity in model organisms at a mesoscopic scale}},
year = {2009}
}
@article{Varshney2011,
abstract = {Despite recent interest in reconstructing neuronal networks, complete wiring diagrams on the level of individual synapses remain scarce and the insights into function they can provide remain unclear. Even for Caenorhabditis elegans, whose neuronal network is relatively small and stereotypical from animal to animal, published wiring diagrams are neither accurate nor complete and self-consistent. Using materials from White et al. and new electron micrographs we assemble whole, self-consistent gap junction and chemical synapse networks of hermaphrodite C. elegans. We propose a method to visualize the wiring diagram, which reflects network signal flow. We calculate statistical and topological properties of the network, such as degree distributions, synaptic multiplicities, and small-world properties, that help in understanding network signal propagation. We identify neurons that may play central roles in information processing, and network motifs that could serve as functional modules of the network. We explore propagation of neuronal activity in response to sensory or artificial stimulation using linear systems theory and find several activity patterns that could serve as substrates of previously described behaviors. Finally, we analyze the interaction between the gap junction and the chemical synapse networks. Since several statistical properties of the C. elegans network, such as multiplicity and motif distributions are similar to those found in mammalian neocortex, they likely point to general principles of neuronal networks. The wiring diagram reported here can help in understanding the mechanistic basis of behavior by generating predictions about future experiments involving genetic perturbations, laser ablations, or monitoring propagation of neuronal activity in response to stimulation.},
author = {Varshney, Lav R and Chen, Beth L and Paniagua, Eric and Hall, David H and Chklovskii, D B},
doi = {10.1371/journal.pcbi.1001066},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Anatomic,Animals,Caenorhabditis elegans,Caenorhabditis elegans: anatomy {\&} histology,Caenorhabditis elegans: physiology,Computational Biology,Gap Junctions,Gap Junctions: physiology,Gap Junctions: ultrastructure,Interneurons,Interneurons: cytology,Interneurons: physiology,Mathematical Concepts,Models,Motor Neurons,Motor Neurons: cytology,Motor Neurons: physiology,Nerve Net,Nerve Net: anatomy {\&} histology,Nerve Net: physiology,Neurological,Sensory Receptor Cells,Sensory Receptor Cells: cytology,Sensory Receptor Cells: physiology,Synapses,Synapses: physiology,Synapses: ultrastructure,Systems Biology},
number = {2},
pages = {e1001066},
pmid = {21304930},
title = {{Structural properties of the Caenorhabditis elegans neuronal network.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3033362{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2011}
}
@article{DE03,
author = {Donoho, D and Elad, M},
journal = {PNAS},
pages = {2197--2202},
title = {{Optimally sparse representation in general (nonorthogonal) dictionaries via {\{}L{\}}{\^{}}1 minimization}},
volume = {100},
year = {2003}
}
@article{Lipovetsky2014,
author = {Lipovetsky, Stan},
doi = {10.1080/02664763.2014.932760},
issn = {0266-4763},
journal = {Journal of Applied Statistics},
keywords = {binary logit model,categorical predictors,closed-form analytical solution,contingency table,likelihood function},
number = {February},
pages = {37--49},
title = {{Analytical closed-form solution for binary logit regression by categorical predictors}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02664763.2014.932760},
volume = {42},
year = {2014}
}
@article{Kipnis-Varadhan86,
author = {Kipnis, C and Varadhan, S R S},
journal = {Comm. Math. Phys.},
pages = {1--19},
title = {{Central limit theorem for additive functionals of reversible {\{}M{\}}arkov processes and applications to simple exclusions}},
volume = {104},
year = {1986}
}
@article{Hopfield1974,
annote = {6num2012},
author = {Hopfield, JJ},
journal = {Proceedings of the National Academy of {\ldots}},
title = {{Kinetic proofreading: a new mechanism for reducing errors in biosynthetic processes requiring high specificity}},
url = {http://www.pnas.org/content/71/10/4135.short},
year = {1974}
}
@article{Calabrese09,
author = {Calabrese, A and Paninski, L},
journal = {In preparation},
title = {{Kalman-based methods for tracking nonstationary cluster means in spike-sorting applications}},
year = {2009}
}
@article{Feinberg|2008|,
author = {Feinberg, E H and Vanhoven, M K and Bendesky, A and Wang, G and Fetter, R D and Shen, K and Bargmann, C I},
journal = {Neuron},
pages = {353--363},
title = {{GFP Reconstitution Across Synaptic Partners (GRASP) defines cell contacts and synapses in living nervous systems.}},
volume = {57},
year = {2008}
}
@article{Lee2002,
abstract = {Rats repeatedly ran through a sequence of spatial receptive fields of hippocampal CA1 place cells in a fixed temporal order. A novel combinatorial decoding method reveals that these neurons repeatedly fired in precisely this order in long sequences involving four or more cells during slow wave sleep (SWS) immediately following, but not preceding, the experience. The SWS sequences occurred intermittently in brief ( approximately 100 ms) bursts, each compressing the behavioral sequence in time by approximately 20-fold. This rapid encoding of sequential experience is consistent with evidence that the hippocampus is crucial for spatial learning in rodents and the formation of long-term memories of events in time in humans.},
author = {Lee, Albert K and Wilson, MA A},
issn = {0896-6273},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Computer-Assisted,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Learning,Learning: physiology,Long-Evans,Male,Memory,Memory: physiology,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neuropsychological Tests,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Rats,Signal Processing,Signal Transduction,Signal Transduction: physiology,Sleep,Sleep: physiology,Spike time neural coding,Synaptic Transmission,Synaptic Transmission: physiology},
mendeley-tags = {Spike time neural coding},
month = {dec},
number = {6},
pages = {1183--1194},
pmid = {12495631},
title = {{Memory of sequential experience in the hippocampus during slow wave sleep.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12495631},
volume = {36},
year = {2002}
}
@article{Dickson|2002|,
author = {Dickson, B J},
journal = {Science},
keywords = {Animals Axons/*physiology/ultrastructure Cues Cyto,Cell Surface/physiology Semaphorins/physiology Si,Cyclic/metabolism Protein Biosynthesis Receptors},
number = {5600},
pages = {1959--1964},
title = {{Molecular mechanisms of axon guidance}},
volume = {298}
}
@article{DeFigueiredo|1980|,
abstract = {Applications of Kolmogorov's superposition theorem to nonlinear circuit
and system theory, statistical pattern recognition and image and
multidimensional signal processing are presented and discussed.},
annote = {The paper reviews essentials of the proof of Kolmogorov{\&}{\#}039;s superposition{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}theorem and elucidates some implications for nonlinear circuits and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}system theory.},
author = {{De Figueiredo}, R J P},
journal = {IEEE transactions on automatic control},
keywords = {13th Hilbert conjecture,Kolmogorov theorem,function representation by superposition,interpolation,many dimensional,mathematics},
number = {6},
pages = {1227},
title = {{Implications and applications of Kolmogorov's superposition theorem}},
volume = {25}
}
@book{Chow03,
editor = {Chow, C and Gutkin, B and Hansel, D and Meunier, C and Dalibard, J},
publisher = {Elsevier},
title = {{Methods and Models in Neurophysics}},
year = {2003}
}
@article{sumbre2008entrained,
annote = {2008num4},
author = {Sumbre, G and Muto, A and Baier, H and Poo, M M},
journal = {Nature},
number = {7218},
pages = {102--106},
publisher = {Nature Publishing Group},
title = {{Entrained rhythmic activities of neuronal ensembles as perceptual memory of time interval}},
volume = {456},
year = {2008}
}
@article{RHS02,
author = {Ringach, D and Hawken, M and Shapley, R},
journal = {Journal of Vision},
pages = {12--24},
title = {{Receptive field structure of neurons in monkey primary visual cortex revealed by stimulation with natural image sequences}},
volume = {2},
year = {2002}
}
@article{Silberberg2005,
abstract = {The functions performed by different neural microcircuits depend on the anatomical and physiological properties of the various synaptic pathways connecting neurons. Neural microcircuits across various species and brain regions are similar in terms of their repertoire of neurotransmitters, their synaptic kinetics, their short-term and long-term plasticity, and the target-specificity of their synaptic connections. However, microcircuits can be fundamentally different in terms of the precise recurrent design used to achieve a specific functionality. In this review, which is part of the TINS Microcircuits Special Feature, we compare the connectivity designs in spinal, hippocampal, neocortical and cerebellar microcircuits, and discuss the different computational challenges that each microcircuit faces.},
annote = {2010IIInum12},
author = {Silberberg, Gilad and Grillner, Sten and LeBeau, Fiona E N and Maex, Reinoud and Markram, H},
doi = {10.1016/j.tins.2005.08.004},
issn = {0166-2236},
journal = {Trends in Neurosciences},
keywords = {Animals,Brain,Brain: cytology,Brain: physiology,Jackie,Models,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurological,Spinal Cord,Spinal Cord: cytology,Spinal Cord: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
mendeley-tags = {Jackie},
month = {oct},
number = {10},
pages = {541--551},
pmid = {16122815},
title = {{Synaptic pathways in neural microcircuits.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16122815},
volume = {28},
year = {2005}
}
@article{Bartal|2005|,
abstract = {This paper is concerned with probabilistic approximation of metric
spaces. In previous work we introduced the method of efficient approximation
of metrics by more simple families of metrics in a probabilistic
fashion. In particular we study probabilistic approximations of arbitrary
metric spaces by "hierarchically well-separated tree" metric spaces.
This has proved as a useful technique for simplifying the solutions
to various problems. In this paper we improve the result by proving
an approximation factor of O(log n log log n) getting the gap to
the lower bound within lower order factors. We also give a deterministic
version of the result which gives a tree with low average distortion
of distances. The results have applications in a variety of areas
including approximation bounds for these applications.},
author = {Bartal, Y},
keywords = {continuous networks,distance,internet,metric,network metrics,networks,tree-metrics,unread},
title = {{On Approximating Arbitrary Metrics by Tree Metrics}}
}
@article{Merel2013,
author = {Merel, JS and Fox, Roy and Jebara, Tony and Paninski, L},
journal = {Advances in Neural {\ldots}},
title = {{A multi-agent control framework for co-adaptation in brain-computer interfaces}},
url = {http://papers.nips.cc/paper/5176-a-multi-agent-control-framework-for-co-adaptation-in-brain-computer-interfaces},
year = {2013}
}
@article{Lalor09,
author = {Lalor, E and Ahmadian, Y and Paninski, L},
journal = {Journal of the Optical Society of America A},
pages = {25--42},
title = {{The relationship between optimal and biologically plausible decoding of stimulus velocity in the retina}},
volume = {26},
year = {2009}
}
@article{Hoebe2008,
abstract = {Phototoxicity and photobleaching are major limitations in live-cell fluorescence microscopy. They are caused by fluorophores in an excited singlet or triplet state that generate singlet oxygen and other reactive oxygen species. The principle of controlled light exposure microscopy (CLEM) is based on non-uniform illumination of the field of view to reduce the number of excited fluorophore molecules. This approach reduces phototoxicity and photobleaching 2- to 10-fold without deteriorating image quality. Reduction of phototoxicity and photobleaching depends on the fluorophore distribution in the studied object, the optical properties of the microscope and settings of CLEM electronics. Here, we introduce the CLEM factor as a quantitative measure of reduction in phototoxicity and photobleaching. Finally, we give a guideline to optimize the effect of CLEM without compromising image quality.},
author = {Hoebe, R A and {Van der Voort}, H T M and Stap, J and {Van Noorden}, C J F and Manders, E M M},
doi = {10.1111/j.1365-2818.2008.02009.x},
issn = {1365-2818},
journal = {Journal of microscopy},
keywords = {Cell Line, Tumor,Centromere Protein B,Centromere Protein B: genetics,Centromere Protein B: metabolism,Dermatitis, Phototoxic,Dose-Response Relationship, Radiation,Green Fluorescent Proteins,Green Fluorescent Proteins: genetics,Green Fluorescent Proteins: metabolism,HeLa Cells,Histones,Histones: genetics,Histones: metabolism,Humans,Image Processing, Computer-Assisted,Light,Microscopy,Microscopy, Fluorescence,Microscopy: methods,Photobleaching,Photobleaching: radiation effects,Recombinant Fusion Proteins,Recombinant Fusion Proteins: genetics,Recombinant Fusion Proteins: metabolism},
month = {jul},
number = {Pt 1},
pages = {9--20},
pmid = {18638185},
title = {{Quantitative determination of the reduction of phototoxicity and photobleaching by controlled light exposure microscopy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18638185},
volume = {231},
year = {2008}
}
@article{Gerami2012,
author = {Giudice, P Del and Fusi, S},
doi = {10.1016/j.sder.2012.09.002},
issn = {1558-0768},
journal = {Network: {\ldots}},
month = {dec},
number = {4},
pages = {203},
pmid = {23174489},
title = {{Learning attractors in an asynchronous, stochastic electronic neural network}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23175644 http://informahealthcare.com/doi/abs/10.1088/0954-898X{\_}9{\_}2{\_}003},
volume = {31},
year = {1998}
}
@article{Appleby2005,
abstract = {We postulate that a simple, three-state synaptic switch governs changes in synaptic strength at individual synapses. Under this switch rule, we show that a variety of experimental results on timing-dependent plasticity can emerge from temporal and spatial averaging over multiple synapses and multiple spike pairings. In particular, we show that a critical window for the interaction of pre- and postsynaptic spikes emerges as an ensemble property of the collective system, with individual synapses exhibiting only a minimal form of spike coincidence detection. In addition, we show that a Bienenstock-Cooper-Munro-like, rate-based plasticity rule emerges directly from such a model. This demonstrates that two apparently separate forms of neuronal plasticity can emerge from a much simpler rule governing the plasticity of individual synapses.},
author = {Appleby, Peter a and Elliott, Terry},
doi = {10.1162/0899766054796879},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Stochastic Processes,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
month = {nov},
number = {11},
pages = {2316--2336},
pmid = {16156931},
title = {{Synaptic and temporal ensemble interpretation of spike-timing-dependent plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16156931 http://www.ncbi.nlm.nih.gov/pubmed/16907632},
volume = {17},
year = {2005}
}
@article{DeFelice1993,
author = {DeFelice, LJ and Isaac, A},
journal = {Journal of Statistical Physics},
keywords = {1,a set,action potential,b r a n,chaos,e in n e,e m e m,e s e n,e x c i,h o d g,i n t r,k i n a,n d h u,o d u c,probabilistic ion channels,r e p r,r v e as,resting potential,spontaneous firing,t a b l,t e d the,t i o n,x l e y},
pages = {339--354},
title = {{Chaotic states in a random world: Relationship between the nonlinear differential equations of excitability and the stochastic properties of ion channels}},
url = {http://link.springer.com/article/10.1007/BF01053972},
volume = {70},
year = {1993}
}
@article{Harvey2008,
abstract = {In neurons, individual dendritic spines isolate N-methyl-d-aspartate (NMDA) receptor-mediated calcium ion (Ca2+) accumulations from the dendrite and other spines. However, the extent to which spines compartmentalize signaling events downstream of Ca2+ influx is not known. We combined two-photon fluorescence lifetime imaging with two-photon glutamate uncaging to image the activity of the small guanosine triphosphatase Ras after NMDA receptor activation at individual spines. Induction of long-term potentiation (LTP) triggered robust Ca2+-dependent Ras activation in single spines that decayed in approximately 5 minutes. Ras activity spread over approximately 10 micrometers of dendrite and invaded neighboring spines by diffusion. The spread of Ras-dependent signaling was necessary for the local regulation of the threshold for LTP induction. Thus, Ca2+-dependent synaptic signals can spread to couple multiple synapses on short stretches of dendrite.},
annote = {2010IIInum16},
author = {Harvey, Christopher D and Yasuda, Ryohei and Zhong, Haining and Svoboda, K},
doi = {10.1126/science.1159675},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Animals,Calcium,Calcium: metabolism,Cell Membrane,Cell Membrane: metabolism,Dendritic Spines,Dendritic Spines: physiology,Diffusion,Fluorescence Resonance Energy Transfer,GTPase-Activating Proteins,GTPase-Activating Proteins: metabolism,Glutamic Acid,Glutamic Acid: metabolism,Guanine Nucleotide Exchange Factors,Guanine Nucleotide Exchange Factors: metabolism,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Long-Term Potentiation,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Receptors, N-Methyl-D-Aspartate,Receptors, N-Methyl-D-Aspartate: metabolism,Recombinant Fusion Proteins,Recombinant Fusion Proteins: metabolism,Signal Transduction,Synapses,Synapses: physiology,Transfection,ras Proteins,ras Proteins: metabolism},
month = {jul},
number = {5885},
pages = {136--40},
pmid = {18556515},
title = {{The spread of Ras activity triggered by activation of a single dendritic spine.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18556515},
volume = {321},
year = {2008}
}
@article{DingVoigt99,
author = {Ding, J and Benson, T E and Voigt, H F},
journal = {Journal of Neurophysiology},
month = {dec},
number = {6},
pages = {3434--3457},
title = {{Acoustic and current-pulse responses of identified neurons in the dorsal cochlear nucleus of unanesthetized, decerebrate gerbils}},
volume = {82},
year = {1999}
}
@article{Cole1960,
author = {Cole, K and Moore, John},
doi = {10.1016/S0006-3495(60)86871-3},
issn = {00063495},
journal = {Biophysical Journal},
month = {sep},
number = {1},
pages = {1--14},
publisher = {Elsevier},
title = {{Potassium Ion Current in the Squid Giant Axon: Dynamic Characteristic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349560868713},
volume = {1},
year = {1960}
}
@article{OhkuraNakai05,
abstract = {G-CaMP is a Ca2+ probe based on a single green fluorescent protein

(GFP). G-CaMP shows a large fluorescence increase upon Ca2+ binding,

but its fluorescence is dim and pH sensitive, similar to other single

GFP-based probes. Here we report an improved G-CaMP, named G-CaMP1.6,

which enables easier detection of intracellular Ca2+ signals. G-CaMP1.6

was approximately 40 times more fluorescent than G-CaMP, mainly due

to an increase in quantum yield. Furthermore, compared with G-CaMP,

G-CaMP1.6 had not only a lower pH sensitivity but also a higher selectivity

for divalent cations having an ionic radius similar to Ca2+. Ca2+

sensitivity of G-CaMP1.6 (Kd = 146 nM, Hill coefficient = 3.8, Fmax/Fmin

= 4.9) was slightly shifted toward higher affinity compared with

that of G-CaMP. When expressed in mammalian cells, G-CaMP1.6 showed

large fluorescence changes with drug applications. Notably, local

Ca2+ changes in such tiny structures as dendritic spines of neurons

were successfully observed with G-CaMP1.6, this being the first observation

using a GFP-based probe. Additional mutations in Ca2+-binding sites

of G-CaMP1.6 shifted the affinity for Ca2+ and reduced the Ca2+-buffering

effect. G-CaMP1.6-CaM(E140K), which has a mutation in the Ca2+ binding

site, is an improved probe with its increased brightness and reduced

Ca2+-buffering capacity.},
author = {Ohkura, Masamichi and Matsuzaki, Masanori and Kasai, Haruo and Imoto, Keiji and Nakai, Junichi},
doi = {10.1021/ac0506837},
journal = {Anal Chem},
keywords = {Animals; Calcium; Cell Line; Dendritic Spines; EF},
month = {sep},
number = {18},
pages = {5861--5869},
pmid = {16159115},
title = {{Genetically encoded bright Ca{\^{}}{\{}2+{\}} probe applicable for dynamic Ca{\^{}}{\{}2+{\}} imaging of dendritic spines.}},
url = {http://dx.doi.org/10.1021/ac0506837},
volume = {77},
year = {2005}
}
@article{Text,
author = {Text, S I and Model, M L},
doi = {10.1073/pnas.1008587107},
number = {Ml},
pages = {1--7},
title = {{Supporting Information}}
}
@article{VanRullen2005,
abstract = {Many behavioral responses are completed too quickly for the underlying sensory processes to rely on estimation of neural firing rates over extended time windows. Theoretically, first-spike times could underlie such rapid responses, but direct evidence has been lacking. Such evidence has now been uncovered in the human somatosensory system. We discuss these findings and their potential generalization to other sensory modalities, and we consider some future challenges for the neuroscientific community.},
annote = {2010IIInum57},
author = {VanRullen, R and Guyonneau, R and Thorpe, S J},
doi = {10.1016/j.tins.2004.10.010},
issn = {0166-2236},
journal = {Trends in Neurosciences},
keywords = {Action Potentials,Action Potentials: physiology,Animal,Animal: physiology,Animals,Behavior,Behavior: physiology,Cortical Synchronization,Humans,Mental Processes,Mental Processes: physiology,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurons,Neurons: physiology,Perception,Perception: physiology,Reaction Time,Reaction Time: physiology,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology,Spike time neural coding},
mendeley-tags = {Spike time neural coding},
month = {jan},
number = {1},
pages = {1--4},
pmid = {15626490},
title = {{Spike times make sense.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15626490},
volume = {28},
year = {2005}
}
@article{JSR97,
author = {Joeken, S and Schwegler, H and Richter, C},
journal = {Biological Cybernetics},
pages = {153--162},
title = {{Modeling stochastic spike train responses of neurons: An extended Wiener series analysis of pigeon auditory nerve fibers}},
volume = {76},
year = {1997}
}
@article{Beurrier2001,
author = {Beurrier, Corinne and Bioulac, Bernard and Audin, Jacques and Hammond, Constance},
issn = {0022-3077},
journal = {Journal of {\ldots}},
number = {4},
pages = {1351--1356},
publisher = {Am Physiological Soc},
title = {{High-frequency stimulation produces a transient blockade of voltage-gated currents in subthalamic neurons}},
url = {http://jn.physiology.org/content/85/4/1351.short http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:High-Frequency+Stimulation+Produces+a+Transient+Blockade+of+Voltage-Gated+Currents+in+Subthalamic+Neurons{\#}0},
volume = {85},
year = {2001}
}
@article{Tatikonda2004,
annote = {2010IIInum46},
author = {Tatikonda, S. and Mitter, S.},
doi = {10.1109/TAC.2004.831187},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
month = {jul},
number = {7},
pages = {1056--1068},
title = {{Control Under Communication Constraints}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1310461},
volume = {49},
year = {2004}
}
@phdthesis{SHOPHD,
author = {Shoham, S},
school = {University of Utah; available at http://www.princeton.edu/{\~{}}sshoham/Shoham{\_}dissertation01.pdf},
title = {{Advances Towards an Implantable Motor Cortical Interface}},
year = {2001}
}
@article{DavisYoung97,
author = {Davis, K A and Young, E D},
journal = {Journal of Neuroscience},
month = {sep},
number = {17},
pages = {6798--6806},
title = {{Granule cell activation of complex-spiking neurons in dorsal cochlear nucleus}},
volume = {17},
year = {1997}
}
@article{Chow1996,
abstract = {A theoretical and numerical analysis of the Hodgkin-Huxley equations with the inclusion of stochastic channel dynamics is presented. It is shown that the system can be approximated by a one-dimensional bistable Langevin equation. Spontaneous action potentials can arise from the channel fluctuations and are analogous to escape by a particle over a potential barrier. The mean firing rate can be calculated using Kramers' classic result for barrier escape. The probability density function of the interspike intervals can also be estimated. The analytical results compare favorably with numerical simulations of the complete stochastic system.},
annote = {מה ההצדקה למשוואת לנג{\&}{\#}039;ווין פה? אולי כדאי להעמיק קצת בקריאה.},
author = {Chow, C and White, J A},
doi = {10.1016/S0006-3495(96)79494-8},
issn = {00063495},
journal = {Biophysical Journal},
month = {dec},
number = {6},
pages = {3013--3021},
publisher = {Elsevier},
title = {{Spontaneous action potentials due to channel fluctuations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349596794948},
volume = {71},
year = {1996}
}
@article{Odlyzko1988,
abstract = {Let vectors v1, ..., vp be chosen at random from the ??1 vectors of length n. The probability that there is at least one +-1 vector in the subspace (over the reals) spanned by v1, ..., vp that is different from the +-vj is shown to be 4 p 3 3 4n +O 7 10n, as n -{\textgreater}infinity, for p {\textless} n - 10n (log n), where the constant implied by the O-notation is independent of p. The main term in this estimate is the probability that some three of the vj contain another +-1 vector in their linear span. This result answers a question that arose in the work of Kanter and Sompolinsky on associative memories.},
author = {Odlyzko, A. M.},
doi = {10.1016/0097-3165(88)90046-5},
issn = {10960899},
journal = {Journal of Combinatorial Theory, Series A},
number = {1},
pages = {124--133},
title = {{On subspaces spanned by random selections of +-1 vectors}},
volume = {47},
year = {1988}
}
@article{JonesKatz07,
author = {Jones, Lauren M and Fontanini, Alfredo and Sadacca, Brian F and Miller, Paul and Katz, Donald B},
journal = {Proceedings of the National Academy of SciencesJournal of Neuroscience},
pages = {18772--18777},
title = {{Natural stimuli evoke dynamic sequences of states in sensory cortical ensembles}},
volume = {104},
year = {2007}
}
@article{BarbourWang03b,
author = {Barbour, Dennis L and Wang, Xiaoqin},
journal = {Journal of Neuroscience},
month = {aug},
number = {18},
pages = {7194--7206},
title = {{Auditory cortical responses elicited in awake primates by random spectrum stimuli}},
volume = {23},
year = {2003}
}
@article{Mou2017,
abstract = {Algorithm-dependent generalization error bounds are central to statistical learning theory. A learning algorithm may use a large hypothesis space, but the limited number of iterations controls its model capacity and generalization error. The impacts of stochastic gradient methods on generalization error for non-convex learning problems not only have important theoretical consequences, but are also critical to generalization errors of deep learning. In this paper, we study the generalization errors of Stochastic Gradient Langevin Dynamics (SGLD) with non-convex objectives. Two theories are proposed with non-asymptotic discrete-time analysis, using Stability and PAC-Bayesian results respectively. The stability-based theory obtains a bound of O 1 n L √ $\beta$T k , where L is uniform Lipschitz parameter, $\beta$ is inverse tempera-ture, and T k is aggregated step sizes. For PAC-Bayesian theory, though the bound has a slower O(1/ √ n) rate, the contribution of each step is shown with an exponentially decaying factor by imposing 2 regularization, and the uniform Lipschitz constant is also replaced by actual norms of gradients along trajectory. Our bounds have no implicit dependence on dimensions, norms or other capacity measures of parameter, which elegantly characterizes the phenomenon of " Fast Training Guarantees Generalization " in non-convex settings. This is the first algorithm-dependent result with reasonable dependence on aggregated step sizes for non-convex learning, and has important implications to statistical learning aspects of stochastic gradient methods in complicated models such as deep learning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1707.05947v1},
author = {Mou, Wenlong and Wang, Liwei and Zhai, Xiyu and Zheng, Kai},
eprint = {arXiv:1707.05947v1},
title = {{Generalization Bounds of SGLD for Non-convex Learning: Two Theoretical Viewpoints}},
url = {https://arxiv.org/pdf/1707.05947.pdf},
year = {2017}
}
@incollection{Destexhe2000,
author = {Destexhe, Alain and Huguenard, John},
booktitle = {Computational neuroscience: realistic modeling for experimentalists},
title = {{Which formalism to use for modeling voltage-dependent conductances ?}},
year = {2000}
}
@article{Salimans2013,
author = {Salimans, Tim and Knowles, David a.},
doi = {10.1214/13-BA858},
issn = {1936-0975},
journal = {Bayesian Analysis},
keywords = {approximate inference,stochastic approximation,variational bayes},
month = {dec},
number = {4},
pages = {837--882},
title = {{Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression}},
url = {http://projecteuclid.org/euclid.ba/1386166315},
volume = {8},
year = {2013}
}
@article{BerrebiMugnaini91b,
abstract = {This investigation attempted to determine the mode of distribution

and synaptic targets of the cartwheel cell axon in the guinea pig

dorsal cochlear nucleus (DCoN). Antiserum against PEP-19, a putative

calcium-binding neuropeptide, was employed at the light and electron

microscopic levels. We show that in the hind-brain of the guinea

pig, cerebellar Purkinje cells and DCoN cartwheel cells are the most

densely immunoreactive neurons. The PEP-19 immunoreaction product

is localized to all neuronal compartments of these cells. Primary

targets of cartwheel cell axons are the DCoN pyramidal cells, the

large efferent neurons of layer 2. These neurons receive numerous

immunoreactive synaptic boutons on their cell bodies and apical and

basal dendritic arbors. A PEP-19-immunoreactive axonal plexus, largely

formed by cartwheel cell axons, highlights layer 3, co-extensively

with the basal arbors of pyramidal cells. This plexus is oriented

predominantly in the transstrial plane of the DCoN, in parallel with

the sheet-like basal dendritic arbor of pyramidal neurons and with

the isofrequency bands of primary cochlear nerve fibers. PEP-19-positive

boutons contain pleomorphic synaptic vesicles and form symmetric

synaptic junctions, indicative of inhibitory innervation. In addition,

immunoreactive boutons, similar to those synapsing on pyramidal neurons,

were observed on the cell bodies and main dendritic trunks of cartwheel

neurons, indicating a system of recurrent collaterals. Furthermore,

a small number of PEP-19-positive axons of unknown origin reach the

caudal rim of the posteroventral cochlear nucleus. Within the territory

of distribution of the cartwheel cell axon are the dendrites of at

least two other types of DCoN neuron, the vertical cells of Lorente

de N� and the giant cells. These neurons may represent additional

targets of the cartwheel cell axon, but this remains to be ascertained

with specific methods. Our data demonstrate that the cartwheel neurons

modulate the activity of pyramidal neurons and, therefore, play a

key role in shaping the output of the DCoN superficial layers.},
author = {Berrebi, A S and Mugnaini, E},
journal = {Anat Embryol (Berl)},
keywords = {Animals; Auditory Pathways; Axons; Brain Stem; Coc,Immunoelectron; Nerve Tissue Proteins; Neurons},
number = {5},
pages = {427--454},
pmid = {1862946},
title = {{Distribution and targets of the cartwheel cell axon in the dorsal cochlear nucleus of the guinea pig.}},
volume = {183},
year = {1991}
}
@article{Loh2012,
author = {Loh, PL and Wainwright, MJ},
journal = {arXiv preprint arXiv:1212.0478},
pages = {1--9},
title = {{Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses}},
url = {http://arxiv.org/abs/1212.0478},
year = {2012}
}
@article{Marom2002,
author = {Marom, S and Shahaf, G},
issn = {0033-5835},
journal = {Quarterly reviews of biophysics},
keywords = {Animals,Biophysical Phenomena,Biophysics,Cells,Cultured,Electrophysiology,Humans,Learning,Memory,Nerve Net,Neurons,Neurons: physiology,Rats,Software,Synapses,Time Factors},
month = {feb},
number = {1},
pages = {63--87},
pmid = {11997981},
title = {{Development, learning and memory in large random networks of cortical neurons: lessons beyond anatomy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11997981},
volume = {35},
year = {2002}
}
@article{Sommers1988a,
author = {Sommers, HJ and Crisanti, A. and Sompolinsky, H and Stein, Y.},
journal = {Physical Review Letters},
number = {19},
pages = {1895--1898},
publisher = {APS},
title = {{Spectrum of large random asymmetric matrices}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.60.1895},
volume = {60},
year = {1988}
}
@inproceedings{Lindsey1995,
author = {Lindsey, Clark S and Lindblad, Thomas},
booktitle = {Proc. SPIE, Applications and Science of Artificial Neural Networks},
keywords = {accelerator cards,high energy physics triggers,neural network hardware,neurocomputers,pattern recognition},
pages = {1194--1205},
title = {{Survey of neural network hardware}},
volume = {2492},
year = {1995}
}
@article{Friedman|1975|,
abstract = {An algorithm and data structure are presented for searching a file
containing N records, each described by k real valued keys, for the
m closest matches or nearest neighbors to a given query record. The
computation required to organize the file is proportional to k N
log N. The expected number of records examined in each search is
independent of the file size. The expected computation to perform
each search is proportional to log N. Empirical evidence suggests
that except for very small files, this algorithm is considerably
faster than other methods.},
annote = {This is nearest neighbor search algorithm used in matlab.},
author = {Friedman, J H and Bentley, J L and Finkel, R A},
journal = {SLAC-PUB},
keywords = {best match,computational,logarithmic expected time,mathematics,nearest neighbor,search},
title = {{An algorithm for finding best matches in logarithmic expected time}},
volume = {1549}
}
@article{Zhang2003,
annote = {2009num42},
author = {Zhang, Wei and Linden, David J},
doi = {10.1038/nrn1248},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Cells,Cultured,Humans,Learning,Learning: physiology,Memory,Memory: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: metabolism,Neurons: physiology,Physical Stimulation},
number = {11},
pages = {885--900},
pmid = {14595400},
title = {{The other side of the engram: experience-driven changes in neuronal intrinsic excitability.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14595400},
volume = {4},
year = {2003}
}
@article{Krumin2010,
abstract = {Recent years have seen the emergence of microelectrode arrays and optical methods allowing simultaneous recording of spiking activity from populations of neurons in various parts of the nervous system. The analysis of multiple neural spike train data could benefit significantly from existing methods for multivariate time-series analysis which have proven to be very powerful in the modeling and analysis of continuous neural signals like EEG signals. However, those methods have not generally been well adapted to point processes. Here, we use our recent results on correlation distortions in multivariate Linear-Nonlinear-Poisson spiking neuron models to derive generalized Yule-Walker-type equations for fitting ''hidden" Multivariate Autoregressive models. We use this new framework to perform Granger causality analysis in order to extract the directed information flow pattern in networks of simulated spiking neurons. We discuss the relative merits and limitations of the new method.},
author = {Krumin, Michael and Shoham, Shy},
doi = {10.1155/2010/752428},
issn = {1687-5273},
journal = {Computational intelligence and neuroscience},
keywords = {Action Potentials,Algorithms,Animals,Automation,Computer Simulation,Linear Models,Models, Neurological,Models, Statistical,Multivariate Analysis,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Normal Distribution,Poisson Distribution,Regression Analysis,Signal Processing, Computer-Assisted},
month = {jan},
pages = {752428},
pmid = {20454705},
title = {{Multivariate autoregressive modeling and granger causality analysis of multiple spike trains.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2862319{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2010},
year = {2010}
}
@article{An2015,
author = {An, Senjian and Bennamoun, Mohammed and Bennamoun, Mohammed and Edu, U W a},
journal = {Journal of Machine Learning Research},
title = {{How Can Deep Rectifier Networks Achieve Linear Separability and Preserve Distances?}},
volume = {37},
year = {2015}
}
@article{evans2005nonequilibrium,
abstract = {We review recent progress on the zero-range process, a model of interacting particles which hop
between the sites of a lattice with rates that depend on the occupancy of the departure site. We
discuss several applications which have stimulated interest in the model such as shaken granular
gases and network dynamics; we also discuss how the model may be used as a coarse-grained
description of driven phase-separating systems. A useful property of the zero-range process is that
the steady state has a factorized form. We show how this form enables one to analyse in detail
condensation transitions, wherein a finite fraction of particles accumulate at a single site. We
review condensation transitions in homogeneous and heterogeneous systems and also summarize recent
progress in understanding the dynamics of condensation. We then turn to several generalizations
which also, under certain specified conditions, share the property of a factorized steady state.
These include several species of particles; hop rates which depend on both the departure and the
destination sites; continuous masses; parallel discrete-time updating; non-conservation of particles
and sites.},
annote = {2010IIInum54{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Evans, M R and Hanney, T},
doi = {10.1088/0305-4470/38/19/R01},
issn = {0305-4470},
journal = {Journal of Physics A: Mathematical and General},
keywords = {Neuron Model,correlations,math,networks},
mendeley-tags = {Neuron Model,correlations,math,networks},
month = {may},
number = {19},
pages = {R195},
publisher = {IOP Publishing},
title = {{Nonequilibrium statistical mechanics of the zero-range process and related models}},
url = {http://stacks.iop.org/0305-4470/38/i=19/a=R01 http://iopscience.iop.org/0305-4470/38/19/R01},
volume = {38},
year = {2005}
}
@book{BA02,
author = {K., Burnham and Anderson, D},
publisher = {Springer},
title = {{Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach}},
year = {2002}
}
@article{BROW01,
author = {Brown, E and Nguyen, D and Frank, L and Wilson, M and Solo, V},
journal = {PNAS},
pages = {12261--12266},
title = {{An analysis of neural receptive field plasticity by point process adaptive filtering}},
volume = {98},
year = {2001}
}
@article{Valdes-Sosa2005,
abstract = {There is much current interest in identifying the anatomical and functional circuits that are the basis of the brain's computations, with hope that functional neuroimaging techniques will allow the in vivo study of these neural processes through the statistical analysis of the time-series they produce. Ideally, the use of techniques such as multivariate autoregressive (MAR) modelling should allow the identification of effective connectivity by combining graphical modelling methods with the concept of Granger causality. Unfortunately, current time-series methods perform well only for the case that the length of the time-series Nt is much larger than p, the number of brain sites studied, which is exactly the reverse of the situation in neuroimaging for which relatively short time-series are measured over thousands of voxels. Methods are introduced for dealing with this situation by using sparse MAR models. These can be estimated in a two-stage process involving (i) penalized regression and (ii) pruning of unlikely connections by means of the local false discovery rate developed by Efron. Extensive simulations were performed with idealized cortical networks having small world topologies and stable dynamics. These show that the detection efficiency of connections of the proposed procedure is quite high. Application of the method to real data was illustrated by the identification of neural circuitry related to emotional processing as measured by BOLD.},
author = {Vald{\'{e}}s-Sosa, Pedro a and S{\'{a}}nchez-Bornot, Jose M and Lage-Castellanos, Agust{\'{i}}n and Vega-Hern{\'{a}}ndez, Mayrim and Bosch-Bayard, Jorge and Melie-Garc{\'{i}}a, Lester and Canales-Rodr{\'{i}}guez, Erick},
doi = {10.1098/rstb.2005.1654},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Brain,Brain Mapping,Brain Mapping: methods,Brain: anatomy {\&} histology,Brain: physiology,Computer Simulation,Emotions,Emotions: physiology,Female,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models, Neurological,Models, Statistical,Multivariate Analysis,Regression Analysis},
month = {may},
number = {1457},
pages = {969--81},
pmid = {16087441},
title = {{Estimating brain functional connectivity with sparse multivariate autoregression.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1854937{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {360},
year = {2005}
}
@article{Pospischil2008,
abstract = {We review here the development of Hodgkin-Huxley (HH) type models of cerebral cortex and thalamic neurons for network simulations. The intrinsic electrophysiological properties of cortical neurons were analyzed from several preparations, and we selected the four most prominent electrophysiological classes of neurons. These four classes are "fast spiking", "regular spiking", "intrinsically bursting" and "low-threshold spike" cells. For each class, we fit "minimal" HH type models to experimental data. The models contain the minimal set of voltage-dependent currents to account for the data. To obtain models as generic as possible, we used data from different preparations in vivo and in vitro, such as rat somatosensory cortex and thalamus, guinea-pig visual and frontal cortex, ferret visual cortex, cat visual cortex and cat association cortex. For two cell classes, we used automatic fitting procedures applied to several cells, which revealed substantial cell-to-cell variability within each class. The selection of such cellular models constitutes a necessary step towards building network simulations of the thalamocortical system with realistic cellular dynamical properties.},
author = {Pospischil, M and Toledo-Rodriguez, M and Monier, C and Piwkowska, Z and Bal, T and Fr{\'{e}}gnac, Y and Markram, H and Destexhe, A},
doi = {10.1007/s00422-008-0263-8},
issn = {1432-0770},
journal = {Biological Cybernetics},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cerebral Cortex,Cerebral Cortex: physiology,Models,Neurological,Neurons,Patch-Clamp Techniques,Thalamus,Thalamus: physiology,neuron},
mendeley-tags = {neuron},
month = {nov},
number = {4-5},
pages = {427--41},
pmid = {19011929},
title = {{Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19011929},
volume = {99},
year = {2008}
}
@article{Dunning2003,
author = {Dunning, David and Johnson, Kerri and Ehrlinger, Joyce},
journal = {CURRENT DIRECTIONS IN PSYCHOLOGICAL SCIENCE},
pages = {83--87},
title = {{Why people fail to recognize their own incompetence}},
url = {http://cdp.sagepub.com/content/12/3/83.short},
year = {2003}
}
@article{Hong2008,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0701646v2},
author = {Hong, Hyunsuk and Chat, Hugues and Park, Hyunggyu and Tang, Lei-han},
eprint = {0701646v2},
number = {4},
pages = {1--5},
primaryClass = {arXiv:cond-mat},
title = {{Entrainment transition in populations of random frequency oscillators}},
year = {2008}
}
@article{Buzsaki04,
author = {Buzsaki, Gyorgy},
journal = {Nat Neurosci},
month = {may},
number = {5},
pages = {446--451},
title = {{Large-scale recording of neuronal ensembles}},
volume = {7},
year = {2004}
}
@article{Seo2011,
author = {Seo, Jae-sun and Brezzo, Bernard and Liu, Yong and Parker, Benjamin D. and Esser, Steven K. and Montoye, Robert K. and Rajendran, Bipin and Tierno, Jose a. and Chang, Leland and Modha, Dharmendra S. and Friedman, Daniel J.},
doi = {10.1109/CICC.2011.6055293},
isbn = {978-1-4577-0222-8},
journal = {2011 IEEE Custom Integrated Circuits Conference (CICC)},
month = {sep},
pages = {1--4},
publisher = {Ieee},
title = {{A 45nm CMOS neuromorphic chip with a scalable architecture for learning in networks of spiking neurons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6055293},
year = {2011}
}
@article{Goldfarb10,
author = {Goldfarb, D and Ma, S and Scheinberg, K},
journal = {Columbia University IEOR Technical Report},
title = {{Fast Alternating Linearization Methods for Minimizing the Sum of Two Convex Functions}},
year = {2010}
}
@article{Ruseckas2011,
author = {Ruseckas, J. and Kaulakys, B.},
doi = {10.1103/PhysRevE.84.051125},
issn = {1539-3755},
journal = {Physical Review E},
month = {nov},
number = {5},
title = {{Tsallis distributions and 1/f noise from nonlinear stochastic differential equations}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.84.051125},
volume = {84},
year = {2011}
}
@article{Balduzzi2015,
abstract = {Methods from convex optimization such as accelerated gradient descent are widely used as building blocks for deep learning algorithms. However, the reasons for their empirical success are unclear, since neural networks are not convex and standard guarantees do not apply. This paper develops the first rigorous link between online convex optimization and error backpropagation on convolutional networks. The first step is to introduce circadian games, a mild generalization of convex games with similar convergence properties. The main result is that error backpropagation on a convolutional network is equivalent to playing out a circadian game. It follows immediately that the waking-regret of players in the game (the units in the neural network) controls the overall rate of convergence of the network. Finally, we explore some implications of the results: (i) we describe the representations learned by a neural network game-theoretically; (ii) propose a learning setting at the level of individual units that can be plugged into deep architectures; and (iii) propose a new approach to adaptive model selection by applying bandit algorithms to choose which players to wake on each round.},
archivePrefix = {arXiv},
arxivId = {1509.01851},
author = {Balduzzi, David},
eprint = {1509.01851},
journal = {Arxiv},
keywords = {convex optimization,correlated equilibrium,deep learning,error backpropagation,game theory,no-regret learning,online convex optimization},
number = {2000},
pages = {1--20},
title = {{Deep Online Convex Optimization by Putting Forecaster to Sleep}},
url = {http://arxiv.org/abs/1509.01851},
volume = {1},
year = {2016}
}
@article{Ermentrout1995,
author = {Ermentrout, Bard},
pages = {1--23},
title = {{Type I Membranes , Phase Resetting Curves , and Synchrony 1 Introduction}},
year = {1995}
}
@article{Hannestad|1999|,
abstract = {Recent, very accurate simulations of galaxy formation have revealed
that the standard cold dark matter model has great difficulty in
explaining the detailed structure of galaxies. One of the major problems
is that galactic halos are too centrally concentrated. Dark matter
self-interactions have been proposed as a possible means of resolving
this inconsistency. Here, we investigate quantitatively the effect
of dark matter self interactions on formation of galactic halos.
Our numerical framework is extremely simple, while still keeping
the essential physics. We confirm that strongly self-interacting
dark matter leads to less centrally concentrated structures. Interestingly,
we find that for a range of different interaction strengths, the
dark matter halos are unstable to particle ejection on a timescale
comparable to the Hubble time.},
annote = {This paper provised Louville equation of state type simulations of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}gravitationally interacting dark halos with self-interaction.},
author = {Hannestad, S},
journal = {arXiv},
keywords = {astrophysics,dark matter,ejecting particles,halos,interaction,physics,simulation,strongly interacting dark matter,unstable},
pages = {9912558},
title = {{Galactic Halos of Self-Interacting Dark Matter}},
volume = {astro-ph}
}
@article{BCS96,
author = {Bialek, W and Callan, C and Strong, S},
journal = {Physical Review Letters},
pages = {4693--4697},
title = {{Field theories for learning probability distributions}},
volume = {77},
year = {1996}
}
@article{Soltanolkotabi2017,
abstract = {In this paper we study the problem of learning a shallow artificial neural network that best fits a training data set. We study this problem in the over-parameterized regime where the number of observations are fewer than the number of parameters in the model. We show that with quadratic activations the optimization landscape of training such shallow neural networks has certain favorable characteristics that allow globally optimal models to be found efficiently using a variety of local search heuristics. This result holds for an arbitrary training data of input/output pairs. For differentiable activation functions we also show that gradient descent, when suitably initialized, converges at a linear rate to a globally optimal model. This result focuses on a realizable model where the inputs are chosen i.i.d. from a Gaussian distribution and the labels are generated according to planted weight coefficients.},
archivePrefix = {arXiv},
arxivId = {1707.04926},
author = {Soltanolkotabi, Mahdi and Javanmard, Adel and Lee, Jason D.},
eprint = {1707.04926},
journal = {arXiv},
month = {jul},
title = {{Theoretical insights into the optimization landscape of over-parameterized shallow neural networks}},
url = {http://arxiv.org/abs/1707.04926},
year = {2017}
}
@article{Maltoni2012,
author = {Maltoni, D and Rehn, EM},
doi = {10.1162/NECO},
journal = {Artificial Neural Networks in Pattern Recognition},
pages = {1763--1809},
title = {{Incremental learning by message passing in hierarchical temporal memory}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-33212-8{\_}3},
volume = {1809},
year = {2012}
}
@article{Ringach2007,
abstract = {Spiking neurons translate analog intracellular variables into a sequence of action potentials. A simplified model of this transformation is one in which an underlying "generator potential," representing a measure of overall neuronal drive, is passed through a static nonlinearity to produce an instantaneous firing rate. An important question is how adaptive mechanisms adjust the mean and SD of the generator potential to define an "operating point" that controls spike generation. In early sensory pathways adaptation has been shown to rescale the generator potential to maximize the amount of transmitted information. In contrast, we demonstrate that the operating point in the cortex is tuned so that cells respond only when the generator potential executes a large excursion above its mean value. The distance from the mean of the generator potential to spike threshold is, on average, 1 SD of the ongoing activity. Signals above threshold are amplified linearly and do not reach saturation. The operating point is adjusted dynamically so that it remains relatively invariant despite changes in stimulus contrast. We conclude that the operating regimen of the cortex is suitable for the detection of signals in background noise and for enhancing the selectivity of spike responses relative to those of the generator potential (the so-called "iceberg effect"), but not to maximize the transmission of total information.},
annote = {2009num37},
author = {Ringach, Dario L and Malone, Brian J},
doi = {10.1523/JNEUROSCI.1048-07.2007},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Animals,Macaca fascicularis,Models,Neurological,Neurons,Neurons: classification,Neurons: physiology,Nonlinear Dynamics,Photic Stimulation,Photic Stimulation: methods,Physiological,Psychological,Psychological: physiology,Sensory Thresholds,Sensory Thresholds: physiology,Signal Detection,Visual Cortex,Visual Cortex: cytology},
number = {29},
pages = {7673--83},
pmid = {17634362},
title = {{The operating point of the cortex: neurons as large deviation detectors.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17634362},
volume = {27},
year = {2007}
}
@article{Marvin1982,
author = {Marvin, S},
number = {3},
pages = {212--218},
title = {{No Title}},
volume = {70},
year = {1982}
}
@article{Toni|2007|,
abstract = {Although new and functional neurons are produced in the adult brain,
little is known about how they integrate into mature networks. Here
we explored the mechanisms of synaptogenesis on neurons born in the
adult mouse hippocampus using confocal microscopy, electron microscopy
and live imaging. We report that new neurons, similar to mature granule
neurons, were contacted by axosomatic, axodendritic and axospinous
synapses. Consistent with their putative role in synaptogenesis,
dendritic filopodia were more abundant during the early stages of
maturation and, when analyzed in three dimensions, the tips of all
filopodia were found within 200 nm of preexisting boutons that already
synapsed on other neurons. Furthermore, dendritic spines primarily
synapsed on multiple-synapse boutons, suggesting that initial contacts
were preferentially made with preexisting boutons already involved
in a synapse. The connectivity of new neurons continued to change
until at least 2 months, long after the formation of the first dendritic
protrusions.},
annote = {NS050217-02/NS/United States NINDS RRP41-04050/United States PHS{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Journal Article Research Support, N.I.H., Extramural Research Support,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Non-U.S. Gov{\&}{\#}039;t United States},
author = {Toni, N and Teng, E M and Bushong, E A and Aimone, J B and Zhao, C and Consiglio, A and van Praag, H and Martone, M E and Ellisman, M H and Gage, F H},
journal = {Nat Neurosci},
keywords = {Animals Dendritic Spines/metabolism/ultrastructure,Confocal/methods Microscopy,Electron,Inbred C57BL Microscopy,Neurological Neurons/*cytology/*physiology Organo,Transmission/methods Models},
number = {6},
pages = {727--734},
title = {{Synapse formation on neurons born in the adult hippocampus}},
volume = {10}
}
@article{Sacconi06,
abstract = {Second-harmonic generation (SHG) has proven essential for the highest-resolution optical recording of membrane potential (Vm) in intact specimens. Here, we demonstrate single-trial SHG recordings of neuronal somatic action potentials and quantitative recordings of their decay with averaging at multiple sites during propagation along branched neurites at distances up to 350 {\{}micro{\}}m from the soma. We realized these advances by quantifying, analyzing, and thereby minimizing the dynamics of photodamage (PD), a frequent limiting factor in the optical imaging of biological preparations. The optical signal and the PD during SHG imaging of stained cultured Aplysia neurons were examined with intracellular electrode recordings monitoring the resting Vm variations induced by laser-scanning illumination. We found that the PD increased linearly with the dye concentration but grew with the cube of illumination intensity, leading to unanticipated optimization procedures to minimize PD. The addition of appropriate antioxidants in conjunction with an observed Vm recovery after termination of laser scanning further refined the imaging criteria for minimization and control of PD during SHG recording of action potentials. With these advances, the potential of SHG as an effective optical tool for neuroscience investigations is being realized.
},
author = {Sacconi, L and Dombeck, D A and Webb, W W},
journal = {Proceedings of the National Academy of Sciences},
number = {9},
pages = {3124--3129},
title = {{Overcoming photodamage in second-harmonic generation microscopy: Real-time optical recording of neuronal action potentials}},
volume = {103},
year = {2006}
}
@article{HUM70,
author = {Humphrey, D and Schmidt, E and Thompson, W},
journal = {Science},
pages = {758--762},
title = {{Predicting measures of motor performance from multiple cortical spike trains}},
volume = {170},
year = {1970}
}
@article{Rich|1987|,
abstract = {A silicon semiconductor detector near the top of the atmosphere is
used to search for strongly interacting particles in our galactic
halo. The data exclude, as the dominant component of the halo, such
particles with masses between {\~{}} 2 GeV/c2 and 10{\^{}}5 GeV/c2. Comparisons
are made with a previously reported subterranean search for weakly
interacting halo particles.},
annote = {This is one of the experiments directly establishing limits on low-mass{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}dark matter interacting particle},
author = {Rich, J and Rocchia, R and Spiro, M},
journal = {Physics Letters B},
keywords = {astrophysics,dark matter,experimental,interaction,physics,strongly interacting dark matter},
number = {1},
pages = {173},
title = {{A search for strongly interacting dark matter}},
volume = {194}
}
@article{Iyer06,
abstract = {The successful study of dendritic signaling and computation requires the ability to simultaneously monitor neuronal activity at multiple cellular sites. While the difficulties of accessing dendritic submicron structures with conventional micropipette approaches are generally overcome by optical recording techniques, their spatio-temporal resolution has limited such studies to few sites or slow signals. Here we present a novel approach to functional imaging, termed random-access multiphoton (RAMP) microscopy, which combines multiphoton excitation with an inertia-free scanning mechanism. RAMP microscopy employs two-dimensional acousto-optic deflection to rapidly position a focused near-infrared ultrafast laser beam between dwell periods at multiple user-selected sites. Because neuronal structures are generally sparse, activity located throughout various compartments, including thin dendritic branches and spines, can be mapped at high frame rates while maintaining the signal-to-noise ratio of conventional scanning microscopy. Moreover, RAMP microscopy maintains the excellent structural imaging capability of multiphoton excitation, i.e., intrinsic optical sectioning and high lateral resolution from within highly light-scattering brain tissue. RAMP microscopy thus comprises a versatile tool for investigating correlations of dendritic structure and function with significantly enhanced experimental throughput.
},
author = {Iyer, Vijay and Hoogland, Tycho M and Saggau, Peter},
journal = {J Neurophysiol},
month = {jan},
number = {1},
pages = {535--545},
title = {{Fast Functional Imaging of Single Neurons Using Random-Access Multiphoton ({\{}RAMP{\}}) Microscopy}},
volume = {95},
year = {2006}
}
@article{Sima2002,
abstract = {We first present a brief survey of hardness results for training feedforward neural networks. These results are then completed by the proof that the simplest architecture containing only a single neuron that applies a sigmoidal activation function sigma: kappa --{\textgreater} [alpha, beta], satisfying certain natural axioms (e.g., the standard (logistic) sigmoid or saturated-linear function), to the weighted sum of n inputs is hard to train. In particular, the problem of finding the weights of such a unit that minimize the quadratic training error within (beta - alpha)(2) or its average (over a training set) within 5(beta - alpha)(2)/ (12n) of its infimum proves to be NP-hard. Hence, the well-known backpropagation learning algorithm appears not to be efficient even for one neuron, which has negative consequences in constructive learning.},
author = {S{\'{i}}ma, Jir{\'{i}}},
doi = {10.1162/089976602760408035},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Models, Neurological,Neural Networks (Computer),Neurons,Neurons: physiology},
number = {11},
pages = {2709--28},
pmid = {12433296},
title = {{Training a single sigmoidal neuron is hard.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12433296},
volume = {14},
year = {2002}
}
@article{HuysPaninski07,
author = {Huys, Quentin and Paninski, Liam},
journal = {submitted},
title = {{Model-based filtering of, and parameter estimation from, noisy biophysical observations}},
year = {2007}
}
@article{Sjostrom2002,
author = {Sj{\"{o}}str{\"{o}}m, PJ J},
doi = {10.1016/S0959-4388(02)00325-2},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
keywords = {Spike time neural coding},
mendeley-tags = {Spike time neural coding},
month = {jun},
number = {3},
pages = {305--314},
title = {{Spike timing, calcium signals and synaptic plasticity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438802003252},
volume = {12},
year = {2002}
}
@article{RSH02,
author = {Ringach, D and Shapley, R and Hawken, M},
journal = {Journal of Neuroscience},
pages = {5639--5651},
title = {{Orientation selectivity in macaque V1: diversity and laminar dependence}},
volume = {22},
year = {2002}
}
@article{Kaulakys2005,
author = {Kaulakys, B. and Gontis, V. and Alaburda, M.},
doi = {10.1103/PhysRevE.71.051105},
issn = {1539-3755},
journal = {Physical Review E},
month = {may},
number = {5},
pages = {1--11},
title = {{Point process model of 1/f noise vs a sum of Lorentzians}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.71.051105},
volume = {71},
year = {2005}
}
@article{Thorpe2001a,
abstract = {Most experimental and theoretical studies of brain function assume that neurons transmit information as a rate code, but recent studies on the speed of visual processing impose temporal constraints that appear incompatible with such a coding scheme. Other coding schemes that use the pattern of spikes across a population a neurons may be much more efficient. For example, since strongly activated neurons tend to fire first, one can use the order of firing as a code. We argue that Rank Order Coding is not only very efficient, but also easy to implement in biological hardware: neurons can be made sensitive to the order of activation of their inputs by including a feed-forward shunting inhibition mechanism that progressively desensitizes the neuronal population during a wave of afferent activity. In such a case, maximum activation will only be produced when the afferent inputs are activated in the order of their synaptic weights.},
author = {Thorpe, S and Delorme, A and Rullen, R Van},
issn = {0893-6080},
journal = {Neural networks},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Central Nervous System,Central Nervous System: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Perception,Perception: physiology,Signal Transduction,Signal Transduction: physiology,Spike time neural coding,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
mendeley-tags = {Spike time neural coding},
number = {6-7},
pages = {715--25},
pmid = {11665765},
title = {{Spike-based strategies for rapid processing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608001000831},
volume = {14},
year = {2001}
}
@article{Battaglia|1995|,
abstract = {We show that stochastic learning of attractors can take place in a
situation in which either only potentiation or only depression of
synaptic efficacies is caused in a structured Hebbian way. In each
case, the transition in the opposite sense take place at random,
but occurs only upon presentation of a stimulus. The outcome is an
associative memory with the palimpsest property. It is shown that
structured potentiation produces more effective learning than structured
depression, i.e. it creates a network with a much higher number of
retrievable memories.},
annote = {The paper introduces memory via stochastic learning. It is said that{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}variation of each synapse is local in time and space and is subjected{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to a stream of inputs which are essentially random. Synapse modification{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}is then a markov process (depth 1 random process) given current input.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}It is then considered in what condition memory can be hold for given{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}time and not erased from the synapse. Population "associative" memory{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}model is obtained and considered. Fast "exponential" decay is obtained{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}for this model, naturally due to time translational invariance, which{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}seems to not be understood by the authors at that point.},
author = {Battaglia, F P and Fusi, S},
journal = {Network: computation in neural systems},
keywords = {forgetting,memory limit,memory model,neurobiology,stochastic learning},
pages = {261},
title = {{Learning in neural networks with partially structured synaptic transitions.}},
volume = {6}
}
@article{LEY98,
author = {Leydold, J},
journal = {ACM Transactions on Modeling and Computer Simulation},
pages = {254--280},
title = {{A rejection technique for sampling from log-concave multivariate distributions}},
volume = {8},
year = {1998}
}
@phdthesis{Reuveni2012,
author = {Reuveni, I},
pages = {116},
title = {{A novel whole-cell mechanism for long-term memory enhancement}},
year = {2012}
}
@article{Shamir2016,
abstract = {Although neural networks are routinely and successfully trained in practice using simple gradientbased methods, most existing theoretical results are negative, showing that learning such networks is difficult, in a worstcase sense over all data distributions. In this paper, we take a more nuanced view, and consider whether specific assumptions on the " niceness " of the input distribution, or " niceness " of the target function (e.g. in terms of smoothness, nondegeneracy, incoherence, random choice of parameters etc.), are sufficient to guarantee learnability using gradientbased methods. We provide evidence that neither class of assumptions alone is sufficient: For any member of a class of " nice " simple target functions, there are difficult input distributions, and on the other hand, for any member of a general class of " nice " input distributions, there are simple target functions which are difficult to learn. Thus, to formally explain the practical success of neural network learning, it seems that one would need to employ a careful combination of assumptions on both the input distribution and the target function. To prove our results, we develop some tools which may be of independent interest, such as extension of Fourierbased techniques for proving hardness in the statistical queries framework [3], from the Boolean cube to Euclidean space.},
archivePrefix = {arXiv},
arxivId = {1609.01037},
author = {Shamir, Ohad},
eprint = {1609.01037},
journal = {arXiv preprint arXiv:1609.01037},
pages = {1--26},
title = {{Distribution Specific Hardness of Learning Neural Networks}},
url = {https://arxiv.org/abs/1609.01037},
year = {2016}
}
@book{Cajal|1911|,
author = {Cajal, R},
title = {{Histologie du systeme nerveux de l'homme et des vertebres}},
volume = {2}
}
@article{Levitan1994,
abstract = {neuron; regulation},
author = {Levitan, I B},
issn = {0147-006X},
journal = {Annual Review of Physiology},
keywords = {Amino Acid Sequence,Animals,Binding Sites,Brain,Brain: metabolism,Humans,Ion Channels,Ion Channels: chemistry,Ion Channels: genetics,Ion Channels: metabolism,Molecular Sequence Data,Neuron Model,Neurons,Neurons: metabolism,Phosphoprotein Phosphatases,Phosphoprotein Phosphatases: metabolism,Phosphorylation,Potassium Channels,Potassium Channels: metabolism,Protein Kinases,Protein Kinases: metabolism,Tyrosine,Tyrosine: metabolism,regulation},
mendeley-tags = {Neuron Model,regulation},
month = {jan},
number = {1},
pages = {193--212},
pmid = {10218112},
publisher = {Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA},
title = {{Modulation of ion channels by protein phosphorylation and dephosphorylation}},
url = {http://www.annualreviews.org/doi/pdf/10.1146/annurev.ne.11.030188.001003 http://www.annualreviews.org/doi/pdf/10.1146/annurev.ph.56.030194.001205},
volume = {11},
year = {1994}
}
@article{Mezard2002,
author = {M{\'{e}}zard, Marc and Zecchina, R},
doi = {10.1103/PhysRevE.66.056126},
issn = {1063-651X},
journal = {Physical Review E},
keywords = {Message passing},
mendeley-tags = {Message passing},
month = {nov},
number = {5},
pages = {056126},
title = {{Random K-satisfiability problem: From an analytic solution to an efficient algorithm}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.66.056126},
volume = {66},
year = {2002}
}
@article{Jelenkovi1997,
author = {Jelenkovi, Predrag R and Member, Associate and Lazar, Aurel A and Semret, Nemo},
number = {6},
pages = {1052--1071},
title = {{The Effect of Multiple Time Scales and Subexponentiality in MPEG Video Streams on Queueing Behavior}},
volume = {15},
year = {1997}
}
@article{Ringach02,
author = {Ringach, D},
journal = {Journal of Neurophysiology},
pages = {455--463},
title = {{Spatial structure and symmetry of simple-cell receptive fields in macaque primary visual cortex}},
volume = {88},
year = {2002}
}
@book{MS86,
author = {Milman, V and Schechtman, G},
publisher = {Springer-Verlag},
series = {Lecture Notes in Math},
title = {{Asymptotic Theory of Finite Dimensional Normed Spaces}},
volume = {1200},
year = {1986}
}
@article{Luo2008a,
abstract = {Retinal rods and cones, which are the front-end light detectors in the eye, achieve wonders together by being able to signal single-photon absorption and yet also able to adjust their function to brightness changes spanning 10(9)-fold. How these cells detect light is now quite well understood. Not surprising for almost any biological process, the intial step of seeing reveals a rich complexity as the probing goes deeper. The odyssey continues, but the knowledge gained so far is already nothing short of remarkable in qualitative and quantitative detail. It has also indirectly opened up the mystery of odorant sensing. Basic science aside, clinical ophthalmology has benefited tremendously from this endeavor as well. This article begins by recapitulating the key developments in this understanding from the mid-1960s to the late 1980s, during which period the advances were particularly rapid and fit for an intricate detective story. It then highlights some details discovered more recently, followed by a comparison between rods and cones.},
author = {Luo, D.-G. and Xue, T. and Yau, K.-W.},
doi = {10.1073/pnas.0708405105},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {29},
pages = {9855--9862},
pmid = {18632568},
title = {{How vision begins: An odyssey}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0708405105},
volume = {105},
year = {2008}
}
@article{Werner2009a,
author = {Werner, Gerhard},
title = {{No Title}},
year = {2009}
}
@misc{Ackerman2012,
annote = {10num2012},
author = {Ackerman, Eric S},
title = {{Notes From Nonequilibrium Stat-mech course}},
year = {2012}
}
@article{Steinke2011,
author = {Steinke, GK and Gal{\'{a}}n, RF},
doi = {10.1371/Citation},
journal = {PLoS computational biology},
number = {10},
title = {{Brain Rhythms Reveal a Hierarchical Network Organization}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002207},
volume = {7},
year = {2011}
}
@inproceedings{Querlioz2011a,
author = {Querlioz, D and Dollfus, P},
booktitle = {Nanoscale Architectures (NANOARCH), 2011 IEEE/ACM International Symposium on. IEEE},
isbn = {9781457709951},
keywords = {-component,formatting,insert,key,style,styling},
pages = {150--156},
title = {{Learning with memristive devices: How should we model their behavior?}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5941497},
year = {2011}
}
@article{TippingBishop99,
author = {Tipping, Michael E and Bishop, C M},
journal = {Journal Of The Royal Statistical Society Series B},
number = {3},
pages = {611--622},
title = {{Probabilistic Principal Component Analysis}},
volume = {61},
year = {1999}
}
@article{Schreiber2009,
abstract = {Despite intrinsic noise sources, neurons can generate action potentials with remarkable reliability. This reliability is influenced by the characteristics of sensory or synaptic inputs, such as stimulus frequency. Here we use conductance-based models to study the frequency dependence of reliability in terms of the underlying single-cell properties. We are led to distinguish a mean-driven firing regime, where the stimulus mean is sufficient to elicit continuous firing, and a fluctuation-driven firing regime, where spikes are generated by transient stimulus fluctuations. In the mean-driven regime, the stimulus frequency that induces maximum reliability coincides with the firing rate of the cell, whereas in the fluctuation-driven regime, it is determined by the resonance properties of the subthreshold membrane potential. When the stimulus frequency does not match the optimal frequency, the two firing regimes exhibit different "symptoms" of decreased reliability: reduced spike-time precision and reduced spike probability, respectively. As a signature of stochastic resonance, reliable spike generation in the fluctuation-driven regime can benefit from intermediate amounts of noise that boost spike probability without significantly impairing spike-time precision. Our analysis supports the view that neurons are endowed with selection mechanisms that allow only certain stimulus frequencies to induce reliable spiking. By modulating the intrinsic cell properties, the nervous system can thus tune individual neurons to pick out specific input frequency bands with enhanced spike precision or spike probability.},
annote = {2009num38},
author = {Schreiber, Susanne and Samengo, In{\'{e}}s and Herz, Andreas V M},
doi = {10.1152/jn.90711.2008},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Biophysics,Computer Simulation,Electric Impedance,Electric Stimulation,Models,Neural Conduction,Neural Conduction: physiology,Neurological,Neurons,Neurons: classification,Neurons: physiology,Probability,Reaction Time,Reaction Time: physiology,Reproducibility of Results,Stochastic Processes,Time Factors},
month = {may},
number = {5},
pages = {2239},
pmid = {19193775},
publisher = {Am Physiological Soc},
title = {{Two distinct mechanisms shape the reliability of neural responses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19193775},
volume = {101},
year = {2009}
}
@article{Anderson|1993|,
abstract = {Quantum canonical transformations are defined algebraically outside
of a Hilbert space context. This generalizes the quantum canonical
transformations of Weyl and Dirac to include non-unitary transformations.
The importance of non-unitary transformations for constructing solutions
of the Schr{\^{A}}¨odinger equation is discussed. Three elementary canonical
transformations are shown both to have quantum implementations as
finite transformations and to generate, classically and infinitesimally,
the full canonical algebra. A general canonical transformation can
be realized quantum mechanically as a product of these transformations.
Each transformation corresponds to a familiar tool used in solving
differential equations, and the procedure of solving a differential
equation is systematized by the use of the canonical transformations.
Several examples are done to illustrate the use of the canonical
transformations.},
annote = {The paper deals with canonical transformations in quantum mechanics{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}as similarity transformation on q and p preserving dirac bracket.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}It provides quite comprehensive review of issues involved and problems{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}encountered as well as some applications of canonical transformations{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to solve simple quantum problem.},
author = {Anderson, A},
journal = {arXiv},
keywords = {canonical transformations,infinitesimal canonical transformation,physics,quantum mechanics},
pages = {9305054},
title = {{Canonical transformations in quantum mechanics}},
volume = {hep-ph}
}
@book{Thompson2002,
address = {West Sussex, England},
author = {Thompson, JMT M T and Stewart, HB B},
edition = {2nd},
publisher = {John Wiley {\&} Sons Inc},
title = {{Nonlinear dynamics and chaos}},
url = {http://www.google.com/books?hl=iw{\&}lr={\&}id=80ChNIpUDVAC{\&}oi=fnd{\&}pg=PR11{\&}dq=nonlinear+dynamics+and+chaos{\&}ots=u41-gMY67W{\&}sig=w8dtWZD1bYOM3Qlu55molqbXEOU http://books.google.com/books?hl=en{\&}lr={\&}id=80ChNIpUDVAC{\&}oi=fnd{\&}pg=PR11{\&}dq=Nonlinear+Dynamics+and+Chaos{\&}ots=},
year = {2002}
}
@article{KoerberKiang66,
author = {Koerber, K C and Pfeiffer, R R and Warr, W B and Kiang, N Y},
journal = {Experimental Neurology},
month = {oct},
number = {2},
pages = {119--130},
title = {{Spontaneous spike discharges from single units in the cochlear nucleus after destruction of the cochlea}},
volume = {16},
year = {1966}
}
@article{Faugeras2009,
annote = {2010IInum9.6},
author = {Faugeras, O and Touboul, J and Cessac, B},
journal = {Frontiers in Computational Neuroscience},
publisher = {Frontiers Research Foundation},
title = {{A constructive mean-field analysis of multi-population neural networks with random synaptic weights and stochastic inputs}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2649202},
volume = {3},
year = {2009}
}
@article{Hagmann2008,
author = {Hagmann, P and Cammoun, L and Gigandet, X and Meuli, R and Honey, C and Wedeen, V and Sporns, O},
journal = {PLoS Biology},
number = {7},
pages = {e159},
title = {{Mapping the Structural Core of Human Cerebral Cortex}},
volume = {6},
year = {2008}
}
@article{Stampfli1976,
author = {Stampfli, R},
pages = {699--727},
title = {{MEASUREMENT OF THE CONDUCTANCE}},
year = {1976}
}
@article{Durrett1986,
abstract = {In this paper we will describe and analyze a class of multidimensional random walks in random environments which contain the one dimensional nearest neighbor situation as a special case and have the pleasant feature that quite a lot can be said about them. Our results make rigorous a heuristic argument of Marinari et al. (1983), and show that in any d{\textless}∞ we can have (a)Xn is recurrent and (b)Xn∼(log n)2. {\textcopyright} 1986 Springer-Verlag.},
author = {Durrett, Richard},
doi = {10.1007/BF01210794},
issn = {00103616},
journal = {Communications in Mathematical Physics},
number = {1},
pages = {87--102},
title = {{Multidimensional random walks in random environments with subclassical limiting behavior}},
volume = {104},
year = {1986}
}
@article{Bai2006,
author = {Bai, Zhaojun and Skoogh, Daniel},
doi = {10.1016/j.laa.2005.04.032},
issn = {00243795},
journal = {Linear Algebra and its Applications},
keywords = {bilinear systems,krylov subspace,model order reduction,moment-matching},
month = {jun},
number = {2-3},
pages = {406--425},
title = {{A projection method for model reduction of bilinear dynamical systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0024379505002648},
volume = {415},
year = {2006}
}
@article{RoizenblattChow06,
abstract = {The development of a technique to load functional indicators into

living neurons is an ongoing challenge in retinal neurophysiology.

In a number of live-cell preparations, fluorescence-based indicators

have been of particular importance for investigating ionic concentrations,

protein localization, and other physiological parameters. In the

present study, we demonstrate a novel technique that uses a modified

gene gun to propel silver nanoparticles coated with indicators into

live retinal neurons, and we highlight the advantages of using this

technique to deliver these functional indicators.},
author = {Roizenblatt, Roberto and Weiland, James D and Carcieri, Stephen and Qiu, Guanting and Behrend, Matthew and Humayun, Mark S and Chow, Robert H},
doi = {10.1016/j.jneumeth.2005.10.001},
journal = {J Neurosci Methods},
keywords = {Animals; Cells,Cultured; Drug Delivery Systems; Equipment Design,Fluorescence; Nanostructures; Nanotechnology; Par,Inbred C57BL; Microinjections; Microscopy},
month = {may},
number = {1},
pages = {154--161},
pmid = {16290199},
title = {{Nanobiolistic delivery of indicators to the living mouse retina.}},
url = {http://dx.doi.org/10.1016/j.jneumeth.2005.10.001},
volume = {153},
year = {2006}
}
@article{Morales-Masis2010,
abstract = {We present a quantitative analysis of the steady-state electronic transport in a resistive switching device. The device is composed of a thin film of Ag(2)S (solid electrolyte) contacted by a Pt nano-contact acting as ion-blocking electrode, and a large-area Ag reference electrode. When applying a bias voltage both ionic and electronic transport occurs, and depending on the polarity it causes an accumulation of ions around the nano-contact. At small applied voltages (pre-switching) we observed this as a strongly nonlinear current-voltage curve, which is modeled using the Hebb-Wagner treatment for polarization of a mixed conductor. This model correctly describes the transport of the electrons within the polarized solid electrolyte in the steady-state up until the resistance switching, covering the entire range of non-stoichiometries, and including the supersaturation range just before the deposition of elemental silver. In this way, it is a step towards a quantitative understanding of the processes that lead to resistance switching.},
author = {Morales-Masis, Monica and Wiemh{\"{o}}fer, Hans-Dieter and van Ruitenbeek, Jan M},
doi = {10.1039/c0nr00298d},
issn = {2040-3372},
journal = {Nanoscale},
month = {oct},
number = {10},
pages = {2275--2280},
pmid = {20721398},
title = {{Towards a quantitative description of solid electrolyte conductance switches.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20721398},
volume = {2},
year = {2010}
}
@book{DM72,
address = {New York},
author = {Dym, H and McKean, H},
publisher = {Academic Press},
title = {{Fourier Series and Integrals}},
year = {1972}
}
@article{Kasai2010,
annote = {2010IInum11.5},
author = {Kasai, H},
journal = {?},
title = {learning rules and persistence of dendritic spines},
year = {2010}
}
@article{Linaro2011,
author = {Linaro, D and Storace, M and Giugliano, M},
doi = {10.1371/journal.pcbi.1001102},
editor = {Graham, Lyle J.},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {mar},
number = {3},
pages = {e1001102},
title = {{Accurate and Fast Simulation of Channel Noise in Conductance-Based Model Neurons by Diffusion Approximation}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1001102},
volume = {7},
year = {2011}
}
@article{Mathematics2011,
author = {Keener, J P and Hoppensteadt, FC and Rinzel, J},
issn = {0036-1399},
journal = {SIAM Journal on Applied Mathematics},
number = {3},
pages = {503--517},
publisher = {JSTOR},
title = {{Integrate-and-fire models of nerve membrane response to oscillatory input}},
url = {http://www.jstor.org/stable/2101456},
volume = {41},
year = {1981}
}
@misc{Kwakernaak1974,
author = {Kwakernaak, Huibert},
doi = {10.1115/1.3426828},
issn = {00220434},
number = {3},
pages = {373},
title = {{Linear Optimal Control Systems}},
volume = {96},
year = {1974}
}
@incollection{Bengio2011,
author = {Bengio, Yoshua and Delalleau, Olivier},
booktitle = {Algorithmic Learning Theory},
doi = {10.1007/978-3-642-34182-3},
isbn = {978-3-642-34181-6},
issn = {03029743},
keywords = {BML,FML,GRETA,NAO,SAIBA,conversational humanoid robot,expressive gestures,gesturespeech production and synchronization,human-robot interaction},
pages = {18--36},
publisher = {Springer},
title = {{On the Expressive Power of Deep Architectures}},
url = {http://dl.acm.org/citation.cfm?id=2425944.2425970},
volume = {7206},
year = {2011}
}
@article{Yu07,
author = {Yu, Byron M and Kemere, Caleb and Santhanam, Gopal and Afshar, Afsheen and Ryu, Stephen I and Meng, Teresa H and Sahani, Maneesh and Shenoy, Krishna V},
journal = {J Neurophysiol},
number = {5},
pages = {3763--3780},
title = {{Mixture of Trajectory Models for Neural Decoding of Goal-Directed Movements}},
volume = {97},
year = {2007}
}
@article{Maass1995,
author = {Maass, W},
file = {::},
journal = {Advances in neural information processing systems},
pages = {183--190},
publisher = {MORGAN KAUFMANN PUBLISHERS},
title = {{On the computational complexity of networks of spiking neurons}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=M9WuI6tiqRcC{\&}oi=fnd{\&}pg=PA183{\&}dq=On+the+Computational+Complexity+of+Netoworks+of+Spiking+Neurons{\&}ots=Gt6ufW1EQA{\&}sig=O59{\_}sPFyXXkQo1wf-gRUStzFXZg},
year = {1995}
}
@article{Renart2008,
author = {Renart, Alfonso},
pages = {1651--1705},
title = {{Theory of Input Spike Auto- and Cross-Correlations and Their}},
volume = {1705},
year = {2008}
}
@article{Pfister,
annote = {2010num4.5},
author = {Pfister, JP P and Dayan, P and Lengyel, M},
journal = {eng.cam.ac.uk},
keywords = {synapse},
mendeley-tags = {synapse},
title = {{Know Thy Neighbour: A Normative Theory of Synaptic Depression}},
url = {http://www.eng.cam.ac.uk/{~}jptp2/papers/Pfister{\_}09.pdf}
}
@article{Soudry2013b,
archivePrefix = {arXiv},
arxivId = {arXiv:1301.2631v1},
author = {Soudry, D. and Meir, R},
eprint = {arXiv:1301.2631v1},
journal = {arxiv},
title = {{The neuronal response at extended timescales}},
year = {2013}
}
@book{GreenSilverman94,
author = {Green, P and Silverman, B},
publisher = {CRC Press},
title = {{Nonparametric Regression and Generalized Linear Models}},
year = {1994}
}
@article{Fusi|1999|,
abstract = {We analyze in detail the statistical properties of the spike emission
process of a canonical integrate-and-fire neuron, with a linear integrator
and a lower bound for the depolarization, as often used in VLSI implementations
(Mead, 1989). The spike statistics of such neurons appear to be qualitatively
similar to conventional (exponential) integrate-and-fire neurons,
which exhibit a wide variety of characteristics observed in cortical
recordings. We also show that, contrary to current opinion, the dynamics
of a network composed of such neurons has two stable fixed points,
even in the purely excitatory network, corresponding to two different
states of reverberating activity. The analytical results are compared
with numerical simulations and are found to be in good agreement.},
author = {Fusi, S and Mattia, M},
journal = {Neural Computation},
keywords = {forgetting,memory limit,memory model,neurobiology,stochastic learning,unread},
pages = {633},
title = {{Collective behavior of networks with linear (VLSI) integrate-and-fire neurons}},
volume = {11}
}
@article{YS90,
author = {Yang, X and Shamma, S},
journal = {Biophysical Journal},
pages = {987--999},
title = {{Identification of connectivity in neural networks}},
volume = {57},
year = {1990}
}
@article{Bannister2005,
abstract = {The flow of excitation through cortical columns has long since been predicted by studying the axonal projection patterns of excitatory neurones situated within different laminae. In grossly simplified terms and assuming random connectivity, such studies predict that input from the thalamus terminates primarily in layer 4, is relayed 'forward' to layer 3, then to layers 5 and 6 from where the modified signal may exit the cortex. Projection patterns also indicate 'back' projections from layer 5 to 3 and layer 6 to 4. More recently it has become clear that the interconnections between these layers are not random; forward projections primarily contact specific pyramidal subclasses and intracortical back projections innervate interneurones. This indicates that presynaptic axons or postsynaptic dendrites are capable of selecting their synaptic partners and that this selectivity is layer dependent. For the past decade, we and others have studied pyramidal cell targeting in circuits both within, and between laminae using paired intracellular recordings with biocytin filling and have begun to identify further levels of selectivity through the preferential targeting of electrophysiologically and/or morphologically distinct pyramidal subtypes. Presented here, therefore, is a brief overview of current thinking on the layer and subclass specific connectivity of neocortical principle excitatory cells.},
author = {Bannister, a Peter},
doi = {10.1016/j.neures.2005.06.019},
issn = {0168-0102},
journal = {Neuroscience research},
keywords = {Animals,Humans,Neocortex,Neocortex: cytology,Neocortex: metabolism,Neural Pathways,Neural Pathways: cytology,Neural Pathways: metabolism,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: metabolism},
month = {oct},
number = {2},
pages = {95--103},
pmid = {16054257},
title = {{Inter- and intra-laminar connections of pyramidal cells in the neocortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16054257},
volume = {53},
year = {2005}
}
@article{Harris|1999|,
abstract = {Dendritic spines are distinguished by their shapes, subcellular composition,
and synaptic receptor subtypes. Recent studies show that actin-dependent
movements take place in spine heads, that spines emerge from stubby
and shaft synapses after dendritic filopodia disappear, and that
spines can form without synaptic activation, are maintained by optimal
activation, and are lost with excessive activation or during degeneration.},
annote = {MH/DA57351/MH/United States NIMH NS21184/NS/United States NINDS NS33574/NS/United{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}States NINDS etc. Journal Article Research Support, U.S. Gov{\&}{\#}039;t, Non-P.H.S.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Research Support, U.S. Gov{\&}{\#}039;t, P.H.S. Review England},
author = {Harris, K M},
journal = {Curr Opin Neurobiol},
keywords = {Animals Brain/*cytology/physiology Dendrites/*phys},
number = {3},
pages = {343--348},
title = {{Structure, development, and plasticity of dendritic spines}},
volume = {9}
}
@article{Jain2003,
annote = {2011num19},
author = {Jain, Parag and Banerjee, Soumitro},
journal = {Int. J. Bifurc. Chaos},
keywords = {border-collision bifurcations,discontinuous maps,power electronics},
number = {11},
pages = {3341--3352},
publisher = {Citeseer},
title = {{Border collision bifurcations in one-dimensional discontinuous maps}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.9404{\&}rep=rep1{\&}type=pdf},
volume = {13},
year = {2003}
}
@article{Chua1971,
author = {Chua, L},
journal = {Circuit Theory, IEEE Transactions on},
month = {sep},
number = {5},
pages = {507--519},
title = {{Memristor-the missing circuit element}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1083337},
volume = {18},
year = {1971}
}
@article{Averbeck2008,
author = {Averbeck, B B and Seo, M},
journal = {PLOS Comp. Biol.},
pages = {e1000050},
title = {{The statistical neuronanatomy of frontal networks in the macaque}},
volume = {4},
year = {2008}
}
@misc{Fricke|2000|,
annote = {Algorithm for quick single pass labeling of connected components.},
author = {Fricke, T},
keywords = {computational},
title = {{The Hoshen-Kopelman Algorithm}}
}
@incollection{IYEN01,
author = {Iyengar, S},
booktitle = {Advances in Methodological and Applied Aspects of Probability and Statistics},
pages = {507--524},
publisher = {Gordon and Breach},
title = {{The analysis of multiple neural spike trains}},
year = {2001}
}
@inproceedings{Rosenthal2016,
abstract = {{\textcopyright} 2016 IEEE.In recent years, Neural Networks (NNs) have become widely popular for the execution of different machine learning algorithms. Training an NN is computationally intensive since it requires numerous multiplications of matrices that represent synaptic weights. It is therefore appealing to build a hardware-based NN accelerator to gain parallelism and efficient computation. Recently, we have proposed a compact circuit of a non-volatile synaptic weight based on two CMOS transistors and a memristor. In this paper, we present a fully analog NN design based on our previously proposed synapse with a full design of the different layers and their supporting CMOS circuits. We show that the presented NN significantly reduces the area as compared to a CMOS-based NN, while executing online gradient training with similar accuracy and computational speed improvement as a software implementation.},
author = {Rosenthal, E. and Greshnikov, S. and Soudry, D. and Kvatinsky, S.},
booktitle = {Proceedings - IEEE International Symposium on Circuits and Systems},
doi = {10.1109/ISCAS.2016.7527510},
isbn = {9781479953400},
issn = {02714310},
keywords = {CMOS,Multilayer Neural Networks,RRAM,backpropagation,machine learning,memristor,neuromorphic},
title = {{A fully analog memristor-based neural network with online gradient training}},
volume = {2016-July},
year = {2016}
}
@incollection{BearLinden01,
author = {Bear, M F and Linden, D J},
chapter = {The mechan},
editor = {Cowan, W Maxwell and S{\"{u}}dhof, Thomas C and Stevens, Charles F},
pages = {455--517},
publisher = {Johns Hopkins University Press},
title = {{Synapses}},
year = {2001}
}
@article{Parrish|2007|,
author = {Parrish, J Z and Emoto, K and Kim, M D and Jan, Y N},
journal = {Annu Rev Neurosci},
keywords = {Animals Cell Differentiation/genetics Central Nerv},
pages = {399--423},
title = {{Mechanisms that regulate establishment, maintenance, and remodeling of dendritic fields}},
volume = {30}
}
@incollection{BROW03,
author = {Brown, E and Barbieri, R and Eden, U and Frank, L},
booktitle = {Computational Neuroscience: a comprehensive approach},
editor = {Feng, J},
pages = {253--286},
publisher = {CRC Press},
title = {{Likelihood methods for neural data analysis}},
year = {2003}
}
@article{GodsillWest01,
author = {Godsill, S and Doucet, A and West, M},
journal = {Annals of the Institute of Statistical Mathematics},
number = {1},
pages = {82--96},
publisher = {Springer},
title = {{Maximum a Posteriori Sequence Estimation Using Monte Carlo Particle Filters}},
volume = {53},
year = {2001}
}
@inproceedings{Flaherty05,
author = {Flaherty, Patrick and Jordan, Michael I and Arkin, Adam P},
booktitle = {NIPS},
title = {{Robust design of biological experiments}},
year = {2005}
}
@article{PS03,
author = {Pillow, J W and Simoncelli, E},
journal = {Neurocomputing},
pages = {109--115},
title = {{Biases in white noise analysis due to non-{\{}P{\}}oisson spike generation}},
volume = {52},
year = {2003}
}
@article{Tal2001,
abstract = {The input-output relation of a single neuron stands at the basis of every biologically oriented description of the brain. This report shows that the input-output relation of cultured cortical neurons is non-linearly tuned by the input frequency. Increasing the rate of stimulation results in the appearance of ordered temporal firing patterns, which are qualitatively different for different input frequencies. The experimental results of this study lead to the conclusion that frequency tuning of neuronal input-output relation arises from activity-dependent rates at the molecular level underlying the mechanism of excitability itself.},
annote = {2009num16},
author = {Tal, D and Jacobson, E and Lyakhov, V and Marom, S},
issn = {0304-3940},
journal = {Neuroscience Letters},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Electric Stimulation,Electrophysiology,Neurons,Neurons: physiology,Newborn,Physiological,Physiological: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Rats},
month = {mar},
number = {1},
pages = {21--4},
pmid = {11172930},
title = {{Frequency tuning of input-output relation in a rat cortical neuron in-vitro.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11172930},
volume = {300},
year = {2001}
}
@article{Cheng|2006|,
author = {Cheng, D and Hoogenraad, C C and Rush, J and Ramm, E and Schlager, M A and Duong, D M and Xu, P and Wijayawardana, S R and Hanfelt, J and Nakagawa, T and Sheng, M and Peng, J},
journal = {Mol. Cell. Proteomics},
number = {6},
pages = {1158},
title = {{Relative and Absolute Quantification of Postsynaptic Density Proteome Isolated from Rat Forebrain and Cerebellum}},
volume = {5}
}
@misc{scholl-shannon,
author = {Scholl, Holger R},
howpublished = {Available at citeseer.nj.nec.com/104699.html},
title = {{Shannon optimal priors on i.i.d. statistical experiments converge weakly to {\{}J{\}}effreys' prior}},
year = {1998}
}
@article{Baruchi|2004|,
abstract = {A functional holography (FH) approach is introduced for analyzing
the complex activity of biological networks in the space of functional
correlations. Although the activity is often recorded from part of
the nodes only, the goal is to decipher the activity of the whole
network. This is why the analysis is guided by the {\"{i}}¾“whole in every
part{\"{i}}¾” of a holograms{\^{A}}—a small part of a hologram will generate
the whole picture but with lower resolution. The analysis is started
by constructing the space of functional correlations from the similarities
between the activities of the network components using a special
collective normalization or affinity transformation. Using dimension
reduction algorithms like PCA, a connectivity diagram is generated
in the 3-dimensional space of the leading eigenvectors of the algorithm.
The network components are positioned in the 3-dimensional space
by projection on the eigenvectors and connect them with colored lines
that represent the similarities. Temporal (causal) information is
superimposed by coloring the node{\"{i}}¾'s locations according to the
temporal ordering of their activities. Utilizing the analysis, the
existence of hidden manifolds with simple yet characteristic geometrical
and topological features in the complex biological activity was discovered
from cultured networks to the human brain. These findings could be
a consequence of the analysis being consistent with a new holographic
principle by which biological networks regulate their complex activity.},
annote = {The authors introduce concept of functinal holography, which is a{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}set of prescriptions for 3D representation of principal components{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of network activity},
author = {Baruchi, I and Towle, V L and Ben-Jacob, E},
journal = {Complexity},
keywords = {activity imaging,biological networks,functional holography,networks,networks structure,neurobiology,principal component analysis,similarity matrices},
number = {3},
pages = {38},
title = {{Functional holography of complex networks activity - from cultures to the human brain}},
volume = {10}
}
@article{Hooge1976,
abstract = {A survey is given of the recent literature on 1/f noise. Proposals for mathematical models, for empirical relations and for physical models are discussed. The present situation is evaluated and some unsolved problems are indicated.},
author = {Hooge, F},
doi = {10.1016/0378-4363(76)90089-9},
issn = {03784363},
journal = {Physica B+C},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {may},
number = {1},
pages = {14--23},
title = {1/f noise},
url = {http://dx.doi.org/10.1016/0378-4363(76)90089-9},
volume = {83},
year = {1976}
}
@article{SBR02,
author = {Sharpee, T and Rust, N and Bialek, W},
journal = {Neural Computation},
pages = {223--250},
title = {{Analyzing neural responses to natural signals: Maximally informative dimensions}},
volume = {16},
year = {2004}
}
@incollection{ZG04,
author = {Ghahramani, Z},
chapter = {Unsupervis},
publisher = {Springer-Verlag},
title = {{Advanced Lectures on Machine Learning LNAI 3176}},
year = {2004}
}
@article{Ratcliff|2001|,
annote = {The letter discusses noise in simple diffusion decision making model{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}for critising some LATER decision model of Reddi and Carpenter.},
author = {Ratcliff, R},
journal = {Nature neuroscience},
keywords = {decision making,diffusion model,neurobiology,noise},
number = {4},
pages = {336},
title = {{Putting noise into neurophysiological models of simple decision making}},
volume = {4}
}
@article{VanVreeswijk1998,
abstract = {The nature and origin of the temporal irregularity in the electrical activity of cortical neurons in vivo are not well understood. We consider the hypothesis that this irregularity is due to a balance of excitatory and inhibitory currents into the cortical cells. We study a network model with excitatory and inhibitory populations of simple binary units. The internal feedback is mediated by relatively large synaptic strengths, so that the magnitude of the total excitatory and inhibitory feedback is much larger than the neuronal threshold. The connectivity is random and sparse. The mean number of connections per unit is large, though small compared to the total number of cells in the network. The network also receives a large, temporally regular input from external sources. We present an analytical solution of the mean-field theory of this model, which is exact in the limit of large network size. This theory reveals a new cooperative stationary state of large networks, which we term a balanced state. In this state, a balance between the excitatory and inhibitory inputs emerges dynamically for a wide range of parameters, resulting in a net input whose temporal fluctuations are of the same order as its mean. The internal synaptic inputs act as a strong negative feedback, which linearizes the population responses to the external drive despite the strong nonlinearity of the individual cells. This feedback also greatly stabilizes the system's state and enables it to track a time-dependent input on time scales much shorter than the time constant of a single cell. The spatiotemporal statistics of the balanced state are calculated. It is shown that the autocorrelations decay on a short time scale, yielding an approximate Poissonian temporal statistics. The activity levels of single cells are broadly distributed, and their distribution exhibits a skewed shape with a long power-law tail. The chaotic nature of the balanced state is revealed by showing that the evolution of the microscopic state of the network is extremely sensitive to small deviations in its initial conditions. The balanced state generated by the sparse, strong connections is an asynchronous chaotic state. It is accompanied by weak spatial cross-correlations, the strength of which vanishes in the limit of large network size. This is in contrast to the synchronized chaotic states exhibited by more conventional network models with high connectivity of weak synapses.},
author = {van Vreeswijk, C and Sompolinsky, H},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Models,Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Sensory Thresholds,Sensory Thresholds: physiology,Synapses,Synapses: physiology,Time Factors},
month = {aug},
number = {6},
pages = {1321--1371},
pmid = {9698348},
title = {{Chaotic balanced state in a model of cortical circuits}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9698348},
volume = {10},
year = {1998}
}
@article{Kaniadakis2006,
abstract = {Starting from the developed generalized point process model of 1/f noise [B. Kaulakys et al., Phys. Rev. E 71 (2005) 051105] we derive the nonlinear stochastic differential equations for the signal exhibiting 1/f$\beta$ noise and 1/x$\lambda$ distribution density of the signal intensity with different values of $\beta$ and $\lambda$. The processes with 1/f$\beta$ are demonstrated by the numerical solution of the derived equations with the appropriate restriction of the diffusion of the signal in some finite interval. The proposed consideration may be used for modeling and analysis of stochastic processes in different systems with the power-law distributions, long-range memory or with the elements of self-organization.},
author = {Kaniadakis, Giorgio and Carbone, Anna and Lissia, Marcello and Kaulakys, Bronislovas and Ruseckas, Julius and Gontis, Vygintas and Alaburda, Miglius},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {1/f noise,Point processes,Power-law distributions,Stochastic equations,Stochastic processes},
number = {1},
pages = {217--221},
title = {{Nonlinear stochastic models of 1/f noise and power-law distributions}},
url = {http://www.sciencedirect.com/science/article/pii/S0378437106000574},
volume = {365},
year = {2006}
}
@article{Stevenson2008,
author = {Stevenson, I H and Rebesco, J M and Miller, L E and Kording, K P},
journal = {Curr. Opin. Neurobiol.},
pages = {582--588},
title = {{Inferring functional connections between neurons}},
volume = {18},
year = {2008}
}
@article{Edwards93,
author = {Edwards, B E and Wakefield, G H},
journal = {J. Acoust. Soc. Am.},
pages = {3553--3564},
title = {{The spectral shaping of neural discharges by refractory effects}},
volume = {93},
year = {1993}
}
@article{Shiekh|1994|,
abstract = {A preferred form for the path integral discretization is suggested
that allows the implementation of canonical transformations in quantum
theory.},
author = {Shiekh, A Y},
journal = {arXiv},
keywords = {canonical transformations,path integral,physics,quantum mechanics,unread},
pages = {9411199},
title = {{Quantum canonical transformation revisited}},
volume = {hep-th}
}
@article{Rucci08,
author = {Rucci, M},
journal = {Network: Computation in Neural Systems},
pages = {253--285},
title = {{Fixational eye movements, natural image statistics, and fine spatial vision}},
volume = {19},
year = {2008}
}
@book{SER95,
address = {New York},
author = {Serfling, R},
publisher = {Wiley},
title = {{Approximation theorems of mathematical statistics}},
year = {1980}
}
@phdthesis{MINKAPHD,
author = {Minka, T},
school = {MIT},
title = {{A Family of Algorithms for Approximate {\{}B{\}}ayesian Inference}},
year = {2001}
}
@article{Merolla2011,
author = {Merolla, Paul and Arthur, John and Akopyan, Filipp and Imam, Nabil and Manohar, Rajit and Modha, Dharmendra S.},
doi = {10.1109/CICC.2011.6055294},
isbn = {978-1-4577-0222-8},
journal = {2011 IEEE Custom Integrated Circuits Conference (CICC)},
month = {sep},
pages = {1--4},
publisher = {Ieee},
title = {{A digital neurosynaptic core using embedded crossbar memory with 45pJ per spike in 45nm}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6055294},
year = {2011}
}
@inproceedings{Rangan2012,
author = {Kamilov, Ulugbek and Rangan, Sundeep and Fletcher, Alyson K and Unser, Michael},
booktitle = {NIPS},
pages = {2447--2455},
title = {{Approximate Message Passing with Consistent Parameter Estimation and Applications to Sparse Learning}},
year = {2012}
}
@article{SV82,
author = {Shepp, L and Vardi, Y},
journal = {IEEE Trans. Medical Imaging},
pages = {113--122},
title = {{Maximum Likelihood Reconstruction in Positron Emission Tomography}},
volume = {1},
year = {1982}
}
@inproceedings{Chabi2011,
address = {San Diego, CA},
author = {Chabi, Djaafar and Zhao, Weisheng},
booktitle = {Nanoscale Architectures (NANOARCH), 2011 IEEE/ACM International Symposium on. IEEE},
doi = {10.1109/NANOARCH.2011.5941495},
isbn = {978-1-4577-0993-7},
keywords = {-component,1,as illustrated in fig,compute complex functions,defect and variation tolerance,ftna,in order to,inputs,learning,memristors,neural array,neural network,on-chip,supervised learning,the nlbs contain several},
month = {jun},
pages = {137--143},
publisher = {Ieee},
title = {{Robust neural logic block (NLB) based on memristor crossbar array}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5941495 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5941495},
year = {2011}
}
@article{LWM97,
author = {Liang, J and Williams, D and Miller, D},
journal = {J. Opt. Soc. Am. A},
pages = {2884--2892},
title = {{Supernormal vision and high-resolution retinal imaging through adaptive optics}},
volume = {14},
year = {1997}
}
@article{Alexander1990,
author = {Aldrich, RW and Doedel, E.J. and Othmer, H.G.},
issn = {0036-1399},
journal = {SIAM Journal on Applied Mathematics},
keywords = {chaotic,excitable system,fitzhugh-nagumo equation,quasi-periodic,resonance,rotation number,spiking},
number = {5},
pages = {1373--1418},
publisher = {JSTOR},
title = {{On the resonance structure in a forced excitable system}},
url = {http://www.jstor.org/stable/2101952},
volume = {50},
year = {1990}
}
@article{Goncalves2005,
author = {Goncalves, J.M.},
issn = {0018-9286},
journal = {Automatic Control, IEEE Transactions on},
number = {11},
pages = {1877--1882},
publisher = {IEEE},
title = {{Regions of stability for limit cycle oscillations in piecewise linear systems}},
url = {http://ieeexplore.ieee.org/iel5/9/32688/01532425.pdf?arnumber=1532425},
volume = {50},
year = {2005}
}
@article{Amit2012,
abstract = {We describe an attractor network of binary perceptrons receiving inputs from a retinotopic visual feature layer. Each class is represented by a random subpopulation of the attractor layer, which is turned on in a supervised manner during learning of the feed forward connections. These are discrete three state synapses and are updated based on a simple field dependent Hebbian rule. For testing, the attractor layer is initialized by the feedforward inputs and then undergoes asynchronous random updating until convergence to a stable state. Classification is indicated by the sub-population that is persistently activated. The contribution of this paper is two-fold. This is the first example of competitive classification rates of real data being achieved through recurrent dynamics in the attractor layer, which is only stable if recurrent inhibition is introduced. Second, we demonstrate that employing three state synapses with feedforward inhibition is essential for achieving the competitive classification rates due to the ability to effectively employ both positive and negative informative features.},
author = {Amit, Yali and Walker, Jacob},
doi = {10.3389/fncom.2012.00039},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {attractor networks,attractor networks, feedforward inhibition, random,feedforward inhibition,randomized classifiers},
month = {jan},
number = {June},
pages = {39},
pmid = {22737121},
title = {{Recurrent network of perceptrons with three state synapses achieves competitive classification on real inputs.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3381280{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2012}
}
@article{Sanger07,
abstract = {Surface electromyography is used in research, to estimate the activity

of muscle, in prosthetic design, to provide a control signal, and

in biofeedback, to provide subjects with a visual or auditory indication

of muscle contraction. Unfortunately, successful applications are

limited by the variability in the signal and the consequent poor

quality of estimates. I propose to use a nonlinear recursive filter

based on Bayesian estimation. The desired filtered signal is modeled

as a combined diffusion and jump process and the measured electromyographic

(EMG) signal is modeled as a random process with a density in the

exponential family and rate given by the desired signal. The rate

is estimated on-line by calculating the full conditional density

given all past measurements from a single electrode. The Bayesian

estimate gives the filtered signal that best describes the observed

EMG signal. This estimate yields results with very low short-time

variability but also with the capability of very rapid response to

change. The estimate approximates isometric joint torque with lower

error and higher signal-to-noise ratio than current linear methods.

Use of the nonlinear filter significantly reduces noise compared

with current algorithms, and it may therefore permit more effective

use of the EMG signal for prosthetic control, biofeedback, and neurophysiology

research.},
author = {Sanger, Terence D},
doi = {10.1152/jn.00936.2006},
journal = {J Neurophysiol},
keywords = {Adult; Algorithms; Bayes Theorem; Data Interpretat,Skeletal; Online Systems,Statistical; Electromyography; Female; Humans; Is,Statistical; Muscle Fibers; Muscle},
month = {feb},
number = {2},
pages = {1839--1845},
pmid = {17182908},
title = {{Bayesian filtering of myoelectric signals.}},
url = {http://dx.doi.org/10.1152/jn.00936.2006},
volume = {97},
year = {2007}
}
@article{ZGMS98,
author = {Zhang, K and Ginzburg, I and McNaughton, B and Sejnowski, T},
journal = {Journal of Neurophysiology},
pages = {1017--1044},
title = {{Interpreting neuronal population activity by reconstruction: Unified framework with application to hippocampal place cells}},
volume = {79},
year = {1998}
}
@article{ZhangOertel93b,
author = {Zhang, S and Oertel, D},
journal = {Journal of Neurophysiology},
month = {may},
number = {5},
pages = {1398--1408},
title = {{Giant cells of the dorsal cochlear nucleus of mice: intracellular recordings in slices}},
volume = {69},
year = {1993}
}
@article{Nelson2008,
abstract = {The remarkable versatility of the mammalian brain is made possible by a huge diversity of cellular plasticity mechanisms. These include long-term potentiation and depression at both excitatory and inhibitory synapses, as well as a variety of intrinsic and homeostatic plasticity mechanisms. A fundamental challenge for the field is to assemble our detailed knowledge of these specific mechanisms into a coherent picture of how plasticity within cortical circuits works to tune network properties.},
annote = {2008num20},
author = {Nelson, Sacha B and Turrigiano, Gina G},
doi = {10.1016/j.neuron.2008.10.020},
issn = {1097-4199},
journal = {Neuron},
keywords = {Animals,Behavior,Behavior: physiology,Cerebral Cortex,Cerebral Cortex: anatomy {\&} histology,Cerebral Cortex: physiology,Hippocampus,Hippocampus: anatomy {\&} histology,Hippocampus: physiology,Homeostasis,Homeostasis: physiology,Long-Term Potentiation,Long-Term Potentiation: physiology,Long-Term Synaptic Depression,Long-Term Synaptic Depression: physiology,Nerve Net,Nerve Net: anatomy {\&} histology,Nerve Net: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {nov},
number = {3},
pages = {477--82},
pmid = {18995822},
publisher = {Elsevier Inc.},
title = {{Strength through diversity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18995822 http://dx.doi.org/10.1016/j.neuron.2008.10.020},
volume = {60},
year = {2008}
}
@article{Fischer2011,
author = {Fischer, Martin and Janssen, Audrey G H and Fahlke, Christoph},
pages = {327--341},
title = {{COUNTING CHANNELS : A TUTORIAL GUIDE ON ION CHANNEL}},
year = {2011}
}
@article{AZD05,
author = {Arabzadeh, E and Zorzin, E and Diamond, M},
journal = {PLOS Biology},
pages = {e17},
title = {{Neuronal Encoding of Texture in the Whisker Sensory Pathway}},
volume = {3},
year = {2005}
}
@article{Quinn2010,
abstract = {Advances in recording technologies have given neuroscience researchers access to large amounts of data, in particular, simultaneous, individual recordings of large groups of neurons in different parts of the brain. A variety of quantitative techniques have been utilized to analyze the spiking activities of the neurons to elucidate the functional connectivity of the recorded neurons. In the past, researchers have used correlative measures. More recently, to better capture the dynamic, complex relationships present in the data, neuroscientists have employed causal measures-most of which are variants of Granger causality-with limited success. This paper motivates the directed information, an information and control theoretic concept, as a modality-independent embodiment of Granger's original notion of causality. Key properties include: (a) it is nonzero if and only if one process causally influences another, and (b) its specific value can be interpreted as the strength of a causal relationship. We next describe how the causally conditioned directed information between two processes given knowledge of others provides a network version of causality: it is nonzero if and only if, in the presence of the present and past of other processes, one process causally influences another. This notion is shown to be able to differentiate between true direct causal influences, common inputs, and cascade effects in more two processes. We next describe a procedure to estimate the directed information on neural spike trains using point process generalized linear models, maximum likelihood estimation and information-theoretic model order selection. We demonstrate that on a simulated network of neurons, it (a) correctly identifies all pairwise causal relationships and (b) correctly identifies network causal relationships. This procedure is then used to analyze ensemble spike train recordings in primary motor cortex of an awake monkey while performing target reaching tasks, uncovering causal relationships whose directionality are consistent with predictions made from the wave propagation of simultaneously recorded local field potentials.},
annote = {2010IIInum64},
author = {Quinn, Christopher J and Coleman, Todd P and Kiyavash, Negar and Hatsopoulos, Nicholas G},
doi = {10.1007/s10827-010-0247-2},
issn = {1573-6873},
journal = {Journal of Computational Neuroscience},
keywords = {causality,functional connectivity,mutual information,point processes},
month = {jun},
pmid = {20582566},
title = {{Estimating the directed information to infer causal relationships in ensemble neural spike train recordings.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20582566},
year = {2010}
}
@article{HJ05,
author = {Howard, A and Jebara, T},
journal = {Columbia University Computer Science Technical Reports},
title = {{Square root propagation}},
volume = {040-05},
year = {2005}
}
@article{SpirouRyugo93,
author = {Spirou, G A and May, B J and Wright, D D and Ryugo, D K},
journal = {Journal of Comparative Neurology},
month = {mar},
number = {1},
pages = {36--52},
title = {{Frequency organization of the dorsal cochlear nucleus in cats}},
volume = {329},
year = {1993}
}
@article{UTIK97,
author = {Utikal, K},
journal = {Biological Cyberkinetics},
pages = {459--470},
title = {{A new method for detecting neural interconnectivity}},
volume = {76},
year = {1997}
}
@article{Wiener1950,
annote = {2008num37},
author = {Wiener, N},
journal = {Bulletin of the American Academy of Arts and Sciences},
title = {{Cybernetics}},
url = {http://www.jstor.org/stable/3822945},
year = {1950}
}
@article{Gilson2011,
abstract = {Spike-timing-dependent plasticity (STDP) modifies the weight (or strength) of synaptic connections between neurons and is considered to be crucial for generating network structure. It has been observed in physiology that, in addition to spike timing, the weight update also depends on the current value of the weight. The functional implications of this feature are still largely unclear. Additive STDP gives rise to strong competition among synapses, but due to the absence of weight dependence, it requires hard boundaries to secure the stability of weight dynamics. Multiplicative STDP with linear weight dependence for depression ensures stability, but it lacks sufficiently strong competition required to obtain a clear synaptic specialization. A solution to this stability-versus-function dilemma can be found with an intermediate parametrization between additive and multiplicative STDP. Here we propose a novel solution to the dilemma, named log-STDP, whose key feature is a sublinear weight dependence for depression. Due to its specific weight dependence, this new model can produce significantly broad weight distributions with no hard upper bound, similar to those recently observed in experiments. Log-STDP induces graded competition between synapses, such that synapses receiving stronger input correlations are pushed further in the tail of (very) large weights. Strong weights are functionally important to enhance the neuronal response to synchronous spike volleys. Depending on the input configuration, multiple groups of correlated synaptic inputs exhibit either winner-share-all or winner-take-all behavior. When the configuration of input correlations changes, individual synapses quickly and robustly readapt to represent the new configuration. We also demonstrate the advantages of log-STDP for generating a stable structure of strong weights in a recurrently connected network. These properties of log-STDP are compared with those of previous models. Through long-tail weight distributions, log-STDP achieves both stable dynamics for and robust competition of synapses, which are crucial for spike-based information processing.},
author = {Gilson, Matthieu and Fukai, T},
doi = {10.1371/journal.pone.0025339},
issn = {1932-6203},
journal = {PloS one},
keywords = {Models, Neurological,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: cytology,Synapses,Synapses: physiology,Time Factors},
month = {jan},
number = {10},
pages = {e25339},
pmid = {22003389},
title = {{Stability versus neuronal specialization for STDP: long-tail weight distributions solve the dilemma.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3189213{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2011}
}
@article{Koyama2009,
abstract = {A number of important data analysis problems in neuroscience can be solved using state-space models. In this article, we describe fast methods for computing the exact maximum a posteriori (MAP) path of the hidden state variable in these models, given spike train observations. If the state transition density is log-concave and the observation model satisfies certain standard assumptions, then the optimization problem is strictly concave and can be solved rapidly with Newton-Raphson methods, because the Hessian of the loglikelihood is block tridiagonal. We can further exploit this block-tridiagonal structure to develop efficient parameter estimation methods for these models. We describe applications of this approach to neural decoding problems, with a focus on the classic integrate-and-fire model as a key example.},
author = {Koyama, Shinsuke and Paninski, L},
doi = {10.1007/s10827-009-0150-x},
issn = {1573-6873},
journal = {Journal of Computational Neuroscience},
keywords = {laplace approximation,raphson method,state-space models,tridiagonal newton},
month = {apr},
pages = {1--17},
pmid = {19399603},
publisher = {Springer},
title = {{Efficient computation of the maximum a posteriori path and parameter estimation in integrate-and-fire and more general state-space models}},
url = {http://www.springerlink.com/index/64HU3666177KJ6U4.pdf},
volume = {29},
year = {2009}
}
@article{Stoyan1994,
annote = {2010num2.6},
author = {Stoyan, D.},
journal = {Statistics},
number = {3},
pages = {267--270},
publisher = {Taylor $\backslash${\&} Francis},
title = {{Caution with fractal point patterns}},
url = {http://www.informaworld.com/index/780007130.pdf},
volume = {25},
year = {1994}
}
@book{Brookes2005,
author = {Brookes, M},
booktitle = {Imperial College, London, http://www. ee. ic. ac. uk/hp/staff/dmb/matrix/calculus. html},
title = {{The matrix reference manual}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:The+Matrix+Reference+Manual{\#}0},
year = {2005}
}
@article{Gonon2011,
annote = {2011num11},
author = {Gonon, F},
journal = {PloS one},
title = {{Misrepresentation of Neuroscience Data Might Give Rise to Misleading Conclusions in the Media: The Case of Attention Deficit Hyperactivity Disorder}},
url = {http://dx.plos.org/10.1371/journal.pone.0014618},
year = {2011}
}
@article{Stoisiek1976,
abstract = {The fluctuations of the variance of stationary Gaussian random noise withan imposed 1/f power spectrum is treated theoretically, and experimentsunder well-defined conditions of 1/f noise in carbon resistors and bipolar transistors are reported. The close agreement between theoretical and experimental results demonstrates that the statistical properties of 1/f noisein physical sources are fully consistent with the assumption ofstationarity. Journal of Applied Physics is copyrighted by The American Institute of Physics.},
author = {Stoisiek, M. and Wolf, D.},
journal = {Journal of Applied Physics},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {jan},
number = {1},
pages = {362--364},
publisher = {AIP},
shorttitle = {J. Appl. Phys.},
title = {{Recent investigations on the stationarity of 1/f noise}},
url = {http://link.aip.org/link/?JAP/47/362/1 http://link.aip.org/link/?JAPIAU/47/362/1},
volume = {47},
year = {1976}
}
@article{Sussillo2009a,
author = {Sussillo, D and Abbott, L F},
doi = {10.1016/j.neuron.2009.07.018},
issn = {0896-6273},
journal = {Neuron},
number = {4},
pages = {544--557},
publisher = {Elsevier Ltd},
title = {{Generating coherent patterns of activity from chaotic neural networks}},
url = {http://dx.doi.org/10.1016/j.neuron.2009.07.018 http://www.sciencedirect.com/science/article/pii/S0896627309005479},
volume = {63},
year = {2009}
}
@article{GrynkiewiczTsien85,
author = {Grynkiewicz, G and Poenie, M and Tsien, R Y},
journal = {Journal of Biological Chemistry},
number = {6},
pages = {3440--3450},
publisher = {ASBMB},
title = {{A new generation of Ca2+ indicators with greatly improved fluorescence properties}},
volume = {260},
year = {1985}
}
@article{Thorpe2001,
author = {Rullen, RV V and Thorpe, SJ J},
journal = {Neural Computation},
keywords = {Spike time neural coding},
mendeley-tags = {Spike time neural coding},
pages = {1255--1283},
title = {{Rate coding versus temporal order coding: what the retinal ganglion cells tell the visual cortex}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/08997660152002852},
volume = {1283},
year = {2001}
}
@inproceedings{collins00logistic,
author = {Collins, Michael and Schapire, Robert E and Singer, Y},
booktitle = {Computational Learing Theory},
pages = {158--169},
title = {{Logistic Regression, {\{}A{\}}daBoost and {\{}B{\}}regman Distances}},
url = {citeseer.ist.psu.edu/article/collins00logistic.html},
year = {2000}
}
@article{Omondi2000,
author = {Omondi, Amos R},
journal = {International journal of neural systems},
number = {6},
pages = {475--481},
title = {{Neurocomputers: a dead end?}},
volume = {10},
year = {2000}
}
@article{SlotkinHaydar07,
abstract = {Fluorescent semiconductor nanocrystal quantum dots (QDs) are a class

of multifunctional inorganic fluorophores that hold great promise

for clinical applications and biomedical research. Because no methods

currently exist for directed QD-labeling of mammalian cells in the

nervous system in vivo, we developed novel in utero electroporation

and ultrasound-guided in vivo delivery techniques to efficiently

and directly label neural stem and progenitor cells (NSPCs) of the

developing mammalian central nervous system with QDs. Our initial

safety and proof of concept studies of one and two-cell QD-labeled

mouse embryos reveal that QDs are compatible with early mammalian

embryonic development. Our in vivo experiments further show that

in utero labeled NSPCs continue to develop in an apparent normal

manner. These studies reveal that QDs can be effectively used to

label mammalian NSPCs in vivo and will be useful for studies of in

vivo fate mapping, cellular migration, and NSPC differentiation during

mammalian development. Developmental Dynamics, 2007. (c) 2007 Wiley-Liss,

Inc.},
author = {Slotkin, Jonathan R and Chakrabarti, Lina and Dai, Hai Ning and Carney, Rosalind S E and Hirata, Tsutomu and Bregman, Barbara S and Gallicano, G Ian and Corbin, Joshua G and Haydar, Tarik F},
doi = {10.1002/dvdy.21235},
journal = {Dev Dyn},
month = {jul},
pmid = {17626285},
title = {{In vivo quantum dot labeling of mammalian stem and progenitor cells.}},
url = {http://dx.doi.org/10.1002/dvdy.21235},
year = {2007}
}
@article{SHERM01,
author = {Sherman, S},
journal = {Trends in Neuroscience},
pages = {122--126},
title = {{Tonic and burst firing: Dual modes of thalamocortical relay}},
volume = {24},
year = {2001}
}
@article{Rubensson2000,
author = {Rubensson, M. and Lennartson, B.},
doi = {10.1109/CDC.2000.912053},
isbn = {0-7803-6638-7},
journal = {Proceedings of the 39th IEEE Conference on Decision and Control (Cat. No.00CH37187)},
keywords = {discrete time,hybrid systems,limit cycles,linear matrix inequalities,lya-,punov,stability},
number = {2},
pages = {1397--1402},
publisher = {Ieee},
title = {{Stability of limit cycles in hybrid systems using discrete-time Lyapunov techniques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=912053},
year = {2000}
}
@article{Pologruto2003,
abstract = {BACKGROUND: Laser scanning microscopy is a powerful tool for analyzing

the structure and function of biological specimens. Although numerous

commercial laser scanning microscopes exist, some of the more interesting

and challenging applications demand custom design. A major impediment

to custom design is the difficulty of building custom data acquisition

hardware and writing the complex software required to run the laser

scanning microscope. RESULTS: We describe a simple, software-based

approach to operating a laser scanning microscope without the need

for custom data acquisition hardware. Data acquisition and control

of laser scanning are achieved through standard data acquisition

boards. The entire burden of signal integration and image processing

is placed on the CPU of the computer. We quantitate the effectiveness

of our data acquisition and signal conditioning algorithm under a

variety of conditions. We implement our approach in an open source

software package (ScanImage) and describe its functionality. CONCLUSIONS:

We present ScanImage, software to run a flexible laser scanning microscope

that allows easy custom design.},
author = {Pologruto, Thomas A and Sabatini, Bernardo L and Svoboda, Karel},
doi = {10.1186/1475-925X-2-13},
journal = {Biomed Eng Online},
keywords = {Computer-Assisted; Software; Software Design; Use,Confocal; Signal Processing,Equipment Design; Image Enhancement; Microscopy},
month = {may},
pages = {13},
pmid = {12801419},
title = {{ScanImage: flexible software for operating laser scanning microscopes.}},
url = {http://dx.doi.org/10.1186/1475-925X-2-13},
volume = {2},
year = {2003}
}
@book{Collins2004,
abstract = {We consider observability for a class of piecewise-affine hybrid systems without inputs. The aim is to give verifiable conditions for observability in terms of linear equations and inequalities. We first discuss a number of important concepts, such as discrete-event detectability and trajectory observability. We give sufficient conditions for observability, observability in infinitesimal time, and observability after a single discrete event. The former conditions are used to construct an observer for the system, the latter are applied to deduce observability for an example system.},
address = {Berlin, Heidelberg},
author = {Collins, Pieter and van Schuppen, Jan and Alur, Rajeev and Pappas, George},
doi = {10.1007/b96398},
editor = {Alur, Rajeev and Pappas, George J.},
isbn = {978-3-540-21259-1},
keywords = {Computer Science},
pages = {265--279},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Hybrid Systems: Computation and Control}},
url = {http://www.springerlink.com/content/81x60f24bghnwulp/},
volume = {2993},
year = {2004}
}
@article{BD04,
author = {Braess, D and Dette, H},
journal = {Sankhya},
pages = {707--732},
title = {{The asymptotic minimax risk for the estimation of constrained binomial and multinomial probabilities}},
volume = {66},
year = {2004}
}
@article{Sanger94,
author = {Sanger, T},
journal = {Neural Computation},
pages = {12--21},
title = {{Theoretical considerations for the analysis of population coding in motor cortex}},
volume = {6},
year = {1994}
}
@article{Blum1992,
author = {Blum, AL and Rivest, RL},
journal = {Neural Networks},
number = {1},
title = {{Training a 3-node neural network is NP-complete}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608005800103},
volume = {5},
year = {1992}
}
@inproceedings{Poole2016,
abstract = {We combine Riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic, deep neural networks with random weights. Our results reveal an order-to-chaos expressivity phase transition, with networks in the chaotic phase computing nonlinear functions whose global curvature grows exponentially with depth but not width. We prove this generic class of deep random functions cannot be efficiently computed by any shallow network, going beyond prior work restricted to the analysis of single functions. Moreover, we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space. Our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities, and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions.},
archivePrefix = {arXiv},
arxivId = {1606.05340},
author = {Poole, Ben and Lahiri, Subhaneil and Raghu, Maithra and Sohl-Dickstein, Jascha and Ganguli, Surya},
booktitle = {NIPS},
eprint = {1606.05340},
title = {{Exponential expressivity in deep neural networks through transient chaos}},
url = {http://arxiv.org/pdf/1606.05340v2.pdf},
year = {2016}
}
@article{NguyenParker01,
abstract = {We describe the construction of a video-rate two-photon laser scanning

microscope, compare its performance to a similar confocal microscope,

and illustrate its use for imaging local {\{}Ca{\}}{\^{}}{\{}2+{\}} transients from

cortical neurons in brain slices. Key features include the use of

a Ti-sapphire femtosecond laser allowing continuous tuning over a

wide (700-1000 nm) wavelength range, a resonant scanning mirror to

permit frame acquisition at 30 Hz, and efficient wide-field fluorescence

detection. Two-photon imaging provides compelling advantages over

confocal microscopy in terms of improved imaging depth and reduced

phototoxicity and photobleaching, but the high cost of commercial

instruments has limited their widespread adoption. By constructing

one's own system the expense is greatly reduced without sacrifice

of performance, and the microscope can be more readily tailored to

specific applications.},
author = {Nguyen, Q T and Callamaras, N and Hsieh, C and Parker, I},
doi = {10.1054/ceca.2001.0246},
journal = {Cell Calcium},
keywords = {Animals; Calcium; Calcium Signaling; Cerebral Cort,Confocal; Neurons; Photons; Pollen; Spine},
month = {dec},
number = {6},
pages = {383--393},
pmid = {11728133},
title = {{Construction of a two-photon microscope for video-rate {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging.}},
url = {http://dx.doi.org/10.1054/ceca.2001.0246},
volume = {30},
year = {2001}
}
@book{Khalil1996,
author = {Khalil, H.K. K and Grizzle, JW W},
publisher = {Prentice hall Englewood Cliffs, NJ},
title = {{Nonlinear systems}},
url = {http://www.ingelec.uns.edu.ar/asnl/Materiales/Libros/Khalil/booktext00.pdf},
year = {1996}
}
@misc{Crompton|2006|,
annote = {This presentation deals with phase transition and phase diagram and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}critical properties for nonlinear sigma model basically from lattice{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}measurements.},
author = {Crompton, P and Janke, W and Xu, Z and Ying, H},
keywords = {critical properties,lattice,phase diagram,phase transition,physics,quantum field theory,sigma-model},
title = {{Quantum phase transitions and the nonlinear sigma-model}}
}
@article{Coolen2000,
abstract = {A lecture notes style review of the non-equilibrium statistical mechanics of recurrent neural networks with discrete and continuous neurons (e.g. Ising, graded-response, coupled-oscillators). To be published in the Handbook of Biological Physics (North-Holland). Accompanied by a similar review (part I) dealing with the statics.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0006011},
author = {Coolen, a. C. C.},
eprint = {0006011},
journal = {Neural Networks},
keywords = {Disordered Systems and Neural Networks,Quantitative Biology},
pages = {49},
primaryClass = {cond-mat},
title = {{Statistical Mechanics of Recurrent Neural Networks II. Dynamics}},
url = {http://arxiv.org/abs/cond-mat/0006011},
year = {2000}
}
@article{Jing|2005|,
abstract = {In this paper, a novel method is presented for unsupervised image
segmentation based on local homogeneity analysis. First, a criterion
for homogeneity of a certain pattern is proposed. Applying the criterion
to local windows in the original image results in the {\"{i}}¾“H-image{\"{i}}¾”.
The high and low values of the H-image correspond to possible region
boundaries and region interiors respectively. Then, a region growing
method is used to segment the image based on the H-image. Finally,
visually similar regions are merged together to avoid over-segmentation.
Experimental results on real images show the effectiveness and robustness
of the method.},
annote = {In the paper a method for segmentation based on local homogeneity{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of the image is proposed. Homogeneity is determined as H-image built{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}from "vector-average-of-intensities-around-given-point", which may{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}be seen as a "smoothed" generalization of gradient . Homogeneity{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}is low at the edges (H is high) and is high in spatially uniform{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}areas (H is low) where all vectors in sum cancel out. Region growing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}is employed for post-processing to reduce oversegmentation. The performence{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of method is in essense similar to regular gradient-magnitude segmentations.},
author = {Jing, F and Li, M and Zhang, H.-J. and Zhang, B},
keywords = {computational,homogeneity,image processing,segmentation,unsupervised},
title = {{Unsupervised image segmentation using local homogeneity analysis}}
}
@article{SMETT99,
author = {Smetters, D and Majewska, A and Yuste, R},
journal = {Methods},
pages = {215--221},
title = {{Detecting Action Potentials in Neuronal Populations with Calcium Imaging}},
volume = {18},
year = {1999}
}
@article{Hinton2002,
abstract = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual "expert" models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called "contrastive divergence" whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
author = {Hinton, G E},
doi = {10.1162/089976602760128018},
issn = {0899-7667},
journal = {Neural computation},
month = {aug},
number = {8},
pages = {1771--800},
pmid = {12180402},
title = {{Training products of experts by minimizing contrastive divergence.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12180402},
volume = {14},
year = {2002}
}
@article{Bender|2001|,
abstract = {It has recently been shown that, when properly defined, a 2gx4 potential
in quantum mechanics possesses a positive definite spectrum. The
positivity of the spectrum is apparently due to the PT symmetry of
the Hamiltonian. Furthermore, for such a theory the expectation value
{\^{}}x{\&} is not zero. This paper extends these results to a 2gf4 quantum
field theory in D-dimensional Euclidean space. The value of the one-point
Green{\"{i}}¾'s function G15{\^{}}f{\&} in this field theory is calculated in the
weak-coupling and strong-coupling regimes. Nonperturbative techniques
must be used in both of these regimes. For small g, the value of
G1 is dominated by a classical soliton. Strong-coupling graphical
methods are used to calculate G1 for large g.},
annote = {The paper is concerned with computation of green{\&}{\#}039;s function in convex{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}(unstable) field theory and derivation of some identities on it.},
author = {Bender, C M and Meisinger, P N and Yang, H},
journal = {Physical Review D},
keywords = {green's function,phi-4,physics,quantum field theory},
pages = {45001},
title = {{Calculation of the one-point Green's function for a -g$\phi${\^{}}4 quantum field theory}},
volume = {63}
}
@article{Izaguirre04,
address = {San Diego, CA, USA},
author = {Izaguirre, Jes{\'{u}}s A and Hampton, Scott S},
doi = {http://dx.doi.org/10.1016/j.jcp.2004.04.016},
issn = {0021-9991},
journal = {J. Comput. Phys.},
number = {2},
pages = {581--604},
publisher = {Academic Press Professional, Inc.},
title = {{Shadow hybrid {\{}Monte Carlo{\}}: an efficient propagator in phase space of macromolecules}},
volume = {200},
year = {2004}
}
@article{Lyon82,
author = {Lyon, R},
journal = {IEEE Acoustics, Speech, and Sig Proc},
month = {may},
pages = {1282--1285},
title = {{A Computational Model of Filtering, Detection, and Compression in the cochlea}},
volume = {7},
year = {1982}
}
@article{Johnson2011,
abstract = {Confidence is an essential ingredient of success in a wide range of domains ranging from job performance and mental health to sports, business and combat. Some authors have suggested that not just confidence but overconfidence--believing you are better than you are in reality--is advantageous because it serves to increase ambition, morale, resolve, persistence or the credibility of bluffing, generating a self-fulfilling prophecy in which exaggerated confidence actually increases the probability of success. However, overconfidence also leads to faulty assessments, unrealistic expectations and hazardous decisions, so it remains a puzzle how such a false belief could evolve or remain stable in a population of competing strategies that include accurate, unbiased beliefs. Here we present an evolutionary model showing that, counterintuitively, overconfidence maximizes individual fitness and populations tend to become overconfident, as long as benefits from contested resources are sufficiently large compared with the cost of competition. In contrast, unbiased strategies are only stable under limited conditions. The fact that overconfident populations are evolutionarily stable in a wide range of environments may help to explain why overconfidence remains prevalent today, even if it contributes to hubris, market bubbles, financial collapses, policy failures, disasters and costly wars.},
author = {Johnson, Dominic D. P. and Fowler, James H.},
doi = {10.1038/nature10384},
issn = {0028-0836},
journal = {Nature},
keywords = {Animals,Assertiveness,Biological Evolution,Character,Competitive Behavior,Conflict (Psychology),Decision Making,Game Theory,Genetic,Genetic Fitness,Humans,Illusions,Personality,Risk,Selection,Self-Assessment},
month = {sep},
number = {7364},
pages = {317--320},
pmid = {21921915},
publisher = {Nature Publishing Group},
title = {{The evolution of overconfidence}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21921915 http://www.nature.com/doifinder/10.1038/nature10384},
volume = {477},
year = {2011}
}
@article{Ikegaya2012,
abstract = {Cortical synaptic strengths vary substantially from synapse to synapse and exhibit a skewed distribution with a small fraction of synapses generating extremely large depolarizations. Using multiple whole-cell recordings from rat hippocampal CA3 pyramidal cells, we found that the amplitude of unitary excitatory postsynaptic conductances approximates a lognormal distribution and that in the presence of synaptic background noise, the strongest fraction of synapses could trigger action potentials in postsynaptic neurons even with single presynaptic action potentials, a phenomenon termed interpyramid spike transmission (IpST). The IpST probability reached 80{\%}, depending on the network state. To examine how IpST impacts network dynamics, we simulated a recurrent neural network embedded with a few potent synapses. This network, unlike many classical neural networks, exhibited distinctive behaviors resembling cortical network activity in vivo. These behaviors included the following: 1) infrequent ongoing activity, 2) firing rates of individual neurons approximating a lognormal distribution, 3) asynchronous spikes among neurons, 4) net balance between excitation and inhibition, 5) network activity patterns that was robust against external perturbation, 6) responsiveness even to a single spike of a single excitatory neuron, and 7) precise firing sequences. Thus, IpST captures a surprising number of recent experimental findings in vivo. We propose that an unequally biased distribution with a few select strong synapses helps stabilize sparse neuronal activity, thereby reducing the total spiking cost, enhancing the circuit responsiveness, and ensuring reliable information transfer.},
author = {Ikegaya, Y and Sasaki, T and Ishikawa, D and Honma, N and Tao, K and Takahashi, N and Minamisawa, G and Ujita, S and Matsuki, N},
doi = {10.1093/cercor/bhs006},
journal = {Cerebral Cortex},
month = {feb},
number = {2},
pages = {293--304},
title = {{Interpyramid spike transmission stabilizes the sparseness of recurrent network activity}},
url = {http://cercor.oxfordjournals.org/content/early/2012/02/07/cercor.bhs006.short http://cercor.oxfordjournals.org/content/early/2012/02/07/cercor.bhs006.abstract},
volume = {23},
year = {2012}
}
@article{Chiu1979,
author = {Chiu, S Y and Ritchie, J M and Rogart, R B and Stagg, D},
journal = {The Journal of Physiology,},
pages = {149--166},
title = {{A quantitative description of membrane currents in rabbit myelinated nerve.}},
volume = {292},
year = {1979}
}
@article{Donoho2000,
author = {Donoho, DL},
journal = {AMS Math Challenges Lecture},
pages = {1--33},
title = {{High-Dimensional Data Analysis: The Curses and Blessings of Dimensionality}},
url = {http://mlo.cs.man.ac.uk/resources/Curses.pdf},
year = {2000}
}
@article{ZA88,
author = {Zipser, D and Andersen, R},
journal = {Nature},
pages = {679--684},
title = {{A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons}},
volume = {331},
year = {1988}
}
@article{Moll2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1602.07364v1},
author = {Mollen, Christopher and Choi, Junil and Larsson, Erik G and Heath, Robert W},
doi = {10.1109/TWC.2016.2619343},
eprint = {arXiv:1602.07364v1},
isbn = {9783800741779},
issn = {1536-1276},
number = {c},
pages = {1--14},
title = {{Uplink Performance of Wideband Massive MIMO with One-Bit ADCs}},
volume = {1276},
year = {2016}
}
@article{GG84,
author = {Geman, S and Geman, D},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
pages = {721--741},
title = {{Stochastic relaxation, {\{}G{\}}ibbs distribution, and the {\{}B{\}}ayesian restoration of images}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4767596},
volume = {6},
year = {1984}
}
@article{Slutsky1925,
author = {Slutsky, E},
title = {{{\"{U}}ber stochastische asymptoten und grenzwerte}},
url = {http://scholar.google.com/scholar?hl=en{\&}q=Slutsky{\%}2C+E.+1925{\&}btnG={\&}as{\_}sdt=1{\%}2C33{\&}as{\_}sdtp={\#}0},
year = {1925}
}
@article{Mandelbrot1967a,
abstract = {{Noises in thin metallic fills, semiconductors, nerve tissues, and many other media, have measured spectral densities proportional tof{\^{}}theta - 2{\}}withfthe frequency andthetaa constant0 leq theta {\textless} 2. The energy of these "f{\^{}}{\{}theta-2{\}}noises" behaves more "erratically" in time, than expected from functions subject to the Wiener-Khinchin spectral theory. Moreover, blind extrapolation of the "f{\^{}}{\{}theta -2{\}}law" tof=0incorrectly suggests, when0 leq 1, that the total energy is infinite ("infrared catastrophe"). The problems thus raised are of the greatest theoretical interest, and of the greatest practical importance in the design of electronic devices. The present paper reinterprets these spectral measurements without paradox, by introducing a concept to be called "conditional spectrum." Examples are given of functions ruled by chance, that have the observed "erratic" behavior and conditional spectral density. A conditional spectrum is obtained when a procedure, meant to measure a sample Wiener-Khinchin spectrum, is applied to a sample conditioned to be nonconstant. The conditional spectrum is defined, not only for nonconstant samples from all random functions of the Wiener-Khinchin theory, but also for nonconstant samples from certain nonstationary random functions, and for nonconstant samples from a new generalization of random functions, called "sporadic functions." The simplest sporadic functions, having af{\^{}}{\{}-2{\}}conditional spectral density, is a "direct current" with a single discontinuity uniformly distributed over- infty {\textless} t {\textless} infty. The otherf{\^{}}{\{}theta -2{\}}noises to be described partake both of direct current and of white noise (thetheta =2limit off{\^{}}{\{}theta - 2{\}}noise), and continuously span the gap between these limits. In many cases, their noise energy can be said to be proportional to the square of their "dc" componen- - t. Empirical studies will be suggested, and the descriptive value of the concepts of dc component and of spectrum will be discussed.},
author = {Mandelbrot, B. and Xpectra, A Measured},
doi = {10.1109/TIT.1967.1053992},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {apr},
number = {2},
pages = {289--298},
title = {{Some noises with 1/f spectrum, a bridge between direct current and white noise}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1053992},
volume = {13},
year = {1967}
}
@inproceedings{Lee2009,
author = {Lee, H and Grosse, R and Ranganath, R and Ng, A Y},
booktitle = {ICML '09},
doi = {10.1145/1553374.1553453},
isbn = {9781605585161},
keywords = {Deep Learning},
mendeley-tags = {Deep Learning},
pages = {1--8},
title = {{Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553453},
year = {2009}
}
@article{Song2005,
abstract = {How different is local cortical circuitry from a random network? To answer this question, we probed synaptic connections with several hundred simultaneous quadruple whole-cell recordings from layer 5 pyramidal neurons in the rat visual cortex. Analysis of this dataset revealed several nonrandom features in synaptic connectivity. We confirmed previous reports that bidirectional connections are more common than expected in a random network. We found that several highly clustered three-neuron connectivity patterns are overrepresented, suggesting that connections tend to cluster together. We also analyzed synaptic connection strength as defined by the peak excitatory postsynaptic potential amplitude. We found that the distribution of synaptic connection strength differs significantly from the Poisson distribution and can be fitted by a lognormal distribution. Such a distribution has a heavier tail and implies that synaptic weight is concentrated among few synaptic connections. In addition, the strengths of synaptic connections sharing pre- or postsynaptic neurons are correlated, implying that strong connections are even more clustered than the weak ones. Therefore, the local cortical network structure can be viewed as a skeleton of stronger connections in a sea of weaker ones. Such a skeleton is likely to play an important role in network dynamics and should be investigated further.},
author = {Song, S and Sj{\"{o}}str{\"{o}}m, P J and Reigl, M and Nelson, S and Chklovskii, D B},
doi = {10.1371/journal.pbio.0030068},
isbn = {1545-7885 (Electronic)$\backslash$r1544-9173 (Linking)},
issn = {15449173},
journal = {PLoS Biology},
keywords = {Animals,Cell Communication,Cell Communication: physiology,Neural Pathways,Neural Pathways: physiology,Neuronal Plasticity,Neurons,Neurons: physiology,Rats,Signal Transduction,Synapses,Synapses: physiology,Visual Cortex,Visual Cortex: physiology},
month = {mar},
number = {3},
pages = {507--519},
pmid = {15737062},
title = {{Highly nonrandom features of synaptic connectivity in local cortical circuits}},
url = {http://dx.plos.org/10.1371/journal.pbio.0030068 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1054880{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2005}
}
@article{Rosenthal2002,
abstract = {To determine which physiological properties contribute to temperature adaptation in the squid giant axon, action potentials were recorded from four species of squid whose habitats span a temperature range of 20 degrees C. The environments of these species can be ranked from coldest to warmest as follows: Loligo opalescens{\textgreater}Loligo pealei{\textgreater}Loligo plei{\textgreater}Sepioteuthis sepioidea. Action potential conduction velocities and rise times, recorded at many temperatures, were equivalent for all Loligo species, but significantly slower in S. sepioidea. By contrast, the action potential's fall time differed among species and correlated well with the thermal environment of the species ('warmer' species had slower decay times). The biophysical underpinnings of these differences were examined in voltage-clamped axons. Surprisingly, no differences were found between the activation kinetics or voltage-dependence of Na(+) and K(+) currents. Conductance levels, however, did vary. Maximum Na(+) conductance (g(Na)) in S. sepiodea was significantly less than in the Loligo species. K(+) conductance (gK) was highest in L. pealei, intermediate in L. plei and smallest in S. sepiodea. The time course and magnitude of g(K) and g(Na) were measured directly during membrane action potentials. These data reveal clear species-dependent differences in the amount of g(K) and g(Na) recruited during an action potential.},
author = {Rosenthal, Joshua J C and Bezanilla, Francisco},
issn = {0022-0949},
journal = {The Journal of experimental biology},
keywords = {Acclimatization,Acclimatization: physiology,Action Potentials,Animals,Axons,Axons: physiology,Climate,Decapodiformes,Decapodiformes: physiology,Ion Transport,Neural Conduction,Patch-Clamp Techniques,Potassium,Potassium: metabolism,Sodium,Sodium: metabolism,Species Specificity,Temperature,Tropical Climate},
month = {jun},
number = {Pt 12},
pages = {1819--30},
pmid = {12042340},
title = {{A comparison of propagated action potentials from tropical and temperate squid axons: different durations and conduction velocities correlate with ionic conductance levels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12042340},
volume = {205},
year = {2002}
}
@article{NakaharaAmari02,
author = {Nakahara, Hiroyuki and Amari, Shun-ichi},
journal = {Neural Computation},
month = {oct},
number = {10},
pages = {2269--2316},
title = {{Information-geometric measure for neural spikes}},
volume = {14},
year = {2002}
}
@article{Whitley94,
author = {Whitley, D},
journal = {Statistics and Computing},
number = {2},
pages = {65--85},
publisher = {Springer},
title = {{A genetic algorithm tutorial}},
volume = {4},
year = {1994}
}
@article{JACOBS06,
author = {Jacobs, A and Grzywacz, N and Nirenberg, S},
journal = {SFN Abstracts},
title = {{Decoding the parallel pathways of the retina}},
year = {2006}
}
@article{Keskar2016,
abstract = {The stochastic gradient descent method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data, usually {\$}32{\$}--{\$}512{\$} data points, is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a significant degradation in the quality of the model, as measured by its ability to generalize. There have been some attempts to investigate the cause for this generalization drop in the large-batch regime, however the precise answer for this phenomenon is, hitherto unknown. In this paper, we present ample numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions -- and that sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. We also discuss several empirical strategies that help large-batch methods eliminate the generalization gap and conclude with a set of future research ideas and open questions.},
archivePrefix = {arXiv},
arxivId = {1609.04836},
author = {Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
doi = {10.1227/01.NEU.0000255452.20602.C9},
eprint = {1609.04836},
isbn = {9781405161251},
journal = {ICLR},
pages = {1--16},
title = {{On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima}},
url = {http://arxiv.org/abs/1609.04836},
year = {2017}
}
@article{donoho95wavelet,
author = {Donoho, D L and Johnstone, I M and Kerkyacharian, G and Picard, D},
journal = {J. R. Statist. Soc. B.},
number = {2},
pages = {301--337},
title = {{Wavelet Shrinkage: Asymptopia?}},
volume = {57},
year = {1995}
}
@article{Vovan07,
author = {Nikolenko, V and Poskanzer, K and Yuste, R},
journal = {Nature Methods},
pages = {943--950},
title = {{Two-photon photostimulation and imaging of neural circuits}},
volume = {4},
year = {2007}
}
@article{BrozoskiBauer05,
author = {Brozoski, Thomas J and Bauer, Carol A},
journal = {Hearing Research},
month = {aug},
number = {1-2},
pages = {227--236},
title = {{The effect of dorsal cochlear nucleus ablation on tinnitus in rats}},
volume = {206},
year = {2005}
}
@article{Strachan2013,
author = {Strachan, JP and Torrezan, AC},
journal = {Electron Devices, IEEE Transactions on},
month = {jul},
number = {7},
pages = {2194--2202},
title = {{State dynamics and modeling of tantalum oxide memristors}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6542012},
volume = {60},
year = {2013}
}
@article{PILL05a,
author = {Pillow, J W and Paninski, L and Uzzell, V and Simoncelli, E and Chichilnisky, E J},
journal = {Journal of Neuroscience},
pages = {11003--11013},
title = {{Prediction and Decoding of Retinal Ganglion Cell Responses with a Probabilistic Spiking Model}},
volume = {25},
year = {2005}
}
@article{Harindranath|1996|,
abstract = {In these lectures we hope to provide an elementary introduction to
selected topics in light-front dynamics. Starting from the study
of free eld theories of scalar boson, fermion, and massless vector
boson, the canonical field commutators and propagators in the instant
and front forms are compared and contrasted. Poincare algebra is
described next where the explicit expressions for the Poincare generators
of free scalar theory in terms of the eld operators and Fock space
operators are also given. Next, to illustrate the idea of Fock space
description of bound states and to analyze some of the simple relativistic
features of bound systems without getting into the wilderness of
light-front renormalization, Quantum Electrodynamics in one space
- one time dimensions is discussed along with the consideration of
anomaly in this model. Lastly, light-front power counting is discussed.
One of the consequences of light-front power counting in the simple
setting of one space - one time dimensions is illustrated using massive
Thirring model. Next, motivation for light-front power counting is
discussed and power assignments for dynamical variables in three
plus one dimensions are given. Simple examples of tree level Hamiltonians
constructed by power counting are provided and nally the idea of
reducing the number of free parameters in the theory by appealing
to symmetries is illustrated using a tree level example in Yukawa
theory.},
annote = {This is an excellent introduction to light-front dynamics in QFT},
author = {Harindranath, A},
journal = {arXiv},
keywords = {kinematics,light front dynamics,perturbation theory,physics,quantization,quantum chromodynamics,renormalization},
pages = {9612244},
title = {{An introduction to light-front dynamics for pedestrians}},
volume = {hep=ph}
}
@article{HanBoyden07,
author = {Han, Xue and Boyden, Edward S},
journal = {PLoS ONE},
pages = {e299},
publisher = {Public Library of Science},
title = {{Multiple-Color Optical Activation, Silencing, and Desynchronization of Neural Activity, with Single-Spike Temporal Resolution}},
volume = {2},
year = {2007}
}
@article{Kou1973,
author = {Kou, S.R. and Elliott, D.L. and Tarn, T.J.},
journal = {Information and Control},
keywords = {Reservoir Computing},
mendeley-tags = {Reservoir Computing},
number = {1},
pages = {89--99},
publisher = {Elsevier},
title = {{Observability of nonlinear systems}},
url = {http://www.sciencedirect.com/science/article/pii/S0019995873905081},
volume = {22},
year = {1973}
}
@article{Tyrcha2014,
abstract = {We derive learning rules for finding the connections between units in stochastic dynamical networks from the recorded history of a "visible'' subset of the units. We consider two models. In both of them, the visible units are binary and stochastic. In one model the "hidden'' units are continuous-valued, with sigmoidal activation functions, and in the other they are binary and stochastic like the visible ones. We derive exact learning rules for both cases. For the stochastic case, performing the exact calculation requires, in general, repeated summations over an number of configurations that grows exponentially with the size of the system and the data length, which is not feasible for large systems. We derive a mean field theory, based on a factorized ansatz for the distribution of hidden-unit states, which offers an attractive alternative for large systems. We present the results of some numerical calculations that illustrate key features of the two models and, for the stochastic case, the exact and approximate calculations.},
author = {Tyrcha, J and Hertz, John},
doi = {10.3934/mbe.2014.11.149},
journal = {Mathematical biosciences and engineering : MBE},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Computer Simulation,Excitatory Postsynaptic Potentials,Humans,Inhibitory Postsynaptic Potentials,Models, Neurological,Models, Theoretical,Neural Networks (Computer),Neurons,Neurons: physiology,Probability,Stochastic Processes},
month = {feb},
number = {1},
pages = {149--165},
pmid = {24245678},
title = {{Network inference with hidden units.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24245678},
volume = {11},
year = {2014}
}
@article{Kirst2009a,
author = {Kirst, Christoph and Timme, Marc},
doi = {10.3389/neuro.01.009.2009},
issn = {1662-453X},
journal = {Frontiers in neuroscience},
month = {may},
number = {1},
pages = {2--3},
pmid = {19753088},
title = {{How Precise is the Timing of Action Potentials?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2695382{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2009}
}
@article{JO00,
author = {Jongbloed, G},
journal = {Statistics and Probability Letters},
pages = {279--284},
title = {{Minimax lower bounds and moduli of continuity}},
volume = {50},
year = {2000}
}
@article{Masland2013,
author = {Masland, RH},
journal = {Nature},
number = {7461},
pages = {154--155},
title = {{Neuroscience: Accurate maps of visual circuitry}},
url = {http://www.nature.com/nature/journal/v500/n7461/abs/500154a.html},
volume = {500},
year = {2013}
}
@article{Nuho-Maganda2007,
author = {Nuho-Maganda, MA},
isbn = {1424406064},
journal = {{\ldots} Logic, 2007. SPL'07. {\ldots}},
pages = {167--170},
title = {{An Efficient Scalable Parallel Hardware Architecture for Multilayer Spiking Neural Networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4234339},
year = {2007}
}
@article{Weiss1981,
author = {Martynov, GV},
journal = {Journal of Soviet Mathematics},
pages = {1857--1875},
title = {{Evaluation of the normal distribution function}},
url = {http://link.springer.com/article/10.1007/BF01085187},
year = {1981}
}
@article{Lew09,
author = {Lew, S and Wolters, C H and Dierkes, T and R{\"{o}}er, C and MacLeod, R S},
journal = {Appl. Numer. Math.},
pages = {1970--1988},
title = {{Accuracy and run-time comparison for different potential approaches and iterative solvers in finite element method based {\{}EEG{\}} source analysis}},
volume = {59},
year = {2009}
}
@article{Witcher|2007|,
author = {Witcher, M R and Kirov, S A and Harris, K M},
journal = {Glia},
number = {1},
pages = {13--23},
title = {{Plasticity of perisynaptic astroglia during synaptogenesis in the mature rat hippocampus.}},
volume = {55}
}
@article{Frasca|2006|,
abstract = {I analyze numerically a two-dimensional phi{\^{}}4 theory showing that
in the limit of a strong coupling lambda-{\textgreater}infty just the homogeneous
solutions for time evolution are relevant in agreement with the duality
principle in perturbation theory as presented in [M. Frasca, Phys.
Rev. A 58, 3439 (1998)], being negligible the contribution of the
spatial varying parts of the dynamical equations. A consequence is
that the Green function method works for this nonlinear problem in
the large coupling limit as in a linear theory. A numerical proof
is given for this. With these results at hand, I built a strongly
coupled quantum field theory for a phi{\^{}}4 interacting field computing
the first order correction to the generating functional. Mass spectrum
of the theory is obtained turning out to be that of a harmonic oscillator
with no dependence on the dimensionality of space-time. The agreement
with the Lehmann-Ka{\^{A}}¨llen representation of the perturbation series
is then shown at the first order.},
annote = {The article attacks strong coupling limit of phi{\^{}}4 theory by considering{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Hamilton{\&}{\#}039;s equations obtain with the non-potential terms treated{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}as perturbation. Analytic solution of the 0th-order /completely decoupled{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}or ultra-local approximation/ is explicitly derived and used, arguably,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to define Green{\&}{\#}039;s function and field theory based on this Green{\&}{\#}039;s{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}function. 1st order approximant is derived, however no issues of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}divergences of higher order approximants is ever touched.},
author = {Frasca, M},
journal = {Physical Review D},
keywords = {derivatives expansion,hopping expansion,phi{\^{}}4,physics,quantum field theory,strong coupling expansion},
pages = {27701},
title = {{Strongly coupled quantum field theory}},
volume = {73}
}
@article{RUST06,
author = {Rust, N and Mante, V and Simoncelli, E and Movshon, J A},
journal = {Nature Neuroscience},
pages = {1421--1431},
title = {{How {\{}MT{\}} cells analyze the motion of visual patterns}},
volume = {11},
year = {2006}
}
@article{Ji1998,
author = {Ji, C and Psaltis, D},
journal = {Information Theory, IEEE Transactions on},
number = {1},
pages = {256--268},
title = {{Capacity of two-layer feedforward neural networks with binary weights}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=651033},
volume = {44},
year = {1998}
}
@article{Herz2006,
abstract = {The fundamental building block of every nervous system is the single neuron. Understanding how these exquisitely structured elements operate is an integral part of the quest to solve the mysteries of the brain. Quantitative mathematical models have proved to be an indispensable tool in pursuing this goal. We review recent advances and examine how single-cell models on five levels of complexity, from black-box approaches to detailed compartmental simulations, address key questions about neural dynamics and signal processing.},
annote = {2010IInum12.22},
author = {Herz, Andreas V M A.V.M. V M and Gollisch, Tim and Machens, Christian K C.K. and Jaeger, Dieter},
doi = {10.1126/science.1127240},
issn = {1095-9203},
journal = {Science},
keywords = {Action Potentials,Animals,Computer Simulation,Dendrites,Dendrites: physiology,Electric Stimulation,Humans,Mathematics,Models,Nerve Net,Nerve Net: physiology,Neurological,Neuron Model,Neurons,Neurons: physiology,Synapses,Synapses: physiology},
mendeley-tags = {Neuron Model},
month = {oct},
number = {October},
pages = {80--85},
pmid = {17023649},
publisher = {AAAS},
title = {{Modeling Single-Neuron Dynamics Detail and Abstraction}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17023649 http://www.sciencemag.org/cgi/content/abstract/sci;314/5796/80},
volume = {314},
year = {2006}
}
@article{GibsonLanni91,
abstract = {Oil-immersion microscope objective lenses have been designed and optimized

for the study of thin, two-dimensional object sections that are mounted

immediately below the coverslip in a medium that is index matched

to the immersion oil. It has been demonstrated both experimentally

and through geometrical- and physical-optics theory that, when the

microscope is not used with the correct coverslip or immersion oil,

when the detector is not located at the optimal plane in image space,

or when the object does not satisfy specific conditions, aberration

will degrade both the contrast and the resolution of the image. In

biology the most severe aberration is introduced when an oil-immersion

objective lens is used to study thick specimens, such as living cells

and tissues, whose refractive indices are significantly different

from that of the immersion oil. We present a model of the three-dimensional

imaging properties of a fluorescence light microscope subject to

such aberration and compare the imaging properties predicted by the

model with those measured experimentally. The model can be used to

understand and compensate for aberration introduced to a microscope

system under nondesign optical conditions so that both confocal laser

scanning microscopy and optical serial sectioning microscopy can

be optimized.},
author = {Gibson, S F and Lanni, F},
journal = {J Opt Soc Am A},
keywords = {Fluorescence; Microspheres; Models,Mathematics; Microscopy,Theoretical; Optics},
month = {jan},
number = {1},
pages = {154--166},
pmid = {1738047},
title = {{Experimental test of an analytical model of aberration in an oil-immersion objective lens used in three-dimensional light microscopy.}},
volume = {9},
year = {1991}
}
@article{OKA05,
author = {Okatan, M and Wilson, M and Brown, E},
journal = {Neural Computation},
pages = {1927--1961},
title = {{Analyzing Functional Connectivity Using a Network Likelihood Model of Ensemble Neural Spiking Activity}},
volume = {17},
year = {2005}
}
@article{Touboul2009,
author = {Touboul, J and Brette, R},
journal = {Society},
keywords = {080742762,1,10,1137,37b10,37c10,37c25,37c27,37g15,37n25,39a11,92c20,ams subject classifications,and biologically realistic model,bursting,chaos,doi,finding a computationally simple,hybrid dynamical systems,introduction,neuron models,nonlinear dynamics,of the,spike patterns},
number = {4},
pages = {1462--1506},
title = {{Spiking Dynamics of Bidimensional Integrate-and-Fire Neurons}},
volume = {8},
year = {2009}
}
@inproceedings{Kim2012a,
address = {Niagara Falls, NY},
author = {Kim, Yongtae and Zhang, Yong and Li, Peng},
booktitle = {SOC Conference (SOCC), 2012 IEEE International},
isbn = {9781467312950},
month = {sep},
pages = {328--333},
title = {{A digital neuromorphic VLSI architecture with memristor crossbar synaptic array for machine learning}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6398336},
year = {2012}
}
@article{Schmid2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1206.4841v1},
author = {Schmid, Gerhard},
eprint = {arXiv:1206.4841v1},
journal = {Arxiv preprint arXiv:1206.4841},
title = {{In-phase and anti-phase synchronization in noisy Hodgkin-Huxley neurons}},
url = {http://arxiv.org/abs/1206.4841},
year = {2012}
}
@article{KanoldManis99,
abstract = {Pyramidal cells in the dorsal cochlear nucleus (DCN) show three distinct

temporal discharge patterns in response to sound: "pauser," "buildup,"

and "chopper." Similar discharge patterns are seen in vitro and depend

on the voltage from which the cell is depolarized. It has been proposed

that an inactivating A-type K+ current (IKI) might play a critical

role in generating the three different patterns. In this study we

examined the characteristics of transient currents in DCN pyramidal

cells to evaluate this hypothesis. Morphologically identified pyramidal

cells in rat brain slices (P11-P17) exhibited the three voltage-dependent

discharge patterns. Two inactivating currents were present in outside-out

patches from pyramidal cells: a rapidly inactivating (IKIF, tau approximately

11 msec) current insensitive to block by tetraethylammonium (TEA)

and variably blocked by 4-aminopyridine (4-AP) with half-inactivation

near -85 mV, and a slowly inactivating TEA- and 4-AP-sensitive current

(IKIS, tau approximately 145 msec) with half-inactivation near -35

mV. Recovery from inactivation at 34 degrees C was described by a

single exponential with a time constant of 10-30 msec, similar to

the rate at which first spike latency increases with the duration

of a hyperpolarizing prepulse. Acutely isolated cells also possessed

a rapidly activating ({\textless}1 msec at 22 degrees C) transient current

that activated near -45 mV and showed half-inactivation near -80

mV. A model demonstrated that the deinactivation of IKIF was correlated

with the discharge patterns. Overall, the properties of the fast

inactivating K+ current were consistent with their proposed role

in shaping the discharge pattern of DCN pyramidal cells.},
author = {Kanold, P O and Manis, P B},
journal = {J Neurosci},
keywords = {4-Aminopyridine; Animals; Cochlear Nucleus; Electr,Neurological; Neurons; Patch-Clamp Techniques; Po,Sprague-Dawley; Tetraethylammonium; Time Factors},
month = {mar},
number = {6},
pages = {2195--2208},
pmid = {10066273},
title = {{Transient potassium currents regulate the discharge patterns of dorsal cochlear nucleus pyramidal cells.}},
volume = {19},
year = {1999}
}
@article{Han1998,
author = {Han, G and Sanchez-Sinencio, E},
journal = {IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing},
number = {12},
pages = {1550--1563},
title = {{CMOS transconductance multipliers: A tutorial}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=746667},
volume = {45},
year = {1998}
}
@article{Pnevmatikakis2008a,
author = {Pnevmatikakis, E A and Paninski, L},
keywords = {Estimation},
mendeley-tags = {Estimation},
pages = {1--14},
title = {{Sparse nonnegative deconvolution for compressive calcium imaging : algorithms and phase transitions}}
}
@article{Thorson1974,
annote = {2009num17},
author = {Thorson, J. and Biederman-Thorson, M.},
journal = {Science},
number = {4121},
pages = {161},
publisher = {AAAS},
title = {{Distributed Relaxation Processes in Sensory Adaptation: Spatial nonuniformity in receptors can explain both the curious dynamics and logarithmic statics of adaptation}},
url = {http://www.sciencemag.org/cgi/content/abstract/183/4121/161},
volume = {183},
year = {1974}
}
@article{Sorra|1993|,
abstract = {Recent physiological work has used quantal analysis to investigate
the properties of synaptic transmission and long-term potentiation
in hippocampal area CA1. These analyses have revealed changes in
the strength of excitatory post-synaptic responses following long-term
potentiation that could be mediated by cellular mechanisms in the
presynaptic element, in the postsynaptic element, or in both elements.
In these studies, either minimal stimulation, presumably involving
a single presynaptic axon, or recordings from pairs of CA3 and CA1
cells have been used. Interpretation of these quantal analyses requires
knowledge about whether single or multiple synapses occur between
the presynaptic axon and its target CA1 pyramidal cells. Here, light
and serial electron microscopy was used to begin to examine this
question and a related question concerning the ultrastructure of
spines on multiple-synapse boutons. Light microscopic analyses of
Golgi preparations revealed that about 20{\%} of the axons occurring
in stratum radiatum come into close apposition with two to four different
dendrites of a target CA1 cell. An "apposition" was defined as a
point where the axons and dendrites crossed in the same focal plane
and therefore were sufficiently close to allow a dendritic spine
to reach the axon and possibly establish a synaptic contact. An additional
4{\%} of the axons wound back and forth across individual dendrites,
possibly forming multiple synapses closely spaced along the dendrites.
Serial electron microscopy revealed that 24{\%} of the individual axonal
boutons in stratum radiatum make synapses with multiple dendritic
spines arising from either the same or different dendritic segments.
Two adjacent boutons of the same axon could also be found to synapse
with different spines of the same dendrite. Together with the light
microscopic analysis, these observations suggest that multiple synapses
occur between single axons in stratum radiatum and their target CA1
cells, and that at least some of these synapses may occur at different
electronic distances. If these multiple synapses have different physiological
strengths, then they may obscure or smooth peaks in the frequency
histograms that are used for quantal analyses. A three-dimensional
analysis was done to compare the dimensions of pairs of dendritic
spines synapsing with individual axonal boutons. When the pairs of
spines associated with a single bouton arose from different dendrites,
at least some of which were likely to have come from different cells,
the differences between their volumes and the areas of the postsynaptic
densities were on average 100{\%} and ranged up to 650{\%}.(ABSTRACT TRUNCATED
AT 400 WORDS)},
annote = {NICHD P30-HD18655/HD/United States NICHD NINCDS NS21184/NS/United{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}States NINDS Journal Article Research Support, Non-U.S. Gov{\&}{\#}039;t Research{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Support, U.S. Gov{\&}{\#}039;t, P.H.S. United states the official journal of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the Society for Neuroscience},
author = {Sorra, K E and Harris, K M},
journal = {J Neurosci},
keywords = {Animals Axons/*ultrastructure Dendrites/ultrastruc,Electron Models,Structural Neurons/cytology/*ultrastructure Pyram},
number = {9},
pages = {3736--3748},
title = {{Occurrence and three-dimensional structure of multiple synapses between individual radiatum axons and their target pyramidal cells in hippocampal area CA1}},
volume = {13}
}
@article{FredkinRice92,
author = {Fredkin, Donald R and Rice, John A},
journal = {Proceedings of the Royal Society of London. Series B: Biological Sciences},
pages = {125--132},
title = {{Maximum Likelihood Estimation and Identification Directly from Single-Channel Recordings}},
volume = {249},
year = {1992}
}
@article{Lizana|2005|,
abstract = {We developed analytical and numerical methods to study a transport
of non-interacting particles in large networks consisting of M d-dimensional
containers C1, . . . ,CM with radii Ri linked together by tubes of
length lij and radii aij where i, j = 1, 2, . . .M. Tubes may join
directly with each other forming junctions. It is possible that some
links are absent. Instead of solving the diffusion equation for the
full problem we formulated an approach that is computationally more
efficient. We derived a set of rate equations that govern the time
dependence of the number of particles in each container N1(t),N2(t),
. . . ,NM(t). In such a way the complicated transport problem is
reduced to a set of M first order integro-differential equations
in time, which can be solved efficiently by the algorithm presented
here. The rate equations are valid for any network topology under
the assumption that the tubes are thin in comparison to their lengths
and the radii of the containers, aij {\^{a}}‰{\textordfeminine} Ri,Rj , lij . Under these
assumptions the containers can be considered ideally mixed at all
times and transport through the tubes is one-dimensional. These assumptions
were verified numerically. The workings of the method have been demonstrated
on a couple of examples: networks involving three, four and seven
containers, and one network with a three-point junction. Already
simple networks with relatively few containers exhibit interesting
transport behavior. For example, we showed that it is possible to
adjust the geometry of the networks so that the particle concentration
varies in time in a wave-like manner. Such behavior deviates from
simple exponential growth and decay occurring in the two container
system. In addition, we showed how to eliminate junctions from the
dynamical equations in the large time limit.},
author = {Lizana, L and Konkoli, Z},
journal = {arXiv},
keywords = {functions networks,networks,transport,unread},
number = {0503273},
title = {{Particle transport in large networks}},
volume = {cond-mat}
}
@article{NBR03,
author = {Neal, R M and Beal, M and Roweis, S},
journal = {NIPS},
title = {{Inferring State Sequences for Non-linear Systems with Embedded Hidden {\{}M{\}}arkov Models}},
volume = {16},
year = {2003}
}
@article{Abraham2005,
abstract = {In this article we introduce, develop, and discuss the theoretical calculations required for the exact solution of a recently reported phase transition, the geodesic to zigzag transition. In this scenario the interfacial transition emerges from geometric competition between a geodesic, shortest path, configuration and a zigzag configuration which is able to reduce its energy by binding to a centrally positioned defect line. From a technical point of view the transition is unusual as it is described by a change from saddle dominated behavior to pole dominated behavior of the integral representing the partition function ratio. We also establish the precise fluctuation behavior of the interface by computing the spin magnetization at any point in the system.},
author = {Abraham, D B and Mustonen, Ville and Wood, a J},
issn = {1539-3755},
journal = {Physical Review E},
month = {mar},
number = {3 Pt 2A},
pages = {036106},
pmid = {15903492},
title = {{Equilibrium statistical mechanics of a grain boundary.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20866187},
volume = {71},
year = {2005}
}
@article{Eliazar2009,
annote = {2009num40},
author = {Eliazar, Iddo and Klafter, Joseph},
doi = {10.1103/PhysRevE.79.021115},
issn = {1539-3755},
journal = {Physical Review E},
number = {2},
pages = {1--15},
title = {{From Ornstein-Uhlenbeck dynamics to long-memory processes and fractional Brownian motion}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.79.021115},
volume = {79},
year = {2009}
}
@article{Jacks04,
author = {Jackson, B S},
journal = {Neural Computation},
pages = {2125--2195},
title = {{Including Long-Range Dependence in Integrate-and-Fire Models of the High Interspike-Interval Variability of Cortical Neurons}},
volume = {16},
year = {2004}
}
@article{Nesse2010,
abstract = {Spike trains commonly exhibit interspike interval (ISI) correlations caused by spike-activated adaptation currents. Here we investigate how the dynamics of adaptation currents can represent spike pattern information generated from stimulus inputs. By analyzing dynamical models of stimulus-driven single neurons, we show that the activation states of the correlation-inducing adaptation current are themselves statistically independent from spike to spike. This paradoxical finding suggests a biophysically plausible means of information representation. We show that adaptation independence is elicited by input levels that produce regular, non-Poisson spiking. This adaptation-independent regime is advantageous for sensory processing because it does not require sensory inferences on the basis of multivariate conditional probabilities, reducing the computational cost of decoding. Furthermore, if the kinetics of postsynaptic activation are similar to the adaptation, the activation state information can be communicated postsynaptically with no information loss, leading to an experimental prediction that simple synaptic kinetics can decorrelate the correlated ISI sequence. The adaptation-independence regime may underly efficient weak signal detection by sensory afferents that are known to exhibit intrinsic correlated spiking, thus efficiently encoding stimulus information at the limit of physical resolution.},
annote = {

2011num48},
author = {Nesse, William H and Maler, Leonard and Longtin, Andr{\'{e}}},
doi = {10.1073/pnas.1008587107},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Animals,Humans,Kinetics,Models,Neurological,Sensory Receptor Cells,Sensory Receptor Cells: physiology,Synaptic Potentials,Synaptic Potentials: physiology},
month = {dec},
number = {Ml},
pages = {1--7},
pmid = {21131567},
title = {{Biophysical information representation in temporally correlated spike trains}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3009835{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pubmed/21131567},
volume = {107},
year = {2010}
}
@article{Lazar1998,
author = {Jelenkovic, P R and Lazar, A A},
journal = {Submitted to Journal of Appl. Prob},
keywords = {er type conditions,fluid flow queue,hopf factorization,markov,modulated random walk,nential dependency,non-cram,subexpo-,subexponential distributions,supremum distribution,weiner},
number = {November 1995},
pages = {325--347},
title = {{Subexponential asymptotics of a markov-modulated G/G/1 queue}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:SUBEXPONENTIAL+ASYMPTOTICS+OF+A+MARKOV-MODULATED{\#}1},
volume = {347},
year = {1995}
}
@article{Rusakov|1999|,
author = {Rusakov, D A and Kullmann, D M and Stewart, M G},
journal = {Trends Neurosci.},
pages = {382},
title = {{Hippocampal synapses: do they talk to their neighbors?}},
volume = {22}
}
@article{Penny05,
author = {Penny, W and Ghahramani, Z and Friston, K},
journal = {Philos Trans R Soc Lond B Biol Sci.},
pages = {983--993},
title = {{Bilinear Dynamical Systems}},
volume = {360},
year = {2005}
}
@article{roberts2002spike,
annote = {2008num19},
author = {Roberts, P D and Bell, C C},
journal = {Biological Cybernetics},
number = {5},
pages = {392--403},
publisher = {Springer},
title = {{Spike timing dependent synaptic plasticity in biological systems}},
volume = {87},
year = {2002}
}
@article{Fiala|2002|a,
author = {Fiala, J C and Allwardt, B and Harris, K M},
journal = {Nat Neurosci},
number = {4},
pages = {297--298},
title = {{Dendritic spines do not split during hippocampal LTP or maturation.}},
volume = {5}
}
@article{Salinas2005,
author = {Salinas, Emilio and Nevado, Angel},
doi = {10.1523/JNEUROSCI.0631-05.2005},
keywords = {depletion,fluctuation-driven regimen,neural coding,presynaptic spike correlations,synaptic integration,synaptic short-term depression,vesicle},
number = {37},
pages = {8416--8431},
title = {{Short-Term Synaptic Depression Causes a Non-Monotonic}},
volume = {25},
year = {2005}
}
@article{Li2007,
abstract = {Cognitive dysfunction may result from abnormality of ionotropic glutamate receptors. Although various forms of synaptic plasticity in learning that rely on altering of glutamate receptors have been considered, the evidence is insufficient from an informatics view. Dynamics could reflect neuroinformatics encoding, including temporal pattern encoding, spatial pattern encoding, and energy distribution. Discovering informatics encoding is fundamental and crucial to understanding the working principle of the neural system. In this article, we analyzed the dynamic characteristics of response activities during learning training in cultured hippocampal networks under normal and abnormal conditions of ionotropic glutamate receptors, respectively. The rate, which is one of the temporal configurations, was decreased markedly by inhibition of alpha-amino-3-hydroxy-5-methylisoxazole-4-proprionic acid (AMPA) receptors. Moreover, the energy distribution in different characteristic frequencies was changed markedly by inhibition of AMPA receptors. Spatial configurations, including regularization, correlation, and synchrony, were changed significantly by inhibition of N-methyl-d-aspartate receptors. These results suggest that temporal pattern encoding and energy distribution of response activities in cultured hippocampal neuronal networks during learning training are modulated by AMPA receptors, whereas spatial pattern encoding of response activities is modulated by N-methyl-d-aspartate receptors.},
author = {Li, Yanling and Zhou, Wei and Li, Xiangning and Zeng, Shaoqun and Luo, Qingming},
doi = {10.1529/biophysj.107.111153},
issn = {1542-0086},
journal = {Biophysical Journal},
keywords = {Animals,Cells,Cognition Disorders,Cognition Disorders: physiopathology,Computer Simulation,Cultured,Excitatory Amino Acid Antagonists,Excitatory Amino Acid Antagonists: pharmacology,Glutamate,Glutamate: metabolism,Hippocampus,Hippocampus: drug effects,Hippocampus: physiopathology,Learning,Learning: drug effects,Models,Nerve Net,Nerve Net: drug effects,Nerve Net: physiopathology,Neurological,Rats,Receptors},
number = {12},
pages = {4151--4158},
pmid = {17766359},
publisher = {Elsevier},
title = {{Dynamics of learning in cultured neuronal networks with antagonists of glutamate receptors.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17766359},
volume = {93},
year = {2007}
}
@article{Keshner1982,
author = {Keshner, M S},
journal = {Proceedings of the IEEE},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
number = {3},
pages = {212--218},
title = {1/f noise},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:1/f+noise{\#}0},
volume = {70},
year = {1982}
}
@article{Url2007,
author = {Url, Stable and Archive, The Jstor and Archive, The},
number = {4598},
pages = {671--680},
title = {{No Title}},
volume = {220},
year = {2007}
}
@article{Biess2013,
author = {Biess, Armin},
doi = {10.1103/PhysRevE.87.012729},
issn = {1539-3755},
journal = {Physical Review E},
month = {jan},
number = {1},
pages = {012729},
title = {{Shaping of arm configuration space by prescription of non-Euclidean metrics with applications to human motor control}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.87.012729},
volume = {87},
year = {2013}
}
@article{Feldmeyer99,
author = {Feldmeyer, D and Egger, V and Lubke, J and Sakmann, B},
journal = {J Physiol},
pages = {169--90.},
title = {{Reliable synaptic connections between pairs of excitatory layer 4 neurones within a single ``barrel" of developing rat somatosensory cortex}},
volume = {521 Pt 1},
year = {1999}
}
@article{DasGupta05,
author = {{Das Gupta}, A},
journal = {J. Statist. Plann. Inference},
pages = {377--389},
title = {{The matching, birthday and the strong birthday problem: a contemporary review}},
volume = {130},
year = {2005}
}
@article{Abramson1993,
author = {Abramson, S and Saad, D and Marom, E},
journal = {Neural Networks, IEEE {\ldots}},
title = {{Training a network with ternary weights using the CHIR algorithm}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=286901},
year = {1993}
}
@article{Colquhoun1981,
annote = {2010num3.2 (partial)},
author = {Colquhoun, D and Hawkes, A G},
doi = {10.1098/rspb.1981.0003},
issn = {0080-4649},
journal = {Proceedings of the Royal Society of London. Series B, Biological Sciences (1934-1990)},
number = {1183},
pages = {205--235},
title = {{On the Stochastic Properties of Single Ion Channels}},
url = {http://rspb.royalsocietypublishing.org/cgi/doi/10.1098/rspb.1981.0003},
volume = {211},
year = {1981}
}
@article{LeakeVollmer00,
abstract = {The goal of this research is to examine the functional consequences

of patterned electrical stimulation delivered by a cochlear implant

in the deafened developing auditory system. In previous electrophysiological

experiments conducted in the inferior colliculus (IC), we have demonstrated

that the precise cochleotopic organization of the central nucleus

(ICC) develops normally in neonatally deafened unstimulated cats

and is unaltered despite the lack of normal auditory input during

development. However, these studies also showed that chronic electrical

stimulation delivered at a single intracochlear location by one bipolar

channel of a cochlear implant induces significant expansion of the

central representation of the stimulated cochlear sector and degrades

the cochleotopic organization of the IC. This report presents additional

data from a new experimental series of neonatally deafened cats that

received chronic stimulation on two adjacent bipolar intracochlear

channels of a cochlear implant. Results suggest that competing inputs

elicited by electrical stimulation delivered by two adjacent channels

can maintain the selective representations of each activated cochlear

sector within the central auditory system and prevent the expansion

seen after single-channel stimulation. Alternating stimulation of

two channels and use of highly controlled electrical signals may

be particularly effective in maintaining or even sharpening selectivity

of central representations of stimulated cochlear sectors. In contrast,

simultaneous stimulation using two channels of a model analog cochlear

implant processor in one experimental animal failed to maintain channel

selectivity and resulted in marked expansion and fusion of the central

representations of the stimulated channels. This potentially important

preliminary result suggests that under some conditions the central

auditory system may be unable to discriminate simultaneous, overlapping

inputs from adjacent cochlear implant channels as distinct.},
author = {Leake, P A and Snyder, R L and Rebscher, S J and Moore, C M and Vollmer, M},
journal = {Hearing Research},
keywords = {Animal; Electric Stimulation; Electrodes; Evoked,Animals; Animals,Auditory,Brain Stem; Humans; Inferior Colliculus; Neuronal,Newborn; Cats; Cochlear Implants; Deafness; Disea,P.H.S.,U.S. Gov't},
month = {sep},
number = {1-2},
pages = {221--241},
pmid = {10962187},
title = {{Plasticity in central representations in the inferior colliculus induced by chronic single- vs. two-channel electrical stimulation by a cochlear implant after neonatal deafness.}},
volume = {147},
year = {2000}
}
@article{BROW04,
author = {Brown, E and Kass, R and Mitra, P},
journal = {Nature Neuroscience},
pages = {456--461},
title = {{Multiple neural spike train data analysis: state-of-the-art and future challenges}},
volume = {7},
year = {2004}
}
@article{Conklin|2004|,
abstract = {Cells in several areas of the hippocampal formation show place specific
firing patterns, and are thought to form a distributed representation
of an animal{\"{i}}¾'s current location in an environment. Experimental
results suggest that this representation is continually updated even
in complete darkness, indicating the presence of a path integration
mechanism in the rat. Adopting the Neural Engineering Framework (NEF)
presented by Eliasmith and Anderson (2003) we derive a novel attractor
network model of path integration, using heterogeneous spiking neurons.
The network we derive incorporates representation and updating of
position into a single layer of neurons, eliminating the need for
a large external control population, and without making use of multiplicative
synapses. An efficient and biologically plausible control mechanism
results directly from applying the principles of the NEF. We simulate
the network for a variety of inputs, analyze its performance, and
give three testable predictions of our model.},
author = {Conklin, J and Eliasmith, C},
keywords = {attractor network,computational,hippocampus,networks,neural control,neural network,neurobiology,path integration,subiculum,unread},
title = {{A controlled attractor network model of path integration in the rat}}
}
@article{Cyburt|2002|,
abstract = {Self-interacting dark matter (SIDM) was introduced by Spergel {\&} Steinhardt
to address possible discrepancies between collisionless dark matter
simulations and observations on scales of less than 1 Mpc. We examine
the case in which dark matter particles not only have strong self-interactions
but also have strong interactions with baryons. The presence of such
interactions will have direct implications for nuclear and particle
astrophysics. Among these are a change in the predicted abundances
from big bang nucleosynthesis (BBN) and the flux of {\^{I}}³-rays produced
by the decay of neutral pions which originate in collisions between
dark matter and Galactic cosmic rays (CR). From these effects we
constrain the strength of the baryon{\^{A}}–dark matter interactions through
the ratio of baryon - dark matter interaction cross section to dark
matter mass, s. We find that BBN places a weak upper limit to this
ratio {\textless}{\^{a}}ˆ¼ 108 cm2 g{\^{a}}ˆ'1. CR-SIDM interactions, however, limit the
possible DM-baryon cross section to {\textless}{\^{a}}ˆ¼ 5 {\~{A}}— 10{\^{a}}ˆ'3 cm2 g{\^{a}}ˆ'1; this
rules out an energy-independent interaction, but not one which falls
with center-of-mass velocity as s {\^{a}}ˆ� 1/v or steeper.},
annote = {This paper considers constrains on SIDM interaction with Baryonic{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}matter from astrophysical measurements.},
author = {Cyburt, R H and Fields, B D and Pavlidou, V and Wandelt, B D},
journal = {arXiv},
keywords = {astrophysics,cosmic rays,dark matter,interaction,nucleosynthesis,physics,strongly interacting dark matter},
title = {{Constraining strong baryon-dark matter interactions with primordial nucleosynthesis and cosmic rays}},
volume = {astro-ph/0}
}
@article{Beck2009,
author = {Beck, Amir and Teboulle, Marc},
doi = {10.1137/080716542},
journal = {SIAM Journal on Imaging Sciences},
keywords = {65f22,90c06,90c25,algorithms,ams subject classifications,deconvolution,global rate of convergence,image deblurring,iterative shrinkage-thresholding algorithm,l 1 regularization problems,least squares and,linear inverse problem,optimal gradient method,two-step iterative},
month = {jan},
number = {1},
pages = {183--202},
title = {{A fast iterative shrinkage-thresholding algorithm for linear inverse problems}},
url = {http://epubs.siam.org/doi/abs/10.1137/080716542},
volume = {2},
year = {2009}
}
@book{DK01,
author = {Durbin, J and Koopman, S},
publisher = {Oxford University Press},
title = {{Time Series Analysis by State Space Methods}},
year = {2001}
}
@inproceedings{Courbariaux2015a,
abstract = {Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and power-hungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN.},
archivePrefix = {arXiv},
arxivId = {1511.00363},
author = {Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
booktitle = {Nips},
eprint = {1511.00363},
issn = {10495258},
pages = {1--9},
title = {{BinaryConnect: Training Deep Neural Networks with binary weights during propagations}},
url = {http://papers.nips.cc/paper/5647-shape-and-illumination-from-shading-using-the-generic-viewpoint-assumption http://arxiv.org/abs/1511.00363},
year = {2015}
}
@book{WestHarrison97,
author = {West, M and Harrison, P},
publisher = {Springer},
title = {{Bayesian Forecasting and Dynamic Models}},
year = {1997}
}
@article{LLS04,
author = {Lin, Y and Lee, D and Saul, L},
journal = {International Conference on Acoustics, Speech, and Signal Processing},
title = {{Nonnegative deconvolution for time of arrival estimation}},
year = {2004}
}
@article{Pezo2014,
abstract = {To study the effects of stochastic ion channel fluctuations on neural dynamics, several numerical implementation methods have been proposed. Gillespie's method for Markov Chains (MC) simulation is highly accurate, yet it becomes computationally intensive in the regime of a high number of channels. Many recent works aim to speed simulation time using the Langevin-based Diffusion Approximation (DA). Under this common theoretical approach, each implementation differs in how it handles various numerical difficulties-such as bounding of state variables to [0,1]. Here we review and test a set of the most recently published DA implementations (Goldwyn et al., 2011; Linaro et al., 2011; Dangerfield et al., 2012; Orio and Soudry, 2012; Schmandt and Gal{\'{a}}n, 2012; G{\"{u}}ler, 2013; Huang et al., 2013a), comparing all of them in a set of numerical simulations that assess numerical accuracy and computational efficiency on three different models: (1) the original Hodgkin and Huxley model, (2) a model with faster sodium channels, and (3) a multi-compartmental model inspired in granular cells. We conclude that for a low number of channels (usually below 1000 per simulated compartment) one should use MC-which is the fastest and most accurate method. For a high number of channels, we recommend using the method by Orio and Soudry (2012), possibly combined with the method by Schmandt and Gal{\'{a}}n (2012) for increased speed and slightly reduced accuracy. Consequently, MC modeling may be the best method for detailed multicompartment neuron models-in which a model neuron with many thousands of channels is segmented into many compartments with a few hundred channels.},
author = {Pezo, Danilo and Soudry, D. and Orio, Patricio},
doi = {10.3389/fncom.2014.00139},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {Channel noise,Conductance based models,Ion channel,Langevin,Stochastic simulation},
number = {November},
pages = {139},
pmid = {25404914},
title = {{Diffusion approximation-based simulation of stochastic ion channels: which method to use?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4217484{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {8},
year = {2014}
}
@article{Chen2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1101.6081v2},
author = {Chen, Yunmei and Ye, Xiaojing},
eprint = {arXiv:1101.6081v2},
journal = {arXiv preprint arXiv:1101.6081},
keywords = {moreau,nonlinear programming,projection onto a simplex,proximity,s identity},
number = {1},
pages = {1--7},
title = {{Projection onto a simplex}},
url = {http://arxiv.org/abs/1101.6081},
year = {2011}
}
@article{Marder2006,
abstract = {Neurons in most animals live a very long time relative to the half-lives of all of the proteins that govern excitability and synaptic transmission. Consequently, homeostatic mechanisms are necessary to ensure stable neuronal and network function over an animal's lifetime. To understand how these homeostatic mechanisms might function, it is crucial to understand how tightly regulated synaptic and intrinsic properties must be for adequate network performance, and the extent to which compensatory mechanisms allow for multiple solutions to the production of similar behaviour. Here, we use examples from theoretical and experimental studies of invertebrates and vertebrates to explore several issues relevant to understanding the precision of tuning of synaptic and intrinsic currents for the operation of functional neuronal circuits.},
annote = {2010IIInum65},
author = {Marder, E and Goaillard, Jean-Marc},
doi = {10.1038/nrn1949},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Homeostasis,Homeostasis: physiology,Humans,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology},
month = {jul},
number = {7},
pages = {563--74},
pmid = {16791145},
title = {{Variability, compensation and homeostasis in neuron and network function.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16791145},
volume = {7},
year = {2006}
}
@article{Larochelle2009,
author = {Larochelle, Hugo and Bengio, Yoshua},
journal = {The Journal of Machine Learning},
pages = {1--40},
title = {{Exploring strategies for training deep neural networks}},
url = {http://dl.acm.org/citation.cfm?id=1577070},
volume = {1},
year = {2009}
}
@article{PG00,
author = {Plesser, H and Gerstner, W},
journal = {Neural Computation},
pages = {367--384},
title = {{Noise in Integrate-and-Fire Neurons: From Stochastic Input to Escape Rates}},
volume = {12},
year = {2000}
}
@article{Benucci07,
author = {Benucci, A and Frazor, R and Carandini, M},
journal = {Neuron},
pages = {103--117},
title = {{Standing waves and traveling waves distinguish two circuits in visual cortex}},
volume = {55},
year = {2007}
}
@article{Brecht2012,
author = {Brecht, M},
journal = {Current Biology},
number = {16},
pages = {R633--R635},
title = {{Neuronal Communication: Firing Spikes with Spikes}},
url = {http://www.sciencedirect.com/science/article/pii/S0960982212007403},
volume = {22},
year = {2012}
}
@article{Lowen1999a,
annote = {2010num2.5},
author = {Lowen, S B and Liebovitch, L S and White, J A},
journal = {Physical Review E},
number = {5},
pages = {5970},
title = {{Fractal ion-channel behavior generates fractal firing patterns in neuronal models}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.59.5970},
volume = {59},
year = {1999}
}
@book{shepherd2004synaptic,
author = {Shepherd, G.M.},
publisher = {Oxford University Press New York},
title = {{The synaptic organization of the brain}},
url = {http://www.lavoisier.fr/notice/fr603507.html},
year = {2004}
}
@article{Fleidervish2010,
abstract = {In cortical pyramidal neurons, the axon initial segment (AIS) is pivotal in synaptic integration. It has been asserted that this is because there is a high density of Na(+) channels in the AIS. However, we found that action potential-associated Na(+) flux, as measured by high-speed fluorescence Na(+) imaging, was about threefold larger in the rat AIS than in the soma. Spike-evoked Na(+) flux in the AIS and the first node of Ranvier was similar and was eightfold lower in basal dendrites. At near-threshold voltages, persistent Na(+) conductance was almost entirely axonal. On a time scale of seconds, passive diffusion, and not pumping, was responsible for maintaining transmembrane Na(+) gradients in thin axons during high-frequency action potential firing. In computer simulations, these data were consistent with the known features of action potential generation in these neurons.},
author = {Fleidervish, I A and Lasser-Ross, N and Gutnick, M J and Ross, W N},
doi = {10.1038/nn.2574},
issn = {1546-1726},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: metabolism,Cell Membrane,Ion Transport,Ion Transport: physiology,Pyramidal Cells,Pyramidal Cells: metabolism,Ranvier's Nodes,Ranvier's Nodes: metabolism,Rats,Signal Transduction,Signal Transduction: physiology,Sodium,Sodium Channels,Sodium Channels: metabolism,Sodium: metabolism,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: metabolism,Sprague-Dawley,Synaptic Transmission},
month = {jul},
number = {7},
pages = {852--60},
pmid = {20543843},
publisher = {Nature Publishing Group},
title = {{Na+ imaging reveals little difference in action potential-evoked Na+ influx between axon and soma.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3102307{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {13},
year = {2010}
}
@article{Winther1997,
author = {Winther, O and Lautrup, B and Zhang, J B},
doi = {10.1103/PhysRevE.55.836},
issn = {1063-651X},
journal = {Physical Review E},
number = {1},
pages = {836--844},
title = {{Optimal learning in multilayer neural networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.55.836},
volume = {55},
year = {1997}
}
@article{Kornai|2001|,
annote = {This is review on mathematical linguistics.},
author = {Kornai, A},
keywords = {codes,language,linguistics,markov,mathematics},
title = {{Mathematical Linguistics}}
}
@article{AHR05,
author = {Ahrens, M B and Huys, Q and Paninski, L},
journal = {NIPS},
title = {{Estimating non-homogeneous channel densities and synaptic activity from spatiotemporal dendritic voltage recordings}},
year = {2005}
}
@article{Verdes2005,
author = {Verdes, PF},
journal = {Physical Review E},
title = {{Assessing causality from multivariate time series}},
url = {http://journals.aps.org/pre/abstract/10.1103/PhysRevE.72.026222},
year = {2005}
}
@article{Marom1998,
author = {Marom, S},
journal = {Journal of Membrane Biology},
keywords = {conducted a series of,deactivation,environments,excitabil-,hodgkin-huxley,inactivation,ion channel,ity,membrane,modulation,relations between the ionic,studies aimed at uncovering,the},
number = {2},
pages = {105--113},
publisher = {Springer},
title = {{Slow changes in the availability of voltage-gated ion channels: effects on the dynamics of excitable membranes}},
url = {http://www.springerlink.com/index/A79GTMVDYT4L2RJV.pdf},
volume = {161},
year = {1998}
}
@article{ZhangCarney01,
author = {Zhang, X and Heinz, M G and Bruce, I C and Carney, L H},
journal = {Journal of The Acoustical Society Of America},
month = {feb},
number = {2},
pages = {648--670},
title = {{A phenomenological model for the responses of auditory-nerve fibers: I Nonlinear tuning with compression and suppression}},
volume = {109},
year = {2001}
}
@article{DenkWebb90,
author = {Denk, W and Strickler, J H and Webb, W W},
journal = {Science},
month = {apr},
number = {4951},
pages = {73--76},
title = {{Two-photon laser scanning fluorescence microscopy}},
volume = {248},
year = {1990}
}
@article{Soudry2013a,
abstract = {Learning in multilayer neural networks (MNNs) relies on continuous updating of large matrices of synaptic weights by local rules. Such locality can be exploited for massive parallelism when implementing MNNs in hardware. However, these update rules require a multiply and accumulate operation for each synaptic weight, which is challenging to implement compactly using CMOS. In this paper, a method for performing these update operations simultaneously (incremental outer products) using memristor-based arrays is proposed. The method is based on the fact that, approximately, given a voltage pulse, the conductivity of a memristor will increment proportionally to the pulse duration multiplied by the pulse magnitude if the increment is sufficiently small. The proposed method uses a synaptic circuit composed of a small number of components per synapse: one memristor and two CMOS transistors. This circuit is expected to consume between 2{\%} and 8{\%} of the area and static power of previous CMOS-only hardware alternatives. Such a circuit can compactly implement hardware MNNs trainable by scalable algorithms based on online gradient descent (e.g., backpropagation). The utility and robustness of the proposed memristor-based circuit are demonstrated on standard supervised learning tasks.},
author = {Soudry, D. and {Di Castro}, D. and Gal, A. and Kolodny, A. and Kvatinsky, S.},
doi = {10.1109/TNNLS.2014.2383395},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Backpropagation,hardware,memristive systems,memristor,multilayer neural networks (MNNs),stochastic gradient descent,synapse},
number = {10},
pages = {2408--2421},
pmid = {25594981},
title = {{Memristor-Based Multilayer Neural Networks With Online Gradient Descent Training}},
volume = {26},
year = {2015}
}
@article{SCH78,
author = {Schwarz, G},
journal = {Annals of Statistics},
pages = {461--464},
title = {{Estimating the dimension of a model}},
volume = {7},
year = {1978}
}
@misc{chionimpl,
annote = {This presentation deals with ion implantation in solids},
keywords = {implantation,ions,penetration,physics,solid,stopping power},
title = {{Ion Implantation}}
}
@book{Davis06,
author = {Davis, T},
publisher = {SIAM},
title = {{Direct Methods for Sparse Linear Systems}},
year = {2006}
}
@article{Efron2004,
author = {Efron, B and Hastie, T},
journal = {The Annals of statistics},
keywords = {and phrases,boosting,coefficient paths,lasso,linear regression,variable selection},
number = {2},
pages = {407--499},
title = {{Least angle regression}},
url = {http://projecteuclid.org/euclid.aos/1083178935},
volume = {32},
year = {2004}
}
@article{BP01,
author = {Binder, M and Powers, R},
journal = {Journal of Neurophysiology},
pages = {2266--2275},
title = {{Relationship Between Simulated Common Synaptic Input and Discharge Synchrony in Cat Spinal Motoneurons}},
volume = {86},
year = {2001}
}
@article{Grinstein1993,
annote = {2010IInum8.7},
author = {Grinstein, G and Mukamel, D and Seidin, R and Bennett, CH},
journal = {Physical Review Letters},
title = {{Temporally periodic phases and kinetic roughening}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.70.3607},
year = {1993}
}
@article{Fronczak|2006|,
abstract = {In this paper, we study fluctuations over several ensembles of maximum-entropy
random networks. We derive several fluctuation-dissipation relations
characterizing the susceptibilities of different networks to changes
in external fields. In the case of networks with a given degree sequence,
we argue that the scale-free topologies of real-world networks may
arise as a result of the self-organization of real systems into sparse
structures with low susceptibility to random external disruptions.
We also show that the ensembles of networks with a given degree sequence
and networks characterized by two-point correlations are equivalent
to random networks with hidden variables.},
annote = {This is interesting paper attemtping extention of thermodynamic approach{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to analysis in complex networks.},
author = {Fronczak, A and Fronczak, P and Holyst, J A},
journal = {Physical review E},
keywords = {dynamics,fluctuation-dissipation relations,fluctuations,mathematics,networks,partition function,physics,thermodynamics},
pages = {16108},
title = {{Fluctuation-dissipation relations in complex networks}},
volume = {73}
}
@article{Berkes2009,
abstract = {The visual system must learn to infer the presence of objects and features in the world from the images it encounters, and as such it must, either implicitly or explicitly, model the way these elements interact to create the image. Do the response properties of cells in the mammalian visual system reflect this constraint? To address this question, we constructed a probabilistic model in which the identity and attributes of simple visual elements were represented explicitly and learnt the parameters of this model from unparsed, natural video sequences. After learning, the behaviour and grouping of variables in the probabilistic model corresponded closely to functional and anatomical properties of simple and complex cells in the primary visual cortex (V1). In particular, feature identity variables were activated in a way that resembled the activity of complex cells, while feature attribute variables responded much like simple cells. Furthermore, the grouping of the attributes within the model closely parallelled the reported anatomical grouping of simple cells in cat V1. Thus, this generative model makes explicit an interpretation of complex and simple cells as elements in the segmentation of a visual scene into basic independent features, along with a parametrisation of their moment-by-moment appearances. We speculate that such a segmentation may form the initial stage of a hierarchical system that progressively separates the identity and appearance of more articulated visual elements, culminating in view-invariant object recognition.},
author = {Berkes, Pietro and Turner, Richard E and Sahani, Maneesh},
doi = {10.1371/journal.pcbi.1000495},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Algorithms,Animals,Artificial Intelligence,Bayes Theorem,Cats,Models, Neurological,Models, Statistical,Video Recording,Visual Cortex,Visual Cortex: physiology},
month = {sep},
number = {9},
pages = {e1000495},
pmid = {19730679},
title = {{A structured model of video reproduces primary visual cortical organisation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2726939{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@article{Blundell2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.05424v2},
author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
eprint = {arXiv:1505.05424v2},
journal = {ICML 2015},
title = {{Weight Uncertainty in Neural Networks}},
volume = {37},
year = {2015}
}
@article{roberts2008implementation,
annote = {2008num22},
author = {Roberts, P D and Santiago, R A and Lafferriere, G},
journal = {Biological Cybernetics},
number = {6},
pages = {517--523},
publisher = {Springer},
title = {{An implementation of reinforcement learning based on spike timing dependent plasticity}},
volume = {99},
year = {2008}
}
@book{RamonyCajal23,
author = {y Cajal, S},
publisher = {Alianza Editorial},
title = {{Recuerdos de mi vida: Historia de mi labor cientifica}},
year = {1923}
}
@article{Chiappalone2008,
abstract = {To investigate distributed synaptic plasticity at the cell assembly level, we used dissociated cortical networks from embryonic rats grown on grids of 60 extracellular substrate-embedded electrodes (micro-electrode arrays). We developed a set of experimental plasticity protocols based on the pairing of tetanic bursts (20 Hz) with low-frequency stimuli ({\textless} or = 1 Hz), delivered through two separate channels of the array (i.e. associative tetanic stimulation). We tested our protocols on a large data set of 26 stable cultures, selected on the basis of both their initial level of spontaneous firing and the capability of low-frequency test stimuli to evoke spikes. Our main results are summarized as follows: (i) low-frequency stimuli produce neither short- nor long-term changes in the evoked response of the network; (ii) associative tetanic stimulation is able to induce plasticity in terms of a significant increase or decrease of the evoked activity in the whole network; (iii) the amount of change (i.e. increase or decrease of the evoked firing) strongly depends on the specific features of the applied protocols; and (iv) the potentiation induced by a specific associative protocol can last several hours. The results obtained demonstrate that large in vitro cortical assemblies display long-term network potentiation, a mechanism considered to be involved in the memory formation at cellular level. This pilot study could represent a relevant step towards understanding plastic properties at the neuronal population level.},
annote = {2011num42},
author = {Chiappalone, Michela and Massobrio, Paolo and Martinoia, Sergio},
doi = {10.1111/j.1460-9568.2008.06259.x},
issn = {1460-9568},
journal = {The European journal of neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: metabolism,Electric Stimulation,Embryo,Mammalian,Mammalian: anatomy {\&} histology,Nerve Net,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: cytology,Neurons: metabolism,Rats,Sprague-Dawley,Tetany,Tissue Culture Techniques},
month = {jul},
number = {1},
pages = {221--37},
pmid = {18662344},
title = {{Network plasticity in cortical assemblies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18662344},
volume = {28},
year = {2008}
}
@article{Lehrer2008,
annote = {2010IInum12.8},
author = {Lehrer, Jonah},
journal = {boston.com},
title = {{Daydream achiever: A wandering mind can do important work, scientists are learning - and may even be essential}},
year = {2008}
}
@article{Desai1999,
abstract = {During learning and development, the level of synaptic input received by cortical neurons may change dramatically. Given a limited range of possible firing rates, how do neurons maintain responsiveness to both small and large synaptic inputs? We demonstrate that in response to changes in activity, cultured cortical pyramidal neurons regulate intrinsic excitability to promote stability in firing. Depriving pyramidal neurons of activity for two days increased sensitivity to current injection by selectively regulating voltage-dependent conductances. This suggests that one mechanism by which neurons maintain sensitivity to different levels of synaptic input is by altering the function relating current to firing rate.},
annote = {2009num19},
author = {Desai, N S and Rutherford, L C and Turrigiano, G G},
doi = {10.1038/9165},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Animals,Cells,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Cultured,Electric Conductivity,Electrophysiology,Ions,Neuronal Plasticity,Neuronal Plasticity: physiology,Newborn,Newborn: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Rats},
month = {jun},
number = {6},
pages = {515--20},
pmid = {10448215},
title = {{Plasticity in the intrinsic excitability of cortical pyramidal neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10448215},
volume = {2},
year = {1999}
}
@article{Davidge|1999|,
abstract = {Near-infrared images obtained with the Canada-France-Hawaii Telescope
(CFHT) Adaptive Optics Bonnette (AOB) are used to investigate the
stellar content within 18 arcsec of the center of the Local Group
spiral galaxy M33. AGB stars with near-infrared spectral-energy distributions
similar to those of giants in the solar neighborhood and Baade{\"{i}}¾'s
Window are detected over most of the field. Neither the peak brightness
nor the color of the AGB sequence on the (K, J {\^{a}}ˆ' K) color-magnitude
diagram changes with distance from the galaxy center. The bolometric
luminosity function (LF) of these stars has a discontinuity near
Mbol = {\^{a}}ˆ'5.25, and comparisons with evolutionary tracks suggest
that most of the AGB stars formed in a burst of star formation 1
{\^{a}}ˆ' 3 Gyr in the past, indicating that the star formation rate near
the center of M33 has varied significantly during the past few Gyr.
The images are also used to investigate the integrated near-infrared
photometric properties of the nucleus and the central light concentration.
The nucleus is bluer than the central light concentration, in agreement
with previous studies at visible wavelengths. The near-infrared photometric
properties of the nucleus are reminiscent of relatively young clusters
in the Magellanic Clouds, while the photometric properties of the
central light concentration are similar to those of globular clusters.
The CO index of the central light concentration 0.5 arcsec from the
galaxy center is 0.05, which corresponds to [Fe/H] {\^{a}}ˆ'1.2 for simple
stellar systems. Hence, the central light concentration could not
have formed from the chemically-enriched material that dominates
the present-day inner disk of M33.},
author = {Davidge, T J},
journal = {arXiv},
keywords = {astrophysics,galaxy,infrared,physics},
pages = {9910333},
title = {{Near-Infrared Adaptive Optics Imaging of the Central Regions of Nearby Sc Galaxies: I. M33}},
volume = {astro-ph}
}
@article{DePaola2006,
abstract = {We imaged axons in layer (L) 1 of the mouse barrel cortex in vivo. Axons from thalamus and L2/3/5, or L6 pyramidal cells were identified based on their distinct morphologies. Their branching patterns and sizes were stable over times of months. However, axonal branches and boutons displayed cell type-specific rearrangements. Structural plasticity in thalamocortical afferents was mostly due to elongation and retraction of branches (range, 1-150 microm over 4 days; approximately 5{\%} of total axonal length), while the majority of boutons persisted for up to 9 months (persistence over 1 month approximately 85{\%}). In contrast, L6 axon terminaux boutons were highly plastic (persistence over 1 month approximately 40 {\%}), and other intracortical axon boutons showed intermediate levels of plasticity. Retrospective electron microscopy revealed that new boutons make synapses. Our data suggest that structural plasticity of axonal branches and boutons contributes to the remodeling of specific functional circuits.},
author = {Paola, Vincenzo De and Holtmaat, Anthony and Knott, Graham and Song, Sen and Wilbrecht, Linda and Caroni, Pico and Svoboda, K and {De Paola}, V},
doi = {10.1016/j.neuron.2006.02.017},
issn = {0896-6273},
journal = {Neuron},
keywords = {Analysis of Variance,Anatomic,Animals,Antigens,Biological,Diagnostic Imaging,Diagnostic Imaging: methods,Electron,Green Fluorescent Proteins,Green Fluorescent Proteins: genetics,Imaging,Inbred C57BL,Male,Mice,Microscopy,Models,Neocortex,Neocortex: cytology,Neocortex: ultrastructure,Neurites,Neurites: ultrastructure,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: classification,Neurons: cytology,Neurons: ultrastructure,Presynaptic Terminals,Presynaptic Terminals: ultrastructure,Three-Dimensional,Three-Dimensional: methods,Thy-1,Thy-1: genetics,Time Factors,Transgenic,Transmission,Transmission: methods},
month = {mar},
number = {6},
pages = {861--75},
pmid = {16543134},
title = {{Cell type-specific structural plasticity of axonal branches and boutons in the adult neocortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16543134},
volume = {49},
year = {2006}
}
@article{Sun2015,
abstract = {In this note, we focus on smooth nonconvex optimization problems that obey: (1) all local minimizers are also global; and (2) around any saddle point or local maximizer, the objective has a negative directional curvature. Concrete applications such as dictionary learning, generalized phase retrieval, and orthogonal tensor decomposition are known to induce such structures. We describe a second-order trust-region algorithm that provably converges to a global minimizer efficiently, without special initializations. Finally we highlight alternatives, and open problems in this direction.},
archivePrefix = {arXiv},
arxivId = {1510.06096},
author = {Sun, Ju and Qu, Qing and Wright, John},
eprint = {1510.06096},
journal = {arXiv:1510.06096 [cs, math, stat]},
pages = {1--6},
title = {{When Are Nonconvex Problems Not Scary?}},
url = {http://arxiv.org/abs/1510.06096{\%}5Cnhttp://www.arxiv.org/pdf/1510.06096.pdf},
year = {2015}
}
@article{Amaral|1989|,
author = {Amaral, D G and Witter, M P},
journal = {Neuroscience},
keywords = {Animals Hippocampus/*anatomy {\&} histology Rats},
number = {3},
pages = {571--591},
title = {{The three-dimensional organization of the hippocampal formation: a review of anatomical data}},
volume = {31}
}
@article{Yashar10,
author = {Ahmadian, Y and Packer, A and Yuste, R and Paninski, L},
journal = {Under review},
title = {{Fast optimal control of spike trains}},
year = {2010}
}
@article{SS02,
author = {Schwartz, O and Chichilnisky, E J and Simoncelli, E},
journal = {NIPS},
title = {{Characterizing neural gain control using spike-triggered covariance}},
volume = {14},
year = {2002}
}
@article{Sarpeshkar1998,
author = {Sarpeshkar, R},
journal = {Neural Computation},
number = {7},
pages = {1601--1638},
title = {{Analog versus digital: extrapolating from electronics to neurobiology}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976698300017052},
volume = {10},
year = {1998}
}
@article{Edin04,
author = {Edin, F and Machens, C K and Schutze, H and Herz, A V M},
journal = {Journal of Computational Neuroscience},
number = {1},
pages = {47--56},
title = {{Searching for optimal sensory signals: Iterative stimulus reconstruction in closed-loop experiments}},
volume = {17},
year = {2004}
}
@article{Blondel2001,
annote = {2011num22},
author = {Blondel, V D and Bournez, O and Koiran, P and Papadimitriou, C and Tsitsiklis, J N},
doi = {10.1016/S0304-3975(00)00399-6},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {decidability,discrete dynamical systems,hybrid systems,mortality,piecewise a ne systems,piecewise linear systems,stability},
month = {mar},
number = {1-2},
pages = {687--696},
publisher = {Citeseer},
title = {{Deciding stability and mortality of piecewise affine dynamical systems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.6748{\&}rep=rep1{\&}type=ps},
volume = {255},
year = {1999}
}
@book{Boyd2004,
address = {Cambridge},
author = {Boyd, Stephen and Vandenberghe, Lieven},
doi = {10.1017/CBO9780511804441},
isbn = {9780511804441},
publisher = {Cambridge University Press},
title = {{Convex Optimization}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511804441},
year = {2004}
}
@article{Tsien89,
author = {Tsien, Roger Y},
journal = {Ann. Rev. Neurosci.},
pages = {227--253},
title = {{Fluorescent Probes of Cell Signaling}},
volume = {12},
year = {1989}
}
@article{Wilson1972a,
author = {Wilson, KG G and Fisher, ME E},
journal = {Physical Review Letters},
title = {{Critical exponents in 3.99 dimensions}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.28.240},
year = {1972}
}
@article{Anderson1972,
author = {Anderson, PW},
journal = {Science},
number = {4047},
pages = {393--396},
title = {{More is different}},
url = {http://www.worldscientific.com/doi/abs/10.1142/9789812385123{\_}others01},
volume = {177},
year = {1972}
}
@inproceedings{Ho|2004|,
abstract = {Anatomical objects often have complex and varying image appearance
at different portions of the boundary; and it is frequently a challenge
even to select appropriate scales at which to sample the image. This
motivates Bayesian image-match models which are both multiscale and
statistical. We present a novel image-match model for use in Bayesian
segmentation, a multiscale extension of image profile models akin
to those in Active Shape Models. A spherical-harmonic based 3D shape
representation provides a mapping of the object boundary to the sphere
S2, and a scale-space for profiles on the sphere defines a scalespace
on the object. A key feature is that profiles are not blurred across
the object boundary, but only along the boundary. This profile scalespace
is sampled in a coarse-to-fine fashion to produce features for the
statistical image-match model. A framework for model-building and
segmentation has been built, and testing and validation are in progress
with a dataset of 70 segmented images of the caudate nucleus.},
author = {Ho, S and Gerig, G},
booktitle = {MICCAI},
keywords = {anatomical,computational,image processing,multiscale,segmentation},
pages = {176},
title = {{Profile Scale-spaces for Multiscale Image Match}},
volume = {1}
}
@article{marom1996effects,
annote = {2009num37},
author = {Marom, S and Salman, H and Lyakhov, V and Braun, E},
journal = {Journal of Membrane Biology},
number = {3},
pages = {267--274},
publisher = {Springer},
title = {{Effects of density and gating of delayed-rectifier potassium channels on resting membrane potential and its fluctuations}},
volume = {154},
year = {1996}
}
@article{Portugues2014,
author = {Portugues, Ruben and Feierstein, Claudia E. and Engert, Florian and Orger, Michael B.},
doi = {10.1016/j.neuron.2014.01.019},
issn = {08966273},
journal = {Neuron},
month = {mar},
number = {6},
pages = {1328--1343},
publisher = {Elsevier Inc.},
title = {{Whole-Brain Activity Maps Reveal Stereotyped, Distributed Networks for Visuomotor Behavior}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627314000506},
volume = {81},
year = {2014}
}
@article{Laughlin2003,
abstract = {Brains perform with remarkable efficiency, are capable of prodigious computation, and are marvels of communication. We are beginning to understand some of the geometric, biophysical, and energy constraints that have governed the evolution of cortical networks. To operate efficiently within these constraints, nature has optimized the structure and function of cortical networks with design principles similar to those used in electronic networks. The brain also exploits the adaptability of biological systems to reconfigure in response to changing needs.},
annote = {2010IIInum15},
author = {Laughlin, S B and Sejnowski, T J},
doi = {10.1126/science.1089662},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Action Potentials,Animals,Brain,Brain: physiology,Cell Communication,Evolution,Humans,Nerve Net,Nerve Net: physiology,Neuronal Plasticity,Neurons,Neurons: physiology,Synaptic Transmission},
month = {sep},
number = {5641},
pages = {1870--4},
pmid = {14512617},
title = {{Communication in neuronal networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14512617},
volume = {301},
year = {2003}
}
@article{KimPotashner04,
abstract = {The companion study showed that acoustic overstimulation of adult

chinchillas, with a noise level sufficient to damage the cochlea,

led to cytological changes and degeneration of synaptic endings in

the cochlear nucleus within 1-16 weeks. In the present study, the

same stimulus was used to study the long-term effects on the fine

structure of synaptic endings in the cochlear nucleus. For periods

of 6 and 8 months after a single exposure to a damaging noise level,

there ensued a chronic, continuing process of neurodegeneration involving

excitatory and inhibitory synaptic endings. Electron microscopic

observations demonstrated freshly occurring degeneration even as

late as 8 months. Degeneration was widespread in the neuropil and

included the synapses on the globular bushy cell, which forms part

of the main ascending auditory pathway. Neurodegeneration was accompanied

by newly formed synaptic endings, which repopulated some of the sites

vacated previously by axosomatic endings on globular bushy cells.

Many of these synaptic endings must arise from central interneurons.

The findings suggest that overstimulation can induce a self-sustaining

condition of progressive neurodegeneration accompanied by a new growth

of synaptic endings. Noise-induced hearing loss thus may progress

as a neurodegenerative disease with the capacity for synaptic reorganization

within the cochlear nucleus.},
author = {Kim, J J and Gross, J and Morest, D K and Potashner, S J},
doi = {10.1002/jnr.20212},
journal = {Journal of Neuroscience Research},
keywords = {Acoustic Stimulation; Animals; Chinchilla; Cochlea,P.H.S.; Time,U.S. Gov't},
month = {sep},
number = {6},
pages = {817--828},
pmid = {15334600},
title = {{Fine structure of long-term changes in the cochlear nucleus after acoustic overstimulation: chronic degeneration and new growth of synaptic endings.}},
url = {http://dx.doi.org/10.1002/jnr.20212},
volume = {77},
year = {2004}
}
@inproceedings{Goodfellow2014,
abstract = {Training neural networks involves solving large-scale non-convex optimization problems. This task has long been believed to be extremely difficult, with fear of local minima and other obstacles motivating a variety of schemes to improve optimization, such as unsupervised pretraining. However, modern neural networks are able to achieve negligible training error on complex tasks, using only direct training with stochastic gradient descent. We introduce a simple analysis technique to look for evidence that such networks are overcoming local optima. We find that, in fact, on a straight path from initialization to solution, a variety of state of the art neural networks never encounter any significant obstacles.},
archivePrefix = {arXiv},
arxivId = {1412.6544},
author = {Goodfellow, Ian J. and Vinyals, Oriol and Saxe, Andrew M.},
booktitle = {ICLR},
eprint = {1412.6544},
title = {{Qualitatively characterizing neural network optimization problems}},
url = {http://arxiv.org/abs/1412.6544},
year = {2015}
}
@article{Gillespie1977,
author = {Gillespie, DT},
journal = {The journal of physical chemistry},
number = {25},
pages = {2340--2361},
title = {{Exact stochastic simulation of coupled chemical reactions}},
url = {http://pubs.acs.org/doi/pdf/10.1021/j100540a008},
volume = {81},
year = {1977}
}
@article{MolitorManis99,
abstract = {Although it is known that voltage-gated {\{}Ca{\}}{\^{}}{\{}2+{\}} conductances (VGCCs)

contribute to the responses of dorsal cochlear nucleus (DCN) neurons,

little is known about the properties of VGCCs in the DCN. In this

study, the whole cell voltage-clamp technique was used to examine

the pharmacology and voltage dependence of VGCCs in unidentified

DCN neurons acutely isolated from guinea pig brain stem. The majority

of cells responded to depolarization with sustained inward currents

that were enhanced when {\{}Ca{\}}{\^{}}{\{}2+{\}} was replaced by Ba2+, were blocked

partially by Ni2+ (100 microM), and were blocked almost completely

by Cd2+ (50 microM). Experiments using nifedipine (10 microM), omegaAga

IVA (100 nM) and omegaCTX GVIA (500 nM) demonstrated that a variety

of VGCC subtypes contributed to the Ba2+ current in most cells, including

the L, N, and P/Q types and antagonist-insensitive R type. Although

a large depolarization from rest was required to activate VGCCs in

DCN neurons, VGCC activation was rapid at depolarized levels, having

time constants {\textless}1 ms at 22 degrees C. No fast low-threshold inactivation

was observed, and a slow high-threshold inactivation was observed

at voltages more positive than -20 mV, indicating that Ba2+ currents

were carried by high-voltage activated VGCCs. The VGCC subtypes contributing

to the overall Ba2+ current had similar voltage-dependent properties,

with the exception of the antagonist-insensitive R-type component,

which had a slower activation and a more pronounced inactivation

than the other components. These data suggest that a variety of VGCCs

is present in DCN neurons, and these conductances generate a rapid

{\{}Ca{\}}{\^{}}{\{}2+{\}} influx in response to depolarizing stimuli.},
author = {Molitor, S C and Manis, P B},
journal = {J Neurophysiol},
keywords = {Animals; Barium; Cations,Divalent; Cochlear Nucleus; Electric Conductivity},
month = {mar},
number = {3},
pages = {985--998},
pmid = {10085327},
title = {{Voltage-gated {\{}Ca{\}}{\^{}}{\{}2+{\}} conductances in acutely isolated guinea pig dorsal cochlear nucleus neurons.}},
volume = {81},
year = {1999}
}
@article{Santhanam08,
author = {Santhanam, G and Yu, B and Gilja, V and Ryu, S and Afshar, A and Sahani, M and Shenoy, K},
journal = {Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing},
pages = {5208--5211},
title = {{A factor-analysis decoder for high-performance neural prostheses}},
year = {2008}
}
@article{Neuroscience,
archivePrefix = {arXiv},
arxivId = {arXiv:1210.7165v1},
author = {Neuroscience, Theoretical and Universit, Freie},
eprint = {arXiv:1210.7165v1},
pages = {1--17},
title = {{Sensory Stimulus Representation}}
}
@inproceedings{Karoly2016,
author = {Karoly, P. J. and Freestone, D. R. and Soudry, D. and Kuhlmann, L. and Paninski, L. and Cook, M.},
booktitle = {CNS},
title = {{Data-driven neural models part II: connectivity patterns of human seizures}},
year = {2016}
}
@article{Altevogt2008a,
abstract = {The Institute of Medicine's Forum on Neuroscience and Nervous System Disorders established a "Grand Challenges Initiative." The goal is to help frame a broad, integrated research program that would attract substantial funding and generate additional resources to support large-scale efforts to tackle some of the most daunting but important neuroscience questions.},
author = {Altevogt, Bruce M and Hanson, Sarah L and Leshner, Alan I},
doi = {10.1016/j.neuron.2008.10.036},
issn = {1097-4199},
journal = {Neuron},
keywords = {Biomedical Research,Biomedical Research: economics,Biomedical Research: education,Biomedical Research: trends,Brain,Brain: physiology,Education,Humans,Institute of Medicine (U.S.),Neurosciences,Neurosciences: economics,Neurosciences: education,Neurosciences: trends,United States},
month = {nov},
number = {3},
pages = {406--8},
pmid = {18995812},
publisher = {Elsevier Inc.},
title = {{Molecules to minds: grand challenges for the 21st century.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18995812},
volume = {60},
year = {2008}
}
@article{SvobodaYasuda06,
author = {Svoboda, Karel and Yasuda, Ryohei},
journal = {Neuron},
month = {jun},
number = {6},
pages = {823--839},
title = {{Principles of two-photon excitation microscopy and its applications to neuroscience}},
volume = {50},
year = {2006}
}
@article{Xie2003,
author = {Xie, Xiaohui and Seung, H S},
journal = {Neural Computation},
number = {2},
pages = {441--454},
title = {{Equivalence of backpropagation and contrastive Hebbian learning in a layered network}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976603762552988},
volume = {15},
year = {2003}
}
@article{Ascoli01,
author = {Ascoli, G and Krichmar, J and Nasuto, S and Senft, S},
journal = {Philosophical Transactions: Biological Sciences},
pages = {1131--1145},
title = {{Generation, Description and Storage of Dendritic Morphology Data}},
volume = {356},
year = {2001}
}
@article{Zoph2017,
abstract = {Developing state-of-the-art image classification models often requires significant architecture engineering and tuning. In this paper, we attempt to reduce the amount of architecture engineering by using Neural Architecture Search to learn an architectural building block on a small dataset that can be transferred to a large dataset. This approach is similar to learning the structure of a recurrent cell within a recurrent network. In our experiments, we search for the best convolutional cell on the CIFAR-10 dataset and then apply this learned cell to the ImageNet dataset by stacking together more of this cell. Although the cell is not learned directly on ImageNet, an architecture constructed from the best learned cell achieves state-of-the-art accuracy of 82.3{\%} top-1 and 96.0{\%} top-5 on ImageNet, which is 0.8{\%} better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS. This cell can also be scaled down two orders of magnitude: a smaller network constructed from the best cell also achieves 74{\%} top-1 accuracy, which is 3.1{\%} better than the equivalently-sized, state-of-the-art models for mobile platforms.},
archivePrefix = {arXiv},
arxivId = {1707.07012},
author = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
eprint = {1707.07012},
title = {{Learning Transferable Architectures for Scalable Image Recognition}},
url = {http://arxiv.org/abs/1707.07012},
volume = {10},
year = {2017}
}
@article{Doi2005,
abstract = {We have presented a new generation mechanism of slow spiking or repetitive discharges with extraordinarily long inter-spike intervals using the modified Hodgkin-Huxley equations (Doi and Kumagai, 2001). This generation process of slow firing is completely different from that of the well-known potassium A-current in that the steady-state current-voltage relation of the neuronal model is monotonic rather than the N-shaped one of the A-current. In this paper, we extend the previous results and show that the very slow spiking generically appears in both the three-dimensional Hodgkin-Huxley equations and the three dimensional Bonhoeffer-van der Pol (or FitzHugh-Nagumo) equations. The generation of repetitive discharges or the destabilization of the unique equilibrium point (resting potential) is a simple Hopf bifurcation. We also show that the generation of slow spiking does not depend on the stability of the Hopf bifurcation: supercritical or subcritical. The dynamics of slow spiking is investigated in detail and we demonstrate that the phenomenology of slow spiking can be categorized into two types according to the type of the corresponding bifurcation of a fast subsystem: Hopf or saddle-node bifurcation.},
author = {Doi, Shinji and Kumagai, Sadatoshi},
doi = {10.1007/s10827-005-2895-1},
issn = {0929-5313},
journal = {Journal of Computational Neuroscience},
keywords = {Algorithms,Electrophysiology,Membrane Potentials,Membrane Potentials: physiology,Models, Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Potassium Channels,Potassium Channels: physiology},
month = {dec},
number = {3},
pages = {325--56},
pmid = {16502240},
title = {{Generation of very slow neuronal rhythms and chaos near the Hopf bifurcation in single neuron models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16502240},
volume = {19},
year = {2005}
}
@misc{Simelectronics,
author = {SimElectronics},
title = {http://www.mathworks.com/products/simelectronics/}
}
@article{Carlson1974,
author = {Carlson, David and Haynsworth, Emile and Markham, Thomas},
journal = {Siam J. Appl. Math.},
number = {1},
pages = {169--175},
title = {{A Generalization of the Schur Complement by Means of the Moore-Penrose Inverse}},
volume = {26},
year = {1974}
}
@article{Abbott2016,
author = {Abbott, L F and Depasquale, Brian and Memmesheimer, R M},
doi = {10.1038/nn.4241},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {November 2015},
pages = {1--16},
title = {{Building Functional Networks of Spiking Model Neurons}},
year = {2016}
}
@article{No,
author = {No, Serial},
title = {{E-MANUAL}}
}
@article{Wainrib2010,
author = {Pakdaman, K},
journal = {Advances in Applied {\ldots}},
keywords = {2010 mathematics subject classification,60f17,60j75,fluid limit,hodgkin,huxley,kinetic model,langevin approximation,lecar,morris,neuron model,piecewise-deterministic markov process,primary 60f05,stochastic hybrid system,stochastic ion channels},
number = {May},
pages = {761--794},
title = {{Fluid limit theorems for stochastic hybrid systems with application to neuron models}},
url = {http://projecteuclid.org/euclid.aap/1282924062},
volume = {794},
year = {2010}
}
@article{GS02,
author = {Gibbs, A and Su, F},
journal = {International Statistical Review},
pages = {419--436},
title = {{On choosing and bounding probability metrics}},
volume = {70},
year = {2002}
}
@article{Lockery2009,
author = {Lockery, S R and Goodman, M.B. B},
journal = {Nature Neuroscience},
number = {4},
pages = {377--378},
title = {{The quest for action potentials in C. elegans neurons hits a plateau}},
volume = {12},
year = {2009}
}
@article{Garrod|1966|,
abstract = {A path-integral formulation of quantum mechanics is ivestigated which
is closely related to that of Feynman. It differs from Feynman's
formulation in that it involves the Hamiltnoian function of the canonically
conjugate coordinates and momenta. The classical limit yields the
variational principle: delta f(p-N)dt=0. A path integral formula
is also obtained for the energy eigenstate projection operator associated
with the time-independent Schrodinger equation. The classical limit
of the projection operator formula yields a modified form of the
well-known variational principle for the phase-space orbit of given
energy. Relativistically covariant Hamiltonian variational principles
are analyzed and lead naturally to a relativistic scalar wave equation
which involves a proper time variable which is canonically conjugate
to the mass in the same manner as the ordinary time variable is conjugate
to the energy in nonrelativistic quantum theory.},
author = {Garrod, C},
journal = {Review of modern physics},
keywords = {canonical transformations,hamiltonian path integral,physics,quantum mechanics,unread},
number = {3},
pages = {483},
title = {{Hamiltonian path-integral methods}},
volume = {38}
}
@book{Sejnowski,
author = {Sejnowski, Terrence J and Poggio, Tomaso A},
isbn = {9780262090438},
title = {{Dynamical Systems in Neuroscience Computational Neuroscience}}
}
@article{Wu1996,
author = {Wu, CY and Lan, JF},
journal = {Neural Networks, IEEE Transactions on},
number = {1},
title = {{CMOS current-mode neural associative memory design with on-chip learning}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=478401},
volume = {I},
year = {1996}
}
@article{Appleby2006,
abstract = {In earlier work we presented a stochastic model of spike-timing-dependent plasticity (STDP) in which STDP emerges only at the level of temporal or spatial synaptic ensembles. We derived the two-spike interaction function from this model and showed that it exhibits an STDP-like form. Here, we extend this work by examining the general n-spike interaction functions that may be derived from the model. A comparison between the two-spike interaction function and the higher-order interaction functions reveals profound differences. In particular, we show that the two-spike interaction function cannot support stable, competitive synaptic plasticity, such as that seen during neuronal development, without including modifications designed specifically to stabilize its behavior. In contrast, we show that all the higher-order interaction functions exhibit a fixed-point structure consistent with the presence of competitive synaptic dynamics. This difference originates in the unification of our proposed "switch" mechanism for synaptic plasticity, coupling synaptic depression and synaptic potentiation processes together. While three or more spikes are required to probe this coupling, two spikes can never do so. We conclude that this coupling is critical to the presence of competitive dynamics and that multispike interactions are therefore vital to understanding synaptic competition.},
author = {Appleby, Peter a and Elliott, Terry},
doi = {10.1162/neco.2006.18.10.2414},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Stochastic Processes,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
number = {10},
pages = {2414--2464},
pmid = {16907632},
title = {{Stable competitive dynamics emerge from multispike interactions in a stochastic model of spike-timing-dependent plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16907632},
volume = {18},
year = {2006}
}
@article{Silva2005,
author = {Silva, SM and Ruano, AE},
isbn = {0780394224},
journal = {Neural Networks and Brain, 2005. {\ldots}},
title = {{Application of Levenberg-Marquardt method to the training of spiking neural networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1614882},
year = {2005}
}
@article{SatoSvoboda07,
abstract = {Cortical maps, consisting of orderly arrangements of functional columns,

are a hallmark of the organization of the cerebral cortex. However,

the microorganization of cortical maps at the level of single neurons

is not known, mainly because of the limitations of available mapping

techniques. Here, we used bulk loading of {\{}Ca{\}}{\^{}}{\{}2+{\}} indicators

combined with two-photon microscopy to image the activity of multiple

single neurons in layer (L) 2/3 of the mouse barrel cortex in vivo.

We developed methods that reliably detect single action potentials

in approximately half of the imaged neurons in L2/3. This allowed

us to measure the spiking probability following whisker deflection

and thus map the whisker selectivity for multiple neurons with known

spatial relationships. At the level of neuronal populations, the

whisker map varied smoothly across the surface of the cortex, within

and between the barrels. However, the whisker selectivity of individual

neurons recorded simultaneously differed greatly, even for nearest

neighbors. Trial-to-trial correlations between pairs of neurons were

high over distances spanning multiple cortical columns. Our data

suggest that the response properties of individual neurons are shaped

by highly specific subcolumnar circuits and the momentary intrinsic

state of the neocortex.},
author = {Sato, Takashi R and Gray, Noah W and Mainen, Zachary F and Svoboda, Karel},
doi = {10.1371/journal.pbio.0050189},
journal = {PLoS Biol},
month = {jul},
number = {7},
pages = {e189},
pmid = {17622195},
title = {{The Functional Microarchitecture of the Mouse Barrel Cortex.}},
url = {http://dx.doi.org/10.1371/journal.pbio.0050189},
volume = {5},
year = {2007}
}
@article{WB98,
author = {Williams, C and Barber, D},
journal = {IEEE PAMI},
pages = {1342--1351},
title = {{Bayesian classification with Gaussian processes}},
volume = {20},
year = {1998}
}
@article{Feldman2009,
abstract = {Sensory experience and learning alter sensory representations in cerebral cortex. The synaptic mechanisms underlying sensory cortical plasticity have long been sought. Recent work indicates that long-term cortical plasticity is a complex, multicomponent process involving multiple synaptic and cellular mechanisms. Sensory use, disuse, and training drive long-term potentiation and depression (LTP and LTD), homeostatic synaptic plasticity and plasticity of intrinsic excitability, and structural changes including formation, removal, and morphological remodeling of cortical synapses and dendritic spines. Both excitatory and inhibitory circuits are strongly regulated by experience. This review summarizes these findings and proposes that these mechanisms map onto specific functional components of plasticity, which occur in common across the primary somatosensory, visual, and auditory cortices.},
annote = {2010IInum11.7},
author = {Feldman, Daniel E},
doi = {10.1146/annurev.neuro.051508.135516},
issn = {1545-4126},
journal = {Annual Review of Neuroscience},
keywords = {Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Humans,Long-Term Potentiation,Long-Term Potentiation: physiology,Neural Inhibition,Neural Inhibition: physiology,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Perception,Perception: physiology,Sensation,Sensation: physiology,Synapses,Synapses: physiology,Synapses: ultrastructure,Synaptic Transmission,Synaptic Transmission: physiology,synapse},
mendeley-tags = {synapse},
pages = {33--55},
pmid = {19400721},
title = {{Synaptic mechanisms for plasticity in neocortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19400721},
volume = {32},
year = {2009}
}
@article{Salkoff2001,
author = {Salkoff, L and Butler, A and Fawcett, G and Kunkel, M},
journal = {Neuroscience},
keywords = {and mammals with tens,animal like,c,elegans,elegans with 302 neurons,evolution,genes,genome and the evolution,may differ between an,of,of the nervous system,potassium channels,task,the relationship between the,twik},
number = {4},
pages = {853--859},
title = {{Evolution tunes the excitability of individual neurons}},
url = {http://www.sciencedirect.com/science/article/pii/S0306452201000793},
volume = {103},
year = {2001}
}
@article{Chang2009a,
archivePrefix = {arXiv},
arxivId = {arXiv:0901.4275v1},
author = {Chang, HS and Weiss, Y and Freeman, WT},
eprint = {arXiv:0901.4275v1},
journal = {arXiv preprint arXiv:0901.4275},
pages = {1--26},
title = {{Informative sensing}},
url = {http://arxiv.org/abs/0901.4275},
year = {2009}
}
@article{Catsigeras2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1108.1501v1},
author = {Catsigeras, E and Guiraud, P},
eprint = {arXiv:1108.1501v1},
journal = {Arxiv preprint arXiv: {\ldots}},
keywords = {37b20,37b25,37n99,54c08,attractor,msc 2010,periodic points,piecewise contraction,recurrence},
pages = {1--30},
title = {{Beyond Periodicity for Piecewise Contracting Maps}},
url = {http://arxiv.org/abs/1108.1501},
year = {2011}
}
@article{von1988probabilistic,
annote = {2010IInum12.34},
author = {{Von Neumann}, J.},
journal = {Brain theory: reprint volume},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
pages = {110},
publisher = {World Scientific Pub Co Inc},
title = {{Probabilistic logics and the synthesis of reliable organisms from unreliable components}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=QaruU73YWGkC{\&}oi=fnd{\&}pg=PA110{\&}dq=PROBABILISTIC+LOGICS+AND+THE+SYNTHESIS+OP+RELIABLE.+ORGANISMS+PROM+UNRELIABLE+COMPONENTS{\&}ots=AdOY3cy2Nu{\&}sig=i80DJDGUrK51AETEzojzVtx5LwM http://www.google.com/books?hl=en{\&}lr={\&}id=QaruU73YWGkC{\&}oi=fnd{\&}pg=PA110{\&}dq=probabilistic+logics+and+synthesis+of+reliable+organisms{\&}ots=AdOZ-kBZFA{\&}sig=x7{\_}ZyegUqklndMIY-3VLguCmbCM},
year = {1988}
}
@article{KAPPEN00,
author = {Kappen, H J and Spanjers, J J},
journal = {Phys Rev E},
month = {may},
number = {5 Pt B},
pages = {5658--5663},
title = {{{\{}M{\}}ean field theory for asymmetric neural networks}},
volume = {61},
year = {2000}
}
@article{Parlitz1987,
author = {Parlitz, U. and Lauterborn, W.},
journal = {Physical Review A},
number = {3},
pages = {1428},
publisher = {APS},
title = {{Period-doubling cascades and devils staircases of the driven van der Pol oscillator}},
url = {http://pra.aps.org/abstract/PRA/v36/i3/p1428{\_}1},
volume = {36},
year = {1987}
}
@article{VossKurths04,
author = {Voss, Henning U and Timmer, Jens},
journal = {Int J Bifurc Chaos},
number = {6},
pages = {1905--1933},
title = {{Nonlinear Dynamical System Identification from Uncertain and Indirect Measurements}},
volume = {14},
year = {2004}
}
@article{Vogt2015,
author = {Vogt, Nina},
doi = {10.1038/nmeth.3306},
issn = {1548-7091},
journal = {Nature Methods},
month = {feb},
number = {3},
pages = {170--171},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Meth},
title = {{Microscopy: Fast volumetric imaging in live samples}},
url = {http://dx.doi.org/10.1038/nmeth.3306},
volume = {12},
year = {2015}
}
@article{Lorentz|1962|,
abstract = {The purpose of this paper is to give an introduction to some recent
developments connected with properties of compact sets of continuous
functions. These developments, because of their importance on one
hand and their simple and basic character on the other deserve to
be more widely known.},
author = {Lorentz, G G},
journal = {The american mathematical monthly},
keywords = {Kolmogorov theorem,function representation by superposition,function width,interpolation,mathematics,unread},
number = {6},
pages = {469},
title = {{Metric entropy, widths and superpositions of functions}},
volume = {69}
}
@article{Kalman60,
author = {Kalman, R E},
journal = {Journal of Basic Engineering},
number = {1},
pages = {35--45},
title = {{A new approach to linear filtering and prediction problems}},
volume = {82},
year = {1960}
}
@article{PARM98,
author = {Parmigiani, Giovanni},
journal = {Sankhya A},
pages = {446--458},
title = {{Designing Observation Times For Interval Censored Data}},
volume = {60},
year = {1998}
}
@article{Harris|1989|,
author = {Harris, K M and Stevens, J K},
journal = {J Neurosci},
keywords = {Animals Axons/ultrastructure Biophysics Dendrites/,Computer-Assisted Male Microscopy,Electron Models,Inbred Strains Synapses/ultrastructure,Neurological Neurons/classification/*ultrastructu},
number = {8},
pages = {2982--2997},
title = {{Dendritic spines of CA 1 pyramidal cells in the rat hippocampus: serial electron microscopy with reference to their biophysical characteristics}},
volume = {9}
}
@article{BC03,
author = {Bal, G and Chou, T},
journal = {Inverse Problems},
pages = {1053--1065},
title = {{On the reconstruction of diffusions using a single first-exit time distribution}},
volume = {20},
year = {2003}
}
@book{HJO01,
address = {Boston},
author = {Hyvarinen, A and Karhunen, J and Oja, E},
publisher = {Wiley},
title = {{Independent Component Analysis}},
year = {2001}
}
@article{MiyawakiTsien97,
author = {Miyawaki, A and Llopis, J and Heim, R and McCaffery, J M and Adams, J A and Ikura, M and Tsien, R Y},
journal = {Nature},
number = {6645},
pages = {882--887},
title = {{Fluorescent indicators for {\{}Ca{\}}{\^{}}{\{}2+{\}} based on green fluorescent proteins and calmodulin.}},
volume = {388},
year = {1997}
}
@article{Venkatesh1993,
author = {Venkatesh, S S},
doi = {10.1016/0022-0000(93)90003-F},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
month = {apr},
number = {2},
pages = {198--217},
title = {{Directed drift: A new linear threshold algorithm for learning binary weights on-line}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002200009390003F http://www.sciencedirect.com/science/article/pii/002200009390003F},
volume = {46},
year = {1993}
}
@article{AMP04,
author = {Andersen, R and Musallam, S and Pesaran, B},
journal = {Current Opinion in Neurobiology},
pages = {720--726},
title = {{Selecting the signals for a brain-machine interface}},
volume = {14},
year = {2004}
}
@misc{rswormatlas,
author = {Wormatlas.org},
title = {{Wormatlas: a database of behavioral and structural anatomy of Caenorhabditis elegans}}
}
@book{McLachlan2004,
author = {MacLachlan, Geoffrey J},
file = {::},
publisher = {Wiley-Interscience},
title = {{Discriminant analysis and statistical pattern recognition}},
year = {1992}
}
@article{NeherAugustine92,
abstract = {1. Digital imaging and photometry were used in conjunction with the

fluorescent Ca2+ indicator, Fura-2, to examine intracellular Ca2+

signals produced by depolarization of single adrenal chromaffin cells.

2. Depolarization with a patch pipette produced radial gradients

of Ca2+ within the cell, with Ca2+ concentration highest in the vicinity

of the plasma membrane. These gradients dissipated within a few hundred

milliseconds when the voltage-gated Ca2+ channels were closed. 3.

Dialysis of Fura-2 into the chromaffin cell caused concentration-dependent

changes in the depolarization-induced Ca2+ signal, decreasing its

magnitude and slowing its recovery time course. These changes were

used to estimate the properties of the endogenous cytoplasmic Ca2+

buffer with which Fura-2 competes for Ca2+. 4. The spatially averaged

Fura-2 signal was well described by a model assuming fast competition

between Fura-2 and an endogenous buffer on a millisecond time scale.

Retrieval of calcium by pumps and slow buffers occurs on a seconds-long

time scale. No temporal changes indicative of buffers with intermediate

kinetics could be detected. 5. Two independent estimates of the capacity

of the fast endogenous Ca2+ buffer suggest that 98-99{\%} of the Ca2+

entering the cell normally is taken up by this buffer. This buffer

appears to be immobile, because it does not wash out of the cell

during dialysis. It has a low affinity for Ca2+ ions, because it

does not saturate with 1 microM-Ca2+ inside the cell. 6. The low

capacity, affinity and mobility of the endogenous Ca2+ buffer makes

it possible for relatively small amounts of exogenous Ca2+ buffers,

such as Fura-2, to exert a significant influence on the characteristics

of the Ca2+ concentration signal as measured by fluorescence ratios.

On the other hand, even at moderate Fura-2 concentrations (0.4 mM)

Fura-2 will dominate over the endogenous buffers. Under these conditions

radiometric Ca2+ concentration signals are largely attenuated, but

absolute fluorescence changes (at 390 nm) accurately reflect calcium

fluxes.},
author = {Neher, E and Augustine, G J},
journal = {J Physiol},
keywords = {Adrenal Glands; Animals; Calcium; Calcium Channels,Biological,Cultured; Fura-2; Mathematics; Microscopy,Fluorescence; Models},
month = {may},
pages = {273--301},
pmid = {1331424},
title = {{Calcium gradients and buffers in bovine chromaffin cells.}},
volume = {450},
year = {1992}
}
@article{Zhang2011,
author = {Zhang, Yili and Liu, Rong-Yu and Heberton, George a and Smolen, Paul and Baxter, Douglas a and Cleary, Leonard J and Byrne, John H},
doi = {10.1038/nn.2990},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {dec},
number = {2},
pages = {294--297},
publisher = {Nature Publishing Group},
title = {{Computational design of enhanced learning protocols}},
url = {http://www.nature.com/doifinder/10.1038/nn.2990},
volume = {15},
year = {2011}
}
@article{Chen05,
author = {Chen, Zhe and Becker, Suzanna and Bondy, Jeff and Bruce, Ian C and Haykin, Simon C},
issn = {0899-7667},
journal = {Neural Comput.},
number = {12},
pages = {2648--2671},
title = {{A Novel Model-Based Hearing Compensation Design Using a Gradient-Free Optimization Method}},
volume = {17},
year = {2005}
}
@article{Komiyama2010,
abstract = {Cortical neurons form specific circuits, but the functional structure of this microarchitecture and its relation to behaviour are poorly understood. Two-photon calcium imaging can monitor activity of spatially defined neuronal ensembles in the mammalian cortex. Here we applied this technique to the motor cortex of mice performing a choice behaviour. Head-fixed mice were trained to lick in response to one of two odours, and to withhold licking for the other odour. Mice routinely showed significant learning within the first behavioural session and across sessions. Microstimulation and trans-synaptic tracing identified two non-overlapping candidate tongue motor cortical areas. Inactivating either area impaired voluntary licking. Imaging in layer 2/3 showed neurons with diverse response types in both areas. Activity in approximately half of the imaged neurons distinguished trial types associated with different actions. Many neurons showed modulation coinciding with or preceding the action, consistent with their involvement in motor control. Neurons with different response types were spatially intermingled. Nearby neurons (within approximately 150 mum) showed pronounced coincident activity. These temporal correlations increased with learning within and across behavioural sessions, specifically for neuron pairs with similar response types. We propose that correlated activity in specific ensembles of functionally related neurons is a signature of learning-related circuit plasticity. Our findings reveal a fine-scale and dynamic organization of the frontal cortex that probably underlies flexible behaviour.},
annote = {2010IInum10.6},
author = {Komiyama, Takaki and Sato, Takashi R and O'Connor, Daniel H and Zhang, Ying-Xin and Huber, Daniel and Hooks, Bryan M and Gabitto, Mariano and Svoboda, K},
doi = {10.1038/nature08897},
issn = {1476-4687},
journal = {Nature},
month = {apr},
number = {7292},
pages = {1182--1186},
pmid = {20376005},
publisher = {Nature Publishing Group},
title = {{Learning-related fine-scale specificity imaged in motor cortex circuits of behaving mice.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20376005},
volume = {464},
year = {2010}
}
@article{Boucsein2009,
abstract = {To understand the mechanisms of fast information processing in the brain, it is necessary to determine how rapidly populations of neurons can respond to incoming stimuli in a noisy environment. Recently, it has been shown experimentally that an ensemble of neocortical neurons can track a time-varying input current in the presence of additive correlated noise very fast, up to frequencies of several hundred hertz. Modulations in the firing rate of presynaptic neuron populations affect, however, not only the mean but also the variance of the synaptic input to postsynaptic cells. It has been argued that such modulations of the noise intensity (multiplicative modulation) can be tracked much faster than modulations of the mean input current (additive modulation). Here, we compare the response characteristics of an ensemble of neocortical neurons for both modulation schemes. We injected sinusoidally modulated noisy currents (additive and multiplicative modulation) into layer V pyramidal neurons of the rat somatosensory cortex and measured the trial and ensemble-averaged spike responses for a wide range of stimulus frequencies. For both modulation paradigms, we observed low-pass behavior. The cutoff frequencies were markedly high, considerably higher than the average firing rates. We demonstrate that modulations in the variance can be tracked significantly faster than modulations in the mean input. Extremely fast stimuli (up to 1 kHz) can be reliably tracked, provided the stimulus amplitudes are sufficiently high.},
annote = {ההבדל בין רעש כפלי לחיבורי לא נובע פשוט מכך שרעש חיבורי קטן ביחס לסינוס, בעוד שרעש כיפלי יכול ליצור שינויים גדולים?},
author = {Boucsein, Cl and Tetzlaff, T and Meier, R and Aertsen, A and Naundorf, B},
doi = {10.1523/JNEUROSCI.3424-08.2009},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Biophysical Processes,Electric Stimulation,Electric Stimulation: methods,Long-Evans,Membrane Potentials,Membrane Potentials: physiology,Neocortex,Neocortex: cytology,Newborn,Noise,Nonlinear Dynamics,Patch-Clamp Techniques,Patch-Clamp Techniques: methods,Pyramidal Cells,Pyramidal Cells: physiology,Rats},
month = {jan},
number = {4},
pages = {1006--10},
pmid = {19176809},
title = {{Dynamical response properties of neocortical neuron ensembles: multiplicative versus additive noise.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19176809},
volume = {29},
year = {2009}
}
@article{Parisi1986,
author = {Parisi, Giorgio},
journal = {Journal of Physics A: Mathematical and General},
title = {{A memory which forgets}},
url = {http://iopscience.iop.org/0305-4470/19/10/011},
volume = {617},
year = {1999}
}
@article{Markram2006,
abstract = {IBM's Blue Gene supercomputer allows a quantum leap in the level of detail at which the brain can be modelled. I argue that the time is right to begin assimilating the wealth of data that has been accumulated over the past century and start building biologically accurate models of the brain from first principles to aid our understanding of brain function and dysfunction.},
author = {Markram, Henry},
doi = {10.1038/nrn1848},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Brain,Humans,Models, Neurological,Neural Networks (Computer),Quantum Theory},
month = {feb},
number = {2},
pages = {153--60},
pmid = {16429124},
shorttitle = {Nat Rev Neurosci},
title = {{The blue brain project.}},
url = {http://dx.doi.org/10.1038/nrn1848},
volume = {7},
year = {2006}
}
@article{Bemporad2002,
author = {Bemporad, a},
doi = {10.1016/S0005-1098(01)00174-1},
issn = {00051098},
journal = {Automatica},
keywords = {constraints,linear quadratic regulators,piecewise linear controllers,predictive control},
month = {jan},
number = {1},
pages = {3--20},
title = {{The explicit linear quadratic regulator for constrained systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0005109801001741},
volume = {38},
year = {2002}
}
@article{LeFeber2008,
abstract = {Learning, or more generally, plasticity may be studied using cultured neuronal networks on multi electrode arrays. Many protocols have been proposed to change connectivity in such networks. So far, only one of these protocols, proposed by Shahaf and Marom, aimed to change the input-output relationship of a selected connection in the network. Although the results were quite promising, the experiments appeared difficult to repeat and the protocol did not serve as a basis for wider investigation yet. Here, we repeated their protocol, and compared our 'learning curves' to the original results. Although in some experiments the protocol did not seem to work, we found that on average, the protocol showed a significant learning effect indeed. We frequently found learning curves that initially declined as in the original results, but then increased again before finally settling at a low level.},
author = {le Feber, Joost and Stegenga, Jan and Rutten, Wim and Feber, Joost},
doi = {10.1109/IEMBS.2008.4650356},
isbn = {9781424418152},
issn = {1557-170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cells,Cerebral Cortex,Cerebral Cortex: physiology,Computer Simulation,Cultured,Electric Stimulation,Electric Stimulation: methods,Learning,Learning: physiology,Models,Nerve Net,Nerve Net: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Newborn,Rats,Synaptic Transmission,Synaptic Transmission: physiology,Wistar},
month = {jan},
pages = {5081--4},
pmid = {19163859},
title = {{Do external stimuli, applied to train cultured cortical networks, disturb the balance between activity and connectivity?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19163859},
volume = {2008},
year = {2008}
}
@article{Du2017,
abstract = {Although gradient descent (GD) almost always escapes saddle points asymptotically [Lee et al., 2016], this paper shows that even with fairly natural random initialization schemes and non-pathological functions, GD can be significantly slowed down by saddle points, taking exponential time to escape. On the other hand, gradient descent with perturbations [Ge et al., 2015, Jin et al., 2017] is not slowed down by saddle points—it can find an approximate local minimizer in polynomial time. This result implies that GD is inherently slower than perturbed GD, and justifies the importance of adding perturbations for efficient non-convex optimization. While our focus is theoretical, we also present experiments that illustrate our theoretical findings.},
archivePrefix = {arXiv},
arxivId = {1705.10412},
author = {Du, Simon S and Jin, Chi and Lee, Jason D and Jordan, Michael I and P{\'{o}}czos, Barnab{\'{a}}s and Singh, Aarti},
eprint = {1705.10412},
journal = {arXiv},
pages = {1--21},
title = {{Gradient Descent Can Take Exponential Time to Escape Saddle Points}},
url = {https://arxiv.org/pdf/1705.10412.pdf},
year = {2017}
}
@article{Sorra|2000|,
author = {Sorra, K E and Harris, K M},
journal = {Hippocampus},
pages = {501--511},
title = {{Overview on the structure, composition, function, development, and plasticity of hippocampal dendritic spines}},
volume = {10}
}
@article{Welchman08,
author = {Welchman, Andrew E and Lam, Judith M and Bulthoff, Heinrich H},
journal = {Proceedings of the National Academy of Sciences},
number = {33},
pages = {12087--12092},
title = {{Bayesian motion estimation accounts for a surprising bias in 3D vision}},
volume = {105},
year = {2008}
}
@article{Faber2007,
author = {Faber, G M and Silva, J and Livshitz, L and Rudy, Y},
journal = {Biophysical Journal},
number = {5},
pages = {1522--1543},
publisher = {Elsevier},
title = {{Kinetic properties of the cardiac L-type Ca2+ channel and its role in myocyte electrophysiology: a theoretical investigation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S000634950770961X},
volume = {92},
year = {2007}
}
@article{Badel08b,
author = {Badel, Laurent and Lefort, Sandrine and Berger, Thomas K and Petersen, Carl C H and Gerstner, Wulfram and Richardson, Magnus J E},
journal = {Biological Cybernetics},
pages = {361--370},
title = {{Extracting non-linear integrate-and-fire models from experimental data using dynamic {\{}I-V{\}} curves}},
volume = {99},
year = {2008}
}
@article{Daum2005,
annote = {2010num1.5},
author = {Daum, F and Co, R},
journal = {IEEE Aerospace and Electronic Systems Magazine},
title = {{Nonlinear filters: beyond the Kalman filter}},
url = {http://scholar.google.com/scholar?hl=en{\&}q={\%}22Nonlinear+Filters:+beyond+the+kalman+filter{\%}22+{\&}btnG=Search{\&}as{\_}sdt=2000{\&}as{\_}ylo={\&}as{\_}vis=0{\#}0},
year = {2005}
}
@book{Ricc77,
author = {Ricciardi, L},
publisher = {Springer},
title = {{Diffusion processes and related topics in biology}},
year = {1977}
}
@incollection{Long|2008|,
author = {Long, F and Peng, H and Liu, X and Kim, S and Myers, E},
booktitle = {Lecture Notes in Computer Science: Research in Computational Molecular Biology},
pages = {128--139},
publisher = {Springer Berlin},
title = {{Automatic recognition of cells (ARC) for 3D images of C. Elegans.}}
}
@article{Mattia2000a,
author = {Mattia, Maurizio},
pages = {2305--2329},
title = {{Efficient Event-Driven Simulation of Large Networks of}},
volume = {2329},
year = {2000}
}
@article{Boyd2006,
annote = {2010IIInum47},
author = {Boyd, S and Ghosh, A and Prabhakar, B and Shah, D},
doi = {10.1109/TIT.2006.874516},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {jun},
number = {6},
pages = {2508--2530},
title = {{Randomized gossip algorithms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1638541},
volume = {52},
year = {2006}
}
@article{MulyPotashner02,
abstract = {Chinchillas are notable for a low-frequency hearing range similar

to that of humans and a marked sensitivity to loud noise. A single

noise exposure that produces cochlear damage may lead to progressive

loss of synaptic endings in the cochlear nucleus, followed by new

axonal growth. As an index of synaptic regulation during such changes,

we have examined the expression of a synaptic vesicle protein, synaptophysin,

in the cochlear nucleus following a damaging acoustic stimulus in

adult chinchillas. With one ear protected by a plug, following a

3-h exposure to an octave-band noise of 108 dB sound pressure level,

centered at 4 kHz, the unprotected cochlea and the cochlear nuclei

exhibited degeneration of hair cells and axons over periods of 7,

14, 30, 90, and 150 days. Axonal degeneration, as revealed by a silver

degeneration method, was heavy ipsilateral to the cochlear damage,

but sparse degeneration also appeared on the contralateral, unexposed

side. Synaptophysin immunostaining underwent a major, bilateral decline

in the anteroventral and posteroventral cochlear nuclei, interrupted

at intervening periods by transient increases in the numbers of stained

structures. A distinction in staining between large perisomatic structures

and smaller puncta in the neuropil and between the dorsal and the

ventral zones of the ventral cochlear nuclei revealed some variations

in the response and degree of recovery of synaptophysin staining.

These findings could best be explained by degeneration of synaptic

endings followed by new growth of terminals and by regulatory changes

in the levels of synaptophysin expression and synaptic vesicle accumulation

over time.},
author = {Muly, S M and Gross, J S and Morest, D K and Potashner, S J},
journal = {Experimental Neurology},
keywords = {Acoustic Stimulation; Animals; Axons; Chinchilla;,P.H.S.; Synaptophysin,U.S. Gov't},
month = {sep},
number = {1},
pages = {202--221},
pmid = {12429223},
title = {{Synaptophysin in the cochlear nucleus following acoustic trauma.}},
volume = {177},
year = {2002}
}
@article{Gamerman98,
author = {Gamerman, Dani},
journal = {Biometrika},
number = {1},
pages = {215--227},
title = {{Markov Chain Monte Carlo for Dynamic Generalised Linear Models}},
volume = {85},
year = {1998}
}
@article{Linaro2011a,
abstract = {Understanding the computational capabilities of the nervous system means to "identify" its emergent multiscale dynamics. For this purpose, we propose a novel model-driven identification procedure and apply it to sparsely connected populations of excitatory integrate-and-fire neurons with spike frequency adaptation (SFA). Our method does not characterize the system from its microscopic elements in a bottom-up fashion, and does not resort to any linearization. We investigate networks as a whole, inferring their properties from the response dynamics of the instantaneous discharge rate to brief and aspecific supra-threshold stimulations. While several available methods assume generic expressions for the system as a black box, we adopt a mean-field theory for the evolution of the network transparently parameterized by identified elements (such as dynamic timescales), which are in turn non-trivially related to single-neuron properties. In particular, from the elicited transient responses, the input-output gain function of the neurons in the network is extracted and direct links to the microscopic level are made available: indeed, we show how to extract the decay time constant of the SFA, the absolute refractory period and the average synaptic efficacy. In addition and contrary to previous attempts, our method captures the system dynamics across bifurcations separating qualitatively different dynamical regimes. The robustness and the generality of the methodology is tested on controlled simulations, reporting a good agreement between theoretically expected and identified values. The assumptions behind the underlying theoretical framework make the method readily applicable to biological preparations like cultured neuron networks and in vitro brain slices.},
author = {Linaro, D and Storace, Marco and Mattia, Maurizio},
doi = {10.3389/fncom.2011.00043},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {linear dynamical regime,mean-field theory,non-,non-linear dynamical regime,spike frequency adaptation,spiking neuron networks,system bifurcations,system identification},
month = {jan},
number = {October},
pages = {43},
pmid = {22016731},
title = {{Inferring network dynamics and neuron properties from population recordings}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3191764{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3191764/},
volume = {5},
year = {2011}
}
@article{Wagenaar:2005ys,
abstract = {One of the major modes of activity of high-density cultures of dissociated
neurons is globally synchronized bursting. Unlike in vivo, neuronal
ensembles in culture maintain activity patterns dominated by global
bursts for the lifetime of the culture (up to 2 years). We hypothesize
that persistence of bursting is caused by a lack of input from other
brain areas. To study this hypothesis, we grew small but dense monolayer
cultures of cortical neurons and glia from rat embryos on multi-electrode
arrays and used electrical stimulation to substitute for afferents.
We quantified the burstiness of the firing of the cultures in spontaneous
activity and during several stimulation protocols. Although slow
stimulation through individual electrodes increased burstiness as
a result of burst entrainment, rapid stimulation reduced burstiness.
Distributing stimuli across several electrodes, as well as continuously
fine-tuning stimulus strength with closed-loop feedback, greatly
enhanced burst control. We conclude that externally applied electrical
stimulation can substitute for natural inputs to cortical neuronal
ensembles in transforming burst-dominated activity to dispersed spiking,
more reminiscent of the awake cortex in vivo. This nonpharmacological
method of controlling bursts will be a critical tool for exploring
the information processing capacities of neuronal ensembles in vitro
and has potential applications for the treatment of epilepsy.},
author = {Wagenaar, D A and Madhavan, Radhika and Pine, Jerome and Potter, S M},
doi = {10.1523/JNEUROSCI.4209-04.2005},
journal = {Journal of Neuroscience},
keywords = {networks},
mendeley-tags = {networks},
number = {3},
pages = {680--688},
pmid = {15659605},
title = {{Controlling bursting in cortical cultures with closed-loop multi-electrode stimulation}},
volume = {25},
year = {2005}
}
@article{Harris|1992|,
author = {Harris, K M and Jensen, F E and B., Tsao},
journal = {J Neurosci},
pages = {2685--2705},
title = {{Three-dimensional structure of dendritic spines and synapses in rat hippocampus (CA1) at postnatal day 15 and young adult ages: Implications for the maturation of synaptic physiology and long term potentiation.}},
volume = {12}
}
@article{Kerr05,
author = {Kerr, Jason N D and Greenberg, David and Helmchen, Fritjof},
journal = {PNAS},
month = {sep},
number = {39},
pages = {14063--14068},
title = {{Imaging input and output of neocortical networks in vivo}},
volume = {102},
year = {2005}
}
@phdthesis{SAHPHD,
author = {Sahani, M},
school = {California Institute of Technology},
title = {{Latent variable models for neural data analysis}},
year = {1999}
}
@article{Mosher|1992|,
abstract = {Localization error bounds are presented for both EEG and MEG as graphical
error contours for a 37 sensor arrangment. Both one and two dipole
cases were examined for all possible dipole orientations and locations
within a head quadrant. The results show a strong dependence on absolute
dipole location and orientation. The results also show that fusion
of the EEG and MEG measurements into a combined model reduces the
lower bound. A Monte-Carlo simulation was performed to check the
tightness of the bounds for a selected case. The simple head model,
the white and relatively low power noise, and the few relatively
strong dipoles were all selected in this study as optimistic conditions
to establish possibly fundamental resolution limits for any localization
effort.},
annote = {The paper derives spatial resolution limits of EEG. It is shown that{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}spatial resolution is of the order of 1cm, consistent with the spatial{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}separation of the electrodes themselves.},
author = {Mosher, J C and Spencer, M E and Leahy, R M and Lewis, P S},
journal = {IEEE},
keywords = {electroencyphalogram,localization,magnetoencephalograms,neurobiology,resolution},
pages = {150},
title = {{Error bounds for MEG and EEG source localization}}
}
@article{BK04,
author = {Bellare, M and Kohno, T},
journal = {EUROCRYPT},
pages = {401--418},
title = {{Hash Function Balance and Its Impact on Birthday Attacks}},
year = {2004}
}
@article{GCK86,
author = {Georgopoulos, A and Kettner, R and Schwartz, A},
journal = {Science},
pages = {1416--1419},
title = {{Neuronal population coding of movement direction}},
volume = {233},
year = {1986}
}
@article{Dimitrov09,
author = {Dimitrov, Alexander and Sheiko, Melissa and Baker, Jonathan and Yen, Shih-Cheng},
journal = {Journal of Computational Neuroscience},
title = {{Spatial and temporal jitter distort estimated functional properties of visual sensory neurons}},
year = {2009}
}
@article{todorov2000direct,
annote = {2010IInum12.1},
author = {Todorov, E},
journal = {Nature Neuroscience},
pages = {391--398},
publisher = {NATURE AMERICA},
title = {{Direct cortical control of muscle activation in voluntary arm movements: a model}},
volume = {3},
year = {2000}
}
@article{Anderson2000a,
author = {Anderson, J. S.},
doi = {10.1126/science.290.5498.1968},
issn = {00368075},
journal = {Science},
month = {dec},
number = {5498},
pages = {1968--1972},
title = {{The Contribution of Noise to Contrast Invariance of Orientation Tuning in Cat Visual Cortex}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.290.5498.1968},
volume = {290},
year = {2000}
}
@article{Zhang2014,
abstract = {This paper investigates the exponential synchronization of coupled memristor-based chaotic neural networks with both time-varying delays and general activation functions. And here, we adopt nonsmooth analysis and control theory to handle memristor-based chaotic neural networks with discontinuous right-hand side. In particular, several new criteria ensuring exponential synchronization of two memristor-based chaotic neural networks are obtained via periodically intermittent control. In addition, the new proposed results here are very easy to verify and also complement, extend the earlier publications. Numerical simulations on the chaotic systems are presented to illustrate the effectiveness of the theoretical results.},
author = {Zhang, Guodong and Shen, Yi},
doi = {10.1016/j.neunet.2014.03.009},
issn = {1879-2782},
journal = {Neural networks: the official journal of the International Neural Network Society},
keywords = {chaotic dynamical systems,exponential synchronization},
month = {jul},
pages = {1--10},
pmid = {24704882},
publisher = {Elsevier Ltd},
title = {{Exponential synchronization of delayed memristor-based chaotic neural networks via periodically intermittent control.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24704882},
volume = {55},
year = {2014}
}
@inproceedings{KruminShoham08,
author = {Krumin, M and Shoham, S},
booktitle = {14th Nordic-Baltic Conference on Biomedical Engineering and Medical Physics},
pages = {378--379},
title = {{Characterization of Input-Output Relations in Single Neurons using Spatiotemporal Photo-stimulation}},
year = {2008}
}
@article{Banerjee2005,
annote = {2011num26},
author = {Banerjee, A and Guo, X and Wang, H},
doi = {10.1109/TIT.2005.850145},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {jul},
number = {7},
pages = {2664--2669},
title = {{On the Optimality of Conditional Expectation as a Bregman Predictor}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1459065},
volume = {51},
year = {2005}
}
@article{Sanger1989,
author = {Sanger, Terence D.},
doi = {10.1016/0893-6080(89)90044-0},
issn = {08936080},
journal = {Neural Networks},
keywords = {--neural network,cortical receptive fields,feedforward,form,hebbian learning,image coding,karhunen-loeve trans-,texture,unsupervised learning},
month = {jan},
number = {6},
pages = {459--473},
title = {{Optimal unsupervised learning in a single-layer linear feedforward neural network}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0893608089900440},
volume = {2},
year = {1989}
}
@article{Zamarreno-Ramos2011,
abstract = {In this paper we present a very exciting overlap between emergent nanotechnology and neuroscience, which has been discovered by neuromorphic engineers. Specifically, we are linking one type of memristor nanotechnology devices to the biological synaptic update rule known as spike-time-dependent-plasticity (STDP) found in real biological synapses. Understanding this link allows neuromorphic engineers to develop circuit architectures that use this type of memristors to artificially emulate parts of the visual cortex. We focus on the type of memristors referred to as voltage or flux driven memristors and focus our discussions on a behavioral macro-model for such devices. The implementations result in fully asynchronous architectures with neurons sending their action potentials not only forward but also backward. One critical aspect is to use neurons that generate spikes of specific shapes. We will see how by changing the shapes of the neuron action potential spikes we can tune and manipulate the STDP learning rules for both excitatory and inhibitory synapses. We will see how neurons and memristors can be interconnected to achieve large scale spiking learning systems, that follow a type of multiplicative STDP learning rule. We will briefly extend the architectures to use three-terminal transistors with similar memristive behavior. We will illustrate how a V1 visual cortex layer can assembled and how it is capable of learning to extract orientations from visual data coming from a real artificial CMOS spiking retina observing real life scenes. Finally, we will discuss limitations of currently available memristors. The results presented are based on behavioral simulations and do not take into account non-idealities of devices and interconnects. The aim of this paper is to present, in a tutorial manner, an initial framework for the possible development of fully asynchronous STDP learning neuromorphic architectures exploiting two or three-terminal memristive type devices. All files used for the simulations are made available through the journal web site.},
author = {Zamarre{\~{n}}o-Ramos, C and Camu{\~{n}}as-Mesa, L A and P{\'{e}}rez-Carrasco, J A and Masquelier, T and Serrano-Gotarredona, T and Linares-Barranco, B},
doi = {10.3389/fnins.2011.00026},
issn = {1662-453X},
journal = {Frontiers in neuroscience},
keywords = {learning,memristor,nanotechnology,neural network,spikes,stdp,synapses,visual cortex},
month = {jan},
pages = {26},
pmid = {21442012},
title = {{On spike-timing-dependent-plasticity, memristive devices, and building a self-learning visual cortex}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3062969{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2011}
}
@article{Rangarajan2000a,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0105266v1},
author = {Rangarajan, Govindan},
eprint = {0105266v1},
journal = {Physics Letters A},
primaryClass = {arXiv:cond-mat},
title = {{First passage time distribution for anomalous diffusion}},
url = {http://www.sciencedirect.com/science/article/pii/S0375960100005181},
year = {2000}
}
@article{colbert1996axonal,
author = {Colbert, C.M. and Johnston, D.},
journal = {The Journal of neuroscience},
number = {21},
pages = {6676},
publisher = {Society for Neuroscience},
title = {{Axonal action-potential initiation and Na+ channel densities in the soma and axon initial segment of subicular pyramidal neurons}},
url = {http://neuro.cjb.net/content/16/21/6676.short},
volume = {16},
year = {1996}
}
@article{TIP01,
author = {Tipping, M},
journal = {Journal of Machine Learning Research},
pages = {211--244},
title = {{Sparse {\{}B{\}}ayesian learning and the relevance vector machine}},
volume = {1},
year = {2001}
}
@phdthesis{Neal95,
author = {Neal, R M},
number = {118},
publisher = {Springer},
school = {University of Toronto},
series = {Lecture Notes in Statistics},
title = {{Bayesian learning for neural networks}},
url = {http://www.db.toronto.edu/{~}radford/ftp/thesis.pdf},
year = {1995}
}
@article{Dickman2000,
author = {Dickman, R and Mu{\~{n}}oz, MA},
journal = {Brazilian Journal of  {\ldots}},
title = {{Paths to self-organized criticality}},
url = {http://www.scielo.br/scielo.php?pid=S0103-97332000000100004{\&}script=sci{\_}arttext},
year = {2000}
}
@article{Schwalger2010,
annote = {2010IIInum74},
author = {Schwalger, T and Fisch, K and Benda, J and Lindner, B},
doi = {10.1371/journal.pcbi.1001026},
editor = {Latham, Peter E},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {dec},
number = {12},
pages = {e1001026},
title = {{How Noisy Adaptation of Neurons Shapes Interspike Interval Histograms and Correlations}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1001026},
volume = {6},
year = {2010}
}
@article{Imennov2009,
abstract = {We have developed a biophysical model of a population of electrically stimulated auditory nerve fibers. It can be used to interpret results from physiological and behavioral experiments with cochlear implants and propose novel stimulation strategies. Our model consists of myelinated internodes described by a passive resistor-capacitor network, membrane capacitance, and leakage current at the nodes of Ranvier, as well as stochastic representations of nodal voltage-dependent channels. To approximate physiological properties measured in the auditory nerve (AN) of an acutely deafened cat, electrical parameters of the model fiber were chosen based on literature-reported values. Using our model, we have replicated the following properties within 10 {\%} of the reported feline single-fiber measurements: relative spread (5.8 {\%}), spike latency (630 micros), jitter (93 micros), chronaxie (238 micros), relative refractory period (4.6 ms), and conduction velocity (14 m/s). Moreover, we have successfully matched response characteristics of a population of fibers with the same number of diameter-distributed model fibers, enabling us to simulate responses of the entire AN. To demonstrate the performance of our model, we compare responses of a population of ANs stimulated with two speech encoding strategies, Continuous Interleaved Sampling and Compressed Analog.},
author = {Imennov, Nikita S and Rubinstein, Jay T},
doi = {10.1109/TBME.2009.2016667},
issn = {1558-2531},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Animals,Cats,Cochlear Implants,Cochlear Nerve,Cochlear Nerve: physiology,Computer Simulation,Electric Stimulation,Electric Stimulation: methods,Ion Channel Gating,Ion Channel Gating: physiology,Models, Neurological,Nerve Fibers,Nerve Fibers: physiology,Ranvier's Nodes,Ranvier's Nodes: physiology,Signal Processing, Computer-Assisted,Spiral Ganglion,Spiral Ganglion: physiology,Stochastic Processes},
month = {oct},
number = {10},
pages = {2493--501},
pmid = {19304476},
title = {{Stochastic population model for electrical stimulation of the auditory nerve.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19304476},
volume = {56},
year = {2009}
}
@article{Coron2012,
author = {Coron, JM},
number = {September},
pages = {1--24},
title = {{My main works in control theory}},
url = {http://www.ann.jussieu.fr/{~}coron/Documents/Main{\_}works{\_}in{\_}control{\_}theory.pdf},
year = {2012}
}
@article{NelkenYoung97,
author = {Nelken, I and Young, E D},
journal = {Journal of Neurophysiology},
month = {aug},
number = {2},
pages = {790--799},
title = {{Linear and nonlinear spectral integration in type IV neurons of the dorsal cochlear nucleus I Regions of linear interaction}},
volume = {78},
year = {1997}
}
@article{Wolters07,
author = {Wolters, C},
journal = {SIAM News},
number = {2},
title = {{The Finite Element Method in {\{}EEG/MEG{\}} Source Analysis}},
volume = {52},
year = {2007}
}
@article{Schooler2009,
author = {Schooler, Jonathan and Barbara, Santa},
title = {{The Brain Stop Paying Attention: Zoning Out Is a Crucial Mental State}},
year = {2009}
}
@book{BIL95,
address = {New York},
author = {Billingsley, P.},
edition = {Third},
publisher = {Wiley},
title = {{Probability and Measure}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Probability+and+Measure{\#}0},
year = {1995}
}
@techreport{bilmes1997-em,
author = {Bilmes, Jeff},
institution = {ICSI},
number = {TR-97-021},
title = {{A Gentle Tutorial of the {\{}EM{\}} algorithm and its application to Parameter Estimation for {\{}G{\}}aussian Mixture and Hidden {\{}M{\}}arkov Models}},
year = {1997}
}
@article{Maisak2013,
author = {Maisak, Matthew S. and Haag, Juergen and Ammer, Georg and Serbe, Etienne and Meier, Matthias and Leonhardt, Aljoscha and Schilling, Tabea and Bahl, Armin and Rubin, Gerald M. and Nern, Aljoscha and Dickson, Barry J. and Reiff, Dierk F. and Hopp, Elisabeth and Borst, Alexander},
doi = {10.1038/nature12320},
issn = {0028-0836},
journal = {Nature},
month = {aug},
number = {7461},
pages = {212--216},
publisher = {Nature Publishing Group},
title = {{A directional tuning map of Drosophila elementary motion detectors}},
url = {http://www.nature.com/doifinder/10.1038/nature12320},
volume = {500},
year = {2013}
}
@article{Jahnke2009a,
author = {Jahnke, S and Memmesheimer, R M and Timme, M},
doi = {10.1186/1471-2202-10-S1-O20},
number = {01},
pages = {2008--2009},
title = {{BMC Neuroscience}},
volume = {2},
year = {2009}
}
@article{Marinari1983a,
author = {Marinari, E. and Parisi, G. and Ruelle, D. and Windey, P.},
doi = {10.1007/BF01219521},
issn = {0010-3616},
journal = {Communications in Mathematical Physics},
month = {mar},
number = {1},
pages = {1--12},
title = {{On the interpretation of 1/f noise}},
url = {http://www.springerlink.com/index/10.1007/BF01219521},
volume = {89},
year = {1983}
}
@article{Gamerman97,
author = {Gamerman, Dani},
journal = {Statistics and Computing},
number = {1},
pages = {57--68},
title = {{Sampling from the posterior distribution in generalized linear mixed models}},
volume = {7},
year = {1997}
}
@article{Pullum|2006|,
abstract = {MATHEMATICAL LINGUISTICS is the study of mathematical structures and
methods that are of importance to linguistics. As in other branches
of applied mathematics, the in uence of the empirical subject matter
is somewhat indirect: theorems are often proved more for their inherent
mathematical value than for their applicability. Nevertheless, the
internal organization of linguistics remains the best guide for understanding
the internal subdivisions of mathematical linguistics, and we will
survey the eld following the traditional division of linguistics
into ! Phonetics, ! Phonology, ! Morphology, ! Syntax, and ! Semantics,
looking at other branches of linguistics such as ! Sociolinguistics
or ! Language Acquisition only to the extent that these have developed
their own mathematical methods.},
author = {Pullum, G K and Kornai, A},
keywords = {codes,language,linguistics,markov,mathematics,phonetics},
title = {{Mathematical Linguistics}}
}
@article{YusteKatz91,
author = {Yuste, R and Katz, L C},
journal = {Neuron},
pages = {333--344},
title = {{Control of postsynaptic {\{}Ca{\^{}}{\{}2+{\}}{\}} influx in developing neocortex by excitatory and inhibitory neurotransmitters}},
volume = {6},
year = {1991}
}
@article{Steinmetz2000,
abstract = {Voltage-gated ion channels in neuronal membranes fluctuate randomly between different conformational states due to thermal agitation. Fluctuations between conducting and nonconducting states give rise to noisy membrane currents and subthreshold voltage fluctuations and may contribute to variability in spike timing. Here we study subthreshold voltage fluctuations due to active voltage-gated Na+ and K+ channels as predicted by two commonly used kinetic schemes: the Mainen et al. (1995) (MJHS) kinetic scheme, which has been used to model dendritic channels in cortical neurons, and the classical Hodgkin-Huxley (1952) (HH) kinetic scheme for the squid giant axon. We compute the magnitudes, amplitude distributions, and power spectral densities of the voltage noise in isopotential membrane patches predicted by these kinetic schemes. For both schemes, noise magnitudes increase rapidly with depolarization from rest. Noise is larger for smaller patch areas but is smaller for increased model temperatures. We contrast the results from Monte Carlo simulations of the stochastic nonlinear kinetic schemes with analytical, closed-form expressions derived using passive and quasi-active linear approximations to the kinetic schemes. For all subthreshold voltage ranges, the quasi-active linearized approximation is accurate within 8{\%} and may thus be used in large-scale simulations of realistic neuronal geometries.},
author = {Steinmetz, P N and Manwani, a and Koch, C and London, M and Segev, I},
issn = {0929-5313},
journal = {Journal of Computational Neuroscience},
keywords = {Animals,Cell Membrane,Cell Membrane: metabolism,Cell Membrane: ultrastructure,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Humans,Kinetics,Linear Models,Membrane Potentials,Membrane Potentials: physiology,Models,Monte Carlo Method,Neurological,Neurons,Neurons: metabolism,Neurons: ultrastructure,Patch-Clamp Techniques,Potassium Channels,Potassium Channels: metabolism,Potassium Channels: ultrastructure,Sodium Channels,Sodium Channels: metabolism,Sodium Channels: ultrastructure,Temperature},
number = {2},
pages = {133--48},
pmid = {11030518},
title = {{Subthreshold voltage noise due to channel fluctuations in active neuronal membranes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11030518},
volume = {9},
year = {2000}
}
@book{SN95,
editor = {Sakmann, B and Neher, B},
publisher = {Springer},
title = {{Single-channel recording}},
year = {1995}
}
@book{Herman|1999|,
address = {Boston},
author = {Herman, G T and Kuba, A},
publisher = {Birkhauser},
title = {{Discrete Tomography: Foundations, Algorithms, and Applications.}}
}
@article{Badel2008,
author = {Badel, Laurent and Lefort, Sandrine},
doi = {10.1152/jn.01107.2007.},
journal = {Journal of {\ldots}},
pages = {656--666},
title = {{Dynamic IV curves are reliable predictors of naturalistic pyramidal-neuron voltage traces}},
url = {http://jn.physiology.org/content/99/2/656.short},
year = {2008}
}
@book{Liu02,
author = {Liu, J},
publisher = {Springer},
title = {{Monte carlo strategies in scientific computing}},
year = {2002}
}
@article{siwy2002correlation,
annote = {2009num5},
author = {Siwy, Z and Ausloos, M and Ivanova, K},
journal = {Physical Review E},
number = {3},
pages = {31907},
publisher = {APS},
title = {{Correlation studies of open and closed state fluctuations in an ion channel: Analysis of ion current through a large-conductance locust potassium channel}},
volume = {65},
year = {2002}
}
@incollection{Barber1998,
author = {Barber, D and Bishop, C M},
booktitle = {Neural Networks and Machine Learning},
number = {Bishop 1995},
pages = {Neural Networks and Machine Learning},
title = {{Ensemble learning in Bayesian neural networks}},
url = {http://research.microsoft.com/pubs/67172/bishop-ensemble-nato-98.pdf?origin=publication{\_}detail},
year = {1998}
}
@article{LeCun1989,
author = {LeCun, Y and Boser, B and Denker, J S and Henderson, D and Howard, R E and Hubbard, W and Jackel, L D},
doi = {10.1162/neco.1989.1.4.541},
issn = {0899-7667},
journal = {Neural Computation},
month = {dec},
number = {4},
pages = {541--551},
title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541},
volume = {1},
year = {1989}
}
@book{Hertz91,
address = {Redwood City CA},
author = {Hertz, J and Krogh, A and Palmer, R G},
publisher = {Addison-Wesley},
title = {{Introduction to the {\{}T{\}}heory of {\{}N{\}}eural {\{}C{\}}omputation}},
year = {1991}
}
@article{Srivastava|2001|,
abstract = {The light-front (LF) quantization of QCD in light-cone gauge has a
number of remarkable advantages, including explicit unitarity, a
physical Fock expansion, the absence of ghost degrees of freedom,
and the decoupling properties needed to prove factorization theorems
in high momentum transfer inclusive and exclusive reactions. We present
a systematic study of LF-quantized gauge theory following the Dirac
method and construct the Dyson-Wick S-matrix expansion based on LF-time-ordered
products. The free theory gauge field is shown to satisfy the Lorentz
condition as an operator equation as well as the light-cone gauge
condition. Its propagator is found to be transverse with respect
to both its four-momentum and the gauge direction. The interaction
Hamiltonian of QCD can be expressed in a form resembling that of
covariant theory, except for additional instantaneous interactions
which can be treated systematically. The renormalization constants
in YM theory are shown to satisfy the identity Z1 = Z3 at one loop
order. The QCD function computed in the noncovariant light-cone gauge
agrees with that known in the conventional framework. Some comments
on the relationship of our LF framework, with the doubly transverse
gauge propagator, to the analytic effective charge and renormalization
scheme defined by the pinch technique, the unitarity relations and
the spectral representation are also made. LF quantization thus provides
a consistent formulation of gauge theory, despite the fact that the
hyperplanes x{\^{}}pm = 0 used to impose boundary conditions constitute
characteristic surfaces of a hyperbolic partial di erential equation.},
author = {Srivastava, P P and Brodsky, S J},
journal = {arXiv},
keywords = {generalized parton distribution,light front dynamics,perturbation theory,physics,quantum chromodynamics,unread},
pages = {11372},
title = {{Light-front-quantized QCD in light-cone gauge: the doubly transverse gauge propagator}},
volume = {hep-ph}
}
@book{Gelman06,
author = {Gelman, A and Hill, J},
publisher = {Cambridge},
title = {{Data Analysis Using Regression and Multilevel/Hierarchical Models}},
year = {2006}
}
@article{EAT86,
author = {Eaton, M},
journal = {Journal of Multivariate Analysis},
pages = {272--276},
title = {{A characterization of spherical distributions}},
volume = {20},
year = {1986}
}
@article{Cheng2015,
abstract = {Compared to Multilayer Neural Networks with real weights, Binary Multilayer Neural Networks (BMNNs) can be implemented more efficiently on dedicated hardware. BMNNs have been demonstrated to be effective on binary classification tasks with Expectation BackPropagation (EBP) algorithm on high dimensional text datasets. In this paper, we investigate the capability of BMNNs using the EBP algorithm on multiclass image classification tasks. The performances of binary neural networks with multiple hidden layers and different numbers of hidden units are examined on MNIST. We also explore the effectiveness of image spatial filters and the dropout technique in BMNNs. Experimental results on MNIST dataset show that EBP can obtain 2.12{\%} test error with binary weights and 1.66{\%} test error with real weights, which is comparable to the results of standard BackPropagation algorithm on fully connected MNNs.},
archivePrefix = {arXiv},
arxivId = {1503.03562},
author = {Cheng, Z and Soudry, D. and Mao, Z and Lan, Z},
eprint = {1503.03562},
journal = {arXiv: 1503.03562},
pages = {1--8},
title = {{Training Binary Multilayer Neural Networks for Image Classification using Expectation Backpropagation}},
url = {http://arxiv.org/abs/1503.03562},
year = {2015}
}
@article{Meerson2009,
archivePrefix = {arXiv},
arxivId = {arXiv:0906.5550v2},
author = {Meerson, Baruch and Sasorov, P.V. V},
eprint = {arXiv:0906.5550v2},
journal = {Physical Review E},
number = {4},
pages = {41130},
publisher = {APS},
title = {{WKB theory of epidemic fade-out in stochastic populations}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.80.041130},
volume = {80},
year = {2009}
}
@misc{Jurrus2006,
author = {Jurrus, E and Tasdizen, T and Koshevoy, P and Fletcher, P and Hardy, M and Chien, C and Denk, W and Whitaker, R},
title = {{Axon tracking in serial block-free scanning electron microscopy.}},
year = {2006}
}
@article{Ferretti|2004|,
abstract = {We report the inclusion of electron-electron correlation in the calculation
of transport properties within an ab initio scheme. A key step is
the reformulation of Landauer{\"{i}}¾'s approach in terms of an effective
transmittance for the interacting electron system. We apply this
framework to analyze the effect of short range interactions on Pt
atomic wires and discuss the coherent and incoherent correction to
the mean-field approach.},
annote = {This is a celebrated in 2004 paper about electron transport in nano{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}junctions},
author = {Ferretti, A and Calzolari, A and Felice, R Di and Manghi, F and Caldas, M J and Nardelli, M Buongiorno and Molinari, E},
journal = {arXiv},
keywords = {nano-junctions,nanotechnology,physics,quantum physics},
pages = {409222},
title = {{First principle theory of correlated transport through nano-junctions}},
volume = {cond-mat}
}
@article{Jia2010a,
annote = {2010IIInum1},
author = {Jia, H and Rochefort, N L and Chen, Xi and Konnerth, A},
doi = {10.1038/nature08947},
issn = {0028-0836},
journal = {Nature},
keywords = {Jackie,Neuron Model},
mendeley-tags = {Jackie,Neuron Model},
month = {apr},
number = {7293},
pages = {1307--1312},
publisher = {Nature Publishing Group},
title = {{Dendritic organization of sensory input to cortical neurons in vivo}},
url = {http://www.nature.com/doifinder/10.1038/nature08947},
volume = {464},
year = {2010}
}
@article{BZ90,
author = {Bialek, W and Zee, A},
journal = {Journal of Statistical Physics},
pages = {103--115},
title = {{Coding and computation with neural spike trains}},
volume = {59},
year = {1990}
}
@article{Hennequin2014,
author = {Hennequin, Guillaume and Aitchison, Laurence and Lengyel, Mate},
journal = {Advances in Neural Information Processing Systems},
pages = {1--9},
title = {{Fast Sampling-Based Inference in Balanced Neuronal Networks}},
year = {2014}
}
@article{BloomfieldMiller86,
author = {Bloomfield, S A and Miller, R F},
journal = {J. Neurosci.},
number = {1},
pages = {1--13},
title = {{A functional organization of ON and OFF pathways in the rabbit retina}},
volume = {6},
year = {1986}
}
@article{Ermentrout,
author = {Ermentrout, Bard},
title = {{Foundations of Mathematical Neuroscience}}
}
@article{Akhmatskaya09,
address = {San Diego, CA, USA},
author = {Akhmatskaya, Elena and Bou-Rabee, Nawaf and Reich, Sebastian},
doi = {http://dx.doi.org/10.1016/j.jcp.2008.12.014},
issn = {0021-9991},
journal = {J. Comput. Phys.},
number = {6},
pages = {2256--2265},
publisher = {Academic Press Professional, Inc.},
title = {{A comparison of generalized hybrid Monte Carlo methods with and without momentum flip}},
volume = {228},
year = {2009}
}
@article{KMY04,
author = {Kersten, D and Mamassian, P and Yuille, A},
editor = {Knill, D and Richards, W},
journal = {Annual Review of Psychology},
pages = {271--304},
publisher = {Cambridge University Press},
title = {{OBJECT PERCEPTION AS {\{}B{\}}AYESIAN INFERENCE}},
volume = {55},
year = {2004}
}
@article{Huggins10,
author = {Huggins, J and Paninski, L},
journal = {J. Comput. Neuro.},
title = {{Optimal experimental design for sampling voltage on dendritic trees}},
volume = {In press},
year = {2011}
}
@article{Valle2002,
author = {Valle, M},
journal = {Analog Integrated Circuits and Signal Processing},
keywords = {analog vlsi neural networks,on chip learning,supervised learning},
pages = {263--287},
title = {{Analog VLSI implementation of artificial neural networks with Supervised On-Chip Learning}},
url = {http://link.springer.com/article/10.1023/A:1020717929709},
year = {2002}
}
@article{Markram1997a,
author = {Markram, H and Tsodyks, M},
title = {{The information content of action potential trains a synaptic basis}},
url = {http://www.springerlink.com/index/D147526985585781.pdf},
year = {1997}
}
@article{Losavio08,
author = {Losavio, Bradley E and Liang, Yong and Santamar{\'{i}}a-Pang, Alberto and Kakadiaris, Ioannis A and Colbert, Costa M and Saggau, Peter},
journal = {Journal of Neurophysiology},
pages = {2422--2429},
title = {{Live Neuron Morphology Automatically Reconstructed From Multiphoton and Confocal Imaging Data}},
volume = {100},
year = {2008}
}
@article{Denk1996,
abstract = {Recent advances in optical imaging technology have enabled the measurement

of {\{}Ca{\}}{\^{}}{\{}2+{\}} dynamics in individual synaptic spines with high time

resolution. Results from work using this new technology have confirmed

the view that individual synaptic spines can act as functional chemical

compartments with independent dynamics of second-messenger concentration.

In particular, the ability of {\{}Ca{\}}{\^{}}{\{}2+{\}} to directly mediate Hebbian

coincidence detection has been confirmed.},
author = {Denk, W and Yuste, R and Svoboda, K and Tank, D W},
journal = {Curr Opin Neurobiol},
keywords = {Animals; Calcium; Calcium Channels; Dendrites; Ele,Fluorescence; Optics; Receptors,Medical,N-Methyl-D-Aspartate; Synapses; Technology},
month = {jun},
number = {3},
pages = {372--378},
pmid = {8794079},
title = {{Imaging calcium dynamics in dendritic spines.}},
volume = {6},
year = {1996}
}
@book{GR00,
edition = {6th},
editor = {Jeffrey, A and Zwillinger, D},
publisher = {Academic Press},
title = {{Gradshteyn and Ryzhik's Table of Integrals, Series, and Products}},
year = {2000}
}
@article{Destexhe2004,
author = {Destexhe, Alain and Marder, E},
number = {October},
pages = {789--795},
title = {circuit computations},
volume = {431},
year = {2004}
}
@article{Lasota1987,
author = {Lasota, Andrzej and Mackey, M.C.},
issn = {0167-2789},
journal = {Physica D: Nonlinear Phenomena},
number = {1-2},
pages = {143--154},
publisher = {Elsevier},
title = {{Noise and statistical periodicity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0167278987901254},
volume = {28},
year = {1987}
}
@book{Davis1981,
author = {Davis, MHA and Marcus, SI},
title = {{An introduction to nonlinear filtering}},
url = {http://link.springer.com/chapter/10.1007/978-94-009-8546-9{\_}4},
year = {1981}
}
@article{Ball1993,
author = {Ball, F and Yeo, G and Milne, R and Edeson, R and Madsen, B and Sansom, M},
doi = {10.1016/S0006-3495(93)81375-4},
issn = {00063495},
journal = {Biophysical Journal},
number = {2},
pages = {357--374},
publisher = {Elsevier},
title = {{Single ion channel models incorporating aggregation and time interval omission}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349593813754},
volume = {64},
year = {1993}
}
@article{Bray1988,
author = {Bray, AJ and Rodgers, GJ},
journal = {Physical Review B},
number = {16},
pages = {11461},
publisher = {APS},
title = {{Diffusion in a sparsely connected space: A model for glassy relaxation}},
url = {http://prb.aps.org/abstract/PRB/v38/i16/p11461{\_}1},
volume = {38},
year = {1988}
}
@article{Whittingstall|2003|,
abstract = {Background: The electroencephalogram (EEG) reflects the electrical
activity in the brain on the surface of scalp. A major challenge
in this field is the localization of sources in the brain responsible
for eliciting the EEG signal measured at the scalp. In order to estimate
the location of these sources, one must correctly model the sources,
i.e., dipoles, as well as the volume conductor in which the resulting
currents flow. In this study, we investigate the effects of dipole
depth and orientation on source localization with varying sets of
simulated random noise in 4 realistic head models. Methods: Dipole
simulations were performed using realistic head models and using
the boundary element method (BEM). In all, 92 dipole locations placed
in temporal and parietal regions of the head with varying depth and
orientation were investigated along with 6 different levels of simulated
random noise. Localization errors due to dipole depth, orientation
and noise were investigated. Results: The results indicate that there
are no significant differences in localization error due tangential
and radial dipoles. With high levels of simulated Gaussian noise,
localization errors are depth-dependant. For low levels of added
noise, errors are similar for both deep and superficial sources.
Conclusion: It was found that if the signal-to-noise ratio is above
a certain threshold, localization errors in realistic head models
are, on average the same for deep and superficial sources. As the
noise increases, localization errors increase, particularly for deep
sources.},
annote = {The paper analyses bounds on spatial resolution of EEGs. Localization{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}bounds derived turn out to be 1-5mm.},
author = {Whittingstall, K and Stroink, G and Gates, L and Connolly, J F and Finley, A},
journal = {BioMedical Engineering Online},
keywords = {electroencyphalogram,localization,magnetoencephalograms,neurobiology,resolution},
title = {{Effects of dipole position, orientation and noise on the accuracy of EEG source localization}},
volume = {2}
}
@article{Boutayeb1997,
abstract = {In this paper, convergence analysis of the extended Kalman filter
(EKF), when used as an observer for nonlinear deterministic
discrete-time systems, is presented. Based on a new formulation of the
first-order linearization technique, sufficient conditions to ensure
local asymptotic convergence are established. Furthermore, it is shown
that the design of the arbitrary matrix plays an important role in
enlarging the domain of attraction and then improving the convergence of
the modified EKF significantly. The efficiency of this approach,
compared to the classical version of the EKF, is shown through a
nonlinear identification problem as well as a state and parameter
estimation of nonlinear discrete-time systems},
author = {Boutayeb, M. and Rafaralahy, H. and Darouach, M.},
doi = {10.1109/9.566674},
isbn = {0-7803-2685-7},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Convergence analysis,Deterministic nonlinear discrete-time systems,Extended Kalman filter,Lyapunov approach},
number = {4},
pages = {581--586},
title = {{Convergence analysis of the extended Kalman filter used as an observer for nonlinear deterministic discrete-time systems}},
volume = {42},
year = {1997}
}
@book{Neter96,
author = {Neter, J and Wasserman, W and Others},
publisher = {Irwin Homewood, IL},
title = {{Applied linear statistical models}},
year = {1996}
}
@article{Ishwaran99,
author = {Ishwaran, Hemant},
journal = {Journal of Computational and Graphical Statistics},
pages = {779--799},
title = {{Applications of hybrid {\{}Monte Carlo to Bayesian{\}} generalized linear models: quasicomplete separation and neural networks}},
volume = {8},
year = {1999}
}
@article{Rokni2007,
abstract = {It is often assumed that learning takes place by changing an otherwise stable neural representation. To test this assumption, we studied changes in the directional tuning of primate motor cortical neurons during reaching movements performed in familiar and novel environments. During the familiar task, tuning curves exhibited slow random drift. During learning of the novel task, random drift was accompanied by systematic shifts of tuning curves. Our analysis suggests that motor learning is based on a surprisingly unstable neural representation. To explain these results, we propose that motor cortex is a redundant neural network, i.e., any single behavior can be realized by multiple configurations of synaptic strengths. We further hypothesize that synaptic modifications underlying learning contain a random component, which causes wandering among synaptic configurations with equivalent behaviors but different neural representations. We use a simple model to explore the implications of these assumptions.},
author = {Rokni, Uri and Richardson, Andrew G and Bizzi, Emilio and Seung, H S},
doi = {10.1016/j.neuron.2007.04.030},
issn = {0896-6273},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Animal,Animals,Behavior,Learning,Learning: physiology,Macaca mulatta,Models,Motor Cortex,Motor Cortex: cytology,Movement,Movement: physiology,Neurological,Neurons,Neurons: classification,Neurons: physiology,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology,Statistical},
month = {may},
number = {4},
pages = {653--666},
pmid = {17521576},
title = {{Motor learning with unstable neural representations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17521576},
volume = {54},
year = {2007}
}
@article{HSP42,
author = {Hecht, S and Shlaer, S and Pirenne, M},
journal = {Journal of General Physiology},
pages = {819--840},
title = {{Energy, quanta, and vision}},
volume = {25},
year = {1942}
}
@article{IZH01,
author = {Izhikevich, E},
journal = {Neural Networks},
pages = {883--894},
title = {{Resonate-and-fire neurons}},
volume = {14},
year = {2001}
}
@article{Maass2007,
abstract = {It has previously been shown that generic cortical microcircuit models can perform complex real-time computations on continuous input streams, provided that these computations can be carried out with a rapidly fading memory. We investigate the computational capability of such circuits in the more realistic case where not only readout neurons, but in addition a few neurons within the circuit, have been trained for specific tasks. This is essentially equivalent to the case where the output of trained readout neurons is fed back into the circuit. We show that this new model overcomes the limitation of a rapidly fading memory. In fact, we prove that in the idealized case without noise it can carry out any conceivable digital or analog computation on time-varying inputs. But even with noise, the resulting computational model can perform a large class of biologically relevant real-time computations that require a nonfading memory. We demonstrate these computational implications of feedback both theoretically, and through computer simulations of detailed cortical microcircuit models that are subject to noise and have complex inherent dynamics. We show that the application of simple learning procedures (such as linear regression or perceptron learning) to a few neurons enables such circuits to represent time over behaviorally relevant long time spans, to integrate evidence from incoming spike trains over longer periods of time, and to process new information contained in such spike trains in diverse ways according to the current internal state of the circuit. In particular we show that such generic cortical microcircuits with feedback provide a new model for working memory that is consistent with a large set of biological constraints. Although this article examines primarily the computational role of feedback in circuits of neurons, the mathematical principles on which its analysis is based apply to a variety of dynamical systems. Hence they may also throw new light on the computational role of feedback in other complex biological dynamical systems, such as, for example, genetic regulatory networks.},
author = {Maass, W and Joshi, Prashant and Sontag, Eduardo D},
doi = {10.1371/journal.pcbi.0020165},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Brain,Brain: physiology,Computer Simulation,Computers,Feedback,Feedback: physiology,Models,Molecular,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Physiological,Physiological: physiology,Reservoir Computing,Synaptic Transmission,Synaptic Transmission: physiology},
mendeley-tags = {Reservoir Computing},
month = {jan},
number = {1},
pages = {e165},
pmid = {17238280},
title = {{Computational aspects of feedback in neural circuits.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1779299{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2007}
}
@article{Coates|2005|,
abstract = {Network tomography is a process for inferring "internal" link-level
delay and loss performance information based on end-to-end (edge)
network measurements. These methods require knowledge of the network
topology; therefore a first crucial step in the tomography process
is topology identi- fication. This paper considers the problem of
discovering network topology solely from host-based, unicast measure-
ments, without internal network cooperation. First, we in- troduce
a novel delay-based measurement scheme that does not require clock
synchronization, making it more practical than other previous proposals.
Due to the nature of the measurement procedure, our methodology has
the potential to identify layer two switching elements (provided
they are logical topology branching points and induce some measur-
able switching delay). Second, we propose a maximum pe- nalized likelihood
criterion for topology identification. This is a global optimality
criterion, in contrast to other recent proposals for topology identification
that employ subopti- mal, pair-merging strategies. We develop a novel
Markov Chain Monte Carlo (MCMC) procedure for rapid determi- nation
of the most likely topologies. The performance of our new probing
scheme and identification algorithm is explored through simulation
and Internet experiments.},
author = {Coates, M and Castro, R and Nowak, R},
keywords = {continuous networks,distance,internet,metric,network metrics,networks,unread},
title = {{Maximum Likelihood Network Topology Identification from Edge-based Unicast Measurements}}
}
@article{Vintch2015,
abstract = {The response properties of neurons in the early stages of the visual system can be described using the rectified responses of a set of self-similar, spatially shifted linear filters. In macaque primary visual cortex (V1), simple cell responses can be captured with a single filter, whereas complex cells combine a set of filters, creating position invariance. These filters cannot be estimated using standard methods, such as spike-triggered averaging. Subspace methods like spike-triggered covariance can recover multiple filters but require substantial amounts of data, and recover an orthogonal basis for the subspace in which the filters reside, rather than the filters themselves. Here, we assume a linear-nonlinear-linear-nonlinear (LN-LN) cascade model in which the first LN stage consists of shifted ("convolutional") copies of a single filter, followed by a common instantaneous nonlinearity. We refer to these initial LN elements as the "subunits" of the receptive field, and we allow two independent sets of subunits, each with its own filter and nonlinearity. The second linear stage computes a weighted sum of the subunit responses and passes the result through a final instantaneous nonlinearity. We develop a procedure to directly fit this model to electrophysiological data. When fit to data from macaque V1, the subunit model significantly outperforms three alternatives in terms of cross-validated accuracy and efficiency, and provides a robust, biologically plausible account of receptive field structure for all cell types encountered in V1. SIGNIFICANCE STATEMENT We present a new subunit model for neurons in primary visual cortex that significantly outperforms three alternative models in terms of cross-validated accuracy and efficiency, and provides a robust and biologically plausible account of the receptive field structure in these neurons across the full spectrum of response properties.},
author = {Vintch, Brett and Movshon, J. Anthony and Simoncelli, Eero P.},
doi = {10.1523/JNEUROSCI.2815-13.2015},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {V1,model,receptive field,subunits},
number = {44},
pages = {14829--41},
pmid = {26538653},
title = {{A Convolutional Subunit Model for Neuronal Responses in Macaque V1.}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2815-13.2015{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/26538653{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4635132},
volume = {35},
year = {2015}
}
@book{CasellaBerger,
author = {Casella, G and Berger, R},
publisher = {Duxbury Press},
title = {{Statistical Inference}},
year = {2001}
}
@article{Spira1976,
abstract = {1. Spike propagation across the nonhomogeneous section of the giant axon in ganglion T3 of the cockroach was analyzed by intracellular microelectrodes recording at the posterior and anterior ends of T3. Ascending and descending potentials were evoked by stimulation of A5-A6 and T2-T3 connectives. 2. At high frequencies, descending and ascending impulses exhibit the following: a) consecutive reduction in the spike amplitude, b) a decrease in the afterhyperpolarization; c) gradual appearance of a prepotential together with an increase in delay of spike initiation; d) failure of full spike invasion into the recording area, showing only a decremental potential. 3. The duration of a train required to block spike propagation when the whole connective is stimulated is much shorter (about 6 times) than that required when a single giant axon is stimulated. 4. The conduction block is associated with a marked decrease in effective membrane resistance, greater than that expected from depolarization and delayed rectification. 5. Synaptic potentials could be recorded in the giant axons in the caudal base of ganglion T3 after stimulation of either the ipsilateral or contralateral connectives at both ends of the ganglion. These synaptic potentials could be blocked by d-tubocurarine (d-TC) or low Ca2+-high Mg2+. 6. Activation of these synapses produces a marked increase in membrane conductance, blocking propagation of spike trains through the ganglion. 7. After these synapses are blocked by d-TC or low Ca2+-high Mg2+, high-frequency stimulation still produces a conduction block. 8. It seems that conduction of spike during repetitive stimulation is affected both by accumulation of extracellular potassium, which depolarizes the membrane and causes sodium inactivation, and by activation of synaptic inputs to shunt the membrane in this region. 8. Each of these two mechanisms by itself can produce conduction block along the giant axons in ganglion T3.},
annote = {2010IInum12.20{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Spira, M E and Yarom, Y and Parnas, I},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Afferent,Afferent: physiology,Animals,Axons,Axons: physiology,Cockroaches,Cockroaches: physiology,Male,Membrane Potentials,Neural Conduction,Neuron Model,Neurons,Synapses,Synapses: physiology},
mendeley-tags = {Neuron Model},
month = {jul},
number = {4},
pages = {882--99},
pmid = {966043},
publisher = {Am Physiological Soc},
title = {{Modulation of spike frequency by regions of special axonal geometry and by synaptic inputs.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/966043 http://jn.physiology.org/cgi/content/abstract/39/4/882},
volume = {39},
year = {1976}
}
@article{Texier|2004|,
abstract = {We study the quantum transport in multiterminal networks of quasi-one-dimensional
diffusive wires. When calculating the weak localization correction
to the conductances, we show that the Cooperon must be properly weighted
over each wire. This can even change the sign of the weak localization
correction in certain geometries.},
annote = {The paper deals with quantum electric current transport in network{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of diffusive wires.},
author = {Texier, C and Montambaux, G},
journal = {arXiv},
keywords = {physics,quantum,transport,wires},
number = {0404716},
title = {{How to increase a transmission with weak localization? A geometrical effect}},
volume = {cond-mat}
}
@article{Schuster2002,
author = {Schuster, Heinz Georg},
doi = {10.1103/PhysRevE.65.026120},
pages = {2--5},
title = {{¨ rn Davidsen * and Heinz Georg Schuster Jo ¨}},
volume = {65},
year = {2002}
}
@article{KL04,
author = {Kelly, R and Lee, T S},
journal = {Advances in Neural Information Processing Systems},
pages = {1359--1366},
title = {{Decoding {\{}V{\}}1 neuronal activity using particle filtering with {\{}V{\}}olterra$\backslash$ kernels}},
volume = {15},
year = {2004}
}
@article{Vespignani2000,
author = {Vespignani, A and Dickman, R and Munoz, MA and Zapperi, S},
journal = {Physical Review E},
title = {{Absorbing-state phase transitions in fixed-energy sandpiles}},
url = {http://pre.aps.org/abstract/PRE/v62/i4/p4564{\_}1},
year = {2000}
}
@article{Branco2010,
annote = {2010IIInum49},
author = {Branco, T. and Clark, B. A. and H{\"{a}}usser, M},
doi = {10.1126/science.1189664},
issn = {0036-8075},
journal = {Science},
keywords = {Neuron Model,dendrites},
mendeley-tags = {Neuron Model,dendrites},
month = {aug},
title = {{Dendritic Discrimination of Temporal Input Sequences in Cortical Neurons}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1189664},
volume = {1671},
year = {2010}
}
@inproceedings{Maas2013,
abstract = {Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2{\%} absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks.},
author = {Maas, Andrew L. and Hannun, Awni Y. and Ng, Andrew Y.},
booktitle = {Proceedings of the 30 th International Conference on Machine Learning},
file = {::},
pages = {6},
title = {{Rectifier Nonlinearities Improve Neural Network Acoustic Models}},
url = {https://pdfs.semanticscholar.org/367f/2c63a6f6a10b3b64b8729d601e69337ee3cc.pdf https://web.stanford.edu/{~}awni/papers/relu{\_}hybrid{\_}icml2013{\_}final.pdf},
year = {2013}
}
@article{bonifazi2006information,
author = {Bonifazi, Paolo and Torre, V},
keywords = {networks},
mendeley-tags = {networks},
publisher = {Citeseer},
title = {{Information processing in dissociated neuronal cultures of rat hippocampal neurons}},
year = {2006}
}
@article{Smith05,
author = {Smith, Anne C and Stefani, Mark R and Moghaddam, Bita and Brown, Emery N},
doi = {10.1152/jn.00765.2004},
journal = {J Neurophysiol},
number = {3},
pages = {1776--1792},
title = {{Analysis and Design of Behavioral Experiments to Characterize Population Learning}},
volume = {93},
year = {2005}
}
@article{Colquhoun2003,
abstract = {Properties of maximum likelihood estimators of rate constants for channel mechanisms are investigated, to see what can and cannot be inferred from experimental results. The implementation of the HJCFIT method is described; it maximises the likelihood of an entire sequence of apparent open and shut times, with the rate constants in a specified reaction mechanism as free parameters. The exact method for missed brief events is used. Several methods for testing the quality of the fit are described. The distributions of rate constants, and correlations between them, are investigated by doing sets of 1000 fits to simulated experiments. In a standard nicotinic receptor mechanism, all nine free rate constants can be estimated even from one single channel recording, as long as the two binding sites are independent, even when the number of channels in the patch is not known. The estimates of rate constants that apply to diliganded channels are robust; good estimates can be obtained even with erroneous assumptions (e.g. about the value of a fixed rate constant or the independence of sites). Rate constants that require distinction between the two sites are less robust, and require that an EC50 be specified, or that records at two concentrations be fitted simultaneously. Despite the complexity of the problem, it appears that there exist two solutions with very similar likelihoods, as in the simplest case. The hazards that result from this, and from the strong positive correlation between estimates of opening and shutting rates, are discussed.},
annote = {2010IIInum37},
author = {Colquhoun, D and Hatton, C J and Hawkes, A G},
doi = {10.1113/jphysiol.2002.034165},
issn = {0022-3751},
journal = {The Journal of physiology},
keywords = {Binding Sites,Binding Sites: physiology,Biological,Cholinergic,Cholinergic: physiology,Computer Simulation,Ion Channel Gating,Ion Channel Gating: physiology,Ligands,Models,Receptors,Software},
month = {mar},
number = {Pt 3},
pages = {699--728},
pmid = {12562901},
title = {{The quality of maximum likelihood estimates of ion channel rate constants.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2342730{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {547},
year = {2003}
}
@article{WP83,
author = {Watson, A and Pelli, D},
journal = {Perception and Psychophysics},
pages = {113--120},
title = {{{\{}QUEST{\}}: a {\{}B{\}}ayesian adaptive psychophysical method}},
volume = {33},
year = {1983}
}
@article{PAN04d,
author = {Paninski, L},
journal = {IEEE Transactions on Information Theory},
pages = {2200--2203},
title = {{Estimating entropy on m bins given fewer than m samples}},
volume = {50},
year = {2004}
}
@book{STR88,
address = {New York},
author = {Strang, G},
publisher = {Harcourt Brace},
title = {{Linear algebra and its applications}},
year = {1988}
}
@techreport{LV03,
author = {Lovasz, L and Vempala, S},
institution = {Microsoft Research},
number = {2003-04},
title = {{The geometry of logconcave functions and an {\{}O{\}}{\^{}}*(n{\^{}}3) sampling algorithm}},
year = {2003}
}
@article{Lang2011,
abstract = {The fate of a newly arising beneficial mutation depends on many factors, such as the population size and the availability and fitness effects of other mutations that accumulate in the population. It has proved difficult to understand how these factors influence the trajectories of particular mutations, since experiments have primarily focused on characterizing successful clones emerging from a small number of evolving populations. Here, we present the results of a massively parallel experiment designed to measure the full spectrum of possible fates of new beneficial mutations in hundreds of experimental yeast populations, whether these mutations are ultimately successful or not. Using strains in which a particular class of beneficial mutation is detectable by fluorescence, we followed the trajectories of these beneficial mutations across 592 independent populations for 1000 generations. We find that the fitness advantage provided by individual mutations plays a surprisingly small role. Rather, underlying "background" genetic variation is quickly generated in our initially clonal populations and plays a crucial role in determining the fate of each individual beneficial mutation in the evolving population.},
author = {Lang, Gregory I and Botstein, David and Desai, Michael M},
doi = {10.1534/genetics.111.128942},
issn = {1943-2631},
journal = {Genetics},
keywords = {Adaptation,Asexual,Biological,Evolution,Flow Cytometry,Fluorescence,Genes,Genetic,Genetic Fitness,Genetic Variation,Genetics,Microscopy,Models,Molecular,Mutation,Population,Population Density,Population: methods,Reporter,Reproduction,Saccharomyces cerevisiae,Saccharomyces cerevisiae: cytology,Saccharomyces cerevisiae: genetics,Selection},
month = {jul},
number = {3},
pages = {647--661},
pmid = {21546542},
title = {{Genetic variation and the fate of beneficial mutations in asexual populations.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3176544{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {188},
year = {2011}
}
@article{marder2003current,
annote = {2010num5.7},
author = {Marder, E and Prinz, A A},
journal = {Neuron},
number = {1},
pages = {2--4},
publisher = {Elsevier},
title = {{Current compensation in neuronal homeostasis}},
volume = {37},
year = {2003}
}
@article{Green95,
author = {Green, P},
journal = {Biometrika},
pages = {711--732},
title = {{Reversible jump Markov chain Monte Carlo computation and Bayesian model determination}},
volume = {82},
year = {1995}
}
@article{Oram1992,
abstract = {1. Measurements of the magnitude and time course of response were made from 44 cells responsive to static head views at different levels of stimulus effectiveness. In this way responses to complex stimulus patterns evoking good, poor, and midrange responses could be compared across the cell population. 2. Cells exhibiting both good and poor initial discrimination between head views were found at short and long latencies; there was no correlation of any of the temporal response parameters measured with cell response latency. 3. The time course of the population response to the most effective stimuli showed a rapid increase to a peak firing rate (onset to peak, rise time, 58 ms) that was on average 115 spikes/s above spontaneous activity (S/A), followed by slower decay (decay time, 93 ms) to a maintained discharge rate (15{\%} of the peak rate above S/A). 4. Discrimination between responses to different head views exhibited by the population showed a sharp rise and reached highly significant levels within 25 ms after the population's response onset. 5. On average, activity in a single neuron (the Average Cell) rises to 44{\%} of its peak response rate within 5 ms of the response onset. 6. The Average Cell also showed exceptionally fast discrimination between views, significant within 5 ms of response onset. 7. It is argued that the fast rise in firing rate, followed by a decay to a lower rate and the very fast emergence of discrimination are features of pattern processing present in real neural systems that are lacking in many processing models based on artificial networks of neuronlike elements, particularly those where discrimination relies on top-down and/or lateral competitive inhibition. 8. It is concluded that the only way to account for the rapid discrimination is to consider a coding system in which the first spike from multiple sources is used to transmit information between stages of processing.},
author = {Oram, M W and Perrett, D I},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Animals,Discrimination (Psychology),Discrimination (Psychology): physiology,Eye Movements,Eye Movements: physiology,Female,Macaca mulatta,Male,Neurons,Neurons: drug effects,Spike time neural coding},
mendeley-tags = {Spike time neural coding},
month = {jul},
number = {1},
pages = {70--84},
pmid = {1517829},
title = {{Time course of neural responses discriminating different views of the face and head.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1517829},
volume = {68},
year = {1992}
}
@inproceedings{Krizhevsky2012,
author = {Krizhevsky, A and Sutskever, I and Hinton, G E},
booktitle = {NIPS},
title = {{Imagenet classification with deep convolutional neural networks}},
url = {http://books.nips.cc/papers/files/nips25/NIPS2012{\_}0534.pdf},
year = {2012}
}
@article{Lopez-PovedaMeddis01,
author = {Lopez-Poveda, E A and Meddis, R},
journal = {Journal of The Acoustical Society Of America},
month = {dec},
number = {6},
pages = {3107--3118},
title = {{A human nonlinear cochlear filterbank}},
volume = {110},
year = {2001}
}
@misc{Rouder|2006|,
annote = {This presentation deals with diffusion model for decision making{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}in perceptual tasks},
author = {Rouder, J N},
keywords = {decision making,diffusion model,macaque,neurobiology,perceptual tasks},
title = {{A diffusion model of human decision making in perceptial tasks}}
}
@article{DelaRocha2005,
abstract = {Unreliability is a ubiquitous feature of synaptic transmission in the brain. The information conveyed in the discharges of an ensemble of cells (e.g., in the spike count or in the timing of synchronous events) may not be faithfully transmitted to the postsynaptic cell because a large fraction of the spikes fail to elicit a synaptic response. In addition, short-term depression increases the failure rate with the presynaptic activity. We use a simple neuron model with stochastic depressing synapses to understand the transformations undergone by the spatiotemporal patterns of incoming spikes as these are first converted into synaptic current and afterward into the cell response. We analyze the mean and SD of the current produced by different stimuli with spatiotemporal correlations. We find that the mean, which carries information only about the spike count, rapidly saturates as the input rate increases. In contrast, the current deviation carries information about the correlations. If the afferent action potentials are uncorrelated, it saturates monotonically, whereas if they are correlated it increases, reaches a maximum, and then decreases to the value produced by the uncorrelated stimulus. This means that, at high input rates, depression erases from the synaptic current any trace of the spatiotemporal structure of the input. The non-monotonic behavior of the deviation can be inherited by the response rate provided that the mean current saturates below the current threshold setting the cell in the fluctuation-driven regimen. Afferent correlations therefore enable the modulation of the response beyond the saturation of the mean current.},
author = {de la Rocha, J and Parga, N},
doi = {10.1523/JNEUROSCI.0631-05.2005},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Computer Simulation,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Stochastic Processes,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {sep},
number = {37},
pages = {8416--31},
pmid = {16162924},
title = {{Short-term synaptic depression causes a non-monotonic response to correlated stimuli.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16162924},
volume = {25},
year = {2005}
}
@misc{Zeitouni2006a,
author = {Zeitouni, Ofer},
title = {{LECTURE NOTES ON RANDOM WALKS}},
year = {2006}
}
@article{Seidemann08,
abstract = {Behavioral performance in detection and discrimination tasks is likely to be limited by the quality and nature of the signals carried by populations of neurons in early sensory cortical areas. Here we used voltage-sensitive dye imaging (VSDI) to directly measure neural population responses in the primary visual cortex (V1) of monkeys performing a reaction-time detection task. Focusing on the temporal properties of the population responses, we found that V1 responses are consistent with a stimulus-evoked response with amplitude and latency that depend on target contrast and a stimulus-independent additive noise with long-lasting temporal correlations. The noise had much lower amplitude than the ongoing activity reported previously in anesthetized animals. To understand the implications of these properties for subsequent processing stages that mediate behavior, we derived the Bayesian ideal observer that specifies how to optimally use neural responses in reaction time tasks. Using the ideal observer analysis, we show that 1) the observed temporal correlations limit the performance benefit that can be attained by accumulating V1 responses over time, 2) a simple temporal decorrelation operation with time-lagged excitation and inhibition minimizes the detrimental effect of these correlations, 3) the neural information relevant for target detection is concentrated in the initial response following stimulus onset, and 4) a decoder that optimally uses V1 responses far outperforms the monkey in both speed and accuracy. Finally, we demonstrate that for our particular detection task, temporal decorrelation followed by an appropriate running integrator can approach the speed and accuracy of the optimal decoder.
},
author = {Chen, Yuzhi and Geisler, Wilson S and Seidemann, Eyal},
doi = {10.1152/jn.00698.2007},
journal = {J Neurophysiol},
number = {3},
pages = {1366--1379},
title = {{Optimal Temporal Decoding of Neural Population Responses in a Reaction-Time Visual Detection Task}},
url = {http://jn.physiology.org/cgi/content/abstract/99/3/1366},
volume = {99},
year = {2008}
}
@book{WAT80,
address = {Boston},
author = {Watson, G},
publisher = {Wiley},
title = {{Approximation theory and numerical methods}},
year = {1980}
}
@article{Smith2010,
abstract = {Visual cortex shows smooth retinotopic organization on the macroscopic scale, but it is unknown how receptive fields are organized at the level of neighboring neurons. This information is crucial for discriminating among models of visual cortex. We used in vivo two-photon calcium imaging to independently map ON and OFF receptive field subregions of local populations of layer 2/3 neurons in mouse visual cortex. Receptive field subregions were often precisely shared among neighboring neurons. Furthermore, large subregions seem to be assembled from multiple smaller, non-overlapping subregions of other neurons in the same local population. These experiments provide, to our knowledge, the first characterization of the diversity of receptive fields in a dense local network of visual cortex and reveal elementary units of receptive field organization. Our results suggest that a limited pool of afferent receptive fields is available to a local population of neurons and reveal new organizational principles for the neural circuitry of the mouse visual cortex.},
author = {Smith, Spencer L and H{\"{a}}usser, Michael},
doi = {10.1038/nn.2620},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Action Potentials,Animals,Calcium,Calcium: metabolism,Mice,Mice, Inbred C57BL,Microelectrodes,Microscopy, Fluorescence, Multiphoton,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Photic Stimulation,Space Perception,Space Perception: physiology,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = {sep},
number = {9},
pages = {1144--9},
pmid = {20711183},
publisher = {Nature Publishing Group},
title = {{Parallel processing of visual space by neighboring neurons in mouse visual cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2999824{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {13},
year = {2010}
}
@article{Ishizuka|1990|,
author = {Ishizuka, N and Weber, J and Amaral, D G},
journal = {J Comp Neurol},
pages = {580--623},
title = {{Organization of intrahippocampal projections originating from CA3 pyramidal cells in the rat}},
volume = {295}
}
@article{Taylor2010,
annote = {9num2012},
author = {Taylor, J E and Adler, R J},
title = {{Topological complexity of smooth random functions}},
url = {http://webee.technion.ac.il/people/adler/stflour.pdf},
year = {2010}
}
@book{Gelman03,
author = {Gelman, A and Carlin, J and Stern, H and Rubin, D},
publisher = {CRC Press},
title = {{Bayesian Data Analysis}},
year = {2003}
}
@article{Olmi2005,
abstract = {{We investigate the onset of collective oscillations in a network of pulse-coupled leaky-integrate-and-fire neurons in the presence of quenched and annealed disorder. We find that the disorder induces a weak form of chaos that is analogous to that arising in the Kuramoto model for a finite number N of oscillators [O.V. Popovych at al., Phys. Rev. E 71{\}} 065201(R) (2005)]. In fact, the maximum Lyapunov exponent turns out to scale to zero for N going to infinite, with an exponent that is different for the two types of disorder. In the thermodynamic limit, the random-network dynamics reduces to that of a fully homogenous system with a suitably scaled coupling strength. Moreover, we show that the Lyapunov spectrum of the periodically collective state scales to zero as 1/N{\^{}}2, analogously to the scaling found for the `splay state'.},
annote = {2010IInum9.1},
archivePrefix = {arXiv},
arxivId = {arXiv:1002.4993v1},
author = {Olmi, Simona and Livi, Roberto and Politi, Antonio and Torcini, Alessandro},
eprint = {arXiv:1002.4993v1},
keywords = {Disordered Systems and Neural Networks},
month = {feb},
pages = {1--10},
title = {{Collective oscillations in disordered neural networks}},
url = {http://arxiv.org/abs/1002.4993},
year = {2005}
}
@article{Fehr2002,
abstract = {Human cooperation is an evolutionary puzzle. Unlike other creatures, people frequently cooperate with genetically unrelated strangers, often in large groups, with people they will never meet again, and when reputation gains are small or absent. These patterns of cooperation cannot be explained by the nepotistic motives associated with the evolutionary theory of kin selection and the selfish motives associated with signalling theory or the theory of reciprocal altruism. Here we show experimentally that the altruistic punishment of defectors is a key motive for the explanation of cooperation. Altruistic punishment means that individuals punish, although the punishment is costly for them and yields no material gain. We show that cooperation flourishes if altruistic punishment is possible, and breaks down if it is ruled out. The evidence indicates that negative emotions towards defectors are the proximate mechanism behind altruistic punishment. These results suggest that future study of the evolution of human cooperation should include a strong focus on explaining altruistic punishment.},
author = {Fehr, Ernst and G{\"{a}}chter, Simon},
doi = {10.1038/415137a},
issn = {0028-0836},
journal = {Nature},
keywords = {Altruism,Cooperative Behavior,Emotions,Evolution,Female,Games, Experimental,Humans,Male,Punishment},
month = {jan},
number = {6868},
pages = {137--40},
pmid = {11805825},
title = {{Altruistic punishment in humans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11805825},
volume = {415},
year = {2002}
}
@article{Kirkpatrick1983a,
author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
journal = {Science},
number = {4598},
title = {{Optimization by Simulated Annealing}},
volume = {220},
year = {1983}
}
@article{alopex98,
author = {Anderson, M and Micheli-Tzanakou, E},
journal = {Bioengineering Conference, 1998. Proceedings of the IEEE 24th Annual Northeast},
pages = {18--20},
title = {{Computer-brain interaction to optimize auditory stimuli based on neuronal responses}},
year = {1998}
}
@article{Levy1996,
abstract = {In 1969 Barlow introduced the phrase "economy of impulses" to express the tendency for successive neural systems to use lower and lower levels of cell firings to produce equivalent encodings. From this viewpoint, the ultimate economy of impulses is a neural code of minimal redundancy. The hypothesis motivating our research is that energy expenditures, e.g., the metabolic cost of recovering from an action potential relative to the cost of inactivity, should also be factored into the economy of impulses. In fact, coding schemes with the largest representational capacity are not, in general, optimal when energy expenditures are taken into account. We show that for both binary and analog neurons, increased energy expenditure per neuron implies a decrease in average firing rate if energy efficient information transmission is to be maintained.},
annote = {2010IIInum36},
author = {Levy, W B and Baxter, R A},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Energy Metabolism,Energy Metabolism: physiology,Models,Neurological,Neurons,Neurons: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {apr},
number = {3},
pages = {531--43},
pmid = {8868566},
title = {{Energy efficient neural codes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8868566},
volume = {8},
year = {1996}
}
@article{Hershenson2001,
author = {Hershenson, M.delM. and Boyd, S.P. and Lee, T.H.},
doi = {10.1109/43.905671},
issn = {02780070},
journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
number = {1},
pages = {1--21},
title = {{Optimal design of a CMOS op-amp via geometric programming}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=905671},
volume = {20},
year = {2001}
}
@article{Bruin2009,
author = {Bruin, Henk and Deane, Jonathan H B},
journal = {Proc. of the AMS},
number = {4},
pages = {1389--1395},
title = {{Piecewise contractions are asymptotically periodic}},
url = {http://www.ams.org/proc/2009-137-04/S0002-9939-08-09633-0/S0002-9939-08-09633-0.pdf},
volume = {137},
year = {2009}
}
@article{Tibs96,
author = {Tibshirani, R},
journal = {Journal of the Royal Statistical Society. Series B},
pages = {267--288},
title = {{Regression shrinkage and selection via the lasso}},
volume = {58},
year = {1996}
}
@article{Freestone2014,
abstract = {This research introduces a new method for functional brain imaging via a process of model inversion. By estimating parameters of a computational model, we are able to track effective connectivity and mean membrane potential dynamics that cannot be directly measured using electrophysiological measurements alone. The ability to track the hidden aspects of neurophysiology will have a profound impact on the way we understand and treat epilepsy. For example, under the assumption the model captures the key features of the cortical circuits of interest, the framework will provide insights into seizure initiation and termination on a patient-specific basis. It will enable investigation into the effect a particular drug has on specific neural populations and connectivity structures using minimally invasive measurements. The method is based on approximating brain networks using an interconnected neural population model. The neural population model is based on a neural mass model that describes the functional activity of the brain, capturing the mesoscopic biophysics and anatomical structure. The model is made subject-specific by estimating the strength of intra-cortical connections within a region and inter-cortical connections between regions using a novel Kalman filtering method. We demonstrate through simulation how the framework can be used to track the mechanisms involved in seizure initiation and termination.},
author = {Freestone, Dean R and Karoly, Philippa J and Ne{\v{s}}i{\'{c}}, Dragan and Aram, Parham and Cook, Mark J and Grayden, David B},
doi = {10.3389/fnins.2014.00383},
file = {::},
isbn = {1662-4548 (Print)$\backslash$r1662-453X (Linking)},
issn = {1662-4548},
journal = {Frontiers in neuroscience},
keywords = {effective connectivity,epilepsy,functional connectivity,kalman filter,model,model inversion,neural mass model,parameter estimation,seizures},
number = {November},
pages = {383},
pmid = {25506315},
publisher = {Frontiers Media SA},
title = {{Estimation of effective connectivity via data-driven neural modeling.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25506315 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4246673 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4246673{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {8},
year = {2014}
}
@article{NadarajahKotz08,
author = {Nadarajah, S and Kotz, S},
journal = {Acta Applicandae Mathematicae},
pages = {99--118},
title = {{Estimation Methods for the Multivariate t Distribution}},
volume = {102},
year = {2008}
}
@book{GRE81,
address = {New York},
author = {Grenander, U},
publisher = {Wiley},
title = {{Abstract inference}},
year = {1981}
}
@book{Papoulis1965,
author = {Papoulis, A and Pillai, S U},
publisher = {McGraw-Hill New York},
title = {{Probability, Random Variables, and Stochastic Processes}},
url = {http://www.slac.stanford.edu/spires/find/books/www?key=323292},
year = {1965}
}
@article{Goychuk2004,
annote = {2009num23},
archivePrefix = {arXiv},
arxivId = {arXiv:physics/0407105v2},
author = {Goychuk, Igor and H{\"{a}}nggi, P and Hanggi, P},
eprint = {0407105v2},
journal = {Physical Review E},
number = {5},
pages = {51915},
primaryClass = {arXiv:physics},
publisher = {APS},
title = {{Fractional diffusion modeling of ion channel gating}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.70.051915 http://pre.aps.org/abstract/PRE/v70/i5/e051915},
volume = {70},
year = {2004}
}
@article{Roxin2004,
author = {Roxin, Alex and Riecke, Hermann and Solla, S A},
doi = {10.1103/PhysRevLett.92.198101},
issn = {0031-9007},
journal = {Physical Review Letters},
number = {19},
pages = {1--4},
title = {{Self-Sustained Activity in a Small-World Network of Excitable Neurons}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.92.198101},
volume = {92},
year = {2004}
}
@article{Newman2005,
author = {Newman, Mej},
doi = {10.1080/00107510500052444},
issn = {0010-7514},
journal = {Contemporary Physics},
month = {sep},
number = {5},
pages = {323--351},
title = {{Power laws, Pareto distributions and Zipf's law}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00107510500052444},
volume = {46},
year = {2005}
}
@article{Mackay1992,
author = {MacKay, D J C},
journal = {Neural computation},
number = {1},
pages = {448--472},
title = {{A practical Bayesian framework for backpropagation networks}},
url = {http://www.mitpressjournals.org/doi/pdf/10.1162/neco.1992.4.3.448},
volume = {472},
year = {1992}
}
@article{Ermentrout1998a,
abstract = {We show that negative feedback to highly nonlinear frequency-current (F-I) curves results in an effective linearization. (By highly nonlinear we mean that the slope at threshold is infinite or very steep.) We then apply this to a specific model for spiking neurons and show that the details of the adaptation mechanism do not affect the results. The crucial points are that the adaptation is slow compared to other processes and the unadapted F-I curve is highly nonlinear.},
author = {Ermentrout, B},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation, Physiological,Adaptation, Physiological: physiology,Calcium,Calcium: physiology,Electric Conductivity,Feedback,Models, Neurological,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Potassium,Potassium: physiology,Time Factors},
month = {oct},
number = {7},
pages = {1721--9},
pmid = {9744894},
title = {{Linearization of F-I curves by adaptation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9744894},
volume = {10},
year = {1998}
}
@article{SEE02,
author = {Seeger, M},
journal = {Journal of Machine Learning Research},
pages = {233--269},
title = {{{\{}PAC{\}}-{\{}B{\}}ayesian generalisation error bounds for {\{}G{\}}aussian process classifiers}},
volume = {3},
year = {2002}
}
@article{Davidsen2002,
annote = {2010num2.10},
author = {Davidsen, J{\"{o}}rn and Schuster, Heinz},
doi = {10.1103/PhysRevE.65.026120},
issn = {1063-651X},
journal = {Physical Review E},
number = {2},
pages = {2--5},
title = {{Simple model for 1/f{\^{}}{\{}$\alpha${\}} noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.65.026120},
volume = {65},
year = {2002}
}
@article{Srinivasan|1999|,
abstract = {We outline a different method of describing scalar field particle
production in a uniform electric field. In the standard approach,
the (analytically continued) harmonic oscillator paradigm is important
in describing particle production. In the gauges normally considered,
in which the four vector potential depends only on the time or space
coordinate, the system reduces to a non-relativistic effective Schr{\^{A}}¨odinger
equation with an inverted oscillator potential. The Bogolubov coefficients
are determined by tunnelling in this potential. In the Schwinger
proper time method of determining the effective Lagrangian, the analytically
continued propagator for the usual oscillator system is regarded
as the correct propagator for the inverted oscillator system and
is used to obtain the gauge invariant result. However, there is another
gauge in which the particle production process has striking similarities
with the one used to describe Hawking radiation in black holes. The
gauge we use to describe the electric field in is the lightcone gauge,
so named because the mode functions for a scalar field are found
to be singular on the lightcone. We use these modes in evaluating
the effective Lagrangian using the proper time technique. The key
feature of this analysis is that these modes can be explicitly {\"{i}}¾“normalized{\"{i}}¾”
by using the criterion that they reduce to the usual flat space modes
in the limit of the electric field tending to zero. This normalization
procedure allows one to determine the Schwinger proper time kernel
without using the analytical continuation of the harmonic oscillator
kernel that is resorted to in the standard analysis. We find that
the proper time kernel is not the same as the analytically continued
oscillator kernel though the effective Lagrangian is the standard
result as it should be. We also consider an example of a confined
electric field system using the lightcone gauge modes that has several
features of interest. In particular, our analysis indicates that
the Bogolubov coefficients, in taking the limit to the uniform electric
field case, are multiplied by energy dependent boundary factors that
have not been taken into account before.},
author = {Srinivasan, K and Padmanabhan, T},
journal = {arXiv},
keywords = {particle production,physics,quantum mechanics,unread,vacuum},
pages = {9911022},
title = {{A novel approach to particle production in an uniform electric field}},
volume = {gr-qc}
}
@article{Nisamaneephong|1993|,
abstract = {We show that gaussian quantum fluctuations, even if infinitesimal,
are suf- ficient to destroy the superfluidity of a disordered boson
system in 1D and 2D. The critical disorder is thus finite no matter
how small the repulsion is between particles. Within the gaussian
approximation, we study the nature of the elementary excitations,
including their density of states and mobility edge transition. We
give the gaussian exponent eta at criticality in 1D and show that
its ratio to eta of the pure system is universal.},
author = {Nisamaneephong, P and Zhang, L},
journal = {arXiv},
keywords = {bose-glass,gaussian theory of phase transition,physics,quantum mechanics,superfluidity},
pages = {9307044},
title = {{A gaussian theory of superfluid bose-glass phase transition}},
volume = {cond-mat}
}
@article{Fisher08,
author = {Fisher, Jonathan A N and Barchi, Jonathan R and Welle, Cristin G and Kim, Gi-Ho and Kosterin, Paul and Obaid, Ana Lia and Yodh, Arjun G and Contreras, Diego and Salzberg, Brian M},
doi = {10.1152/jn.00929.2007},
journal = {J Neurophysiol},
number = {3},
pages = {1545--1553},
title = {{Two-Photon Excitation of Potentiometric Probes Enables Optical Recording of Action Potentials From Mammalian Nerve Terminals In Situ}},
volume = {99},
year = {2008}
}
@article{Mauduit1992,
abstract = {Neural network simulations on a parallel architecture are reported. The architecture is scalable and flexible enough to be useful for simulating various kinds of networks and paradigms. The computing device is based on an existing coarse-grain parallel framework (INMOS transputers), improved with finer-grain parallel abilities through VLSI chips, and is called the Lneuro 1.0 (for LEP neuromimetic) circuit. The modular architecture of the circuit makes it possible to build various kinds of boards to match the expected range of applications or to increase the power of the system by adding more hardware. The resulting machine remains reconfigurable to accommodate a specific problem to some extent. A small-scale machine has been realized using 16 Lneuros, to experimentally test the behavior of this architecture. Results are presented on an integer version of Kohonen feature maps. The speedup factor increases regularly with the number of clusters involved (to a factor of 80). Some ways to improve this family of neural network simulation machines are also investigated.},
author = {Mauduit, N and Duranton, M and Gobert, J and Sirat, J a},
doi = {10.1109/72.129414},
issn = {1045-9227},
journal = {Neural Networks, IEEE {\ldots}},
month = {jan},
number = {3},
pages = {414--22},
pmid = {18276445},
title = {{Lneuro 1.0: A piece of hardware LEGO for building neural network systems}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18276445 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=129414},
volume = {3},
year = {1992}
}
@article{Bento|2000|,
abstract = {Self-interacting dark matter has been suggested in order to overcome
the difficulties of the Cold Dark Matter model on galactic scales.
We argue that a scalar gauge singlet coupled to the Higgs boson,
which could lead to an invisibly decaying Higgs, is an interesting
candidate for this self- interacting dark matter particle. We also
present estimates on the abundance of these particles today as well
as consequences to non-Newtonian forces.},
author = {Bento, M C and Bertolami, O and Rosenfeld, R and Teodoro, L},
journal = {arXiv},
keywords = {Higgs boson,astrophysics,dark matter,interacting,non-newtonian,physics,self-interacting},
pages = {3350},
title = {{Self-Interacting Dark Matter and Invisibly Decaying Higgs}},
volume = {astro-ph}
}
@article{Merolla2014,
abstract = {Inspired by the brain's structure, we have developed an efficient, scalable, and flexible non–von Neumann architecture that leverages contemporary silicon technology. To demonstrate, we built a 5.4-billion-transistor chip with 4096 neurosynaptic cores interconnected via an intrachip network that integrates 1 million programmable spiking neurons and 256 million configurable synapses. Chips can be tiled in two dimensions via an interchip communication interface, seamlessly scaling the architecture to a cortexlike sheet of arbitrary size. The architecture is well suited to many applications that use complex neural networks in real time, for example, multiobject detection and classification. With 400-pixel-by-240-pixel video input at 30 frames per second, the chip consumes 63 milliwatts},
author = {Merolla, Paul A and Arthur, John V and Alvarez-Icaza, Rodrigo and Cassidy, Andrew S and Sawada, Jun and Akopyan, Filipp and Jackson, Bryan L and Imam, Nabil and Guo, Chen and Nakamura, Yutaka and Brezzo, Bernard and Vo, Ivan and Esser, Steven K and Appuswamy, Rathinakumar and Taba, Brian and Amir, Arnon and Flickner, Myron D and Risk, William P and Manohar, Rajit and Modha, Dharmendra S},
doi = {10.1126/science.1254642},
file = {::},
isbn = {1853467960},
issn = {0036-8075},
journal = {Science},
number = {6197},
pages = {668--673},
pmid = {25104385},
title = {{A million spiking-neuron integrated circuit with a scalable communication network and interface}},
url = {http://www.sciencemag.org/content/345/6197/668.short http://www.sciencemag.org/cgi/doi/10.1126/science.1254642},
volume = {345},
year = {2014}
}
@article{Gilboa2005a,
annote = {2009num22},
author = {Gilboa, G and Chen, R and Brenner, N},
journal = {Journal of Neuroscience},
number = {28},
pages = {6479},
publisher = {Soc Neuroscience},
title = {{History-dependent multiple-time-scale dynamics in a single-neuron model}},
url = {http://neuro.cjb.net/cgi/content/abstract/25/28/6479},
volume = {25},
year = {2005}
}
@article{Li|1994|,
author = {Li, X G and Somogyi, P and Ylinen, A and Buzsaki, G},
journal = {J Comp Neurol},
keywords = {Animals Female Hippocampus/*cytology/ultrastructur,Sprague-Dawley Rats,Wistar Synapses/physiology/ultrastructure Termino},
number = {2},
pages = {181--208},
title = {{The hippocampal CA3 network: an in vivo intracellular labeling study}},
volume = {339}
}
@article{Gurkiewicz2007,
abstract = {The activity of trans-membrane proteins such as ion channels is the essence of neuronal transmission. The currently most accurate method for determining ion channel kinetic mechanisms is single-channel recording and analysis. Yet, the limitations and complexities in interpreting single-channel recordings discourage many physiologists from using them. Here we show that a genetic search algorithm in combination with a gradient descent algorithm can be used to fit whole-cell voltage-clamp data to kinetic models with a high degree of accuracy. Previously, ion channel stimulation traces were analyzed one at a time, the results of these analyses being combined to produce a picture of channel kinetics. Here the entire set of traces from all stimulation protocols are analysed simultaneously. The algorithm was initially tested on simulated current traces produced by several Hodgkin-Huxley-like and Markov chain models of voltage-gated potassium and sodium channels. Currents were also produced by simulating levels of noise expected from actual patch recordings. Finally, the algorithm was used for finding the kinetic parameters of several voltage-gated sodium and potassium channels models by matching its results to data recorded from layer 5 pyramidal neurons of the rat cortex in the nucleated outside-out patch configuration. The minimization scheme gives electrophysiologists a tool for reproducing and simulating voltage-gated ion channel kinetics at the cellular level.},
author = {Gurkiewicz, Meron and Korngreen, Alon},
doi = {10.1371/journal.pcbi.0030169},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Cell Membrane,Cell Membrane: physiology,Computer Simulation,Ion Channel Gating,Ion Channel Gating: physiology,Ion Channels,Ion Channels: physiology,Membrane Potentials,Membrane Potentials: physiology,Models, Genetic,Models, Neurological,Neurons,Neurons: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {aug},
number = {8},
pages = {e169},
pmid = {17784781},
title = {{A numerical approach to ion channel modelling using whole-cell voltage-clamp recordings and a genetic algorithm.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1963494{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2007}
}
@article{simandl2001filtering,
annote = {2008num25},
author = {{\v{S}}imandl, M and Kr{\'{a}}lovec, J and Tichavsky, P},
journal = {Automatica},
number = {11},
pages = {1703--1716},
publisher = {Elsevier},
title = {{Filtering, predictive, and smoothing Cram{\{}{\'{e}}{\}}r--Rao bounds for discrete-time nonlinear dynamic systems}},
volume = {37},
year = {2001}
}
@article{Ostojic2011,
abstract = {Neurons transform time-varying inputs into action potentials emitted stochastically at a time dependent rate. The mapping from current input to output firing rate is often represented with the help of phenomenological models such as the linear-nonlinear (LN) cascade, in which the output firing rate is estimated by applying to the input successively a linear temporal filter and a static non-linear transformation. These simplified models leave out the biophysical details of action potential generation. It is not a priori clear to which extent the input-output mapping of biophysically more realistic, spiking neuron models can be reduced to a simple linear-nonlinear cascade. Here we investigate this question for the leaky integrate-and-fire (LIF), exponential integrate-and-fire (EIF) and conductance-based Wang-Buzs{\'{a}}ki models in presence of background synaptic activity. We exploit available analytic results for these models to determine the corresponding linear filter and static non-linearity in a parameter-free form. We show that the obtained functions are identical to the linear filter and static non-linearity determined using standard reverse correlation analysis. We then quantitatively compare the output of the corresponding linear-nonlinear cascade with numerical simulations of spiking neurons, systematically varying the parameters of input signal and background noise. We find that the LN cascade provides accurate estimates of the firing rates of spiking neurons in most of parameter space. For the EIF and Wang-Buzs{\'{a}}ki models, we show that the LN cascade can be reduced to a firing rate model, the timescale of which we determine analytically. Finally we introduce an adaptive timescale rate model in which the timescale of the linear filter depends on the instantaneous firing rate. This model leads to highly accurate estimates of instantaneous firing rates.},
author = {Ostojic, Srdjan and Brunel, N},
doi = {10.1371/journal.pcbi.1001056},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Humans,Linear Models,Neurons,Neurons: physiology,Nonlinear Dynamics},
month = {jan},
number = {1},
pages = {e1001056},
pmid = {21283777},
title = {{From spiking neuron models to linear-nonlinear models.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3024256{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2011}
}
@article{Rochery|2005|,
abstract = {We present a new model for the extraction of networks from images
in the presence of occlusions. Such occlusions cause gaps in the
extracted network that need to be closed. Using higher-order active
contours, which allow the incorporation of sophisticated geometric
information, we introduce a new, non-local, {\"{i}}¾‘gap closure{\"{i}}¾' force
that causes pairs of network extremities that are close together
to extend towards one another and join, thus closing the gap between
them. We demonstrate the benefits of the model using the problem
of road network extraction, presenting results on aerial images.},
annote = {The paper describes a method for gap closure in active contour road{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}extraction based on "higher-order" level set describing forces on{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}active contour leading to leaking of active contours though high-curvature{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}areas.},
author = {Rochery, M and Jermyn, I H and Zerubia, J},
keywords = {active contours,computational,image processing,level set},
title = {{Gap closure in (road) networks using higher-order active contours}}
}
@article{HAHN03,
author = {Hahnloser, R and Seung, S and Slotine, J},
journal = {Neural Computation},
pages = {621--638},
title = {{Permitted and Forbidden Sets in Symmetric Threshold-Linear Networks}},
volume = {15},
year = {2003}
}
@article{Milev2003,
abstract = {In real-life applications of multilayer neural networks, the scale of integration, processing speed, and manufacturability are of key importance. A simple analog-signal synapse model is implemented on a standard 0.35 /spl mu/m CMOS process requiring no floating-gate capability. A neural-matrix of 2176 analog current-mode synapses arranged in eight layers of 16 neurons with 16 inputs each is constructed for the purpose of a fingerprint feature extraction application. Synapse weights are stored on the analog storage capacitors, and synapse nonlinearity with respect to weight is investigated. The capability of the synapse to operate in feedforward and learning modes is studied and demonstrated. The effect of the synapse's inherent quadratic nonlinearity on learning convergence and on the optimization of vector direction is analyzed. Transistor-level analog simulations verify the hardware circuit. System-level MatLab simulations verify the synapse mathematical model. The conclusion reached is that the proposed implementation is very suitable for large-scale artificial neural networks - especially if on-chip integration with other products on a standard CMOS process is required.},
author = {Milev, M and Hristov, M},
doi = {10.1109/TNN.2003.816369},
issn = {1045-9227},
journal = {Neural Networks, IEEE Transactions on},
month = {sep},
number = {5},
pages = {1187--200},
pmid = {18244570},
title = {{Analog implementation of ANN with inherent quadratic nonlinearity of the synapses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18244570},
volume = {14},
year = {2003}
}
@article{Yu1992,
abstract = {From a theoretic point of view, we show that for an arbitrary T-element training set with t(t less-than-or-equal-to T) different inputs, the backpropagation error surface does not have suboptimal local minima if the network is capable of exactly implementing an arbitrary training set consisting of t different patterns. As a special case, the error surface of a backpropagation network with one hidden layer and t - 1 hidden units has no local minima, if the network is trained by an arbitrary T-element set with t different inputs.},
author = {Yu, Xiao Hu},
doi = {10.1109/72.165604},
isbn = {1045-9227},
issn = {19410093},
journal = {IEEE Transactions on Neural Networks},
number = {6},
pages = {1019--1021},
pmid = {18267858},
title = {{Can Backpropagation Error Surface Not Have Local Minima}},
volume = {3},
year = {1992}
}
@inproceedings{TB99,
author = {Tishby, N and Pereira, F and Bialek, W},
booktitle = {Proceedings 37th Allerton Conference on Communication, Control, and Computing},
title = {{The information bottleneck method.}},
year = {1999}
}
@article{Ahmari|2002|,
author = {Ahmari, S E and Smith, S J},
journal = {Neuron},
number = {3},
pages = {333--336},
title = {{Knowing a nascent synapse when you see it.}},
volume = {34}
}
@article{KONT97,
author = {Kontoyiannis, I},
journal = {IEEE Transactions Information Theory},
pages = {1339--1341},
title = {{Second-order noiseless source coding theorems}},
volume = {43},
year = {1997}
}
@article{Schmandt2012,
author = {Schmandt, Nicolaus and Gal{\'{a}}n, Roberto},
doi = {10.1103/PhysRevLett.109.118101},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {sep},
number = {11},
pages = {1--5},
title = {{Stochastic-Shielding Approximation of Markov Chains and its Application to Efficiently Simulate Random Ion-Channel Gating}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.109.118101},
volume = {109},
year = {2012}
}
@article{Jugloff2000,
abstract = {The contribution of voltage-dependent ion channels to nerve function depends upon their cell-surface distributions. Nevertheless, the mechanisms underlying channel localization are poorly understood. Two phenomena appear particularly important: the clustering of channels by membrane-associated guanylate kinases (MAGUKs), such as PSD-95, and the regional stabilization of cell-surface proteins by differential suppression of endocytosis. Could these phenomena be related? To test this possibility we examined the effect of PSD-95 on the internalization rate of Kv1.4 K+ channels in transfected HEK293 cells using cell-surface biotinylation assays. When expressed alone Kv1.4 was internalized with a half-life of 87 min, but, in the presence of PSD-95, Kv1.4 internalization was completely suppressed. Immunochemistry and electrophysiology showed PSD-95 had little effect on total or cell-surface levels of Kv1.4 or on current amplitude, activation, or inactivation kinetics. Clustering was necessary and sufficient to suppress Kv1.4 internalization since C35S-PSD-95, a mutant reported to bind but not cluster Kv1.4, (confirmed by imaging cells co-expressing a functional, GFP-variant-tagged Kv1.4) restored and, surprisingly, enhanced the rate of Kv1.4 internalization (t1/2 = 16 min). These data argue PSD-95-mediated clustering suppresses Kv1.4 internalization and suggest a fundamentally new role for PSD-95, and perhaps other MAGUKs, orchestrating the stabilization of channels at the cell-surface.},
author = {Jugloff, D G M},
doi = {10.1074/jbc.275.2.1357},
issn = {00219258},
journal = {Journal of Biological Chemistry},
month = {jan},
number = {2},
pages = {1357--1364},
title = {{Internalization of the Kv1.4 Potassium Channel Is Suppressed by Clustering Interactions with PSD-95}},
url = {http://www.jbc.org/cgi/content/abstract/275/2/1357},
volume = {275},
year = {2000}
}
@article{GAT97,
author = {Gat, I and Tishby, N and Abeles, M},
journal = {Network: Computation in Neural Systems},
pages = {297--322},
title = {{Hidden {\{}M{\}}arkov modeling of simultaneously recorded cells in the associative cortex of behaving monkeys}},
volume = {8},
year = {1997}
}
@article{Werner2009,
annote = {2010num2.1},
author = {Werner, G},
journal = {Frontiers in Fractal Physiology},
title = {{Fractals in the nervous system: conceptual implications for theoretical neuroscience}},
url = {http://arxiv.org/pdf/0910.2741 http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059969/},
year = {2010}
}
@article{daoudal2003long,
annote = {2009num48},
author = {Daoudal, G and Debanne, D},
journal = {Learning {\&} Memory},
number = {6},
pages = {456},
publisher = {Cold Spring Harbor Lab},
title = {{Long-term plasticity of intrinsic excitability: learning rules and mechanisms}},
volume = {10},
year = {2003}
}
@article{Rigotti2010,
abstract = {Neural activity of behaving animals, especially in the prefrontal cortex, is highly heterogeneous, with selective responses to diverse aspects of the executed task. We propose a general model of recurrent neural networks that perform complex rule-based tasks, and we show that the diversity of neuronal responses plays a fundamental role when the behavioral responses are context-dependent. Specifically, we found that when the inner mental states encoding the task rules are represented by stable patterns of neural activity (attractors of the neural dynamics), the neurons must be selective for combinations of sensory stimuli and inner mental states. Such mixed selectivity is easily obtained by neurons that connect with random synaptic strengths both to the recurrent network and to neurons encoding sensory inputs. The number of randomly connected neurons needed to solve a task is on average only three times as large as the number of neurons needed in a network designed ad hoc. Moreover, the number of needed neurons grows only linearly with the number of task-relevant events and mental states, provided that each neuron responds to a large proportion of events (dense/distributed coding). A biologically realistic implementation of the model captures several aspects of the activity recorded from monkeys performing context-dependent tasks. Our findings explain the importance of the diversity of neural responses and provide us with simple and general principles for designing attractor neural networks that perform complex computation.},
author = {Rigotti, Mattia and Rubin, Daniel Ben Dayan and Wang, Xiao-Jing and Fusi, Stefano and Neuroscience, Computational},
doi = {10.3389/fncom.2010.00024},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {attractor neural network,mixed selectivity,persistent activity,prefrontal cortex,randomly,rule-based behavior},
month = {jan},
number = {October},
pages = {24},
pmid = {21048899},
title = {{Internal representation of task rules by recurrent dynamics: the importance of the diversity of neural responses.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2967380{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2010}
}
@inproceedings{Vasilkoski2011,
address = {San Jose, CA},
author = {Vasilkoski, Z and Ames, H and Chandler, B and Gorchetchnikov, A and Leveille, J and Livitz, G and Mingolla, E and Versace, M},
booktitle = {The 2011 International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.2011.6033553},
isbn = {978-1-4244-9635-8},
month = {jul},
pages = {2563--2569},
publisher = {Ieee},
title = {{Review of stability properties of neural plasticity rules for implementation on memristive neuromorphic hardware}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6033553},
year = {2011}
}
@article{SIEG51,
author = {Siegert, A},
journal = {Physical Review},
pages = {617--623},
title = {{On the First Passage Time Probability Problem}},
volume = {81},
year = {1951}
}
@book{Hille2001,
address = {Sunderland, MA 01375},
author = {Hille, B},
edition = {3rd},
publisher = {Sinauer Associates},
title = {{Ion Channels of Excitable Membranes}},
year = {2001}
}
@article{Kwan2012,
abstract = {A fundamental process underlying all brain functions is the propagation of spiking activity in networks of excitatory and inhibitory neurons. In the neocortex, although functional connections between pairs of neurons have been studied extensively in brain slices, they remain poorly characterized in vivo, where the high background activity, global brain states, and neuromodulation can powerfully influence synaptic transmission. To understand how spikes are transmitted in cortical circuits in vivo, we used two-photon calcium imaging to monitor ensemble activity and targeted patching to stimulate a single neuron in mouse visual cortex.},
author = {Kwan, Alex C and Dan, Yang},
doi = {10.1016/j.cub.2012.06.007},
issn = {1879-0445},
journal = {Current biology : CB},
month = {aug},
number = {16},
pages = {1459--67},
pmid = {22748320},
title = {{Dissection of cortical microcircuits by single-neuron stimulation in vivo.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22748320},
volume = {22},
year = {2012}
}
@book{McLachlanKrishnan96,
abstract = {The only single-source--now completely updated and revised--to offer a unified treatment of the theory, methodology, and applications of the EM algorithm Complete with updates that capture developments from the past decade, The EM Algorithm and Extensions, Second Edition successfully provides a basic understanding of the EM algorithm by describing its inception, implementation, and applicability in numerous statistical contexts. In conjunction with the fundamentals of the topic, the authors discuss convergence issues and computation of standard errors, and, in addition, unveil many parallels and connections between the EM algorithm and Markov chain Monte Carlo algorithms. Thorough discussions on the complexities and drawbacks that arise from the basic EM algorithm, such as slow convergence and lack of an in-built procedure to compute the covariance matrix of parameter estimates, are also presented. While the general philosophy of the First Edition has been maintained, this timely new edition has been updated, revised, and expanded to include: The EM Algorithm and Extensions, Second Edition serves as an excellent text for graduate-level statistics students and is also a comprehensive resource for theoreticians, practitioners, and researchers in the social and physical sciences who would like to extend their knowledge of the EM algorithm.},
author = {Mclachlan, Geoffrey J and Krishnan, Thriyambakam},
isbn = {9780471201700},
publisher = {Wiley-Interscience},
title = {{The EM Algorithm and Extensions Second Edition}},
year = {2008}
}
@article{Musha1997a,
author = {Musha, T. and Yamamoto, Mitsuaki},
journal = {{\ldots} in Medicine and Biology Society, 1997 {\ldots}},
pages = {2692--2697},
title = {1/f fluctuations in biological systems},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=756890},
year = {1997}
}
@article{Remtulla1985,
abstract = {The thicknesses and spheric and aspheric curvatures of the optic components were measured from cross-sections of frozen eyes of C57B1/6J mice. The equivalent refractive index of the crystalline lens was obtained from its back-vertex power in albumin. Refractive indices of the cornea, aqueous and vitreous humors were obtained by refractometry or interferometry at four wavelengths across the visible spectrum. The measurements parallel earlier ones on the hooded rat. The eyes of the mouse and rat differ mainly in size, by a linear scale factor of 1.9-2.0, and only slightly in refractive index. Thus refraction, chromatic aberration, and retinal illumination are easily compared in the two species. An analysis of the contribution of each optical surface to refraction may facilitate extrapolation to other strains of mice. Chromatic aberration is discussed with respect to depth of field and the retinoscopy artefact.},
author = {Remtulla, S and Hallett, P E},
issn = {0042-6989},
journal = {Vision research},
keywords = {Animals,Biometry,Color Perception,Color Perception: physiology,Eye,Eye: anatomy {\&} histology,Mice,Mice, Inbred C57BL,Mice, Inbred C57BL: anatomy {\&} histology,Mice, Inbred C57BL: physiology,Ocular Physiological Phenomena,Rats,Rats, Inbred Strains,Refraction, Ocular,Retina,Retina: physiology},
month = {jan},
number = {1},
pages = {21--31},
pmid = {3984214},
title = {{A schematic eye for the mouse, and comparisons with the rat.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3984214},
volume = {25},
year = {1985}
}
@article{kenkre1973generalized,
annote = {2009num58},
author = {Kenkre, V M and Montroll, E W and Shlesinger, M F},
journal = {Journal of Statistical Physics},
number = {1},
pages = {45--50},
publisher = {Springer},
title = {{Generalized master equations for continuous-time random walks}},
volume = {9},
year = {1973}
}
@article{NYK05,
author = {Nykamp, D Q},
journal = {SIAM Journal on Applied Mathematics},
pages = {2005--2032},
title = {{Revealing pairwise coupling in linear-nonlinear networks}},
volume = {65},
year = {2005}
}
@article{Santos|2003|,
abstract = {We tutorially review the determinantal Quantum Monte Carlo method
for fermionic systems, using the Hubbard model as a case study. Starting
with the basic ingredients of Monte Carlo simulations for classical
systems, we introduce aspects such as importance sampling, sources
of errors, and finite-size scaling analyses. We then set up the preliminary
steps to prepare for the simulations, showing that they are actually
carried out by sampling discrete Hubbard-Stratonovich auxiliary fields.
In this process the Green{\"{i}}¾'s function emerges as a fundamental tool,
since it is used in the updating process, and, at the same time,
it is directly related to the quantities probing magnetic, charge,
metallic, and superconducting behaviours. We also discuss the as
yet unresolved {\"{i}}¾‘minus-sign problem{\"{i}}¾', and two ways to stabilize
the algorithm at low temperatures.},
author = {dos Santos, R R},
journal = {Brazilian Journal of Physics},
keywords = {fermionic systems,physics,quantum monte carlo},
pages = {36},
title = {{Introduction to quantum monte carlo simulations for fermionic systems, unread}},
volume = {33}
}
@book{DEV01,
address = {New York},
author = {Devroye, L and Lugosi, G},
publisher = {Springer-Verlag},
title = {{Combinatorial Methods in Density Estimation}},
year = {2001}
}
@article{Dordek2016,
abstract = {Many recent models study the downstream projection from grid cells to place cells, while recent data have pointed out the importance of the feedback projection. We thus asked how grid cells are affected by the nature of the input from the place cells. We propose a single-layer neural network with feedforward weights connecting place-like input cells to grid cell outputs. Place-to-grid weights are learned via a generalized Hebbian rule. The architecture of this network highly resembles neural networks used to perform Principal Component Analysis (PCA). Both numerical results and analytic considerations indicate that if the components of the feedforward neural network are non-negative, the output converges to a hexagonal lattice. Without the non-negativity constraint, the output converges to a square lattice. Consistent with experiments, grid spacing ratio between the first two consecutive modules is -1.4. Our results express a possible linkage between place cell to grid cell interactions and PCA.},
author = {Dordek*, Y. and Soudry*, D. and Meir, R. and Derdikman, D.},
doi = {10.7554/eLife.10094},
issn = {2050-084X},
journal = {eLife},
keywords = {bat,entorhinal,grid cell,hippocampus,human,mouse,navigation,neuroscience,place cell,rat},
number = {MARCH2016},
pages = {e10094},
pmid = {26952211},
publisher = {eLife Sciences Publications Limited},
title = {{Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis (*contributed equally)}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26952211 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4841785},
volume = {5},
year = {2016}
}
@article{Hinton2012,
abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
doi = {arXiv:1207.0580},
eprint = {1207.0580},
isbn = {9781467394673},
journal = {ArXiv: 1207.0580},
pages = {1--18},
title = {{Improving neural networks by preventing co-adaptation of feature detectors}},
url = {http://arxiv.org/abs/1207.0580},
year = {2012}
}
@article{Berger2010,
abstract = {A neuroscience-based mathematical model of how a neuron stochastically processes data and communicates information is introduced and analyzed. Call the neuron in question 'neuron j", or just "j". The information j transmits approximately describes the time-varying intensity of the excitation j is continuously experiencing from neural spike trains delivered to its synapses by thousands of other neurons. Neuron j "encodes" this excitation history into a sequence of time instants at which it generates neural spikes of its own. By propagating these spikes along its axon, j acts as a multiaccess, partially degraded broadcast channel with thousands of input and output terminals that employs a time-continuous version of pulse position modulation. The mathematical model features three parameters, m, {\~{A}}{\^{A}}¿, and b, which largely characterize j as an engine of computation and communication. Each set of values of these parameters corresponds to a long term maximization of the bits j conveys to its targets per joule it expends doing so, which is achieved by distributing the random duration between successive spikes j generates according to a gamma pdf with parameters {\~{A}}{\^{A}}¿ and b and distributing b/A according to a beta probability density with parameters {\~{A}}{\^{A}}¿ and m-{\~{A}}{\^{A}}¿, where A is the random intensity of the effectively Poisson process of spikes that arrive to the union of all of j's synapses at a randomly chosen time instant.},
annote = {2010IIInum40},
author = {Berger, Toby and Levy, W B},
doi = {10.1109/TIT.2009.2037089},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {852--874},
title = {{A Mathematical Theory of Energy Efficient Neural Computation and Communication}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5420278},
volume = {56},
year = {2010}
}
@article{Liao|2006|,
abstract = {We propose a marginal posterior mode (MPM) approach to the reconstruction
of 3D label images from only a few projections, using Gibbs priors.
This work is motivated by electron tomography of biological macromolecules.
The strategy is to produce a tesselation of space into small voxels
and label each voxel as containing ice, protein, or ribosomal nucleic
acid (RNA), based on (because of the radiation damage) only a few
electron micrographs.},
annote = {This paper considers method for markov-field-like reconstruction{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}from few projections. Two steps - algebraic reconstruction from projections,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}tuned then by assumption that underlying data are from two gaussian-distributed{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}intensity classes + assumption on homogeneity aka markov-random-field{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}filtering [Gibbs distribution]. Nice work but very {\&}{\#}039;expensive{\&}{\#}039;.},
author = {Liao, H Y and Herman, G T},
keywords = {Gibbs distribution,bayesian,computational,discrete tomography,marginal posterior,mathematics,stochastic optimization,two-class},
title = {{Discrete tomography with a very few views using Gibbs priors and a Marginal Posterior Mode approach}}
}
@article{SZ98,
author = {Stevens, C and Zador, A},
journal = {Proc. 5th joint symp. neural computation, UCSD},
title = {{Novel integrate-and-fire-like model of repetitive firing in cortical neurons}},
year = {1998}
}
@article{LATH02,
author = {Nirenberg, S and Carcieri, S and Jacobs, A and Latham, P},
journal = {Nature},
pages = {698--701},
title = {{Retinal ganglion cells act largely as independent encoders}},
volume = {411},
year = {2002}
}
@article{Choi|1996|,
author = {Choi, K W and Mozer, B and Benzer, S},
journal = {Proc Natl Acad Sci U S A},
keywords = {Animals Drosophila/embryology/genetics/*physiology},
number = {12},
pages = {5737--5741},
title = {{Independent determination of symmetry and polarity in the Drosophila eye}},
volume = {93}
}
@article{Kirst2009,
author = {Kirst, Christoph and Geisel, Theo and Timme, Marc},
doi = {10.1103/PhysRevLett.102.068101},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {feb},
number = {6},
pages = {1--4},
title = {{Sequential Desynchronization in Networks of Spiking Neurons with Partial Reset}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.102.068101},
volume = {102},
year = {2009}
}
@article{Chklovskii|2003|,
abstract = {Background: Axon calibers vary widely among different animals, neuron
classes, and even within the same neuron. What determines the diameter
of axon branches?

Results: We pursue the hypothesis that the axon caliber has evolved
to minimize signal propagation delays, while keeping arbor volume
to a minimum. For a general cost function, we show that the optimal
diameters of mother and daughter branches at a bifurcation satisfy
a power law. The derivation relies on the fact that the axon conduction
speed scales as a power of axon diameter. Although available data
are consistent with the law, there is a large spread in the data.
Future experimental tests will determine whether this spread is due
to biological variability or measurement error.

Conclusions: Minimization of arbor volume and signal propagation delay
may have been an important factor in the evolution of the brain.},
annote = {Paper presents derivation showing that for circuit design minimizing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}general cost function monotonous in two variables of axonal volume{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and conduction delay [action potential speed], a generic power law{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}can be determined for diameters of axons at branch points, i.e. sum{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of power of two branches equals a power of third branch},
author = {Chklovskii, Dmitri B and Stepanyants, Armen},
journal = {BMC Neuroscience},
keywords = {axon diameters,branching,cortical cirtuits,neurobiology,neurogeometry,optimization,power-law},
pages = {18},
title = {{Power-law for axon diameters at branch point}},
volume = {4}
}
@article{mercik2001stochastic,
annote = {2010num3.3},
author = {Mercik, S and Weron, K},
journal = {Physical Review E},
number = {5},
pages = {51910},
publisher = {APS},
title = {{Stochastic origins of the long-range correlations of ionic current fluctuations in membrane channels}},
volume = {63},
year = {2001}
}
@article{Okada04,
author = {Tatsuno, Masami and Okada, Masato},
journal = {Neural Computation},
month = {apr},
number = {4},
pages = {737--765},
title = {{Investigation of possible neural architectures underlying information-geometric measures}},
volume = {16},
year = {2004}
}
@article{jackson2004jobshop,
annote = {2010IIInum56},
author = {Jackson, J R},
journal = {Management science},
keywords = {Neuron Model,correlations,math,networks},
mendeley-tags = {Neuron Model,correlations,math,networks},
number = {12},
pages = {1796--1802},
publisher = {JSTOR},
title = {{Jobshop-like queueing systems}},
url = {http://www.jstor.org/stable/30046149},
volume = {50},
year = {2004}
}
@article{ChangGodfrey02,
author = {Chang, Henry and Chen, Kejian and Kaltenbach, James A and Zhang, Jinsheng and Godfrey, Donald A},
journal = {Hearing Research},
month = {feb},
number = {1-2},
pages = {59--68},
title = {{Effects of acoustic trauma on dorsal cochlear nucleus neuron activity in slices}},
volume = {164},
year = {2002}
}
@article{Holmes05,
author = {Holmes, P and Shea-Brown, E and Moehlis, J and Bogacz, R and Gao, J and Aston-Jones, G and Clayton, E and Rajkowski, J and Cohen, J},
journal = {IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences},
pages = {2496--2503},
title = {{Optimal decisions: From neural spikes, through stochastic differential equations, to behavior}},
volume = {88},
year = {2005}
}
@article{Smith07,
author = {Smith, S},
journal = {Curr. Opin. Neurobio.},
pages = {601--608},
title = {{Circuit reconstruction tools today}},
volume = {17},
year = {2007}
}
@article{Lubeck2003,
author = {Lubeck, S and Heger, PC},
journal = {arXiv preprint cond-mat/0309165},
title = {{Universal finite-size scaling behavior and universal dynamical scaling behavior of absorbing phase transitions with a conserved field}},
url = {http://arxiv.org/abs/cond-mat/0309165},
year = {2003}
}
@article{Fiala|2003|,
author = {Fiala, J C and Kirov, S A and Feinberq, M D and Petrak, L J and George, P and Goddard, C A and Harris, K M},
journal = {J. Comp. Neurol.},
pages = {90--103},
title = {{Timing of neuronal and glial ultrastructure disruption during brain slice preparation and recovery in vitro.}},
volume = {465}
}
@article{CP00,
author = {Camarri, M and Pitman, J},
journal = {Electronic Journal of Probability},
pages = {1--18},
title = {{LIMIT DISTRIBUTIONS AND RANDOM TREES DERIVED FROM THE BIRTHDAY PROBLEM WITH UNEQUAL PROBABILITIES}},
volume = {5},
year = {2000}
}
@article{DGK01,
author = {DiMatteo, I and Genovese, C and Kass, R},
journal = {Biometrika},
pages = {1055--1073},
title = {{Bayesian curve fitting with free-knot splines}},
volume = {88},
year = {2001}
}
@article{Marinari1983,
abstract = {A simple model showing a 1f behavior is proposed. It is argued, on the basis of a scaling argument, that is has (lnf)k corrections. Numerical simulations confirm this picture.},
author = {Marinari, E and Parisi, Giorgio and Ruelle, D and Windey, Paul},
doi = {10.1103/PhysRevLett.50.1223},
isbn = {0031-9007},
issn = {0031-9007},
journal = {Physical Review Letters},
number = {1},
pages = {1223--1225},
publisher = {APS},
title = {{Random walk in a random environment and 1/f noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.50.1223 http://adsabs.harvard.edu/cgi-bin/nph-data{\_}query?bibcode=1983PhRvL..50.1223M{\&}link{\_}type=ABSTRACT{\%}5Cnpapers2://publication/doi/10.1103/PhysRevLett.50.1223},
volume = {50},
year = {1983}
}
@article{Aquino2010,
author = {Aquino, Gerardo and Bologna, Mauro and Grigolini, Paolo and West, BJ},
doi = {10.1103/PhysRevLett.105.040601},
issn = {0031-9007},
journal = {Physical review letters},
month = {jul},
number = {4},
pages = {040601},
title = {{Beyond the death of linear response: 1/f optimal information transport}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.105.040601},
volume = {105},
year = {2010}
}
@article{BeroukhaWoody98,
author = {Beroukha, A and Gruen, E and Woody, C D},
journal = {Neuroreport},
month = {oct},
number = {15},
pages = {3457--3461},
title = {{Facilitation of acoustic responses of cartwheel neurons of the cat dorsal cochlear nucleus}},
volume = {9},
year = {1998}
}
@book{Strunk2007,
author = {Strunk, William},
title = {{The elements of style}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=sj5{\_}wr6zIEcC{\&}oi=fnd{\&}pg=PR8{\&}dq=The+Elements+of+Style{\&}ots=mt8VpnN6oL{\&}sig=kwoGzWNo-fwsq6EGcpRmKJifWm8},
year = {1918}
}
@inproceedings{Teh2006,
author = {Teh, Y W and Newman, D and Welling, M},
booktitle = {Neural Information Processing Systems},
keywords = {collapsed inference lda variational},
pages = {1--9},
title = {{A collapsed variational Bayesian inference algorithm for latent Dirichlet allocation}},
year = {2006}
}
@article{Munoz1999,
author = {Munoz, MA and Dickman, R and Vespignani, A and Zapperi, S},
journal = {Physical Review E},
title = {{Avalanche and spreading exponents in systems with absorbing states}},
url = {http://pre.aps.org/abstract/PRE/v59/i5/p6175{\_}1},
year = {1999}
}
@inproceedings{mohamed2012bayesian,
author = {Mohamed, Shakir and Heller, Katherine and Ghahramani, Zoubin},
booktitle = {International Conference on Machine Learning},
pages = {1--8},
title = {{Bayesian and L1 approaches to sparse unsupervised learning}},
url = {http://arxiv.org/abs/1106.1157},
year = {2012}
}
@misc{Eagleman2011,
annote = {2011num52},
author = {Eagleman, D},
booktitle = {The Atlantic},
title = {{The brain on trial}},
year = {2011}
}
@article{ben-lower,
annote = {2008num26},
author = {Ben-Haim, Z and Eldar, Y C},
journal = {IEEE Transactions on Information Theory},
title = {{A Lower Bound on the Bayesian MSE Based on the Optimal Bias Function}}
}
@article{Duranton1996,
author = {Duranton, Marc},
journal = {{\ldots} for Neural Networks, 1996., Proceedings of Fifth {\ldots}},
pages = {157--160},
title = {{L-Neuro 2.3: A VLSI for image processing by neural networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=493786},
year = {1996}
}
@article{Weber1958,
annote = {2011num14},
author = {Weber, M},
journal = {Daedalus},
title = {{Science as a Vocation}},
url = {http://www.jstor.org/stable/20026431},
year = {1958}
}
@article{Kirst2008,
author = {Kirst, Christoph and Timme, Marc},
doi = {10.1103/PhysRevE.78.065201},
issn = {1539-3755},
journal = {Physical Review E},
month = {dec},
number = {6},
pages = {2--5},
title = {{From networks of unstable attractors to heteroclinic switching}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.78.065201},
volume = {78},
year = {2008}
}
@article{LY01,
author = {Lee, T S and Yu, S},
journal = {NIPS},
title = {{An Information-Theoretic Framework for Understanding Saccadic Behaviors}},
volume = {12},
year = {2001}
}
@article{Li2016,
abstract = {This paper considers channel estimation and system performance for the uplink of a single-cell massive multiple-input multiple-output (MIMO) system. Each receive antenna of the base station (BS) is assumed to be equipped with a pair of one-bit analog-to-digital converters (ADCs) to quantize the real and imaginary part of the received signal. We first obtain the Cramer-Rao lower bound for channel estimation, and show that the one-bit ADCs cause the performance of unbiased channel estimators to degrade at high SNR. We then propose a biased channel estimator based on the Bussgang decomposition, which reformulates the nonlinear quantizer as a linear function with identical first- and second-order statistics. The resulting channel estimator works well at high SNRs and outperforms previously proposed approaches across all SNRs.We then derive closed-form expressions at low SNR for an approximation of the achievable rate for the maximal ratio combiner and zero forcing receivers that takes channel estimation error due to both noise and one bit quantization into account. The closed-form expressions in turn allow us to obtain insight into important system design issues such as optimal resource allocation, maximal sum spectral efficiency, overall energy efficiency, and number of antennas. Numerical results are presented to verify our analytical results and demonstrate the benefit of optimizing system performance accordingly.},
archivePrefix = {arXiv},
arxivId = {1609.07427},
author = {Li, Yongzhi and Tao, Cheng and Seco-Granados, Gonzalo and Mezghani, Amine and Swindlehurst, A. Lee and Liu, Liu},
eprint = {1609.07427},
pages = {1--14},
title = {{Channel Estimation and Performance Analysis of One-Bit Massive MIMO Systems}},
url = {http://arxiv.org/abs/1609.07427},
volume = {2},
year = {2016}
}
@article{Aharonian|2004|,
abstract = {Accreting Black Holes (BHs) are believed to be sites of possible particle
acceleration with favorable conditions also for effective gamma-ray
production. However, because of photon-photon pair production, only
low energy (MeV) gamma-rays can escape these compact objects with
typically very large compactness parameter, {\^{I}}{\textordmasculine} = L/LEdd*Rg/R{\^{a}}‰¥ 0.01,
given that in most cases the accretion disks within 10 Schwarzschild
radii Rg radiate with a power exceeding 10 percent of the Eddington
luminosity, LEdd. Therefore the high energy gamma-ray emission of
these objects (both of stellar mass and super-massive BHs) is generally
suppressed, and consequently the unique information on possible particle
acceleration processes near the event horizon of the BH is essentially
lost. Fortunately this is not the case for the super-massive BH located
at the dynamical center of our Galaxy (Sgr A*), which thanks to its
extraordinary low bolometric luminosity ({\^{a}}‰¤ 10{\^{a}}ˆ'8LEdd) is transparent
for gamma-rays up to very high energies, E {\^{a}}ˆ¼ 10 TeV. We discuss
different scenarios of gamma-ray production in Sgr A*, and show that
for a reasonable set of parameters one can expect detectable gamma-ray
fluxes of both hadronic and electronic origin. Some of these scenarios
are applicable not only for the TeV gamma-ray emission recently reported
from the direction of Galactic Center, but may have broader implications
relevant to highly variable nonthermal emission of Sgr A* in radio,
IR and X-ray bands.},
author = {Aharonian, F and Neronov, A},
journal = {arXiv},
keywords = {astrophysics,black holes,galactic center,gamma rays,physics},
number = {0408303},
title = {{High energy gamma rays from the massive black hole in the galactic center}},
volume = {astro-ph}
}
@article{Gray2006,
abstract = {Most excitatory synapses terminate on dendritic spines. Spines vary in size, and their volumes are proportional to the area of the postsynaptic density (PSD) and synaptic strength. PSD-95 is an abundant multi-domain postsynaptic scaffolding protein that clusters glutamate receptors and organizes the associated signaling complexes. PSD-95 is thought to determine the size and strength of synapses. Although spines and their synapses can persist for months in vivo, PSD-95 and other PSD proteins have shorter half-lives in vitro, on the order of hours. To probe the mechanisms underlying synapse stability, we measured the dynamics of synaptic PSD-95 clusters in vivo. Using two-photon microscopy, we imaged PSD-95 tagged with GFP in layer 2/3 dendrites in the developing (postnatal day 10-21) barrel cortex. A subset of PSD-95 clusters was stable for days. Using two-photon photoactivation of PSD-95 tagged with photoactivatable GFP (paGFP), we measured the time over which PSD-95 molecules were retained in individual spines. Synaptic PSD-95 turned over rapidly (median retention times tau(r) is approximately 22-63 min from P10-P21) and exchanged with PSD-95 in neighboring spines by diffusion. PSDs therefore share a dynamic pool of PSD-95. Large PSDs in large spines captured more diffusing PSD-95 and also retained PSD-95 longer than small PSDs. Changes in the sizes of individual PSDs over days were associated with concomitant changes in PSD-95 retention times. Furthermore, retention times increased with developmental age (tau(r) is approximately 100 min at postnatal day 70) and decreased dramatically following sensory deprivation. Our data suggest that individual PSDs compete for PSD-95 and that the kinetic interactions between PSD molecules and PSDs are tuned to regulate PSD size.},
author = {Gray, N W and Weimer, R M and Bureau, I and Svoboda, K},
doi = {10.1371/journal.pbio.0040370},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Afferent,Afferent: metabolism,Animals,Biological,Embryo,Female,Guanylate Kinase,Inbred C57BL,Intracellular Signaling Peptides and Proteins,Intracellular Signaling Peptides and Proteins: met,Mammalian,Mammalian: surgery,Membrane Proteins,Membrane Proteins: metabolism,Mice,Models,Neocortex,Neocortex: metabolism,Nerve Tissue Proteins,Nerve Tissue Proteins: metabolism,Neurological,Neurons,Pregnancy,Protein Binding,Synapses,Synapses: metabolism,Time Factors,Tissue Distribution},
number = {11},
pages = {e370},
pmid = {17090216},
title = {{Rapid redistribution of synaptic PSD-95 in the neocortex in vivo.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1634879{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2006}
}
@article{VCK05,
author = {Ventura, V and Cai, C and Kass, R},
journal = {Journal of Neurophysiology},
pages = {2928--2939},
title = {{Trial-to-trial variability and its effect on time-varying dependence between two neurons}},
volume = {94},
year = {2005}
}
@article{WallstromLiebnerKass07,
author = {Wallstrom, Garrick and Liebner, Jeffrey and Kass, Robert E},
journal = {Journal of Statistical Software},
pages = {1--21},
title = {{An Implementation of {\{}B{\}}ayesian Adaptive Regression Splines ({\{}BARS{\}}) in {\{}C with S and R{\}} Wrappers}},
volume = {26},
year = {2007}
}
@article{BARB01,
author = {Barbieri, R and Quirk, M and Frank, L and Wilson, M and Brown, E},
journal = {Journal of Neuroscience Methods},
pages = {25--37},
title = {{Construction and analysis of non-Poisson stimulus-response models of neural spiking activity}},
volume = {105},
year = {2001}
}
@article{Chung90,
author = {Chung, S and Moore, J and Xia, L and Premkumar, L and Gage, P},
journal = {Phil. Trans. Roy. Soc. Lond. B},
pages = {265--285},
title = {{Characterization of single channel currents using digital signal processing techniques based on hidden Markov models}},
volume = {329},
year = {1990}
}
@article{Gilden1995,
abstract = {When a person attempts to produce from memory a given spatial or temporal interval, there is inevitably some error associated with the estimate. The time course of this error was measured in a series of experiments where subjects repeatedly attempted to replicate given target intervals. Sequences of the errors in both spatial and temporal replications were found to fluctuate as 1/f noises. 1/f noise is encountered in a wide variety of physical systems and is theorized to be a characteristic signature of complexity.},
author = {Gilden, D. and Thornton, T and Mallon, M.},
doi = {10.1126/science.7892611},
issn = {0036-8075},
journal = {Science},
month = {mar},
number = {5205},
pages = {1837--1839},
title = {1/f noise in human cognition},
url = {http://www.sciencemag.org.ezlibrary.technion.ac.il/content/267/5205/1837.short},
volume = {267},
year = {1995}
}
@article{Legenstein,
annote = {2010IIInum72},
author = {Legenstein, R and Maass, W},
journal = {Journal of Neuroscience},
keywords = {active dendrites,binding,branch strength potentiation,computation,dendritic,stdp,synaptic plasticity},
title = {{A model for the self-organization of nonlinear neural computation through synaptic plasticity in dendritic branches}},
volume = {243914}
}
@article{ChaseYoung05,
author = {Chase, Steven M and Young, Eric D},
journal = {Journal of Neuroscience},
month = {aug},
number = {33},
pages = {7575--7585},
title = {{Limited segregation of different types of sound localization information among classes of units in the inferior colliculus}},
volume = {25},
year = {2005}
}
@article{Chua1976,
author = {Chua, L and Kang, S M},
journal = {Proceedings of the IEEE},
number = {2},
title = {{Memristive devices and systems}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1454361},
volume = {64},
year = {1976}
}
@article{LeeMumford03,
author = {Lee, T S and Mumford, D},
journal = {Journal of the Optical Society of America A},
number = {7},
pages = {1434--1448},
publisher = {OSA},
title = {{Hierarchical Bayesian inference in the visual cortex}},
volume = {20},
year = {2003}
}
@article{Wong2010,
author = {Wong, H.-S. Philip and Raoux, Simone and Kim, SangBum and Liang, Jiale and Reifenberg, John P. and Rajendran, Bipin and Asheghi, Mehdi and Goodson, Kenneth E.},
doi = {10.1109/JPROC.2010.2070050},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {chalcogenides,emerging memory,heat conduc-,nonvolatile memory,pcm,pcram,phase change material,phase change memory,pram,thermal physics,tion},
month = {dec},
number = {12},
pages = {2201--2227},
title = {{Phase Change Memory}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5609179},
volume = {98},
year = {2010}
}
@article{Sekirnjak06,
author = {Sekirnjak, Chris and Hottowy, Pawel and Sher, Alexander and Dabrowski, Wladyslaw and Litke, A M and Chichilnisky, E J},
journal = {J Neurophysiol},
number = {6},
pages = {3311--3327},
title = {{Electrical Stimulation of Mammalian Retinal Ganglion Cells With Multielectrode Arrays}},
volume = {95},
year = {2006}
}
@article{Nowak1997,
abstract = {Cortical neurons in vivo respond to sensory stimuli with the generation of action potentials that can show a high degree of variability in both their number and timing with repeated presentations as wells as, on occasion, a high degree of synchronization with other cortical neurons, including in the gamma frequency range of 30-70 Hz. Here we examined whether or not this variability may arise from the intrinsic mechanisms of action potential generation in cortical regular spiking, fast spiking and intrinsic burst-generating neurons maintained in vitro. For this purpose, we performed intracellular recordings in slices of ferret visual cortex and activated these cells with the intracellular injection of various current waveforms. Some of these waveforms were derived from barrages of postsynaptic potentials evoked by visual stimulation recorded in vivo; others were artificially created and contained various amounts of gamma range fluctuations; finally, others consisted of swept-sinewave current (ZAP current) functions. Using such stimuli, we found that, as expected given the resistive and capacitive properties of cortical neurons, low frequencies have a larger effect on the membrane potential of cortical neurons than do higher frequencies. However, increasing the amount of gamma range fluctuations in a stimulus leads to more precise timing of action potentials. This suggests that different frequencies play different roles, low frequencies being efficient for depolarizing cells with high frequencies increasing the precision of action potential timing. In parallel to increases in temporal precision, the addition of higher frequency components increases the range of interspike intervals present in the action potential discharge. These results suggest that higher frequency components such as gamma range fluctuations may facilitate the generation of action potentials with a high temporal precision while at the same time exhibiting a high degree of variability in interspike intervals on single trials. This temporal precision may facilitate the use of temporal codes or the generation of precise synchronization for the transmission and analysis of information within cortical networks.},
author = {Nowak, L G and Sanchez-Vives, M V and McCormick, D a},
issn = {1047-3211},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Electric Stimulation,Electrophysiology,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Ferrets,Ferrets: physiology,Male,Neurons,Neurons: physiology,Photic Stimulation,Synaptic Transmission,Synaptic Transmission: physiology,Vision, Ocular,Vision, Ocular: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
month = {sep},
number = {6},
pages = {487--501},
pmid = {9276174},
title = {{Influence of low and high frequency inputs on spike timing in visual cortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9276174},
volume = {7},
year = {1997}
}
@article{Blythe2007a,
annote = {

8num2012

Looks very interesting. Recommended by Daniel (Yariv's student)},
author = {Blythe, RA a and Evans, MR R},
doi = {10.1088/1751-8113/40/46/R01},
issn = {1751-8113},
journal = {Journal of Physics A: Mathematical and {\ldots}},
month = {nov},
number = {46},
pages = {R333--R441},
title = {{Nonequilibrium steady states of matrix-product form: a solver's guide}},
url = {http://stacks.iop.org/1751-8121/40/i=46/a=R01?key=crossref.20dde31364d32bb5f4334ab21a1a5e03 http://iopscience.iop.org/1751-8121/40/46/R01},
volume = {40},
year = {2007}
}
@book{beran1994statistics,
address = {New York, NY},
author = {Beran, J},
publisher = {Chapman {\&} Hall},
title = {{Statistics for long-memory processes}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=jdzDYWtfPC0C{\&}oi=fnd{\&}pg=PR9{\&}dq=Statistics+for+long-memory+processes{\&}ots=maSXVTTfCu{\&}sig=gq2R7keM80LKxD1hld0DIguoskw},
year = {1994}
}
@article{Grossman1979a,
author = {Grossman, B Y Y and Parnas, I and Spira, M E},
pages = {307--322},
title = {{AX312}},
year = {1979}
}
@article{Pages11,
author = {Pages, Stephane and Cote, Daniel and Koninck, Paul De},
journal = {Frontiers in Cellular Neuroscience},
title = {{Optophysiological approach to resolve neuronal action potentials with high spatial and temporal resolution in cultured neurons}},
volume = {5},
year = {2011}
}
@article{PAN03a,
author = {Paninski, L and Fellows, M and Hatsopoulos, N and Donoghue, J},
journal = {Journal of Neurophysiology},
pages = {515--532},
title = {{Spatiotemporal tuning properties for hand position and velocity in motor cortical neurons}},
volume = {91},
year = {2004}
}
@book{CT91,
address = {New York},
author = {Cover, T M and Thomas, J.A. Joy A},
edition = {second},
publisher = {Wiley},
title = {{Elements of information theory}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:ELEMENTS+OF+information+theory{\#}0},
year = {1991}
}
@article{Bender|1979|,
abstract = {This paper is a continuation of a previous paper on strong-coupling
expansions in quantum field theory. We are concerned here with one-dimensional
quantum field theories (quantum-mechanical models). Our general approach
is to derive graphical rules for construction the strong-coupling
expansion from a Lagrangian path integral in the presence of external
sources. After reviewing the normalization of one-dimensional path
integrals, we examine in detail the model Hamiltonian H=|p|+|q|.
We show that in the strong-coupling expansion the graphs are constructed
from multilegged propagators attached to multilegged vertices. We
use these graphical rules to calculate the ground-state energy for
this Hamiltonian. One motivation for examining expansions involving
multilegged propagators is provided by the Lagrangian for quantum
chromodynamics whose strong-coupling expansion also involves multilegged
propagators.},
annote = {This article extends work by Bender et al in March 1979 on strong{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}coupling expansion by treating kinetic term in Lagrangian as perturbation.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}More general case is examined where both vertices and propagators{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}are multi-leg objects.},
author = {Bender, C M and Cooper, F and Guralnik, G S and Sharp, D H and Roskies, R and Silverstein, M L},
journal = {Physical Review D},
keywords = {derivatives expansion,feynman diagrams,hopping expansion,phi{\^{}}4,physics,quantum field theory,strong coupling expansion},
number = {6},
pages = {1374},
title = {{Multilegged propagators in strong-coupling expansion}},
volume = {20}
}
@article{Holekamp08,
author = {Holekamp, T and Turaga, D and Holy, T},
journal = {Neuron},
pages = {661--672},
title = {{Fast Three-Dimensional Fluorescence Imaging of Activity in Neural Populations by Objective-Coupled Planar Illumination Microscopy}},
volume = {57},
year = {2008}
}
@article{Taro08,
author = {Toyoizumi, T and {Rahnama Rad}, K and Paninski, L},
journal = {Neural Computation},
title = {{Mean-field approximations for coupled populations of generalized linear model spiking neurons with {\{}M{\}}arkov refractoriness}},
volume = {In press},
year = {2008}
}
@article{AHR06,
author = {Ahrens, M B and Paninski, Liam and Sahani, Maneesh},
journal = {Network: Computation in Neural Systems},
pages = {35--67},
title = {{Inferring input nonlinearities in neural encoding models}},
volume = {19},
year = {2008}
}
@article{Tripathy2014,
abstract = {The behavior of neural circuits is determined largely by the electrophysiological properties of the neurons they contain. Understanding the relationships of these properties requires the ability to first identify and catalog each property. However, information about such properties is largely locked away in decades of closed-access journal articles with heterogeneous conventions for reporting results, making it difficult to utilize the underlying data. We solve this problem through the NeuroElectro project: a Python library, RESTful API, and web application (at http://neuroelectro.org) for the extraction, visualization, and summarization of published data on neurons' electrophysiological properties. Information is organized both by neuron type (using neuron definitions provided by NeuroLex) and by electrophysiological property (using a newly developed ontology). We describe the techniques and challenges associated with the automated extraction of tabular electrophysiological data and methodological metadata from journal articles. We further discuss strategies for how to best combine, normalize and organize data across these heterogeneous sources. NeuroElectro is a valuable resource for experimental physiologists attempting to supplement their own data, for computational modelers looking to constrain their model parameters, and for theoreticians searching for undiscovered relationships among neurons and their properties.},
author = {Tripathy, Shreejoy J and Savitskaya, Judith and Burton, Shawn D and Urban, Nathaniel N and Gerkin, Richard C},
doi = {10.3389/fninf.2014.00040},
issn = {1662-5196},
journal = {Frontiers in neuroinformatics},
keywords = {API,Electrophysiology,Natural Language Processing,database,machine learning,metadata,neuroinformatics,text-mining},
language = {English},
month = {jan},
pages = {40},
pmid = {24808858},
publisher = {Frontiers},
title = {{NeuroElectro: a window to the world's neuron electrophysiology data.}},
url = {http://journal.frontiersin.org/Article/10.3389/fninf.2014.00040/abstract},
volume = {8},
year = {2014}
}
@article{Biess2011,
author = {Biess, Armin and Flash, Tamar and Liebermann, Dario G.},
doi = {10.1103/PhysRevE.83.031927},
issn = {1539-3755},
journal = {Physical Review E},
month = {mar},
number = {3},
pages = {031927},
title = {{Riemannian geometric approach to human arm dynamics, movement optimization, and invariance}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.83.031927},
volume = {83},
year = {2011}
}
@article{Kane74,
author = {Kane, E C},
journal = {Journal of Comparative Neurology},
month = {jun},
number = {3},
pages = {301--329},
title = {{Synaptic organization in the dorsal cochlear nucleus of the cat: a light and electron microscopic study}},
volume = {155},
year = {1974}
}
@article{Hetzel2012,
author = {Hetzel, Andrew J and Liew, Jay S and Morrison, Kent E},
journal = {America},
number = {6},
pages = {491--499},
title = {{The Probability that a of Integers Is Diagonalizable}},
volume = {114},
year = {2012}
}
@article{PriebeFerster05,
author = {Priebe, N and Ferster, D},
journal = {Neuron},
pages = {133--145},
title = {{Direction selectivity of excitation and inhibition in simple cells of the cat primary visual cortex}},
volume = {45},
year = {2005}
}
@article{Vardi,
author = {Vardi, Roni and Timor, Reut and Marom, S},
journal = {arXiv preprint arXiv: {\ldots}},
title = {{Synchronization with mismatched synaptic delays: A unique role of elastic neuronal latency}},
url = {http://arxiv.org/abs/1209.2562},
year = {2012}
}
@article{Bouchaud1990,
annote = {Eq. 4.11 with a=0: high-dimentional random walk on random walk potential},
author = {Bouchaud, J P and Georges, A},
issn = {0370-1573},
journal = {Physics reports},
pages = {127--293},
title = {{Anomalous diffusion in disordered media: statistical mechanisms, models and physical applications}},
url = {http://adsabs.harvard.edu/abs/1990PhR...195..127B},
volume = {195},
year = {1990}
}
@article{Ko2013,
abstract = {Sensory processing occurs in neocortical microcircuits in which synaptic connectivity is highly structured and excitatory neurons form subnetworks that process related sensory information. However, the developmental mechanisms underlying the formation of functionally organized connectivity in cortical microcircuits remain unknown. Here we directly relate patterns of excitatory synaptic connectivity to visual response properties of neighbouring layer 2/3 pyramidal neurons in mouse visual cortex at different postnatal ages, using two-photon calcium imaging in vivo and multiple whole-cell recordings in vitro. Although neural responses were already highly selective for visual stimuli at eye opening, neurons responding to similar visual features were not yet preferentially connected, indicating that the emergence of feature selectivity does not depend on the precise arrangement of local synaptic connections. After eye opening, local connectivity reorganized extensively: more connections formed selectively between neurons with similar visual responses and connections were eliminated between visually unresponsive neurons, but the overall connectivity rate did not change. We propose a sequential model of cortical microcircuit development based on activity-dependent mechanisms of plasticity whereby neurons first acquire feature preference by selecting feedforward inputs before the onset of sensory experience--a process that may be facilitated by early electrical coupling between neuronal subsets--and then patterned input drives the formation of functional subnetworks through a redistribution of recurrent synaptic connections.},
author = {Ko, Ho and Cossell, Lee and Baragli, Chiara and Antolik, Jan and Clopath, Claudia and Hofer, Sonja B and Mrsic-Flogel, Thomas D},
doi = {10.1038/nature12015},
issn = {1476-4687},
journal = {Nature},
keywords = {Animals,Animals, Newborn,Eye,Eyelids,Eyelids: physiology,Mice,Mice, Inbred C57BL,Models, Neurological,Movement,Neural Pathways,Neural Pathways: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Synapses,Synapses: metabolism,Synapses: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = {apr},
number = {7443},
pages = {96--100},
pmid = {23552948},
title = {{The emergence of functional microcircuits in visual cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23552948},
volume = {496},
year = {2013}
}
@article{Jahnke2009,
annote = {2010IInum9.5},
author = {Jahnke, S and Memmesheimer, R M and Timme, M},
doi = {10.1186/1471-2202-10-S1-O20},
issn = {1471-2202},
journal = {BMC Neuroscience},
pages = {O20},
title = {{How chaotic is the balanced state?}},
url = {http://www.biomedcentral.com/1471-2202/10/S1/O20 http://www.biomedcentral.com/content/pdf/1471-2202-10-S1-O20.pdf},
volume = {10},
year = {2009}
}
@book{Piersol2000,
abstract = {This is a new edition of a book on random data analysis which has been on the market since 1966 and which was extensively revised in 1971. The book has been a bestseller since. It has been fully updated to cover new procedures developed in the last 15 years and extends the discussion to a broad range of applied fields, such as aerospace, automotive industries or biomedical research. The primary purpose of this book is to provide a practical reference and tool for working engineers and scientists investigating dynamic data or using statistical methods to solve engineering problems. It is comprehensive and self-contained and expands the coverage of the theory, including derivations of the key relationships in probability and random-process theory not usually found to such extent in a book of this kind. It could well be used as a teaching textbook for advanced courses on the analysis of random processes. The first four chapters present the background material on descriptions of data, properties of linear systems and statistical principles. They also include probability distribution formulas for one-, two- and higher-order changes of variables. Chapter five gives a comprehensive discussion of stationary random-process theory, including material on wave-number spectra, level crossings and peak values of normally distributed random data. Chapters six and seven develop mathematical relationships for the detailed analysis of single input/output and multiple input/output linear systems including algorithms. In chapters eight and nine important practical formulas to determine statistical errors in estimates of random data parameters and linear system properties from measured data are derived. Chapter ten deals with data aquisition and processing, including data qualification. Chapter eleven describes methods of data analysis such as data preparation, Fourier transforms, probability density functions, auto- and cross-correlation, spectral functions, joint record functions and multiple input/output functions. Chapter twelve shows how to handle nonstationary data analysis, classification of nonstationary data, probability structure of nonstationary data, calculation of nonstationary mean values or mean square values, correlation structures of nonstationary data and spectral structures of nonstationary data. The last chapter deals with the Hilbert transform including applications for both nondispersive and dispersive propagation problems. All chapters include many illustrations and references as well as examples and problem sets. This allows the reader to use the book for private study purposes. Altogether the book can be recommended for practical working engineers and scientists to support their daily work, as well as for university readers as a teaching textbook in advanced courses. M Krystek},
address = {New York, NY},
author = {Bendat, J S and Piersol, A G},
booktitle = {Measurement Science and Technology},
doi = {10.1088/0957-0233/11/12/702},
edition = {3rd},
issn = {0957-0233},
month = {dec},
number = {12},
publisher = {Wiley},
title = {{Random Data Analysis and Measurement Procedures}},
url = {http://stacks.iop.org/0957-0233/11/i=12/a=702},
volume = {11},
year = {2000}
}
@article{Curcio1990,
abstract = {We have measured the spatial density of cones and rods in eight whole-mounted human retinas, obtained from seven individuals between 27 and 44 years of age, and constructed maps of photoreceptor density and between-individual variability. The average human retina contains 4.6 million cones (4.08-5.29 million). Peak foveal cone density averages 199,000 cones/mm2 and is highly variable between individuals (100,000-324,000 cones/mm2). The point of highest density may be found in an area as large as 0.032 deg2. Cone density falls steeply with increasing eccentricity and is an order of magnitude lower 1 mm away from the foveal center. Superimposed on this gradient is a streak of high cone density along the horizontal meridian. At equivalent eccentricities, cone density is 40-45{\%} higher in nasal compared to temporal retina and slightly higher in midperipheral inferior compared to superior retina. Cone density also increases slightly in far nasal retina. The average human retina contains 92 million rods (77.9-107.3 million). In the fovea, the average horizontal diameter of the rod-free zone is 0.350 mm (1.25 degrees). Foveal rod density increases most rapidly superiorly and least rapidly nasally. The highest rod densities are located along an elliptical ring at the eccentricity of the optic disk and extending into nasal retina with the point of highest density typically in superior retina (5/6 eyes). Rod densities decrease by 15-25{\%} where the ring crosses the horizontal meridian. Rod density declines slowly from the rod ring to the far periphery and is highest in nasal and superior retina. Individual variability in photoreceptor density differs with retinal region and is similar for both cones and rods. Variability is highest near the fovea, reaches a minimum in the midperiphery, and then increases with eccentricity to the ora serrata. The total number of foveal cones is similar for eyes with widely varying peak cone density, consistent with the idea that the variability reflects differences in the lateral migration of photoreceptors during development. Two fellow eyes had cone and rod numbers within 8{\%} and similar but not identical photoreceptor topography.},
author = {Curcio, C a and Sloan, K R and Kalina, R E and Hendrickson, a E},
doi = {10.1002/cne.902920402},
issn = {0021-9967},
journal = {The Journal of comparative neurology},
keywords = {Cell Count,Female,Humans,Male,Middle Aged,Photoreceptor Cells,Photoreceptor Cells: cytology,Retina,Retina: anatomy {\&} histology},
month = {feb},
number = {4},
pages = {497--523},
pmid = {2324310},
title = {{Human photoreceptor topography.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2324310},
volume = {292},
year = {1990}
}
@article{Ji|2003|,
abstract = {We investigate the self-organizing nature of relativistic quantum
field theory in terms of canonical transformation and duality presenting
simple but ex- plicit examples of (phi{\^{}}4)1+1 and (phi{\^{}}6)1+1 theories.
Our purpose is fulfilled by applying the oscillator representation
(OR) method which allows us to convert the original strong interaction
theory into a weekly interacting quasiparticle theory that is equivalent
to the original theory. We discuss advantages of the OR method and
compare the results with what was already obtained by the method
of Gaussian effective potential (GEP) and the Hartree approximation
(HA). While we confirm that the GEP results are identical to the
Hartree re- sults for the ground state energy, we found that the
OR method gives the quasiparticle mass different from the GEP and
HA results. In our exam- ples, the self-organizing nature is revealed
by the vacuum energy density that gets lowered when the quasiparticles
are formed. In the (phi{\^{}}6)1+1 theory, we found two physically meaningful
duality-related quasiparticle solutions which have different symmetry
properties under the transition of quasiparticle field Phi {\^{a}}†' {\^{a}}ˆ'Phi.
However, these two quasiparticle solutions yield the identical effec-
tive potential in the strong coupling limit of the original theory.},
author = {Ji, C.-R. and Kim, J.-I. and Min, D.-P. and Vinnikov, A V},
journal = {arXiv},
keywords = {oscillator representation method,phase transition,phi{\^{}}4,phi{\^{}}6,physics,quantum field theory,symmetry breaking},
pages = {204114},
title = {{The canonical transformation and duality in the 1+1 dimensional phi{\^{}}4 and phi{\^{}}6 theory}},
volume = {hep-ph}
}
@article{Lowen1993b,
annote = {2010num2.2},
author = {Lowen, S B and Teich, MC},
journal = {AIP Conference Proceedings},
title = {{Fractal auditory-nerve firing patterns may derive from fractal switching in sensory hair-cell ion channels}},
url = {http://link.aip.org/link/?APCPCS/285/745/1 http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Fractal+auditory-nerve+firing+patterns+may+derive+from+fractal+switching+in+sensory+hair-cell+ion+channels{\#}0},
year = {1993}
}
@article{michalek99estimating,
author = {Michalek, S and Timmer, J},
journal = {IEEE Trans. Sig. Proc.},
pages = {226--228},
title = {{Estimating rate constants in hidden Markov models by the EM algorithm}},
volume = {47},
year = {1999}
}
@article{Kusenko|2001|,
abstract = {We show that non-topological solitons, known as Q-balls, are promising
candidates for self- interacting dark matter. They can satisfy the
cross-section requirements for a broad range of masses. Unlike previously
considered examples, Q-balls can stick together after collision,
reducing the effective self-interaction rate to a negligible value
after a few collisions per particle. This feature modifies predictions
for halo formation. We also discuss the possibility that Q-balls
have large interaction cross-sections with ordinary matter.},
annote = {This paper introduces an interesting candidate for interacting dark{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}matter.},
author = {Kusenko, A and Steinhardt, P J},
journal = {arXiv},
keywords = {astrophysics,candidate,dark matter,interaction,physics,q-ball,strongly interacting dark matter},
pages = {106008},
title = {{Q-ball candidates for self-interacting dark matter}},
volume = {astro-ph}
}
@inproceedings{Cauwenberghs1994,
address = {Golden, CO},
author = {Cauwenberghs, G},
booktitle = {NIPS},
month = {nov},
title = {{A learning analog neural network chip with continuous-time recurrent dynamics}},
url = {http://www.isn.ucsd.edu/papers/nips93{\_}dynrec.pdf},
year = {1994}
}
@article{Rigat06,
author = {Rigat, F and de Gunst, M and van Pelt, J},
journal = {Bayesian Analysis},
pages = {733--764},
title = {{Bayesian modelling and analysis of spatio-temporal neuronal networks}},
volume = {1},
year = {2006}
}
@article{Vucinic07,
abstract = {We constructed a simple and compact imaging system designed specifically for the recording of fast neuronal activity in a 3D volume. The system uses an Yb:KYW femtosecond laser we designed for use with acousto-optic deflection. An integrated two-axis acousto-optic deflector, driven by digitally synthesized signals, can target locations in three dimensions. Data acquisition and the control of scanning are performed by a LeCroy digital oscilloscope. The total cost of construction was one order of magnitude lower than that of a typical Ti:sapphire system. The entire imaging apparatus, including the laser, fits comfortably onto a small rig for electrophysiology. Despite the low cost and simplicity, the convergence of several new technologies allowed us to achieve the following capabilities: i) full-frame acquisition at video rates suitable for patch clamping; ii) random access in under ten microseconds with dwelling ability in the nominal focal plane; iii) three-dimensional random access with the ability to perform fast volume sweeps at kilohertz rates; and iv) fluorescence lifetime imaging. We demonstrate the ability to record action potentials with high temporal resolution using intracellularly loaded potentiometric dye di-2-ANEPEQ. Our design proffers easy integration with electrophysiology and promises a more widespread adoption of functional two-photon imaging as a tool for the study of neuronal activity. The software and firmware we developed is available for download at http://neurospy.org/ under an open source license. },
author = {Vucinic, Dejan and Sejnowski, Terrence J},
doi = {10.1371/journal.pone.0000699},
journal = {PLoS ONE},
month = {aug},
number = {8},
pages = {e699},
publisher = {Public Library of Science},
title = {{A Compact Multiphoton 3D Imaging System for Recording Fast Neuronal Activity}},
url = {http://dx.doi.org/10.1371/journal.pone.0000699},
volume = {2},
year = {2007}
}
@article{Gokmen2016,
abstract = {In recent years, deep neural networks (DNN) have demonstrated significant business impact in large scale analysis and classification tasks such as speech recognition, visual object detection, pattern extraction, etc. Training of large DNNs, however, is universally considered as time consuming and computationally intensive task that demands datacenter-scale computational resources recruited for many days. Here we propose a concept of resistive processing unit (RPU) devices that can potentially accelerate DNN},
author = {Gokmen, Authors Tayfun and Vlasov, Yurii},
doi = {10.3389/fnins.2016.00333},
file = {:C$\backslash$:/Users/Daniel/Downloads/1603.07341.pdf:pdf},
issn = {1662-4548},
journal = {arXiv},
pages = {333},
title = {{Acceleration of Deep Neural Network Training with Resistive Cross-Point Devices: Design Considerations.}},
volume = {10},
year = {2016}
}
@article{Markram1997b,
abstract = {1. Dual voltage recordings were made from pairs of adjacent, synaptically connected thick tufted layer 5 pyramidal neurones in brain slices of young rat (14-16 days) somatosensory cortex to examine the physiological properties of unitary EPSPs. Pre- and postsynaptic neurones were filled with biocytin and examined in the light and electron microscope to quantify the morphology of axonal and dendritic arbors and the number and location of synaptic contacts on the target neurone. 2. In 138 synaptic connections between pairs of pyramidal neurones 96 (70{\%}) were unidirectional and 42 (30{\%}) were bidirectional. The probability of finding a synaptic connection in dual recordings was 0.1. Unitary EPSPs evoked by a single presynaptic action potential (AP) had a mean peak amplitude ranging from 0.15 to 5.5 mV in different connections with a mean of 1.3 +/- 1.1 mV, a latency of 1.7 +/- 0.9 ms, a 20-80{\%} rise time of 2.9 +/- 2.3 ms and a decay time constant of 40 +/- 18 ms at 32-24 degrees C and -60 +/- 2 mV membrane potential. 3. Peak amplitudes of unitary EPSPs fluctuated randomly from trial to trial. The coefficient of variation (c.v.) of the unitary EPSP amplitudes ranged from 0.13 to 2.8 in different synaptic connections (mean, 0.52; median, 0.41). The percentage of failures of single APs to evoke a unitary EPSP ranged from 0 to 73{\%} (mean, 14{\%}; median, 7{\%}). Both c.v. and percentage of failures decreased with increasing mean EPSP amplitude. 4. Postsynaptic glutamate receptors which mediate unitary EPSPs at -60 mV were predominantly of the L-alpha-amino-3-hydroxy-5-methyl-4-isoxazolepropionate (AMPA) receptor type. Receptors of the N-methyl-D-aspartate (NMDA) type contributed only a small fraction ({\textless} 20{\%}) to the voltage-time integral of the unitary EPSP at -60 mV, but their contribution increased at more positive membrane potentials. 5. Branching patterns of dendrites and axon collaterals of forty-five synaptically connected neurones, when examined in the light microscope, indicated that the axonal and dendritic anatomy of both projecting and target neurones and of uni- and bidirectionally connected neurones was uniform. 6. The number of potential synaptic contacts formed by a presynaptic neurone on a target neurone varied between four and eight (mean, 5.5 +/- 1.1 contacts; n = 19 connections). Synaptic contacts were preferentially located on basal dendrites (63{\%}, 82 +/- 35 microns from the soma, n = 67) and apical oblique dendrites (27{\%}, 145 +/- 59 microns, n = 29), and 35{\%} of all contacts were located on tertiary basal dendritic branches. The mean geometric distances (from the soma) of the contacts of a connection varied between 80 and 585 microns (mean, 147 microns; median, 105 microns). The correlation between EPSP amplitude and the number of morphologically determined synaptic contacts or the mean geometric distances from the soma was only weak (correlation coefficients were 0.2 and 0.26, respectively). 7. Compartmental models constructed from camera lucida drawings of eight target neurones showed that synaptic contacts were located at mean electrotonic distances between 0.07 and 0.33 from the soma (mean, 0.13). Simulations of unitary EPSPs, assuming quantal conductance changes with fast rise time and short duration, indicated that amplitudes of quantal EPSPs at the soma were attenuated, on average, to {\textless} 10{\%} of dendritic EPSPs and varied in amplitude up to 10-fold depending on the dendritic location of synaptic contacts. The inferred quantal peak conductance increase varied between 1.5 and 5.5 nS (mean, 3 nS). 8. The combined physiological and morphological measurements in conjunction with EPSP simulations indicated that the 20-fold range in efficacy of the synaptic connections between thick tufted pyramidal neurones, which have their synaptic contacts preferentially located on basal and apical oblique dendrites, was due to differences in transmitter release probability of the projecting neurones and, to a lesser extent, to differenc},
author = {Markram, H and L{\"{u}}bke, J and Frotscher, Michael and Roth, a and Sakmann, B},
issn = {0022-3751},
journal = {The Journal of physiology},
keywords = {AMPA,AMPA: physiology,Action Potentials,Action Potentials: physiology,Animals,Cell Size,Cell Size: physiology,Cerebral Cortex,Cerebral Cortex: chemistry,Cerebral Cortex: cytology,Cerebral Cortex: growth {\&} development,Dendrites,Dendrites: physiology,Electric Conductivity,Electric Stimulation,Interference,Interference: methods,Ion Channel Gating,Ion Channel Gating: physiology,Microscopy,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: physiology,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Pyramidal Cells: ultrastructure,Rats,Receptors,Synapses,Synapses: chemistry,Synapses: physiology,Synapses: ultrastructure,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors,Video,Video: methods,Wistar},
month = {apr},
number = {1997},
pages = {409--40},
pmid = {9147328},
title = {{Physiology and anatomy of synaptic connections between thick tufted pyramidal neurones in the developing rat neocortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1159394{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1159394/},
volume = {500 ( Pt 2},
year = {1997}
}
@article{Legenstein2005,
abstract = {Spiking neurons are very flexible computational modules, which can implement with different values of their adjustable synaptic parameters an enormous variety of different transformations F from input spike trains to output spike trains. We examine in this letter the question to what extent a spiking neuron with biologically realistic models for dynamic synapses can be taught via spike-timing-dependent plasticity (STDP) to implement a given transformation F. We consider a supervised learning paradigm where during training, the output of the neuron is clamped to the target signal (teacher forcing). The well-known perceptron convergence theorem asserts the convergence of a simple supervised learning algorithm for drastically simplified neuron models (McCulloch-Pitts neurons). We show that in contrast to the perceptron convergence theorem, no theoretical guarantee can be given for the convergence of STDP with teacher forcing that holds for arbitrary input spike patterns. On the other hand, we prove that average case versions of the perceptron convergence theorem hold for STDP in the case of uncorrelated and correlated Poisson input spike trains and simple models for spiking neurons. For a wide class of cross-correlation functions of the input spike trains, the resulting necessary and sufficient condition can be formulated in terms of linear separability, analogously as the well-known condition of learnability by perceptrons. However, the linear separability criterion has to be applied here to the columns of the correlation matrix of the Poisson input. We demonstrate through extensive computer simulations that the theoretically predicted convergence of STDP with teacher forcing also holds for more realistic models for neurons, dynamic synapses, and more general input distributions. In addition, we show through computer simulations that these positive learning results hold not only for the common interpretation of STDP, where STDP changes the weights of synapses, but also for a more realistic interpretation suggested by experimental data where STDP modulates the initial release probability of dynamic synapses.},
author = {Legenstein, R and Naeger, C and Maass, W},
doi = {10.1162/0899766054796888},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Learning,Learning: physiology,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
number = {11},
pages = {2337--82},
pmid = {16156932},
title = {{What can a neuron learn with spike-timing-dependent plasticity?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16156932},
volume = {17},
year = {2005}
}
@article{MiguelHernandez-Lobato2015,
abstract = {Large multilayer neural networks trained with backpropagation have recently achieved state-of-the-art results in a wide range of problems. However, using backprop for neural net learning still has some disadvantages, e.g., having to tune a large number of hyperparameters to the data, lack of calibrated probabilistic predictions, and a tendency to overfit the training data. In principle, the Bayesian approach to learning neural networks does not have these problems. However, existing Bayesian techniques lack scalability to large dataset and network sizes. In this work we present a novel scalable method for learning Bayesian neural networks, called probabilistic backpropagation (PBP). Similar to classical backpropagation, PBP works by computing a forward propagation of probabilities through the network and then doing a backward computation of gradients. A series of experiments on ten real-world datasets show that PBP is significantly faster than other techniques, while offering competitive predictive abilities. Our experiments also show that PBP provides accurate estimates of the posterior variance on the network weights.},
archivePrefix = {arXiv},
arxivId = {1502.05336},
author = {Hern{\'{a}}ndez-Lobato, Miguel and Adams, Ryan P.},
eprint = {1502.05336},
journal = {Journal of Machine Learning Research},
title = {{Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks}},
volume = {37},
year = {2015}
}
@article{Zador2012,
abstract = {Connectivity determines the function of neural circuits. Historically, circuit mapping has usually been viewed as a problem of microscopy, but no current method can achieve high-throughput mapping of entire circuits with single neuron precision. Here we describe a novel approach to determining connectivity. We propose BOINC ("barcoding of individual neuronal connections"), a method for converting the problem of connectivity into a form that can be read out by high-throughput DNA sequencing. The appeal of using sequencing is that its scale--sequencing billions of nucleotides per day is now routine--is a natural match to the complexity of neural circuits. An inexpensive high-throughput technique for establishing circuit connectivity at single neuron resolution could transform neuroscience research.},
author = {Zador, Anthony M and Dubnau, Joshua and Oyibo, Hassana K and Zhan, Huiqing and Cao, Gang and Peikon, Ian D},
doi = {10.1371/journal.pbio.1001411},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Animals,Brain Mapping,Brain Mapping: methods,Connectome,Humans,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Sequence Analysis, DNA,Sequence Analysis, DNA: methods},
month = {jan},
number = {10},
pages = {e1001411},
pmid = {23109909},
title = {{Sequencing the connectome.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3479097{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {10},
year = {2012}
}
@article{Philpot2010,
abstract = {What happens to a single, presynaptically quiescent synapse among a population of active synapses? In this issue of Neuron, Ehlers and colleagues show that, far from being eliminated, these inactive synapses are primed for potentiation and incorporation into a new neural circuit through an upregulation of NR2B-containing NMDA receptors.},
annote = {2010IIInum13},
author = {Philpot, Benjamin D. and Zukin, R. Suzanne},
doi = {10.1016/j.neuron.2010.06.014},
issn = {08966273},
journal = {Neuron},
keywords = {Jackie,synapse},
mendeley-tags = {Jackie,synapse},
month = {jun},
number = {6},
pages = {814--816},
pmid = {20620866},
publisher = {Elsevier Inc.},
title = {{Synapse-Specific Metaplasticity: To Be Silenced Is Not to Silence 2B}},
url = {http://dx.doi.org/10.1016/j.neuron.2010.06.014 http://linkinghub.elsevier.com/retrieve/pii/S0896627310004721 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3501108{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {66},
year = {2010}
}
@article{pulver2005constant,
annote = {2010IInum12.2},
author = {Pulver, S R and Bucher, D and Simon, D J and Marder, E},
journal = {Journal of neurobiology},
number = {1},
pages = {47--61},
publisher = {[New York] Wiley-Interscience, 1969-2006.},
title = {{Constant amplitude of postsynaptic responses for single presynaptic action potentials but not bursting input during growth of an identified neuromuscular junction in the lobster, Homarus americanus}},
volume = {62},
year = {2005}
}
@article{haggard2008human,
annote = {2008num36},
author = {Haggard, P},
journal = {Nature Reviews Neuroscience},
number = {12},
pages = {934--946},
publisher = {Nature Publishing Group},
title = {{Human volition: towards a neuroscience of will}},
volume = {9},
year = {2008}
}
@misc{Channelpedia,
title = {http://channelpedia.epfl.ch/}
}
@article{RootWang07,
abstract = {Investigating how information propagates between layers in the olfactory

system is an important step toward understanding the olfactory code.

Each glomerular output projection neuron (PN) receives two sources

of input: the olfactory receptor neurons (ORNs) of the same glomerulus

and interneurons that innervate many glomeruli. We therefore asked

how these inputs interact to produce PN output. We used receptor

gene mutations to silence all of the ORNs innervating a specific

glomerulus and recorded PN activity with two-photon calcium imaging

and electrophysiology. We found evidence for balanced excitatory

and inhibitory synaptic inputs but saw little or no response in the

absence of direct ORN input. We next asked whether any transformation

of activity occurs at successive layers of the antennal lobe. We

found a strong link between PN firing and dendritic calcium elevation,

the latter of which is tightly correlated with calcium activity in

ORN axons, supporting the idea of glomerular propagation of olfactory

information. Finally, we showed that odors are represented by a sparse

population of PNs. Together, these results are consistent with the

idea that direct receptor input provides the main excitatory drive

to PNs, whereas interneurons modulate PN output. Balanced excitatory

and inhibitory interneuron input may provide a mechanism to adjust

PN sensitivity.},
author = {Root, Cory M and Semmelhack, Julia L and Wong, Allan M and Flores, Jorge and Wang, Jing W},
doi = {10.1073/pnas.0704523104},
journal = {Proc Natl Acad Sci U S A},
month = {jul},
number = {28},
pages = {11826--11831},
pmid = {17596338},
title = {{Propagation of olfactory information in Drosophila.}},
url = {http://dx.doi.org/10.1073/pnas.0704523104},
volume = {104},
year = {2007}
}
@article{Toderici2016a,
abstract = {This paper presents a set of full-resolution lossy image compression methods based on neural networks. Each of the architectures we describe can provide variable compression rates during deployment without requiring retraining of the network: each network need only be trained once. All of our architectures consist of a recurrent neural network (RNN)-based encoder and decoder, a binarizer, and a neural network for entropy coding. We compare RNN types (LSTM, associative LSTM) and introduce a new hybrid of GRU and ResNet. We also study "one-shot" versus additive reconstruction architectures and introduce a new scaled-additive framework. We compare to previous work, showing improvements of 4.3{\%}-8.8{\%} AUC (area under the rate-distortion curve), depending on the perceptual metric used. As far as we know, this is the first neural network architecture that is able to outperform JPEG at image compression across most bitrates on the rate-distortion curve on the Kodak dataset images, with and without the aid of entropy coding.},
archivePrefix = {arXiv},
arxivId = {1608.05148},
author = {Toderici, George and Vincent, Damien and Johnston, Nick and Hwang, Sung Jin and Minnen, David and Shor, Joel and Covell, Michele},
doi = {10.4135/9781412985277},
eprint = {1608.05148},
isbn = {9780761914402},
issn = {08936080},
journal = {arXiv:1608.05148},
pages = {59},
pmid = {21655600},
title = {{Full Resolution Image Compression with Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1608.05148},
year = {2016}
}
@misc{SAH97,
author = {Sahani, M},
howpublished = {Presented at NIC97 meeting, Snowbird, Utah; available at http://www.gatsby.ucl.ac.uk/{\~{}}maneesh/conferences/nic97/poster/home.html},
title = {{Interactively exploring a neural code by active learning}},
year = {1997}
}
@article{CoxRaol04,
author = {Cox, Steven J and Raol, Jay H},
journal = {Mathematical Biosciences},
number = {1},
pages = {9--37},
title = {{Recovering the passive properties of tapered dendrites from single and dual potential recordings}},
volume = {190},
year = {2004}
}
@misc{ImagingManual,
author = {Yuste, R and Konnerth, A and Masters, B R and Others},
booktitle = {Journal of Biomedical Optics},
pages = {19902},
publisher = {SPIE},
title = {{Imaging in Neuroscience and Development, A Laboratory Manual}},
volume = {11},
year = {2006}
}
@article{HeinzCarney01a,
author = {Heinz, M G and Colburn, H S and Carney, L H},
journal = {Neural Computation},
month = {oct},
number = {10},
pages = {2317--2338},
title = {{Evaluating auditory performance limits: II One-parameter discrimination with random-level variation}},
volume = {13},
year = {2001}
}
@article{Mitra|1999|,
abstract = {Modern imaging techniques for probing brain function, including functional
magnetic resonance imaging, intrinsic and extrinsic contrast optical
imaging, and magnetoencephalography, generate large data sets with
complex content. In this paper we develop appropriate techniques
for analysis and visualization of such imaging data to separate the
signal from the noise and characterize the signal. The techniques
developed fall into the general category of multivariate time series
analysis, and in particular we extensively use the multitaper framework
of spectral analysis. We develop specific protocols for the analysis
of fMRI, optical imaging, and MEG data, and illustrate the techniques
by applications to real data sets generated by these imaging modalities.
In general, the analysis protocols involve two distinct stages: {\"{i}}¾“noise{\"{i}}¾”
characterization and suppression, and {\"{i}}¾“signal{\"{i}}¾” characterization
and visualization. An important general conclusion of our study is
the utility of a frequency-based representation, with short, moving
analysis windows to account for nonstationarity in the data. Of particular
note are 1) the development of a decomposition technique (space-frequency
singular value decomposition) that is shown to be a useful means
of characterizing the image data, and 2) the development of an algorithm,
based on multitaper methods, for the removal of approximately periodic
physiological artifacts arising from cardiac and respiratory sources.
},
author = {Mitra, P P and Pesaran, B},
journal = {Biophysical Journal},
keywords = {dynamic,electroencyphalogram,imaging,neurobiology},
pages = {691},
title = {{Analysis of Dynamic Brain Imaging Data}},
volume = {76}
}
@article{HM03,
author = {Hansel, D and Mato, G},
journal = {Neural Computation},
pages = {1--56},
title = {{Asynchronous States and the Emergence of Synchrony in Large Networks of Interacting Excitatory and Inhibitory Neurons}},
volume = {15},
year = {2003}
}
@book{Motwani1996,
address = {Cambridge, UK},
author = {Motwani, R and Raghavan, P},
booktitle = {ACM Computing Surveys (CSUR)},
publisher = {Cambridge University Press},
title = {{Randomized algorithms}},
url = {http://portal.acm.org/citation.cfm?id=234313.234327{\&}guid=on http://dl.acm.org/citation.cfm?id=1882769},
year = {2010}
}
@article{DM89,
author = {Diaconis, P and Mosteller, F},
journal = {Journal of the American Statistical Association},
pages = {853--861},
title = {{Methods for Studying Coincidences}},
volume = {84},
year = {1989}
}
@article{Coleman2010,
abstract = {Point-process models have been shown to be useful in characterizing neural spiking activity as a function of extrinsic and intrinsic factors. Most point-process models of neural activity are parametric, as they are often efficiently computable. However, if the actual point process does not lie in the assumed parametric class of functions, misleading inferences can arise. Nonparametric methods are attractive due to fewer assumptions, but computation in general grows with the size of the data. We propose a computationally efficient method for nonparametric maximum likelihood estimation when the conditional intensity function, which characterizes the point process in its entirety, is assumed to be a Lipschitz continuous function but otherwise arbitrary. We show that by exploiting much structure, the problem becomes efficiently solvable. We next demonstrate a model selection procedure to estimate the Lipshitz parameter from data, akin to the minimum description length principle and demonstrate consistency of our estimator under appropriate assumptions. Finally, we illustrate the effectiveness of our method with simulated neural spiking data, goldfish retinal ganglion neural data, and activity recorded in CA1 hippocampal neurons from an awake behaving rat. For the simulated data set, our method uncovers a more compact representation of the conditional intensity function when it exists. For the goldfish and rat neural data sets, we show that our nonparametric method gives a superior absolute goodness-of-fit measure used for point processes than the most common parametric and splines-based approaches.},
annote = {2011num45},
author = {Coleman, Todd P and Sarma, Sridevi S},
doi = {10.1162/NECO_a_00001-Coleman},
issn = {1530-888X},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Goldfish,Models, Neurological,Neurons,Neurons: physiology,Rats,Statistics, Nonparametric},
month = {aug},
number = {8},
pages = {2002--30},
pmid = {20438334},
title = {{A computationally efficient method for nonparametric modeling of neural spiking activity with point processes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20438334},
volume = {22},
year = {2010}
}
@article{Avrutin2006a,
annote = {2011num16},
author = {Avrutin, V and Schanz, M},
doi = {10.1088/0951-7715/19/3/001},
issn = {0951-7715},
journal = {Nonlinearity},
month = {mar},
number = {3},
pages = {531--552},
title = {{On multi-parametric bifurcations in a scalar piecewise-linear map}},
url = {http://stacks.iop.org/0951-7715/19/i=3/a=001?key=crossref.78e131d86b42e7114a43a970cc3f057a},
volume = {19},
year = {2006}
}
@article{Eytan:2006fi,
abstract = {Cognitive processes depend on synchronization and propagation of electrical activity within and between neuronal assemblies. In vivo measurements show that the size of individual assemblies depends on their function and varies considerably, but the timescale of assembly activation is in the range of 0.1-0.2 s and is primarily independent of assembly size. Here we use an in vitro experimental model of cortical assemblies to characterize the process underlying the timescale of synchronization, its relationship to the effective topology of connectivity within an assembly, and its impact on propagation of activity within and between assemblies. We show that the basic mode of assembly activation, "network spike," is a threshold-governed, synchronized population event of 0.1-0.2 s duration and follows the logistics of neuronal recruitment in an effectively scale-free connected network. Accordingly, the sequence of neuronal activation within a network spike is nonrandom and hierarchical; a small subset of neurons is consistently recruited tens of milliseconds before others. Theory predicts that scale-free topology allows for synchronization time that does not increase markedly with network size; our experiments with networks of different densities support this prediction. The activity of early-to-fire neurons reliably forecasts an upcoming network spike and provides means for expedited propagation between assemblies. We demonstrate this capacity by observing the dynamics of two artificially coupled assemblies in vitro, using neuronal activity of one as a trigger for electrical stimulation of the other.},
annote = {2010IInum10.3{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}1529-2401 (Electronic) Journal Article},
author = {Eytan, D and Marom, S},
journal = {Journal of Neuroscience},
keywords = {Action Potentials Animals Biophysics Cells,Cultured Cerebral Cortex/*physiology *Cortical Sy,Non-U.S. Gov't Time Factors,networks},
mendeley-tags = {networks},
number = {33},
pages = {8465--8476},
title = {{Dynamics and effective topology underlying synchronization in networks of cortical neurons}},
volume = {26},
year = {2006}
}
@article{SullivanWang05,
author = {Sullivan, Megan R and Nimmerjahn, Axel and Sarkisov, Dmitry V and Helmchen, Fritjof and Wang, Samuel S-H},
journal = {Journal of Neurophysiology},
month = {aug},
number = {2},
pages = {1636--1644},
title = {{In vivo calcium imaging of circuit activity in cerebellar cortex}},
volume = {94},
year = {2005}
}
@article{Tlusty2008,
annote = {5num2012},
author = {Tlusty, T},
journal = {Physical Biology},
title = {{A simple model for the evolution of molecular codes driven by the interplay of accuracy, diversity and cost}},
url = {http://iopscience.iop.org/1478-3975/5/1/016001},
year = {2008}
}
@article{Yuan07,
author = {Yuan, Ming and Ekici, Ali and Lu, Zhaosong and Monteiro, Renato},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
pages = {329--346},
title = {{Dimension reduction and coefficient estimation in multivariate linear regression}},
volume = {69},
year = {2007}
}
@inproceedings{Sidenbladh|2001|,
abstract = {This paper describes a framework for learning probabilistic models
of objects and scenes and for exploiting these models for tracking
complex, deformable, or articulated objects in image sequences. We
focus on the probabilistic tracking of people and learn models of
how they appear and move in images. In particular, we learn the likelihood
of observing various spatial and temporal filter responses corresponding
to edges, ridges, and motion differences given a model of the person.
Similarly, we learn probability distributions over filter responses
for general scenes that define a likelihood of observing the filter
responses for arbitrary backgrounds. We then derive a probabilistic
model for tracking that exploits the ratio between the likelihood
that image pixels corresponding to the foreground (person) were generated
by an actual person or by some unknown background. The paper extends
previous work on learning image statistics and combines it with Bayesian
tracking using particle filtering. By combining multiple image cues,
and by using learned likelihood models, we demonstrate improved robustness
and accuracy when tracking complex objects such as people in monocular
image sequences with cluttered scenes and a moving camera.},
address = {Vancouver, Canada},
author = {Sidenbladh, H and Black, M J},
booktitle = {International Conference on Computer Vision},
keywords = {bayesian,computational,image processing,models,tracking},
title = {{Learning Image Statistics for Bayesian Tracking}}
}
@article{Hall|1991|,
author = {Hall, D H and Russell, R L},
journal = {Journal of Neuroscience},
number = {1},
pages = {1--22},
title = {{The posterior nervous system of the nematode Caenorhabditis elegans: Serial Reconstruction of identified neurons and complete pattern of synaptic interactions}},
volume = {11}
}
@article{Svaiter|2004|,
abstract = {We discuss the strong-coupling expansion in Euclidean field theory.
In a formal representation for teh Schwinger functional, we treat
the off-diagonal terms of the Gaussian factor as a perturbation abotu
the remaining terms of the functional integral. In this way, we develop
a perturbative expansion around the ultra-local model, where fields
defined at different points of Euclidean space are decoupled. We
first study the strong-coupling expansion in the lambda phi{\^{}}4{\_}d theory
and also quantum electrodynamics. Assuming the ultra-local approximation,
we examine the singularities of these perturbative expansions, analysing
the analytic structrure of the zero-dimensional generating functions
in the complex coupling constant plane. Second, we discuss the ultra-local
generating functional in two idealized field theory models defined
by the following interaction Lagrangians: L{\_}II(g{\_}1,g{\_}2;phi)=g{\_}1 phi{\^{}}p(x)+g{\_}2
phi{\^{}}-p(x), and the sinh-Gordon model, i.e. L{\_}III(g{\_}3,g{\_}4;phi)=g{\_}3(cosh(g{\_}4
phi(x))-1). To control the divergences of the strong-coupling perturbative
expansion two different steps are used throughout the paper. First,
we introduce a lattice structure to give meaning to the ultra-local
generating functional. Using an analytic regularization procedure
we discuss briefly how it is possible to obtain a renormalized Schwinger
functional associated with these scalar models, going beyond the
ultra-local approximation without using a lattice regularization
procedure. Using the strong-coupling perturbative expansion we shod
how it is possible to compute the renormalized vacuum energy of a
self-interacting scalar field, going beyond the one-loop level.},
annote = {This paper contains good references to the literature on the subject{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of strong-coupling expansions.},
author = {Svaiter, N F},
journal = {arXiv},
keywords = {analytic continuation,physics,quantum field theory,resummation,strong coupling,ultra-local continuation},
pages = {404070},
title = {{The Strong-Coupling Expansion and the Ultra-local Approximation in Field Theory}},
volume = {hep-th}
}
@article{Loader91,
author = {Loader, C},
journal = {Biometrika},
pages = {749--757},
title = {{Inference for a hazard rate change point}},
volume = {78},
year = {1991}
}
@article{Dorogovtsev2008,
archivePrefix = {arXiv},
arxivId = {arXiv:0705.0010v6},
author = {Dorogovtsev, SN and Goltsev, AV and Mendes, JFF},
eprint = {arXiv:0705.0010v6},
journal = {Reviews of Modern Physics},
number = {4},
pages = {1275},
publisher = {APS},
title = {{Critical phenomena in complex networks}},
url = {http://rmp.aps.org/abstract/RMP/v80/i4/p1275{\_}1},
volume = {80},
year = {2008}
}
@article{Yang2013,
abstract = {Memristive devices are electrical resistance switches that can retain a state of internal resistance based on the history of applied voltage and current. These devices can store and process information, and offer several key performance characteristics that exceed conventional integrated circuit technology. An important class of memristive devices are two-terminal resistance switches based on ionic motion, which are built from a simple conductor/insulator/conductor thin-film stack. These devices were originally conceived in the late 1960s and recent progress has led to fast, low-energy, high-endurance devices that can be scaled down to less than 10 nm and stacked in three dimensions. However, the underlying device mechanisms remain unclear, which is a significant barrier to their widespread application. Here, we review recent progress in the development and understanding of memristive devices. We also examine the performance requirements for computing with memristive devices and detail how the outstanding challenges could be met.},
author = {Yang, J Joshua and Strukov, Dmitri B and Stewart, Duncan R},
doi = {10.1038/nnano.2012.240},
isbn = {1748-3395 (Electronic)$\backslash$n1748-3387 (Linking)},
issn = {1748-3395},
journal = {Nature nanotechnology},
number = {1},
pages = {13--24},
pmid = {23269430},
publisher = {Nature Publishing Group},
title = {{Memristive devices for computing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23269430},
volume = {8},
year = {2013}
}
@article{Destexhe1993,
author = {Destexhe, A and Babloyantz, A},
journal = {Biophysical Journal},
title = {{Ionic mechanisms for intrinsic slow oscillations in thalamic relay neurons}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349593811901},
year = {1993}
}
@inproceedings{Hoffer2017a,
abstract = {Background: Deep learning models are typically trained using stochastic gradient descent or one of its variants. These methods update the weights using their gradient, estimated from a small fraction of the training data. It has been observed that when using large batch sizes there is a persistent degradation in generalization performance - known as the "generalization gap" phenomena. Identifying the origin of this gap and closing it had remained an open problem. Contributions: We examine the initial high learning rate training phase. We find that the weight distance from its initialization grows logarithmically with the number of weight updates. We therefore propose a "random walk on random landscape" statistical model which is known to exhibit similar "ultra-slow" diffusion behavior. Following this hypothesis we conducted experiments to show empirically that the "generalization gap" stems from the relatively small number of updates rather than the batch size, and can be completely eliminated by adapting the training regime used. We further investigate different techniques to train models in the large-batch regime and present a novel algorithm named "Ghost Batch Normalization" which enables significant decrease in the generalization gap without increasing the number of updates. To validate our findings we conduct several additional experiments on MNIST, CIFAR-10, CIFAR-100 and ImageNet. Finally, we reassess common practices and beliefs concerning training of deep models and suggest they may not be optimal to achieve good generalization.},
archivePrefix = {arXiv},
arxivId = {1705.08741},
author = {Hoffer, Elad and Hubara, Itay and Soudry, D.},
booktitle = {NIPS (oral presentation)},
eprint = {1705.08741},
month = {may},
pages = {1--13},
title = {{Train longer, generalize better: closing the generalization gap in large batch training of neural networks}},
url = {http://arxiv.org/abs/1705.08741},
year = {2017}
}
@article{Sengupta2010,
author = {Sengupta, B. and Laughlin, S B and Niven, J. E.},
doi = {10.1103/PhysRevE.81.011918},
issn = {1539-3755},
journal = {Physical Review E},
month = {jan},
number = {1},
pages = {1--12},
title = {{Comparison of Langevin and Markov channel noise models for neuronal signal generation}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.81.011918},
volume = {81},
year = {2010}
}
@article{Thompson1999,
author = {Thompson, A and Layzell, P},
journal = {Commun. ACM},
number = {4},
pages = {71--79},
publisher = {ACM New York, NY, USA},
title = {{Analysis of unconventional evolved electronics}},
url = {http://portal.acm.org/citation.cfm?id=299174 http://dl.acm.org/citation.cfm?id=299174},
volume = {42},
year = {1999}
}
@article{Friedman2008,
abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm--the graphical lasso--that is remarkably fast: It solves a 1000-node problem ( approximately 500,000 parameters) in at most a minute and is 30-4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen and B{\"{u}}hlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
doi = {10.1093/biostatistics/kxm045},
issn = {1468-4357},
journal = {Biostatistics (Oxford, England)},
keywords = {Algorithms,Animals,Biometry,Biometry: methods,Data Interpretation, Statistical,Humans,Models, Statistical,Neural Networks (Computer),Proteomics,Proteomics: methods,Reference Values,Regression Analysis,Sample Size,Signal Transduction,Time Factors},
month = {jul},
number = {3},
pages = {432--41},
pmid = {18079126},
title = {{Sparse inverse covariance estimation with the graphical lasso.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3019769{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2008}
}
@book{dayan2001theoretical,
author = {Dayan, P and Abbott, L F},
publisher = {MIT Press},
title = {{Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems}},
url = {http://www.mitpressjournals.org/doi/pdfplus/10.1162/089892903321107891},
year = {2001}
}
@techreport{NEAL93,
address = {Canada},
author = {Neal, R M},
institution = {University of Toronto},
number = {CRG-TR-93-1},
title = {{Probabilistic inference using {\{}M{\}}arkov chain {\{}M{\}}onte {\{}C{\}}arlo methods}},
year = {1993}
}
@article{DantzkerCallaway00,
author = {Dantzker, J L and Callaway, E M},
journal = {Nat Neurosci},
number = {7},
pages = {701--7.},
title = {{Laminar sources of synaptic input to cortical inhibitory interneurons and pyramidal neurons}},
volume = {3},
year = {2000}
}
@article{Megias|2001|,
author = {Megias, M and Emri, Z and Freund, T F and Gulyas, A I},
journal = {Neuroscience},
number = {3},
pages = {527--540},
title = {{Total number and distribution of inhibitory and excitatory synapses on hippocampal CA1 pyramidal cells.}},
volume = {102}
}
@article{WW95,
author = {Wolpert, D and Wolf, D},
journal = {Physical Review E},
pages = {6841--6854},
title = {{Estimating functions of probability distributions from a finite set of samples}},
volume = {52},
year = {1995}
}
@article{Carandini07,
author = {Carandini, M and Horton, J and Sincich, L},
journal = {Journal of Vision},
pages = {1--11},
title = {{Thalamic filtering of retinal spike trains by postsynaptic summation}},
volume = {7},
year = {2007}
}
@article{Jo2010,
author = {Jo, SH H and Chang, Ting and Ebong, Idongesit},
doi = {10.1021/nl904092h},
journal = {Nano {\ldots}},
keywords = {and execu-,decode,digital computers,fetch,he sequential processing of,mann bottleneck of conventional,memristor,nanoelectronics,neuromorphic system,spike-timing dependent plasticity,synaptic adaptation,the classical von neu-,tion of instructions through},
pages = {1297--1301},
title = {{Nanoscale memristor device as synapse in neuromorphic systems}},
url = {http://pubs.acs.org/doi/abs/10.1021/nl904092h},
year = {2010}
}
@article{Chen2002,
author = {Chen, Yangquan},
title = {{41st IEEE CONFERENCE ON DECISION AND CONTROL TUTORIAL WORKSHOP {\#} 2 Editors :}},
year = {2002}
}
@article{Dinh2016,
abstract = {Despite their overwhelming capacity to overfit, deep learning architectures tend to generalize rel-atively well to unseen data, allowing them to be deployed in practice. However, explaining why this is the case is still an open area of research. One standing hypothesis that is gaining popularity, e.g. Hochreiter {\&} Schmidhuber (1997); Keskar et al. (2017), is that the flatness of minima of the loss function found by stochastic gradient based methods results in good generalization. This pa-per argues that most notions of flatness are prob-lematic for deep models and can not be directly applied to explain generalization. Specifically, when focusing on deep networks with rectifier units, we can exploit the particular geometry of pa-rameter space induced by the inherent symmetries that these architectures exhibit to build equivalent models corresponding to arbitrarily sharper min-ima. Furthermore, if we allow to reparametrize a function, the geometry of its parameters can change drastically without affecting its general-ization properties.},
archivePrefix = {arXiv},
arxivId = {1703.04933},
author = {Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
eprint = {1703.04933},
journal = {Arxiv},
title = {{Sharp Minima Can Generalize For Deep Nets}},
url = {https://arxiv.org/pdf/1703.04933.pdf},
year = {2016}
}
@article{Trust2014,
author = {Steck, GP},
journal = {Biometrika},
number = {3},
pages = {433--445},
title = {{Orthant probabilities for the equicorrelated multivariate normal distribution}},
url = {http://www.jstor.org/stable/2333977},
volume = {49},
year = {1962}
}
@article{Harris2000,
author = {Harris, Kenneth D and Henze, Darrell A and Csicsvari, Jozsef and Hirase, Hajime and Buzsaki, Gyorgy},
journal = {J. Neurophys.},
number = {1},
pages = {401--414},
title = {{Accuracy of Tetrode Spike Separation as Determined by Simultaneous Intracellular and Extracellular Measurements}},
volume = {84},
year = {2000}
}
@article{bruneau2005effect,
author = {Bruneau, E.G. and Macpherson, P.C. and Goldman, D. and Hume, R.I. and Akaaboune, M.},
journal = {Developmental biology},
number = {1},
pages = {248--258},
publisher = {Elsevier},
title = {{The effect of agrin and laminin on acetylcholine receptor dynamics in vitro}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0012160605006779},
volume = {288},
year = {2005}
}
@article{Amit1997,
abstract = {We investigate self-sustaining stable states (attractors) in networks of integrate-and-fire neurons. First, we study the stability of spontaneous activity in an unstructured network. It is shown that the stochastic background activity, of 1-5 spikes/s, is unstable if all neurons are excitatory. On the other hand, spontaneous activity becomes self-stabilizing in presence of local inhibition, given reasonable values of the parameters of the network. Second, in a network sustaining physiological spontaneous rates, we study the effect of learning in a local module, expressed in synaptic modifications in specific populations of synapses. We find that if the average synaptic potentiation (LTP) is too low, no stimulus specific activity manifests itself in the delay period. Instead, following the presentation and removal of any stimulus there is, in the local module, a delay activity in which all neurons selective (responding visually) to any of the stimuli presented for learning have rates which gradually increase with the amplitude of synaptic potentiation. When the average LTP increases beyond a critical value, specific local attractors (stable states) appear abruptly against the background of the global uniform spontaneous attractor. In this case the local module has two available types of collective delay activity: if the stimulus is unfamiliar, the activity is spontaneous; if it is similar to a learned stimulus, delay activity is selective. These new attractors reflect the synaptic structure developed during learning. In each of them a small population of neurons have elevated rates, which depend on the strength of LTP. The remaining neurons of the module have their activity at spontaneous rates. The predictions made in this paper could be checked by single unit recordings in delayed response experiments.},
author = {Amit, D J and Brunel, N},
issn = {1047-3211},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Electrophysiology,Feedback,Feedback: physiology,Long-Term Potentiation,Long-Term Potentiation: physiology,Models, Neurological,Motor Activity,Motor Activity: physiology,Neural Networks (Computer),Neurons,Neurons, Afferent,Neurons, Afferent: physiology,Neurons: physiology,Poisson Distribution,Synaptic Membranes,Synaptic Membranes: physiology},
number = {3},
pages = {237--52},
pmid = {9143444},
title = {{Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9143444},
volume = {7},
year = {1997}
}
@article{Rajasekar1988,
author = {Rajasekar, S. and Lakshmanan, M.},
issn = {0167-2789},
journal = {Physica D: Nonlinear Phenomena},
number = {1},
pages = {146--152},
publisher = {Elsevier},
title = {{Period-doubling bifurcations, chaos, phase-locking and devil's staircase in a Bonhoeffer-van der Pol oscillator}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0167278988900917},
volume = {32},
year = {1988}
}
@article{Clopath2010,
abstract = {Electrophysiological connectivity patterns in cortex often have a few strong connections, which are sometimes bidirectional, among a lot of weak connections. To explain these connectivity patterns, we created a model of spike timing-dependent plasticity (STDP) in which synaptic changes depend on presynaptic spike arrival and the postsynaptic membrane potential, filtered with two different time constants. Our model describes several nonlinear effects that are observed in STDP experiments, as well as the voltage dependence of plasticity. We found that, in a simulated recurrent network of spiking neurons, our plasticity rule led not only to development of localized receptive fields but also to connectivity patterns that reflect the neural code. For temporal coding procedures with spatio-temporal input correlations, strong connections were predominantly unidirectional, whereas they were bidirectional under rate-coded input with spatial correlations only. Thus, variable connectivity patterns in the brain could reflect different coding principles across brain areas; moreover, our simulations suggested that plasticity is fast.},
author = {Clopath, Claudia and B{\"{u}}sing, Lars and Vasilaki, E and Gerstner, W},
doi = {10.1038/nn.2479},
issn = {1546-1726},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Computer Simulation,Homeostasis,Homeostasis: physiology,Membrane Potentials,Membrane Potentials: physiology,Models,Neural Pathways,Neural Pathways: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Poisson Distribution,Presynaptic Terminals,Presynaptic Terminals: physiology,Time Factors,Visual Cortex,Visual Cortex: physiology,synapse},
mendeley-tags = {synapse},
month = {mar},
number = {3},
pages = {344--52},
pmid = {20098420},
publisher = {Nature Publishing Group},
title = {{Connectivity reflects coding: a model of voltage-based STDP with homeostasis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20098420},
volume = {13},
year = {2010}
}
@article{Das|2004|,
abstract = {In this paper, we study the question of quantization of quantum field
theories in a general light-front frame.We quantize scalar and fermion
as well as gauge field theories in a systematic manner carrying out
the Hamiltonian analysis carefully. The decomposition of the fields
into positive and negative frequency terms needs to be done carefully
after which we show that the (anti) commutation relations for the
quantum operators become frame independent. The frame dependence
is completely contained in the functions multiplying these operators
in the field decomposition.We derive the propagators from the vacuum
expectation values of the time ordered products of the fields.},
author = {Das, A and Perez, S},
journal = {Physical Review D},
keywords = {generalized parton distribution,infinite momentum frame,light front dynamics,perturbation theory,physics,quantization,quantum chromodynamics,renormalization,unread},
pages = {65006},
title = {{Quantization in a general light-front frame}},
volume = {70}
}
@article{Hausdorff1996,
author = {Hausdorff, JM},
journal = {Physical review E},
title = {{Multiscaled randomness: A possible source of 1/f noise in biology}},
url = {http://pre.aps.org/abstract/PRE/v54/i2/p2154{\_}1},
year = {1996}
}
@article{PAN05e,
author = {Paninski, L and Haith, A and Szirtes, G},
journal = {Journal of Computational Neuroscience},
pages = {69--79},
title = {{Integral equation methods for computing likelihoods and their derivatives in the stochastic integrate-and-fire model}},
volume = {24},
year = {2007}
}
@article{Hackbusch2000,
author = {Hackbusch, W and Khoromskij, B N},
journal = {Computing},
pages = {21--47},
title = {{A sparse H-matrix arithmetic. Part II: application to multi-dimensional problems}},
volume = {64},
year = {2000}
}
@inproceedings{DEIG00,
author = {Deignan, P and Meckl, P and Franchek, M and Abraham, J and Jaliwala, S},
booktitle = {ACC},
number = {ASME0043},
series = {American Control Conference},
title = {{Using mutual information to pre-process input data for a virtual sensor}},
year = {2000}
}
@article{GaryHolt1998,
author = {{Gary Holt}},
title = {{Gary Holt Phd Thesis}},
year = {1998}
}
@article{Dunn2008,
annote = {2011num9},
author = {Dunn, EW W},
journal = {Science},
title = {{Spending money on others promotes happiness}},
url = {http://www.sciencemag.org/cgi/content/full/319/5870/1687?ijkey=r33pt45ZU39aU{\&}keytype=ref{\&}siteid=sci},
year = {2008}
}
@article{Toib1998,
annote = {2009num6},
author = {Toib, A and Lyakhov, V and Marom, S},
journal = {Journal of Neuroscience},
number = {5},
pages = {1893--1903},
publisher = {Soc Neuroscience},
title = {{Interaction between duration of activity and time course of recovery from slow inactivation in mammalian brain Na+ channels}},
url = {http://neuro.cjb.net/cgi/content/abstract/18/5/1893},
volume = {18},
year = {1998}
}
@article{Fisch,
author = {Fisch, Karin and Schwalger, Tilo and Lindner, B and Herz, AVM and Benda, Jan},
journal = {bio.lmu.de},
number = {7071},
title = {{Channel noise from both slow adaptation currents and fast currents is required to explain spike-response variability in a sensory neuron}},
url = {http://www.bio.lmu.de/{~}benda/publications/Fisch2012/Fisch2012.pdf},
volume = {49}
}
@article{Rucci07,
author = {Rucci, M and Iovin, R and Poletti, M and Santini, F},
journal = {Nature},
pages = {851--854},
title = {{Miniature eye movements enhance fine spatial detail}},
volume = {447},
year = {2007}
}
@article{Lee2016,
abstract = {We show that gradient descent converges to a local minimizer, almost surely with random initialization. This is proved by applying the Stable Manifold Theorem from dynamical systems theory.},
archivePrefix = {arXiv},
arxivId = {1602.04915},
author = {Lee, Jason D. and Simchowitz, Max and Jordan, Michael I. and Recht, Benjamin},
eprint = {1602.04915},
journal = {Conference on Learning Theory},
keywords = {dynamical systems,gradient descent,local minimum,saddle points,smooth optimization},
title = {{Gradient Descent Converges to Minimizers}},
url = {http://arxiv.org/abs/1602.04915},
year = {2016}
}
@article{PM96,
author = {Panzeri, S and Treves, A},
journal = {Network: Computation in Neural Systems},
pages = {87--107},
title = {{Analytical estimates of limited sampling biases in different information measures}},
volume = {7},
year = {1996}
}
@article{OhlroggeRyugo01,
author = {Ohlrogge, M and Doucet, J R and Ryugo, D K},
journal = {Journal of Comparative Neurology},
month = {jul},
number = {3},
pages = {290--303},
title = {{Projections of the pontine nuclei to the cochlear nucleus in rats}},
volume = {436},
year = {2001}
}
@article{TR98,
author = {Tuckwell, Henry C and Rodriguez, Roger},
journal = {Journal of Computational Neuroscience},
pages = {91--113},
title = {{Analytical and simulation results for stochastic {\{}Fitzhugh-Nagumo{\}} neurons and neural networks}},
volume = {5},
year = {1998}
}
@article{Ishwaran2005,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0505633v1},
author = {Ishwaran, Hemant and Rao, JS},
doi = {10.1214/009053604000001147},
eprint = {0505633v1},
issn = {0090-5364},
journal = {Annals of Statistics},
keywords = {and phrases,generalized ridge regression,hypervariance,model averaging},
month = {apr},
number = {2},
pages = {730--773},
primaryClass = {arXiv:math},
title = {{Spike and slab variable selection: frequentist and Bayesian strategies}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.aos/1117114335/ http://www.jstor.org/stable/10.2307/3448605},
volume = {33},
year = {2005}
}
@article{Toyoizumi2009,
abstract = {There has recently been a great deal of interest in inferring network connectivity from the spike trains in populations of neurons. One class of useful models that can be fit easily to spiking data is based on generalized linear point process models from statistics. Once the parameters for these models are fit, the analyst is left with a nonlinear spiking network model with delays, which in general may be very difficult to understand analytically. Here we develop mean-field methods for approximating the stimulus-driven firing rates (in both the time-varying and steady-state cases), auto- and cross-correlations, and stimulus-dependent filtering properties of these networks. These approximations are valid when the contributions of individual network coupling terms are small and, hence, the total input to a neuron is approximately gaussian. These approximations lead to deterministic ordinary differential equations that are much easier to solve and analyze than direct Monte Carlo simulation of the network activity. These approximations also provide an analytical way to evaluate the linear input-output filter of neurons and how the filters are modulated by network interactions and some stimulus feature. Finally, in the case of strong refractory effects, the mean-field approximations in the generalized linear model become inaccurate; therefore, we introduce a model that captures strong refractoriness, retains all of the easy fitting properties of the standard generalized linear model, and leads to much more accurate approximations of mean firing rates and cross-correlations that retain fine temporal behaviors.},
annote = {2010IInum9.4},
author = {Toyoizumi, Taro and Rad, Kamiar Rahnama and Paninski, L},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Computer Simulation,Linear Models,Markov Chains,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Time Factors},
month = {may},
number = {5},
pages = {1203--1243},
pmid = {19718814},
title = {{Mean-field approximations for coupled populations of generalized linear model spiking neurons with Markov refractoriness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19718814},
volume = {21},
year = {2009}
}
@article{Haeffele2015,
abstract = {Techniques involving factorization are found in a wide range of applications and have enjoyed significant empirical success in many fields. However, common to a vast majority of these problems is the significant disadvantage that the associated optimization problems are typically non-convex due to a multilinear form or other convexity destroying transformation. Here we build on ideas from convex relaxations of matrix factorizations and present a very general framework which allows for the analysis of a wide range of non-convex factorization problems - including matrix factorization, tensor factorization, and deep neural network training formulations. We derive sufficient conditions to guarantee that a local minimum of the non-convex optimization problem is a global minimum and show that if the size of the factorized variables is large enough then from any initialization it is possible to find a global minimizer using a purely local descent algorithm. Our framework also provides a partial theoretical justification for the increasingly common use of Rectified Linear Units (ReLUs) in deep neural networks and offers guidance on deep network architectures and regularization strategies to facilitate efficient optimization.},
archivePrefix = {arXiv},
arxivId = {1506.0754},
author = {Haeffele, B D and Vidal, R},
eprint = {1506.0754},
journal = {ArXiv:1506.07540},
number = {1},
pages = {7},
title = {{Global Optimality in Tensor Factorization, Deep Learning, and Beyond}},
url = {http://arxiv.org/abs/1506.0754},
year = {2015}
}
@article{Muller2007,
abstract = {We propose a Markov process model for spike-frequency adapting neural ensembles that synthesizes existing mean-adaptation approaches, population density methods, and inhomogeneous renewal theory, resulting in a unified and tractable framework that goes beyond renewal and mean-adaptation theories by accounting for correlations between subsequent interspike intervals. A method for efficiently generating inhomogeneous realizations of the proposed Markov process is given, numerical methods for solving the population equation are presented, and an expression for the first-order interspike interval correlation is derived. Further, we show that the full five-dimensional master equation for a conductance-based integrate-and-fire neuron with spike-frequency adaptation and a relative refractory mechanism driven by Poisson spike trains can be reduced to a two-dimensional generalization of the proposed Markov process by an adiabatic elimination of fast variables. For static and dynamic stimulation, negative serial interspike interval correlations and transient population responses, respectively, of Monte Carlo simulations of the full five-dimensional system can be accurately described by the proposed two-dimensional Markov process.},
annote = {2010IIInum67},
author = {Muller, Eilif and Buesing, Lars and Schemmel, Johannes and Meier, Karlheinz},
doi = {10.1162/neco.2007.19.11.2958},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation, Physiological,Animals,Markov Chains,Models, Neurological,Monte Carlo Method,Neurons,Neurons: physiology,Time Factors},
month = {nov},
number = {11},
pages = {2958--3010},
pmid = {17883347},
title = {{Spike-frequency adapting neural ensembles: beyond mean adaptation and renewal theories.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17883347},
volume = {19},
year = {2007}
}
@article{Edery2000,
abstract = {Living organisms on this planet have adapted to the daily rotation of the earth on its axis. By means of endogenous circadian clocks that can be synchronized to the daily and seasonal changes in external time cues, most notably light and temperature, life forms anticipate environmental transitions, perform activities at biologically advantageous times during the day, and undergo characteristic seasonal responses. The effects of transmeridian flight and shift work are stark reminders that although modern technologies can create "cities that never sleep" we cannot escape the recalcitrance of endogenous clocks that regulate much of our physiology and behavior. Moreover, malfunctions in the human circadian timing system are implicated in several disorders, including chronic sleep disorders in the elderly, manic-depression, and seasonal affective disorders (SAD or winter depression). Recent progress in understanding the molecular mechanisms underlying circadian rhythms has been remarkable. In its most basic form, circadian clocks are comprised of a set of proteins that, by virtue of the design principles involved, generate a self-sustaining transcriptional-translational feedback loop with a free-running period of about 24 h. One or more of the clock components is acutely sensitive to light, resulting in an oscillator that can be synchronized to local time. This review provides an overview of the roles circadian clocks play in nature, how they might have arisen, human health concerns related to clock dysfunction, and mainly focuses on the clockworks found in Drosophila and mice, the two best studied animal model systems for understanding the biochemical and cellular bases of circadian rhythms.},
author = {Edery, I},
issn = {1531-2267},
journal = {Physiological genomics},
keywords = {Animals,Biological,Biological Clocks,Biological Clocks: drug effects,Biological Clocks: genetics,Biological Clocks: physiology,Circadian Rhytems,Circadian Rhythm,Circadian Rhythm: drug effects,Circadian Rhythm: genetics,Circadian Rhythm: physiology,Drosophila melanogaster,Drosophila melanogaster: genetics,Drosophila melanogaster: physiology,Humans,Mice,Models,Neurons,Neurons: physiology,Time Factors},
mendeley-tags = {Circadian Rhytems},
month = {aug},
number = {2},
pages = {59--74},
pmid = {11015601},
title = {{Circadian rhythms in a nutshell.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11015601},
volume = {3},
year = {2000}
}
@article{Ait-Sahalia2008,
author = {A{\"{i}}t-Sahalia, Yacine},
doi = {10.1214/009053607000000622},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {and phrases,diffusions,discrete observations,expansions,likelihood},
month = {apr},
number = {2},
pages = {906--937},
title = {{Closed-form likelihood expansions for multivariate diffusions}},
url = {http://projecteuclid.org/euclid.aos/1205420523},
volume = {36},
year = {2008}
}
@article{Fernandez2005,
abstract = {Many central neurons support active dendritic spike backpropagation mediated by voltage-gated currents. Active spikes in dendrites have been shown capable of providing feedback to the soma to influence somatic excitability and firing dynamics through a depolarizing afterpotential (DAP). In pyramidal cells of the electrosensory lobe of weakly electric fish, Na(+) spikes in dendrites undergo a frequency-dependent broadening that enhances the DAP to increase somatic firing frequency. We use a combination of dynamical analysis and electrophysiological recordings to demonstrate that spike broadening in dendrites is primarily caused by a cumulative inactivation of dendritic Na(+) current. We further show that a reduction in dendritic Na(+) current increases excitability by decreasing the interspike interval and promoting burst firing. This process arises when inactivation of dendritic Na(+) current shifts the latency of the dendritic spike to delay the arrival of the DAP sufficiently to increase its impact on somatic membrane potential despite a reduction in dendritic excitability. Furthermore, the relationship between dendritic Na(+) current density and somatic excitability is nonmonotonic, as intermediate levels of dendritic Na(+) current exert the greatest excitatory influence. These results reveal that temporal shifts in dendritic spike firing provide a novel means for backpropagating spikes to influence the final output of a cell.},
annote = {

2010IIInum8},
author = {Fernandez, Fernando R and Mehaffey, W Hamish and Turner, Ray W and Fernando, R},
doi = {10.1152/jn.00653.2005},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Action Potentials: radiation effects,Animals,Dendrites,Dendrites: drug effects,Dendrites: physiology,Dose-Response Relationship,Electric Fish,Electric Organ,Electric Organ: cytology,Electric Stimulation,Electric Stimulation: methods,Membrane Potentials,Membrane Potentials: drug effects,Membrane Potentials: physiology,Membrane Potentials: radiation effects,Models,Neurological,Nonlinear Dynamics,Patch-Clamp Techniques,Patch-Clamp Techniques: methods,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Radiation,Sodium Channel Blockers,Sodium Channel Blockers: pharmacology,Sodium Channels,Sodium Channels: drug effects,Sodium Channels: physiology,Tetrodotoxin,Tetrodotoxin: pharmacology,Time Factors},
month = {dec},
number = {6},
pages = {3836--48},
pmid = {16120659},
title = {{Dendritic Na+ current inactivation can increase cell excitability by delaying a somatic depolarizing afterpotential.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16120659},
volume = {94},
year = {2005}
}
@article{Reynolds|2003|,
abstract = {Attention increases the contrast gain of V4 neurons, causing them
to respond to an attended stimulus as though its contrast had increased.
When multiple stimuli appear within a neuron{\"{i}}¾'s receptive field
(RF), the neuron responds primarily to the attended stimulus. This
suggests that cortical cells may be {\"{i}}¾“hard wired{\"{i}}¾” to respond preferentially
to the highest-contrast stimulus in their RF, and neural systems
for attention capitalize on this mechanism by dynamically increasing
the effective contrast of the stimulus that is task relevant. To
test this, we varied the relative contrast of two stimuli within
the recorded neurons{\"{i}}¾' RFs, while the monkeys attended away to another
location. In- creasing the physical contrast of one stimulus caused
V4 neurons to respond preferentially to that stimulus and reduced
their responses to competing stimuli. When attention was directed
to the lower-contrast stimulus, it partially overcame the influence
of a competing, higher-contrast stimulus.},
author = {Reynolds, J H and Desimone, R},
journal = {Neuron},
keywords = {attention,decision making,neurobiology,psychology,unread,visual salience},
pages = {853},
title = {{Interacting roles of attention and visual salience in V4}},
volume = {37}
}
@article{Stanley2004,
abstract = {2006 version},
author = {Stanley, Rp},
journal = {Lecture notes, IAS/Park City Mathematics Institute},
pages = {110},
title = {{An introduction to hyperplane arrangements}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.118.5996},
year = {2004}
}
@article{Lampinen2001,
abstract = {We give a short review on the Bayesian approach for neural network learning and demonstrate the advantages of the approach in three real applications. We discuss the Bayesian approach with emphasis on the role of prior knowledge in Bayesian models and in classical error minimization approaches. The generalization capability of a statistical model, classical or Bayesian, is ultimately based on the prior assumptions. The Bayesian approach permits propagation of uncertainty in quantities which are unknown to other assumptions in the model, which may be more generally valid or easier to guess in the problem. The case problem studied in this paper include a regression, a classification, and an inverse problem. In the most thoroughly analyzed regression problem, the best models were those with less restrictive priors. This emphasizes the major advantage of the Bayesian approach, that we are not forced to guess attributes that are unknown, such as the number of degrees of freedom in the model, non-linearity of the model with respect to each input variable, or the exact form for the distribution of the model residuals.},
author = {Lampinen, J and Vehtari, a},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Algorithms,Bayes Theorem,Neural Networks (Computer)},
month = {apr},
number = {3},
pages = {257--74},
pmid = {11341565},
title = {{Bayesian approach for neural networks--review and case studies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11341565},
volume = {14},
year = {2001}
}
@article{VogelsteinPoster10,
author = {Vogelstein, J and Machado, T and Mishchenko, Y and Packer, A and Yuste, R and Paninski, L},
journal = {Computational and Systems Neuroscience Abstracts},
title = {{Methods for neural circuit inference from population calcium imaging data}},
volume = {doi:10.338},
year = {2010}
}
@phdthesis{Batenburg|2002|,
author = {Batenburg, K J},
keywords = {binary images,discrete tomography,image reconstruction,linear programming,mathematics,network flow},
title = {{Analysis and optimization of an algorithm for discrete tomography}}
}
@article{Abel2004b,
abstract = {We examined the effects of recent discharge activity on [Ca2+]i in neocortical pyramidal cells. Our data confirm and extend the observation that there is a linear relationship between plateau [Ca2+]i and firing frequency in soma and proximal apical dendrites. The rise in [Ca2+] activates K+ channels underlying the afterhyperpolarization (AHP), which consists of 2 Ca(2+)-dependent components: the medium AHP (mAHP) and the slow AHP (sAHP). The mAHP is blocked by apamin, indicating involvement of SK-type Ca(2+)-dependent K+ channels. The identity of the apamin-insensitive sAHP channel is unknown. We compared the sAHP and the mAHP with regard to: 1) number and frequency of spikes versus AHP amplitude; 2) number and frequency of spikes versus [Ca2+]i; 3) IAHP versus [Ca2+]i. Our data suggest that sAHP channels require an elevation of [Ca2+]i in the cytoplasm, rather than at the membrane, consistent with a role for a cytoplasmic intermediate between Ca2+ and the K+ channels. The mAHP channels appear to respond to a restricted Ca2+ domain.},
author = {Abel, H J and Lee, J C F and Callaway, J C and Foehring, R C},
doi = {10.1152/jn.00583.2003},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Adrenergic beta-Agonists,Adrenergic beta-Agonists: pharmacology,Animals,Apamin,Apamin: pharmacology,Cadmium,Cadmium: pharmacology,Calcium,Calcium: physiology,Dendrites,Dendrites: drug effects,Dendrites: metabolism,Dose-Response Relationship,Electric Impedance,Electric Stimulation,Electric Stimulation: methods,Extracellular Space,Extracellular Space: drug effects,Extracellular Space: physiology,Fura-2,Fura-2: metabolism,Isoproterenol,Isoproterenol: pharmacology,Membrane Potentials,Membrane Potentials: drug effects,Membrane Potentials: physiology,Neocortex,Neocortex: cytology,Newborn,Patch-Clamp Techniques,Patch-Clamp Techniques: methods,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: drug effects,Pyramidal Cells: physiology,Radiation,Rats,Sprague-Dawley,Time Factors},
month = {jan},
number = {1},
pages = {324--35},
pmid = {12917389},
title = {{Relationships between intracellular calcium and afterhyperpolarizations in neocortical pyramidal neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12917389},
volume = {91},
year = {2004}
}
@article{GER01,
author = {Gerstner, W},
journal = {Neural Networks},
pages = {599--610},
title = {{Coding Properties of Spiking Neurons: Reverse and Cross-Correlations}},
volume = {14},
year = {2001}
}
@article{Frieden2001,
author = {Frieden, B R},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
title = {{Probability, statistical optics, and data testing: a problem solving approach}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=hpxpyOak1psC{\&}oi=fnd{\&}pg=PA1{\&}dq=Probability,+statistical+optics,+and+data+testing+:a+problem+solving+approach{\&}ots=T9nSTkepMw{\&}sig=1etXGfbOdTJMRuomaDM4HnPe4To},
year = {2001}
}
@article{Ribrault2011,
author = {Ribrault, Claire and Sekimoto, Ken and Triller, Antoine},
doi = {10.1038/nrn3025},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
month = {jun},
number = {7},
pages = {375--387},
publisher = {Nature Publishing Group},
title = {{From the stochasticity of molecular processes to the variability of synaptic transmission}},
url = {http://www.nature.com/doifinder/10.1038/nrn3025},
volume = {12},
year = {2011}
}
@article{Rossi2000,
author = {Pastor-Satorras, R and Vespignani, A and Rossi, M},
journal = {arXiv preprint cond-mat/ {\ldots}},
title = {{The universality class of absorbing phase transitions with a conserved field}},
url = {http://arxiv.org/abs/cond-mat/0004242 http://arxiv.org/abs/cond-mat/0006254},
year = {2000}
}
@inproceedings{Latimer2014,
author = {Latimer, Kenneth W. and Chichilnisky, E. J. and Rieke, Fred and Pillow, J W},
booktitle = {Neural Information Processing Systems},
pages = {954--962},
title = {{Inferring synaptic conductances from spike trains with a biophysically inspired point process model}},
year = {2014}
}
@article{Nykamp2007,
abstract = {We describe an approach for determining causal connections among nodes of a probabilistic network even when many nodes remain unobservable. The unobservable nodes introduce ambiguity into the estimate of the causal structure. However, in some experimental contexts, such as those commonly used in neuroscience, this ambiguity is present even without unobservable nodes. The analysis is presented in terms of a point process model of a neuronal network, though the approach can be generalized to other contexts. The analysis depends on the existence of a model that captures the relationship between nodal activity and a set of measurable external variables. The mathematical framework is sufficiently general to allow a large class of such models. The results are modestly robust to deviations from model assumptions, though additional validation methods are needed to assess the success of the results.},
author = {Nykamp, D Q},
doi = {10.1016/j.mbs.2006.08.020},
issn = {0025-5564},
journal = {Mathematical biosciences},
keywords = {Algorithms,Animals,Computer Simulation,Estimation,Humans,Likelihood Functions,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Statistical},
mendeley-tags = {Estimation},
month = {feb},
number = {2},
pages = {204--51},
pmid = {17070863},
title = {{A mathematical framework for inferring connectivity in probabilistic neuronal networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17070863},
volume = {205},
year = {2007}
}
@article{Robinson:2002zr,
abstract = {In cerebral cortex, cells tend to fire in response to strong transient
fluctuations in input, produced by synchronous population activity,
which reset the precision of firing and erase correlations between
prior and future spike times. Here, using experiments and modeling,
we study the accumulation of spike time variance in response to single
decaying transient stimuli. All such responses go through distinct
stages in time. When the stimulus is high, variance is held low,
while at low stimulus levels near threshold, variance rises dramatically,
approaching a Poisson level. This behavior was reproduced in a stochastically
simulated Hodgkin-Huxley model, and in two simpler models, class
1 (Morris-Lecar) and class 2 (FitzHugh-Nagumo), incorporating Ornstein-Uhlenbeck
noise. Early stage variance represents perturbation of uniform limit-cycle
motion of the dynamical variables. Late stage variance reflects random
motion of the dynamical variables captured within the basin of the
resting fixed point. We show that the two stages have different sensitivities
to the amplitude and time scale of noise, and relate this to coherence
resonance. This rapid breakdown in reliability during responses to
transient stimuli may restrict precise signalling by spike times
to brief time windows, and limit the duration of coherent synchronous
responses in the cortex.},
author = {Robinson, H P C and Harsch, Annette},
journal = {Physical Review B},
keywords = {networks},
mendeley-tags = {networks},
number = {6 Pt 1},
pages = {61902},
pmid = {12513313},
title = {{Stages of spike time variability during neuronal responses to transient inputs}},
volume = {66},
year = {2002}
}
@article{Stern2007,
abstract = {Cells adjust their transcriptional state to accommodate environmental and genetic perturbations. An open question is to what extent transcriptional response to perturbations has been specifically selected along evolution. To test the possibility that transcriptional reprogramming does not need to be 'pre-designed' to lead to an adaptive metabolic state on physiological timescales, we confronted yeast cells with a novel challenge they had not previously encountered. We rewired the genome by recruiting an essential gene, HIS3, from the histidine biosynthesis pathway to a foreign regulatory system, the GAL network responsible for galactose utilization. Switching medium to glucose in a chemostat caused repression of the essential gene and presented the cells with a severe challenge to which they adapted over approximately 10 generations. Using genome-wide expression arrays, we show here that a global transcriptional reprogramming ({\textgreater}1200 genes) underlies the adaptation. A large fraction of the responding genes is nonreproducible in repeated experiments. These results show that a nonspecific transcriptional response reflecting the natural plasticity of the regulatory network supports adaptation of cells to novel challenges.},
annote = {2010IInum12.4},
author = {Stern, Shay and Dror, Tali and Stolovicki, Elad and Brenner, N and Braun, E},
doi = {10.1038/msb4100147},
issn = {1744-4292},
journal = {Molecular systems biology},
keywords = {Adaptation,Biological,Cluster Analysis,Fungal,Gene Expression Regulation,Genes,Genetic,Genome,Glucose,Glucose: metabolism,Models,Physiological,Saccharomyces cerevisiae,Saccharomyces cerevisiae Proteins,Saccharomyces cerevisiae Proteins: physiology,Time Factors,Transcription,Transcription Factors,Transcription Factors: metabolism},
number = {106},
pages = {106},
pmid = {17453047},
title = {{Genome-wide transcriptional plasticity underlies cellular adaptation to novel challenge.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17453047},
volume = {3},
year = {2007}
}
@article{TheerDenk03,
author = {Theer, Patrick and Hasan, Mazahir T and Denk, W},
journal = {Opt Lett},
month = {jun},
number = {12},
pages = {1022--1024},
title = {{Two-photon imaging to a depth of 1000 $\mu$m in living brains by use of a Ti:Al{\_}2O{\_}3 regenerative amplifier}},
volume = {28},
year = {2003}
}
@article{OhkiReid06,
abstract = {In the visual cortex of higher mammals, neurons are arranged across
the cortical surface in an orderly map of preferred stimulus orientations.
This map contains 'orientation pinwheels', structures that are arranged
like the spokes of a wheel such that orientation changes continuously
around a centre. Conventional optical imaging first demonstrated
these pinwheels, but the technique lacked the spatial resolution
to determine the response properties and arrangement of cells near
pinwheel centres. Electrophysiological recordings later demonstrated
sharply selective neurons near pinwheel centres, but it remained
unclear whether they were arranged randomly or in an orderly fashion.
Here we use two-photon calcium imaging in vivo to determine the microstructure
of pinwheel centres in cat visual cortex with single-cell resolution.
We find that pinwheel centres are highly ordered: neurons selective
to different orientations are clearly segregated even in the very
centre. Thus, pinwheel centres truly represent singularities in the
cortical map. This highly ordered arrangement at the level of single
cells suggests great precision in the development of cortical circuits
underlying orientation selectivity.},
author = {Ohki, Kenichi and Chung, Sooyoung and Kara, Prakash and Hubener, Mark and Bonhoeffer, Tobias and Reid, R Clay},
doi = {10.1038/nature05019},
journal = {Nature},
keywords = {Animals; Cats; Electrophysiology; Models,Neurological; Morphogenesis; Neurons; Photic Stim},
month = {aug},
number = {7105},
pages = {925--928},
pmid = {16906137},
title = {{Highly ordered arrangement of single neurons in orientation pinwheels.}},
url = {http://dx.doi.org/10.1038/nature05019},
volume = {442},
year = {2006}
}
@article{Theorem1989,
author = {Theorem, A Central Limit and Of, Fourier Transforms and Dependent, Strongly and Processes, Stationary},
keywords = {central limit theorem,strongly dependent processes},
number = {4},
pages = {375--383},
title = {{A central limit theorem}},
volume = {10},
year = {1989}
}
@article{Camerer|2005|,
abstract = {The canonical model in economics considers people to be rational and
self-regarding. However, much evidence challenges this view, raising
the question of when "Economic Man{\"{i}}¾'{\"{i}}¾' dominates the outcome of
social interactions, and when bounded rationality or other-regarding
preferences dominate. Here we show that strategic incentives are
the key to answering this question. A minority of self-regarding
individuals can trigger a {\"{i}}¾‘{\"{i}}¾‘noncooperative{\"{i}}¾'{\"{i}}¾' aggregate outcome
if their behavior generates incentives for the majority of other-regarding
individuals to mimic the minority{\"{i}}¾'s behavior. Likewise, a minority
of other-regarding individuals can generate a {\"{i}}¾‘{\"{i}}¾‘cooperative{\"{i}}¾'{\"{i}}¾'
aggregate outcome if their behavior generates incentives for a majority
of self-regarding people to behave cooperatively. Similarly, in strategic
games, aggregate outcomes can be either far from or close to Nash
equilibrium if players with high degrees of strategic thinking mimic
or erase the effects of others who do very little strategic thinking.
Recently developed theories of other-regarding preferences and bounded
rationality explain these findings and provide better predictions
of actual aggregate behavior than does traditional economic theory.},
annote = {The paper provides some review about the bounded rationality models{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of economic behavior and argues that in the presence of a fraction{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of rational players, even a number of "irrational" players (called{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}here reciprocators, which are however rational players with shifted{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}concept of rationality such as the concept of "global equity" or{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}"justice") have to behave as rational players. Interesting here is{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the solution to the following game: given a market of limited size{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and a number of companies that may enter this market with the return{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}being nothing when there are too many companies in the market - how{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}many companies will enter market. The bounded rationality model ("cognitive{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}hierarchi" model) in which group is organized in layers, where each{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}subsequent layer is aware of statistical decision of the layers below{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}it, but not above, and in which population of each layer is given{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}by Poission distribution with mean 1.5, remarkably well reproduces{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}experimental data.},
author = {Camerer, C F and Fehr, E},
journal = {Science},
keywords = {bounded rationality,cooperation,economics,reciprocators},
pages = {47},
title = {{When does "economic man" dominate social behavior?}},
volume = {311}
}
@article{Abbott2004,
abstract = {Neurons are often considered to be the computational engines of the brain, with synapses acting solely as conveyers of information. But the diverse types of synaptic plasticity and the range of timescales over which they operate suggest that synapses have a more active role in information processing. Long-term changes in the transmission properties of synapses provide a physiological substrate for learning and memory, whereas short-term changes support a variety of computations. By expressing several forms of synaptic plasticity, a single neuron can convey an array of different signals to the neural circuit in which it operates.},
annote = {2010IInum11.4},
author = {Abbott, L F and Regehr, W G},
doi = {10.1038/nature03010},
issn = {1476-4687},
journal = {Nature},
keywords = {Animals,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: cytology,Neurons: physiology,Sound Localization,Sound Localization: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {oct},
number = {7010},
pages = {796--803},
pmid = {15483601},
title = {{Synaptic computation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15483601},
volume = {431},
year = {2004}
}
@article{BS04,
author = {Braess, D and Sauer, T},
journal = {Journal of Approximation Theory},
pages = {187--206},
title = {{Bernstein polynomials and learning theory}},
volume = {128},
year = {2004}
}
@article{Soudry2014d,
abstract = {Long term temporal correlations frequently appear at many levels of neural activity. We show that when such correlations appear in isolated neurons, they indicate the existence of slow underlying processes and lead to explicit conditions on the dynamics of these processes. Moreover, although these slow processes can potentially store information for long times, we demonstrate that this does not imply that the neuron possesses a long memory of its input, even if these processes are bidirectionally coupled with neuronal response. We derive these results for a broad class of biophysical neuron models, and then fit a specific model to recent experiments. The model reproduces the experimental results, exhibiting long term (days-long) correlations due to the interaction between slow variables and internal fluctuations. However, its memory of the input decays on a timescale of minutes. We suggest experiments to test these predictions directly.},
author = {Soudry, D. and Meir, Ron},
doi = {10.3389/fncom.2014.00035},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {Input-output analysis,Linear filters,Long memory,Neurons,Noise,Power spectral density,Temporal correlations,input,input-output analysis,linear filters,long memory,neurons,noise,output analysis,power,power spectral density,temporal correlations},
number = {1 APR},
pmid = {24744724},
title = {{The neuronal response at extended timescales: long-term correlations without long-term memory}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3978321/},
volume = {8},
year = {2014}
}
@article{Cukierman1996,
author = {Cukierman, S.},
issn = {0022-2631},
journal = {Journal of Membrane Biology},
keywords = {neuron,regulation},
mendeley-tags = {neuron,regulation},
number = {3},
pages = {203--214},
publisher = {Springer},
title = {{Regulation of voltage-dependent sodium channels}},
url = {http://www.springerlink.com/index/2TAJTRFWGWC5GKJK.pdf},
volume = {151},
year = {1996}
}
@article{Iyengar85,
author = {Iyengar, Satish},
journal = {SIAM Journal on Applied Mathematics},
pages = {983--989},
title = {{Hitting Lines with Two-Dimensional {\{}B{\}}rownian Motion}},
volume = {45},
year = {1985}
}
@article{PAN03c,
author = {Paninski, L},
journal = {Network: Computation in Neural Systems},
pages = {437--464},
title = {{Convergence properties of some spike-triggered analysis techniques}},
volume = {14},
year = {2002}
}
@article{Sporea2013,
abstract = {We introduce a supervised learning algorithm for multilayer spiking neural networks. The algorithm overcomes a limitation of existing learning algorithms: it can be applied to neurons firing multiple spikes in artificial neural networks with hidden layers. It can also, in principle, be used with any linearizable neuron model and allows different coding schemes of spike train patterns. The algorithm is applied successfully to classic linearly nonseparable benchmarks such as the XOR problem and the Iris data set, as well as to more complex classification and mapping problems. The algorithm has been successfully tested in the presence of noise, requires smaller networks than reservoir computing, and results in faster convergence than existing algorithms for similar tasks such as SpikeProp.},
author = {Sporea, Ioana and Gr{\"{u}}ning, Andr{\'{e}}},
doi = {10.1162/NECO_a_00396},
issn = {1530-888X},
journal = {Neural computation},
month = {feb},
number = {2},
pages = {473--509},
pmid = {23148411},
title = {{Supervised learning in multilayer spiking neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23148411},
volume = {25},
year = {2013}
}
@article{Naghshtabrizi2007,
author = {Hespanha, J.P. and Naghshtabrizi, Payam and Xu, Yonggang},
journal = {Proceedings of the IEEE},
keywords = {1,Reservoir Computing,fig,general ncs architecture},
mendeley-tags = {Reservoir Computing},
number = {1},
pages = {138--162},
publisher = {IEEE},
title = {{A survey of recent results in networked control systems}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4118465},
volume = {95},
year = {2007}
}
@article{Peng1995,
abstract = {The healthy heartbeat is traditionally thought to be regulated according to the classical principle of homeostasis whereby physiologic systems operate to reduce variability and achieve an equilibrium-like state [Physiol. Rev. 9, 399-431 (1929)]. However, recent studies [Phys. Rev. Lett. 70, 1343-1346 (1993); Fractals in Biology and Medicine (Birkhauser-Verlag, Basel, 1994), pp. 55-65] reveal that under normal conditions, beat-to-beat fluctuations in heart rate display the kind of long-range correlations typically exhibited by dynamical systems far from equilibrium [Phys. Rev. Lett. 59, 381-384 (1987)]. In contrast, heart rate time series from patients with severe congestive heart failure show a breakdown of this long-range correlation behavior. We describe a new method--detrended fluctuation analysis (DFA)--for quantifying this correlation property in non-stationary physiological time series. Application of this technique shows evidence for a crossover phenomenon associated with a change in short and long-range scaling exponents. This method may be of use in distinguishing healthy from pathologic data sets based on differences in these scaling properties.},
author = {Peng, C K and Havlin, Shlomo and Stanley, H E and Goldberger, a L},
doi = {10.1063/1.166141},
issn = {1054-1500},
journal = {Chaos (Woodbury, N.Y.)},
keywords = {Heart Diseases,Heart Diseases: physiopathology,Heart Failure,Heart Failure: physiopathology,Heart Rate,Heart Rate: physiology,Humans,Mathematics,Models,Nonlinear Dynamics,Statistical,Stochastic Processes,Systole,Systole: physiology,Time Factors},
month = {jan},
number = {1},
pages = {82--7},
pmid = {11538314},
title = {{Quantification of Scaling Exponents and Crossover Phenomena in Nonstationary Heartbeat Time Series}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11538314 http://chaos.aip.org/resource/1/chaoeh/v5/i1/p82{\_}s1},
volume = {5},
year = {1995}
}
@article{Cardone|2003|,
abstract = {Shape similarity assessment is a fundamental geometric reasoning problem
that finds application in several different product design and manufacturing
applications. A computationally efficient way to assess shape similarity
is to first abstract 3D object shapes into shape signatures and use
shape signatures to perform similarity assessment. Several different
types of shape signatures have been developed in the past. This paper
provides a survey of existing algorithms for computing and comparing
shape signatures. Our survey consists of a description of the desired
properties of shape signatures, a scheme for classifying different
types of shape signatures, and descriptions of representative algorithms
for computing and comparing shape signatures. This survey concludes
by identifying directions for future research.},
annote = {The paper reviews what shape similarity assessment algorithms are{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}used in applications.},
author = {Cardone, A and Gupta, S K and Karnik, M},
journal = {Journal of computing and information science in engineering},
keywords = {computational,image processing,shape similarity,similarity based object retrieval},
pages = {109},
title = {{A survey of shape similarity assessment algorithms for product design and manufacturing applications}},
volume = {3}
}
@article{Zhang2012a,
author = {Zhang, Bai and Miller, DJ},
journal = {sites.google.com},
number = {1},
pages = {175--182},
title = {{Nonlinear System Modeling with Random Matrices: Echo State Networks Revisited}},
url = {http://sites.google.com/site/baizhangwebsite/home/ESN{\_}submitted{\_}IEEE{\_}TNN.pdf},
volume = {23},
year = {2012}
}
@article{Kepplinger2011,
abstract = {BACKGROUND: Stochastic resonance therapy (SRT) is used for rehabilitation of patients with various neuropsychiatric diseases. An alteration in tryptophan metabolism along the kynurenine pathway has been identified in the central and peripheral nervous systems in patients with neuroinflammatory and neurodegenerative diseases and during the aging process. This study investigated the effect of SRT as an exercise activity on serum tryptophan metabolites in healthy subjects. METHODS: Serum L-tryptophan, L-kynurenine, kynurenic acid, and anthranilic acid levels were measured one minute before SRT and at one, 5, 15, 30, and 60 minutes after SRT. We found that SRT affected tryptophan metabolism. Serum levels of L-tryptophan, L-kynurenine, and kynurenic acid were significantly reduced for up to 60 minutes after SRT. Anthranilic acid levels were characterized by a moderate, non significant transient decrease for up to 15 minutes, followed by normalization at 60 minutes. Tryptophan metabolite ratios were moderately altered, suggesting activation of metabolism after SRT. Lowering of tryptophan would generally involve activation of tryptophan catabolism and neurotransmitter, protein, and bone biosynthesis. Lowering of kynurenic acid by SRT might be relevant for improving symptoms in patients with neuropsychiatric disorders, such as Parkinson's disease, Alzheimer's disease, schizophrenia, and depression, as well as certain pain conditions.},
author = {Kepplinger, Berthold and Baran, Halina and Sedlnitzky-Semler, Brenda and Badawi, Nagy-Roland and Erhart, Helene},
doi = {10.4137/IJTR.S7986},
issn = {1178-6469},
journal = {International journal of tryptophan research : IJTR},
month = {jan},
number = {1},
pages = {49--60},
pmid = {22174588},
title = {{Stochastic resonance activity influences serum tryptophan metabolism in healthy human subjects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22174588 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3236008{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2011}
}
@article{Schaeffer|1892|,
author = {Schaeffer, K},
journal = {Arch Mikrosc Anat},
pages = {611--632},
title = {{Beitrag zur Histologie der Ammonshornformation}},
volume = {39}
}
@article{Kany|2006|,
annote = {This text supposedly deals with the theory of bayesian decision making{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and learning.},
author = {Kany, M and Nagy, I and Pavelkova, I L and Suzdaleva, E},
keywords = {bayesian,bayesian learning,computational,decision making,neurobiology},
title = {{Bayesian Decision Making}}
}
@article{Goldin2003,
author = {Goldin, a},
doi = {10.1016/S0959-4388(03)00065-5},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {3},
pages = {284--290},
title = {{Mechanisms of sodium channel inactivation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438803000655},
volume = {13},
year = {2003}
}
@article{DAN82,
author = {Daniels, H},
journal = {Annals of Statistics},
pages = {394--400},
title = {{Sequential tests contructed from images}},
volume = {10},
year = {1982}
}
@inproceedings{Chan2012,
address = {Brisbane},
author = {Chan, William and Lohn, Jason},
booktitle = {The 2012 International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/IJCNN.2012.6252822},
isbn = {978-1-4673-1490-9},
month = {jun},
pages = {1--6},
publisher = {Ieee},
title = {{Spike timing dependent plasticity with memristive synapse in neuromorphic systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6252822},
year = {2012}
}
@article{Holler1989,
author = {Holler, Mark and Tam, Simon and Castro, Hernan and Benson, Ronald},
doi = {10.1109/IJCNN.1989.118698},
journal = {International Joint Conference on Neural Networks},
pages = {191--196 vol.2},
publisher = {Ieee},
title = {{An electrically trainable artificial neural network (ETANN) with 10240 'floating gate' synapses}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=118698},
year = {1989}
}
@article{Fuda|1987|,
abstract = {It is shown that with the introduction of an external lightlike vector,
a light front perturbation theory for the S matrix in quantum field
theory can be developed in which the individual terms in the series
are invariant functions of the particle variable and the external
vector. No limiting processes are involved. The dependence of the
results on the external lightlike vector is discussed.},
author = {Fuda, M G},
journal = {Physical Review C},
keywords = {light front dynamics,perturbation theory,physics,quantum chromodynamics,renormalization,unread},
number = {2},
pages = {702},
title = {{Invariant light front perturbation theory}},
volume = {36}
}
@article{Moreno-Bote2008,
abstract = {Spike correlations between neurons are ubiquitous in the cortex, but their role is not understood. Here we describe the firing response of a leaky integrate-and-fire neuron (LIF) when it receives a temporarily correlated input generated by presynaptic correlated neuronal populations. Input correlations are characterized in terms of the firing rates, Fano factors, correlation coefficients, and correlation timescale of the neurons driving the target neuron. We show that the sum of the presynaptic spike trains cannot be well described by a Poisson process. In fact, the total input current has a nontrivial two-point correlation function described by two main parameters: the correlation timescale (how precise the input correlations are in time) and the correlation magnitude (how strong they are). Therefore, the total current generated by the input spike trains is not well described by a white noise gaussian process. Instead, we model the total current as a colored gaussian process with the same mean and two-point correlation function, leading to the formulation of the problem in terms of a Fokker-Planck equation. Solutions of the output firing rate are found in the limit of short and long correlation timescales. The solutions described here expand and improve on our previous results (Moreno, de la Rocha, Renart, {\&} Parga, 2002) by presenting new analytical expressions for the output firing rate for general IF neurons, extending the validity of the results for arbitrarily large correlation magnitude, and by describing the differential effect of correlations on the mean-driven or noise-dominated firing regimes. Also the details of this novel formalism are given here for the first time. We employ numerical simulations to confirm the analytical solutions and study the firing response to sudden changes in the input correlations. We expect this formalism to be useful for the study of correlations in neuronal networks and their role in neural processing and information transmission.},
author = {Moreno-Bote, Rub{\'{e}}n and Renart, Alfonso and Parga, N},
doi = {10.1162/neco.2008.03-07-497},
issn = {1530-888X},
journal = {Neural Computation},
keywords = {Action Potentials,Algorithms,Computer Simulation,Humans,Markov Chains,Models,Neural Inhibition,Neural Inhibition: physiology,Neurological,Neurons,Neurons: physiology,Normal Distribution,Poisson Distribution,Presynaptic Terminals,Presynaptic Terminals: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
number = {7},
pages = {1651--705},
pmid = {18254697},
title = {{Theory of input spike auto- and cross-correlations and their effect on the response of spiking neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18254697},
volume = {20},
year = {2008}
}
@article{Cossell2015,
author = {Cossell, Lee and Iacaruso, Maria Florencia and Muir, Dylan R. and Houlton, Rachael and Sader, Elie N. and Ko, Ho and Hofer, Sonja B. and Mrsic-Flogel, Thomas D.},
doi = {10.1038/nature14182},
issn = {0028-0836},
journal = {Nature},
month = {feb},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nature},
title = {{Functional organization of excitatory synaptic strength in primary visual cortex}},
url = {http://dx.doi.org/10.1038/nature14182},
volume = {advance on},
year = {2015}
}
@inproceedings{Greshnikov2016,
author = {Greshnikov, S and Rosenthal, E and Soudry, D. and Kvatinsky, S},
booktitle = {Proceeding of the IEEE International Conference on Circuits and Systems},
pages = {1394--1397},
title = {{A Fully Analog Memristor-Based Multilayer Neural Network with Online Backpropagation Training}},
year = {2016}
}
@article{Wolf09,
author = {Wolf, Michael T and Cham, Jorge G and Branchaud, Edward A and Mulliken, Grant H and Burdick, Joel W and Andersen, Richard A},
journal = {The International Journal of Robotics Research},
pages = {1240--1256},
title = {{A Robotic Neural Interface for Autonomous Positioning of Extracellular Recording Electrodes}},
volume = {28},
year = {2009}
}
@article{DenkHorstmann04,
author = {{W. Denk}, W and Horstmann, H},
journal = {PLOS Biol.},
pages = {e329},
title = {{Serial block-face scanning electron microscopy to reconstruct three-dimensional tissue nanostructure}},
volume = {2},
year = {2004}
}
@article{Montroll1982,
abstract = {It is shown, following Shockley [Shockley, W. (1957) Proc. IRE 45, 279-290], that, when a population is engaged in tasks whose completion requires the successful conclusion of many independent subtasks, the distribution function for successes in the primary task is log normal. It is also shown that, when the dispersion of the log-normal distribution is large, the distribution is mimicked by a 1/x distribution over a wide range of x. This argument provides a generic set of processes that yields the much observed 1/x distribution, and will also lead to a 1/f noise spectrum. It is commonly found that distributions that seem to be log normal over a broad range (say to the 95th percentile of a population) change to an inverse fractional power (Pareto) distribution for the last few percentile. Annual income distributions are examples with this structure. The very wealthy generally achieve their superwealth through amplification processes that are not available to most. We have introduced a simple amplification model to characterize the transition from a log-normal distribution to an inverse-power Pareto tail.},
author = {Montroll, E W},
doi = {10.1073/pnas.79.10.3380},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {may},
number = {10},
pages = {3380--3383},
title = {{On 1/f Noise and Other Distributions with Long Tails}},
url = {http://www.pnas.org/cgi/content/abstract/79/10/3380},
volume = {79},
year = {1982}
}
@article{Cohen89,
author = {Cohen, L},
journal = {Annual Review of Physiology},
pages = {487--582},
title = {{Optical approaches to neuronal function.}},
volume = {51},
year = {1989}
}
@article{TRUC05,
author = {Truccolo, W and Eden, U and Fellows, M and Donoghue, J and Brown, E},
journal = {Journal of Neurophysiology},
pages = {1074--1089},
title = {{A Point Process Framework for Relating Neural Spiking Activity to Spiking History, Neural Ensemble and Extrinsic Covariate Effects}},
volume = {93},
year = {2005}
}
@article{Berry1997,
author = {Berry, M and Warland, D and Meister, M},
journal = {Proc Natl Acad Sci USA},
number = {10},
pages = {5411--5416},
title = {{The structure and precision of retinal spike trains}},
volume = {94},
year = {1997}
}
@article{Li2005,
author = {Li, Hongying and Hou, Zhonghuai and Xin, Houwen},
doi = {10.1103/PhysRevE.71.061916},
issn = {1539-3755},
journal = {Physical Review E},
month = {jun},
number = {6},
title = {{Internal noise stochastic resonance for intracellular calcium oscillations in a cell system}},
url = {http://pre.aps.org/abstract/PRE/v71/i6/e061916},
volume = {71},
year = {2005}
}
@article{Lichtman2008,
abstract = {A central aim of neuroscience is to map neural circuits, in order to learn how they account for mental activities and behaviours and how alterations in them lead to neurological and psychiatric disorders. However, the methods that are currently available for visualizing circuits have severe limitations that make it extremely difficult to extract precise wiring diagrams from histological images. Here we review recent advances in this area, along with some of the opportunities that these advances present and the obstacles that remain.},
author = {Lichtman, Jeff W and Livet, Jean and Sanes, Joshua R},
doi = {10.1038/nrn2391},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Animals, Genetically Modified,Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Brain: ultrastructure,Coloring Agents,Coloring Agents: diagnostic use,Humans,Luminescent Proteins,Luminescent Proteins: diagnostic use,Luminescent Proteins: genetics,Microscopy, Electron,Neural Pathways,Neural Pathways: physiology,Neural Pathways: ultrastructure,Neurons,Neurons: physiology,Neurosciences,Neurosciences: methods,Neurosciences: trends,Staining and Labeling,Transgenes},
month = {jun},
number = {6},
pages = {417--422},
pmid = {18446160},
title = {{A technicolour approach to the connectome.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2577038{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2008}
}
@article{Gal2013a,
archivePrefix = {arXiv},
arxivId = {arXiv:1210.7414v5},
author = {Gal, A and Marom, Shimon},
eprint = {arXiv:1210.7414v5},
journal = {Physical Review E (In press)},
title = {{Self-organized criticality in single neuron excitability}},
url = {http://arxiv.org/abs/1210.7414},
year = {2013}
}
@book{CoxBook62,
author = {Cox, D R},
pages = {142 p.},
publisher = {Methuen; Wiley London, New York,},
title = {{Renewal theory}},
type = {Book},
year = {1962}
}
@article{Cauwenberghs1992,
author = {Cauwenberghs, G},
journal = {Neural Networks, IEEE Transactions on},
month = {may},
number = {3},
pages = {488--497},
title = {{Analysis and verification of an analog VLSI incremental outer-product learning system}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=129421},
volume = {3},
year = {1992}
}
@article{Carney93,
author = {Carney, L H},
journal = {Journal of The Acoustical Society Of America},
month = {jan},
number = {1},
pages = {401--417},
title = {{A model for the responses of low-frequency auditory-nerve fibers in cat}},
volume = {93},
year = {1993}
}
@article{Valiant2009,
author = {Valiant, Leslie G.},
doi = {10.1145/1462153.1462156},
issn = {00045411},
journal = {Journal of the ACM},
month = {jan},
number = {1},
pages = {1--21},
title = {{Evolvability}},
url = {http://portal.acm.org/citation.cfm?doid=1462153.1462156},
volume = {56},
year = {2009}
}
@article{Choi2017,
abstract = {Hybrid analog-digital beamforming architectures with low-resolution analog-to-digital converters (ADCs) reduce hardware cost and power consumption in multiple-input multiple-output (MIMO) millimeter wave (mmWave) communication systems. In this paper, we propose a hybrid architecture with resolution-adaptive ADCs for mmWave receivers with large antenna arrays. We adopt array response vectors for the analog combiners and derive ADC bit allocation (BA) algorithms. The two proposed BA algorithms minimize the mean square quantization error of received analog signals under a total ADC power constraint. It is beneficial to assign more bits to the ADC with a larger channel gain on the corresponding radio frequency (RF) chain, and the optimal number of ADC bits is logarithmically proportional to the RF chain's signal-to-noise ratio raised to the 1/3 power. Contributions of this paper include 1) an ADC bit allocation algorithm to improve communication performance of a hybrid MIMO receiver, 2) a revised ADC bit allocation algorithm that is robust to additive noise, and 3) a worst-case analysis of the ergodic rate of the proposed MIMO receiver that quantifies system tradeoffs and serves as the lower bound. Simulation results validate the ergodic rate formula and demonstrate that the proposed BA algorithms outperform a fixed-ADC approach in both spectral and energy efficiency. For a power constraint equivalent to that of fixed 4-bit ADCs, the revised BA algorithm makes the quantization error negligible while achieving 22{\%} better energy efficiency. Having negligible quantization error allows existing state-of-the-art digital beamforming techniques to be readily applied to the proposed system.},
archivePrefix = {arXiv},
arxivId = {1704.03137},
author = {Choi, Jinseok and Evans, Brian L. and Gatherer, Alan},
eprint = {1704.03137},
pages = {1--13},
title = {{Resolution-Adaptive Hybrid MIMO Architectures for Millimeter Wave Communications}},
url = {http://arxiv.org/abs/1704.03137},
year = {2017}
}
@article{dK03,
author = {de Kamps, M},
journal = {Neural Computation},
pages = {2129--2146},
title = {{A simple and stable numercial solution for the population density equation}},
volume = {15},
year = {2003}
}
@article{Pissadaki2010,
author = {Pissadaki, Eleftheria Kyriaki and Sidiropoulou, Kyriaki and Reczko, Martin and Poirazi, P},
doi = {10.1371/journal.pcbi.1001038},
editor = {Graham, Lyle J.},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {dec},
number = {12},
pages = {e1001038},
title = {{Encoding of Spatio-Temporal Input Characteristics by a CA1 Pyramidal Neuron Model}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1001038},
volume = {6},
year = {2010}
}
@article{Larkum2008,
abstract = {Dendritic signal integration is one of the fundamental building blocks of information processing in the brain. Dendrites are endowed with mechanisms of nonlinear summation of synaptic inputs leading to regenerative dendritic events including local sodium, NMDA and calcium spikes. The generation of these events requires distinct spatio-temporal activation patterns of synaptic inputs. We hypothesise that the recent findings on dendritic spikes and local synaptic plasticity rules suggest clustering of common inputs along a subregion of a dendritic branch. These clusters may enable dendrites to separately threshold groups of functionally similar inputs, thus allowing single neurons to act as a superposition of many separate integrate and fire units. Ultimately, these properties expand our understanding about the computational power of neuronal networks.},
author = {Larkum, M E and Nevian, Thomas},
doi = {10.1016/j.conb.2008.08.013},
issn = {0959-4388},
journal = {Current Opinion in Neurobiology},
keywords = {Animals,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Neurons,Neurons: cytology,Signal Transduction,Signal Transduction: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {jun},
number = {3},
pages = {321--31},
pmid = {18804167},
title = {{Synaptic clustering by dendritic signalling mechanisms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18804167},
volume = {18},
year = {2008}
}
@article{Duane-etal87,
author = {Duane, Simon and Kennedy, A D and Pendleton, Brian J and Roweth, Duncan},
doi = {DOI: 10.1016/0370-2693(87)91197-X},
issn = {0370-2693},
journal = {Physics Letters B},
number = {2},
pages = {216--222},
title = {{Hybrid {\{}Monte Carlo{\}}}},
url = {http://www.sciencedirect.com/science/article/B6TVN-46YSWPH-2XF/2/0f89cdc6cf214a2169b03df7414f3df4},
volume = {195},
year = {1987}
}
@book{KT81,
address = {New York},
author = {Karlin, S. and Taylor, H.M.},
publisher = {Academic Press},
title = {{A First Course in Stochastic Processes}},
url = {http://orton.catie.ac.cr/cgi-bin/wxis.exe/?IsisScript=COLPOS.xis{\&}method=post{\&}formato=2{\&}cantidad=1{\&}expresion=mfn=006365},
year = {1981}
}
@inproceedings{Rezende2014,
abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.},
archivePrefix = {arXiv},
arxivId = {1401.4082},
author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
booktitle = {ICML '14},
eprint = {1401.4082},
isbn = {9781634393973},
pages = {1278--1286},
title = {{Stochastic Backpropagation and Approximate Inference in Deep Generative Models}},
url = {http://arxiv.org/abs/1401.4082},
year = {2014}
}
@article{Schoen2012,
abstract = {Dendrites carry signals between synapses and the soma and play a central role in neural computation. Although they contain many nonlinear ion channels, their signal-transfer properties are linear under some experimental conditions. In experiments with continuous-time inputs, a resonant linear two-port model has been shown to provide a near-perfect fit to the dendrite-to-soma input-output relationship. In this study, we focused on this linear aspect of signal transfer using impedance functions that replace biophysical channel models in order to describe the electrical properties of the dendritic membrane. The membrane impedance model of dendrites preserves the accuracy of the two-port model with minimal computational complexity. Using this approach, we demonstrate two membrane impedance profiles of dendrites that reproduced the experimentally observed two-port results. These impedance profiles demonstrate that the two-port results are compatible with different computational schemes. In addition, our model highlights how dendritic resonance can minimize the location-dependent attenuation of signals at the resonant frequency. Thus, in this model, dendrites function as linear-resonant filters that carry signals between nonlinear computational units.},
author = {Schoen, Alan and Salehiomran, Ali and Larkum, Matthew E and Cook, Erik P},
doi = {10.1162/NECO_a_00366},
issn = {1530-888X},
journal = {Neural computation},
month = {sep},
pages = {3126--3144},
pmid = {22970871},
title = {{A Compartmental Model of Linear Resonance and Signal Transfer in Dendrites.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22970871},
volume = {3144},
year = {2012}
}
@article{Crammer2012,
author = {Crammer, K and Gentile, C},
doi = {10.1007/s10994-012-5321-8},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {online learning,regret,upper confidence bound},
month = {oct},
number = {3},
pages = {347--383},
title = {{Multiclass classification with bandit feedback using adaptive regularization}},
url = {http://link.springer.com/10.1007/s10994-012-5321-8},
volume = {90},
year = {2012}
}
@article{Johnston|1997|,
annote = {New York: Oxford UP},
author = {Johnston, D and Amaral, D G},
pages = {417--458},
title = {{In the Synaptic Organization of the Brain}}
}
@article{ManwaniKoch99,
author = {Manwani, Amit and Koch, Christof},
journal = {Neural Computation},
number = {8},
pages = {1797--1829},
title = {{Detecting and Estimating Signals in Noisy Cable Structures, I: Neuronal Noise Sources}},
volume = {11},
year = {1999}
}
@article{Beggs2012,
abstract = {Relatively recent work has reported that networks of neurons can produce avalanches of activity whose sizes follow a power law distribution. This suggests that these networks may be operating near a critical point, poised between a phase where activity rapidly dies out and a phase where activity is amplified over time. The hypothesis that the electrical activity of neural networks in the brain is critical is potentially important, as many simulations suggest that information processing functions would be optimized at the critical point. This hypothesis, however, is still controversial. Here we will explain the concept of criticality and review the substantial objections to the criticality hypothesis raised by skeptics. Points and counter points are presented in dialog form.},
author = {Beggs, John M and Timme, Nicholas},
doi = {10.3389/fphys.2012.00163},
issn = {1664-042X},
journal = {Frontiers in physiology},
keywords = {avalanche,criticality,criticality, scale-free, avalanche, network, multi,ising model,multi-electrode array,network,scale-free,statistical physics},
month = {jan},
number = {June},
pages = {163},
pmid = {22701101},
title = {{Being critical of criticality in the brain.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3369250{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2012}
}
@article{Dunn2004,
author = {Dunn, N A and Lockery, S R and Pierce-Shimomura, J T and Conery, J S},
journal = {Journal of Computational Neuroscience},
pages = {137--147},
title = {{A neural network model of chemotaxis predicts functions of synaptic connections in the nematode Caenorhabditis elegans.}},
volume = {17},
year = {2004}
}
@book{Jones86,
editor = {Peters, A and Jones, E},
publisher = {Plenum Press},
series = {Cerebral Cortex},
title = {{Visual Cortex}},
volume = {3},
year = {1986}
}
@article{DoiCosyne08,
author = {Doi, E and Paninski, L and Simoncelli, E},
journal = {COSYNE},
title = {{Maximizing sensory information with an arbitrary size of neural populations}},
year = {2008}
}
@article{Arora2017,
abstract = {This paper makes progress on several open theoretical issues related to Generative Adversarial Networks. A definition is provided for what it means for the training to generalize, and it is shown that generalization is not guaranteed for the popular distances between distributions such as Jensen-Shannon or Wasserstein. We introduce a new metric called neural net distance for which generalization does occur. We also show that an approximate pure equilibrium in the 2-player game exists for a natural training objective (Wasserstein). Showing such a result has been an open problem (for any training objective). Finally, the above theoretical ideas lead us to propose a new training protocol, MIX+GAN, which can be combined with any existing method. We present experiments showing that it stabilizes and improves some existing methods.},
archivePrefix = {arXiv},
arxivId = {1703.00573},
author = {Arora, Sanjeev and Ge, Rong and Liang, Yingyu and Ma, Tengyu and Zhang, Yi},
eprint = {1703.00573},
file = {::},
month = {mar},
title = {{Generalization and Equilibrium in Generative Adversarial Nets}},
url = {http://arxiv.org/abs/1703.00573},
year = {2017}
}
@book{KS97,
author = {Karatzas, I and Shreve, S},
publisher = {Springer},
title = {{Brownian Motion and Stochastic Calculus}},
year = {1997}
}
@article{Williams2009a,
abstract = {Central neurons receive thousands of synaptic inputs. A recent study shows how pyramidal neurons of the mammalian neocortex integrate synaptic input in a parallel manner, illustrating how a chain of dendritic integration mechanisms act to signal distal dendritic excitatory synaptic input.},
annote = {2010IInum12.30},
author = {Williams, SR Stephen R SR Stephen R and Wozny, Christian},
doi = {10.1016/j.cub.2009.08.031},
issn = {0960-9822},
journal = {Current biology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Dendrites,Dendrites: metabolism,Dendrites: physiology,Mammals,Mammals: metabolism,Mammals: physiology,Models,Neocortex,Neocortex: metabolism,Neocortex: physiology,Neural Pathways,Neurological,Neuron Model,Synaptic Potentials},
mendeley-tags = {Neuron Model},
month = {nov},
number = {20},
pages = {R956--R957},
pmid = {19889375},
publisher = {Elsevier Ltd},
title = {{Neuroscience: The chain reaction of dendritic integration}},
url = {http://dx.doi.org/10.1016/j.cub.2009.08.031 http://www.sciencedirect.com/science/article/pii/S0960982209016078 http://www.ncbi.nlm.nih.gov/pubmed/19889375},
volume = {19},
year = {2009}
}
@article{Hegseth|2006|,
abstract = {The path integral formulation of quantum mechanics constructs the
propagator by evaluating the action, S, for all classical paths in
coordinate space. A corresponding momentum path integral may also
be defined through Fourier transforms in the endpoints. These momentum
path integrals are especially simple for several special cases, yet
no one has, to my knowledge, ever formally constructed them from
first principles, i.e., by considering all classical paths in momentum
space. I show that this is possible because there exists another
classical mechanics based on an alternate classical action, R. Hamilton{\"{i}}¾'s
Canonical equations result from a variational principle in both S
and R. S uses fixed beginning and ending spatial points while R uses
fixed beginning and ending momentum points. This alternative action{\"{i}}¾'s
classical mechanics also includes a Hamilton- Jacobi equation. I
also present some important subtle points concerning the beginning
and ending conditions on the action necessary to apply a Canonical
transformation. These properties explain the failure of the Canonical
transformation in the phase space path integral. It follows that
a path integral may be formulated from first principles using S in
the coordinate representation, or R, in the momentum representation.
Several example calculations are presented that illustrate this broader
view of the path integral. In particular, the normalized amplitude
for a free particle is found without using the Schr{\~{A}}{\P}dinger equation,
the internal spin degree of freedom is simply and naturally derived,
and the simple harmonic oscillator is calculated.},
annote = {The paper considers path integral formulation of quantum mechanics{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}for paths in momentum space},
author = {Hegseth, J},
keywords = {canonical transformation,path integral,physics},
title = {{Path integrals from classical momentum paths}}
}
@article{DominguezRead06,
annote = {Letter},
author = {Dominguez, Melissa and Becker, Suzanna and Bruce, Ian and Read, Heather},
journal = {Neural Computation},
month = {dec},
number = {12},
pages = {2942--2958},
title = {{A spiking neuron model of cortical correlates of sensorineural hearing loss: spontaneous firing, synchrony, and tinnitus}},
volume = {18},
year = {2006}
}
@article{Waldrop2013,
author = {Waldrop, M Mitchell},
doi = {10.1038/503022a},
issn = {1476-4687},
journal = {Nature},
keywords = {Animals,Bees,Bees: cytology,Bees: physiology,Biomimetics,Brain,Brain: cytology,Brain: physiology,Computers,Electronics,Electronics: instrumentation,Humans,Models,Neurological,Neurons,Neurons: physiology},
month = {nov},
number = {7474},
pages = {22--4},
pmid = {24201264},
title = {{Neuroelectronics: Smart connections}},
url = {http://www.nature.com/news/neuroelectronics-smart-connections-1.14089?WT.ec{\_}id=NATURE-20131107},
volume = {503},
year = {2013}
}
@article{FRECHETTE-ETAL05,
author = {Frechette, E S and Sher, A and Grivich, M I and Petrusca, D and Litke, A M and Chichilnisky, E J},
journal = {J Neurophysiol},
number = {1},
pages = {119--135},
title = {{Fidelity of the ensemble code for visual motion in the primate retina.}},
volume = {94},
year = {2005}
}
@article{Salimans2017,
abstract = {We explore the use of Evolution Strategies, a class of black box optimization algorithms, as an alternative to popular RL techniques such as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show that ES is a viable solution strategy that scales extremely well with the number of CPUs available: By using hundreds to thousands of parallel workers, ES can solve 3D humanoid walking in 10 minutes and obtain competitive results on most Atari games after one hour of training time. In addition, we highlight several advantages of ES as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation.},
archivePrefix = {arXiv},
arxivId = {1703.03864},
author = {Salimans, Tim and Ho, Jonathan and Chen, Xi and Sutskever, Ilya},
doi = {10.1.1.51.6328},
eprint = {1703.03864},
file = {::},
isbn = {3-540-63746-X},
issn = {ISSN 0302-9743},
journal = {arXiv},
month = {mar},
pmid = {27474269},
title = {{Evolution Strategies as a Scalable Alternative to Reinforcement Learning}},
url = {http://arxiv.org/abs/1703.03864},
year = {2017}
}
@article{Carandini2004,
abstract = {The visual cortex responds to repeated presentations of the same stimulus with high variability. Because the firing mechanism is remarkably noiseless, the source of this variability is thought to lie in the membrane potential fluctuations that result from summated synaptic input. Here this hypothesis is tested through measurements of membrane potential during visual stimulation. Surprisingly, trial-to-trial variability of membrane potential is found to be low. The ratio of variance to mean is much lower for membrane potential than for firing rate. The high variability of firing rate is explained by the threshold present in the function that converts inputs into firing rates. Given an input with small, constant noise, this function produces a firing rate with a large variance that grows with the mean. This model is validated on responses recorded both intracellularly and extracellularly. In neurons of visual cortex, thus, a simple deterministic mechanism amplifies the low variability of summated synaptic inputs into the large variability of firing rate. The computational advantages provided by this amplification are not known.},
annote = {2010IInum10.7},
author = {Carandini, Matteo},
doi = {10.1371/journal.pbio.0020264},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Action Potentials,Animals,Brain,Brain: pathology,Cats,Cell Membrane,Cell Membrane: metabolism,Cerebral Cortex,Electrophysiology,Evoked Potentials, Visual,Guinea Pigs,Kinetics,Membrane Potentials,Models, Neurological,Models, Statistical,Neurons,Neurons: metabolism,Neurons: physiology,Normal Distribution,Photic Stimulation,Synapses,Synaptic Transmission,Visual Cortex,Visual Cortex: physiology,Visual Pathways},
number = {9},
pages = {E264},
pmid = {15328535},
title = {{Amplification of trial-to-trial response variability by neurons in visual cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15328535},
volume = {2},
year = {2004}
}
@article{Strelioff|2006|,
abstract = {We study prediction of chaotic time series when a perfect model is
available but the initial condition is measured with uncertainty.
A common approach for predicting future data given these circumstances
is to apply the model despite the uncertainty. In systems with fold
dynamics, we find prediction is improved over this strategy by recognizing
this behavior. A systematic study of the Logistic map demonstrates
prediction of the most likely trajectory can be extended three time
steps. Finally, we discuss application of these ideas to the Rossler
attractor.},
author = {Strelioff, C C and Hubler, A W},
journal = {Physical Review Letters},
keywords = {Physics,chaos,dynamical systems,mathematics},
pages = {44101},
title = {{Medium-Term Prediction of Chaos}},
volume = {79}
}
@article{Wu05a,
author = {Wu, W and Gao, Y and Bienenstock, E and Donoghue, J P and Black, M J},
journal = {Neural Computation},
pages = {80--118},
title = {{Bayesian population coding of motor cortical activity using a {\{}K{\}}alman filter.}},
volume = {18},
year = {2006}
}
@article{Valmianski2010,
author = {Valmianski, Ilya and Shih, AY},
doi = {10.1152/jn.00484.2010.},
journal = {Journal of {\ldots}},
pages = {1803--1811},
title = {{Automatic identification of fluorescently labeled brain cells for rapid functional imaging}},
url = {http://classic.jn.physiology.org/content/104/3/1803.short},
year = {2010}
}
@article{MOR99A,
author = {Moran, D and Schwartz, A},
journal = {Journal of Neurophysiology},
pages = {2676--2692},
title = {{Motor cortical representation of speed and direction during reaching}},
volume = {82},
year = {1999}
}
@book{DEV96,
address = {New York},
author = {Devroye, L and Gyorfi, L and Lugosi, G},
publisher = {Springer-Verlag},
title = {{A probabilistic theory of pattern recognition}},
year = {1996}
}
@article{Mainen1995,
author = {Mainen, Z F and Sejnowski, T J},
journal = {Science},
number = {5216},
pages = {1503},
publisher = {AAAS},
title = {{Reliability of spike timing in neocortical neurons}},
url = {http://www.sciencemag.org/cgi/content/abstract/sci;268/5216/1503},
volume = {268},
year = {1995}
}
@article{Cessac2008a,
abstract = {We derive rigorous results describing the asymptotic dynamics of a discrete time model of spiking neurons introduced in Soula et al. (Neural Comput. 18, 1, 2006). Using symbolic dynamic techniques we show how the dynamics of membrane potential has a one to one correspondence with sequences of spikes patterns ("raster plots"). Moreover, though the dynamics is generically periodic, it has a weak form of initial conditions sensitivity due to the presence of a sharp threshold in the model definition. As a consequence, the model exhibits a dynamical regime indistinguishable from chaos in numerical experiments.},
author = {Cessac, B},
doi = {10.1007/s00285-007-0117-3},
isbn = {0028500701173},
issn = {1432-1416},
journal = {Journal of mathematical biology},
keywords = {2000,37n25,92b20,Action Potentials,Action Potentials: physiology,Algorithms,Biological,Long-Term Potentiation,Long-Term Potentiation: physiology,Long-Term Synaptic Depression,Long-Term Synaptic Depression: physiology,Markov Chains,Membrane Potentials,Membrane Potentials: physiology,Models,Nerve Net,Nerve Net: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,dynamical systems,formalism,gibbs distributions,mathematics subject classification,neural networks,neurons dynamics,spike train statistics,symbolic coding,thermodynamic},
month = {mar},
number = {3},
pages = {311--45},
pmid = {17874106},
title = {{A discrete time neural network model with spiking neurons. Rigorous results on the spontaneous dynamics.}},
url = {http://arxiv.org/abs/1002.3275 http://www.ncbi.nlm.nih.gov/pubmed/17874106 http://www.springerlink.com/index/18LU31L3W8181760.pdf},
volume = {56},
year = {2008}
}
@article{Montero2011,
author = {Montero, Miquel},
doi = {10.1103/PhysRevE.84.051139},
issn = {1539-3755},
journal = {Physical Review E},
month = {nov},
number = {5},
pages = {1--7},
title = {{Parrondo-like behavior in continuous-time random walks with memory}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.84.051139},
volume = {84},
year = {2011}
}
@article{AG94,
author = {Ashe, J and Georgopoulos, A},
journal = {Cerebral Cortex},
pages = {590--600},
title = {{Movement parameters and neural activity in motor cortex and area 5}},
volume = {4},
year = {1994}
}
@article{Solla,
author = {Solla, S A and Winther, O},
journal = {Computer physics communications},
number = {March 1999},
pages = {1--6},
title = {{Optimal online learning: a Bayesian approach}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.4205{\&}rep=rep1{\&}type=pdf},
year = {1999}
}
@article{vincent1997slow,
annote = {2009num59},
author = {Vincent, E and Hammann, J and Ocio, M and Bouchaud, J P and Cugliandolo, L F},
journal = {LECTURE NOTES IN PHYSICS-NEW YORK THEN BERLIN-},
pages = {184--219},
publisher = {Springer},
title = {{Slow dynamics and aging in spin glasses}},
year = {1997}
}
@article{SH02,
author = {Sollich, P and Halees, A},
journal = {Neural Computation},
pages = {1393--1428},
title = {{Learning curves for {\{}G{\}}aussian process regression: Approximations and bounds}},
volume = {14},
year = {2002}
}
@article{Beckerman|2006|,
abstract = {Cooperative processes, or algorithms, are procedures that generate
large-scale, or global, effects through sequences of small-scale,
or local, operations. Such procedures underlie life as we know it.
They are encountered in a variety of physical and chemical systems,
and are found in biological systems at all levels of organization.
In a cooperative system, global computations are performed by many
units operating in parallel. Cooperativity emerges in these systems
through interactions among component units. Each unit generates a
new state from its previous one by combining information available
internally with signals received from neighboring units and from
outside. This article considers cooperativity and parallelism in
two classes of mathematical models of brain function developed by
researchers in the field over the past 10 to 15 years. The human
brain, containing approximately 1011 neurons and perhaps as many
as 1015 distinct synaptic connections, is the archetype of a highly
cooperative, massively parallel system. The first class of models
and accompanying solution methods were constructed to carry out tasks
in perceptual inferencing, such as the segmentation of a scene into
its component surfaces, figure{\^{A}}–ground segregation, and object recognition.
In these computer-based approaches we construct a Markov random field
(MRF) to capture correlations in a visual image and then use simulated
annealing, or one of its siblings, to generate sequences of small
changes. The solution methods are stochastic in character; the computations
are intrinsically parallel and are inspired by our thinking about
how the early stages of visual processing might occur in the brain.
The second class of mathematical models and methods has as its central
theme the notion of assembly coding. These models and methods were
developed to carry out the same tasks as those in the first class,
but we now construct families of coupled first-order ordinary differential
equations that describe circuits of interconnected neurons. We then
evolve these nonlinear dynamical systems through sequences of states
that converge to fixed points, limit cycles, or chaotic attractors.
The solution methods can be either deterministic or stochastic; the
computations are parallel and highly distributed, and they model
circuits found in the mammalian brain.},
annote = {This rather vague paper draws picture of mathematical visual information{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}processing pathway in brain as the author sees it.},
author = {Beckerman, M},
journal = {SIAM News},
keywords = {brain function,computational,image analysis,markov random field,mathematical models,neurobiology,perception},
number = {5},
title = {{Cooperativity and Parallelism in mathematical models of brain function}},
volume = {31}
}
@article{Luo|2007|,
author = {Luo, L},
journal = {Brain Research Reviews},
pages = {220--227},
title = {{Fly MARCM and mouse MADM: genetic methods of labeling and manipulating single neurons}},
volume = {55}
}
@article{Ulbricht2005,
abstract = {Voltage-gated sodium channels open (activate) when the membrane is depolarized and close on repolarization (deactivate) but also on continuing depolarization by a process termed inactivation, which leaves the channel refractory, i.e., unable to open again for a period of time. In the "classical" fast inactivation, this time is of the millisecond range, but it can last much longer (up to seconds) in a different slow type of inactivation. These two types of inactivation have different mechanisms located in different parts of the channel molecule: the fast inactivation at the cytoplasmic pore opening which can be closed by a hinged lid, the slow inactivation in other parts involving conformational changes of the pore. Fast inactivation is highly vulnerable and affected by many chemical agents, toxins, and proteolytic enzymes but also by the presence of beta-subunits of the channel molecule. Systematic studies of these modulating factors and of the effects of point mutations (experimental and in hereditary diseases) in the channel molecule have yielded a fairly consistent picture of the molecular background of fast inactivation, which for the slow inactivation is still lacking.},
annote = {2009num45},
author = {Ulbricht, Werner},
doi = {10.1152/physrev.00024.2004},
issn = {0031-9333},
journal = {Physiological Reviews},
keywords = {Anesthetics,Animals,Electrophysiology,Humans,Kinetics,Local,Local: pharmacology,Membrane Potentials,Muscle,Point Mutation,Protein Isoforms,Skeletal,Skeletal: physiology,Sodium Channel Blockers,Sodium Channels,Sodium Channels: chemistry,Sodium Channels: genetics,Sodium Channels: physiology},
number = {4},
pages = {1271--301},
pmid = {16183913},
title = {{Sodium channel inactivation: molecular determinants and modulation.}},
url = {http://physrev.physiology.org/content/85/4/1271.short http://www.ncbi.nlm.nih.gov/pubmed/16183913},
volume = {85},
year = {2005}
}
@article{jackson1957networks,
annote = {2010IIInum55},
author = {Jackson, J R},
journal = {Operations Research},
keywords = {Neuron Model,correlations,math,networks},
mendeley-tags = {Neuron Model,correlations,math,networks},
number = {4},
pages = {518--521},
publisher = {JSTOR},
title = {{Networks of waiting lines}},
url = {http://www.jstor.org/stable/167249},
volume = {5},
year = {1957}
}
@article{Sompolinsky2009,
author = {Sompolinsky, Haim and Gu, Robert},
doi = {10.1371/journal.pbio.1000141},
number = {7},
title = {{Time-Warp – Invariant Neuronal Processing}},
volume = {7},
year = {2009}
}
@article{Donoghue2012,
author = {O'Donoghue, B and Candes, E},
journal = {Foundations of Computational Mathematics},
pages = {1--17},
title = {{Adaptive restart for accelerated gradient schemes}},
url = {http://link.springer.com/article/10.1007/s10208-013-9150-3},
year = {2012}
}
@article{Uebachs2006a,
annote = {2009num8},
author = {Uebachs, M and Schaub, C and Perez-Reyes, E and Beck, H},
journal = {The journal of physiology},
number = {3},
pages = {519},
publisher = {Physiological Soc},
title = {{T-type Ca2+ channels encode prior neuronal activity as modulated recovery rates}},
url = {http://jp.physoc.org/content/571/3/519.full},
volume = {571},
year = {2006}
}
@article{RegehrTank94,
abstract = {The mossy fiber synapse between dentate granule cells and CA3 pyramidal

cells in the guinea pig hippocampus shows a robust short-term synaptic

enhancement. We have simultaneously measured presynaptic residual

free calcium ([Ca2+]i) and postsynaptic field potentials at this

synapse to examine the role of [Ca2+]i in this enhancement. Single

action potentials produced an increase in [Ca2+]i of 10-50 nM that

decayed to resting levels with a time constant of about 1 sec. Trains

of action potentials produced larger [Ca2+]i increases that returned

more slowly to resting levels. Following the onset of moderate frequency

stimulus trains (0.1-5 Hz), synaptic transmission and [Ca2+]i both

increased and eventually plateaued. During the steady-state phase

a linear relationship between [Ca2+]i and synaptic enhancement was

observed. During the initial buildup, however, [Ca2+]i rose more

rapidly than synaptic enhancement. Similarly, during the decay phase

immediately following termination of a stimulus train, [Ca2+]i returned

to prestimulus levels faster than synaptic enhancement. High concentrations

of the calcium buffer EGTA in the presynaptic terminal slowed the

buildup and decay of both [Ca2+]i and synaptic enhancement produced

by stimulus trains. Under these conditions, the time course of [Ca2+]i

and synaptic enhancement were well matched. This suggests that, despite

the differences in kinetic rates observed for normal buffering conditions,

increases in [Ca2+]i play a causal role in short-term enhancement.

An increase in [Ca2+]i of 10-30 nM produced a twofold enhancement.

We propose a simple kinetic model to explain these results. The model

assumes that synaptic enhancement is controlled by a Ca-dependent

first-order reaction. According to this scheme, a change in [Ca2+]i

alters neurotransmitter release, but the slow kinetics of the underlying

reaction introduces a temporal filter, producing a delay in the change

in synaptic enhancement.},
author = {Regehr, W G and Delaney, K R and Tank, D W},
journal = {J Neurosci},
keywords = {Animals; Calcium; Edetic Acid; Egtazic Acid; Elect},
month = {feb},
number = {2},
pages = {523--537},
pmid = {8301352},
title = {{The role of presynaptic calcium in short-term enhancement at the hippocampal mossy fiber synapse.}},
volume = {14},
year = {1994}
}
@article{Chang|1973|,
abstract = {Renormalizable coupled scalar and dirac field theories are quantized
in equal-x{\^{}}+ surfaces (called light fronts). Schwinger's action principle
is employed to deduce the correct canonical equal-x{\^{}}+ (anti-)commutation
relations. These theories are shown to be Lorentz-invariant. Generalized
Schwinger conditions for a quantum field theory to be Lorentz-invariant
are given and discussed in an appendix. Spectral sum rules are derived.
Leading singularities of Green's functions and products of field
operators near the light cone are studied and the implications to
current algebra sum rules are discussed. We also discuss some of
the delicate features of the light-front formulation.},
author = {Chang, S.-J. and Root, R G},
journal = {Physical Review D},
keywords = {dirac field,generalized parton distribution,infinite momentum frame,light front dynamics,perturbation theory,physics,quantization,quantum chromodynamics,renormalization,scalar field},
number = {4},
pages = {1133},
title = {{Quantum field theories in the infinite-momentum frame I. Quantization of scalar and dirac fields}},
volume = {7}
}
@book{HARV91,
author = {Harvey, A},
publisher = {Cambridge University Press},
title = {{Forecasting, Structural Time Series Models and the {\{}K{\}}alman Filter}},
year = {1991}
}
@article{Bento|2002|,
abstract = {Self-interacting dark matter has been suggested in order to overcome
the difficulties of the cold dark matter model on galactic scales.
We argue that a scalar gauge singlet coupled to the Higgs boson,
which could lead to an invisibly decaying Higgs boson, is an interesting
candidate for this self-interacting dark matter particle. We also
present estimates on the abundance of these particles today as well
as the consequences to non-Newtonian forces.},
annote = {The paper attempts to explain dark matter via non-newtonian gravity{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}caused by a Higgs boson.},
author = {Bento, M C and Bertolami, O and Rosenfeld, R and Teodoro, L},
journal = {Physical Review D},
keywords = {Higgs boson,astrophysics,dark matter,non-newtonian,physics},
pages = {41302},
title = {{Self-Interacting dark matter and the Higgs boson}},
volume = {62}
}
@article{Ling2016,
author = {Ling, Anqi and Huang, Yandong and Shuai, Jianwei and Lan, Yueheng},
doi = {10.1038/srep22662},
issn = {2045-2322},
journal = {Scientific Reports},
number = {February},
pages = {22662},
publisher = {Nature Publishing Group},
title = {{Channel based generating function approach to the stochastic Hodgkin-Huxley neuronal system}},
url = {http://www.nature.com/articles/srep22662},
volume = {6},
year = {2016}
}
@article{GBP08,
author = {Shental, Ori and Bickson, Danny and Siegel, Paul H and Wolf, Jack K and Dolev, Danny},
journal = {arXiv:0810.1119v1},
title = {{Gaussian Belief Propagation for Solving Systems of Linear Equations: Theory and Application}},
year = {2008}
}
@article{Arora2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1310.6343v1},
author = {Arora, Sanjeev and Bhaskara, A and Ge, R and Ma, T},
eprint = {arXiv:1310.6343v1},
journal = {arXiv preprint arXiv:1310.6343},
title = {{Provable bounds for learning some deep representations}},
url = {http://arxiv.org/abs/1310.6343},
year = {2013}
}
@article{AsifMoura05,
author = {Asif, A and Moura, J},
journal = {IEEE Transactions on Signal Processing},
pages = {630--642},
title = {{Block Matrices with L-Block Banded Inverse: Inversion Algorithms}},
volume = {53},
year = {2005}
}
@inproceedings{Huang2007,
address = {Sparks, NV},
author = {Huang, G and Sekar, D C and Naeemi, A and Shakeri, K and Meindl, J D},
booktitle = {2007 IEEE 57th Electronic Components and Technology Conference (ECTC 2007)},
doi = {10.1109/ECTC.2007.374017},
isbn = {1-4244-0984-5},
month = {may},
pages = {1659--1666},
publisher = {IEEE},
title = {{Compact Physical Models for Power Supply Noise and Chip/Package Co-Design of Gigascale Integration}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4250103},
year = {2007}
}
@article{Polsky2004,
author = {Polsky, A and Mel, BW W and Schiller, J},
journal = {Nature Neuroscience},
number = {6},
pages = {621--627},
publisher = {Nature Publishing Group},
title = {{Computational subunits in thin dendrites of pyramidal cells}},
url = {http://www.nature.com/neuro/journal/v7/n6/abs/nn1253.html http://www.nature.com/neuro/journal/vaop/ncurrent/full/nn1253.html},
volume = {7},
year = {2004}
}
@article{Nowicki2007,
author = {Nowicki, Krzysztof and Snijders, TAB},
journal = {Journal of the American Statistical Association},
keywords = {1,and other phenomena where,cluster analysis,colored graph,gibbs sampling,interactions between,introduction and preview,latent class model,mixture model,physical,relational structure models are,social network,used to describe social},
number = {455},
pages = {1077--1087},
title = {{Estimation and prediction for stochastic blockstructures}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214501753208735},
volume = {96},
year = {2001}
}
@misc{MICrONS,
title = {https://www.iarpa.gov/index.php/research-programs/microns}
}
@article{Stevens1998,
abstract = {Cortical neurons in the waking brain fire highly irregular, seemingly random, spike trains in response to constant sensory stimulation, whereas in vitro they fire regularly in response to constant current injection. To test whether, as has been suggested, this high in vivo variability could be due to the postsynaptic currents generated by independent synaptic inputs, we injected synthetic synaptic current into neocortical neurons in brain slices. We report that independent inputs cannot account for this high variability, but this variability can be explained by a simple alternative model of the synaptic drive in which inputs arrive synchronously. Our results suggest that synchrony may be important in the neural code by providing a means for encoding signals with high temporal fidelity over a population of neurons.},
author = {Stevens, C F and Zador, a M},
doi = {10.1038/659},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Electric Stimulation,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Models, Neurological,Neural Inhibition,Neural Inhibition: physiology,Neurons,Neurons: physiology,Patch-Clamp Techniques,Rats,Rats, Long-Evans,Synapses,Synapses: physiology,Time Factors},
month = {jul},
number = {3},
pages = {210--7},
pmid = {10195145},
title = {{Input synchrony and the irregular firing of cortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10195145},
volume = {1},
year = {1998}
}
@article{Hohn2001,
author = {Hohn, Nicolas and Burkitt, Anthony},
doi = {10.1103/PhysRevE.63.031902},
issn = {1063-651X},
journal = {Physical Review E},
month = {feb},
number = {3},
pages = {384--388},
title = {{Shot noise in the leaky integrate-and-fire neuron}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.63.031902},
volume = {63},
year = {2001}
}
@article{Freeman|2003|,
abstract = {Columnar structure in the cerebral cortex has been demonstrated in
numerous studies. However, in the visual system, it is not clear
from imaging, basic physiological and anatomical approaches how multiple
stimulus parameters are related within columns. We have analyzed
recordings from pairs of neurons in the striate cortex of the cat
using various spatial and temporal parameters.We find that most parameters
are clustered within inferred columns with the exception of spatial
phase. Diversity of phase could be useful for serial processing in
central visual pathways.},
author = {Freeman, R D},
journal = {Cerebral Cortex},
keywords = {cortex,cortical column,neurobiology},
pages = {70},
title = {{Cortical Columns: A Multi-parameter Examination}},
volume = {13}
}
@article{Damle|1997|,
abstract = {We present the theory of nonzero temperature (T) spin dynamics and
transport in one-dimensional Heisenberg antiferromagnets with an
energy gap Delta. For T {\textless} Delta, we develop a semiclassical picture
of thermally excited particles. Multiple inelastic collisions between
the particles are crucial, and are described by a two-particle S-matrix
which has a super-universal form at low momenta. This is established
by computations on the O(3) {\"{I}}ƒ-model, and strong and weak coupling
expansions (the latter using a Majorana fermion representation) for
the two-leg S = 1/2 Heisenberg antiferromagnetic ladder. As an aside,
we note that the strong-coupling calculation reveals a S = 1, two
particle bound state which leads to the presence of a second peak
in the T = 0 inelastic neutron scattering (INS) cross-section for
a range of values of momentum transfer. We obtain exact, or numerically
exact, universal expressions for the thermal broadening of the quasi-particle
peak in the INS cross-section, for the magnetization transport, and
for the field dependence of the NMR relaxation rate 1/T1 of the effective
semiclassical model: these are expected to be asymptotically exact
for the quantum antiferromagnets. The results for 1/T1 are compared
with the experimental findings of Takigawa et.al. and the agreement
is quite good. In the regime Delta {\textless} T {\textless} (a typical microscopic exchange)
we argue that a complementary description in terms of semiclassical
waves applies, and give some exact results for the thermodynamics
and dynamics.},
author = {Damle, K and Sachdev, S},
journal = {arXiv},
keywords = {heisenberg model,nonlinear sigma-model,phase transition,physics,quantum field theory,spin dynamics,transport},
pages = {9711014},
title = {{Spin dynamics and transport in gapped one-dimensional Heisenberg antiferromagnets at nonzero temperatures}},
volume = {cond-mat}
}
@article{NIC03,
author = {Nicolelis, M and Dimitrov, D and Carmena, J and Crist, R and Lehew, G and Kralik, J and Wise, S},
journal = {PNAS},
pages = {11041--11046},
title = {{Chronic, multisite, multielectrode recordings in macaque monkeys}},
volume = {100},
year = {2003}
}
@article{SpirouYoung91,
author = {Spirou, G A and Young, E D},
journal = {Journal of Neurophysiology},
month = {nov},
number = {5},
pages = {1750--1768},
title = {{Organization of dorsal cochlear nucleus type IV unit response maps and their relationship to activation by bandlimited noise}},
volume = {66},
year = {1991}
}
@article{Soudry2014a,
abstract = {Long term temporal correlations frequently appear at many levels of neural activity. We show that when such correlations appear in isolated neurons, they indicate the existence of slow underlying processes and lead to explicit conditions on the dynamics of these processes. Moreover, although these slow processes can potentially store information for long times, we demonstrate that this does not imply that the neuron possesses a long memory of its input, even if these processes are bidirectionally coupled with neuronal response. We derive these results for a broad class of biophysical neuron models, and then fit a specific model to recent experiments. The model reproduces the experimental results, exhibiting long term (days-long) correlations due to the interaction between slow variables and internal fluctuations. However, its memory of the input decays on a timescale of minutes. We suggest experiments to test these predictions directly.},
author = {Soudry, D. and Meir, Ron},
doi = {10.3389/fncom.2014.00029},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {Adaptation,Analytical methods,Conductance based neuron models,Ion channels,Linear response,Noise,Power spectral density,System identification,adaptation,analytical methods,conductance based neuron models,input,ion channe,ion channels,linear,linear filters,long memory,neurons,noise,output analysis,power,power spectral density,response,system identification,temporal correlations},
month = {apr},
number = {April},
pages = {1--23},
pmid = {24744724},
title = {{The neuronal response at extended timescales: a linearized spiking input-output relation}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3978321{\&}tool=pmcentrez{\&}rendertype=abstract http://journal.frontiersin.org/Journal/10.3389/fncom.2014.00035/abstract http://www.frontiersin.org/Computational{\_}Neuroscience/10.3389/fncom.2014.00029/ab},
volume = {8},
year = {2014}
}
@article{Brockwell07a,
author = {Brockwell, A E and Kass, R E and Schwartz, A B},
journal = {Proceedings of the IEEE},
pages = {1--18},
title = {{Statistical Signal Processing and the Motor Cortex}},
volume = {95},
year = {2007}
}
@article{Klaus2011,
abstract = {The size distribution of neuronal avalanches in cortical networks has been reported to follow a power law distribution with exponent close to -1.5, which is a reflection of long-range spatial correlations in spontaneous neuronal activity. However, identifying power law scaling in empirical data can be difficult and sometimes controversial. In the present study, we tested the power law hypothesis for neuronal avalanches by using more stringent statistical analyses. In particular, we performed the following steps: (i) analysis of finite-size scaling to identify scale-free dynamics in neuronal avalanches, (ii) model parameter estimation to determine the specific exponent of the power law, and (iii) comparison of the power law to alternative model distributions. Consistent with critical state dynamics, avalanche size distributions exhibited robust scaling behavior in which the maximum avalanche size was limited only by the spatial extent of sampling ("finite size" effect). This scale-free dynamics suggests the power law as a model for the distribution of avalanche sizes. Using both the Kolmogorov-Smirnov statistic and a maximum likelihood approach, we found the slope to be close to -1.5, which is in line with previous reports. Finally, the power law model for neuronal avalanches was compared to the exponential and to various heavy-tail distributions based on the Kolmogorov-Smirnov distance and by using a log-likelihood ratio test. Both the power law distribution without and with exponential cut-off provided significantly better fits to the cluster size distributions in neuronal avalanches than the exponential, the lognormal and the gamma distribution. In summary, our findings strongly support the power law scaling in neuronal avalanches, providing further evidence for critical state dynamics in superficial layers of cortex.},
annote = {Yet another attempted proof of avalanches in data. This time they seem to take more precautions, along the lines of the Clauset et al paper  ...

Ronny},
author = {Klaus, Andreas and Yu, Shan and Plenz, D},
doi = {10.1371/journal.pone.0019779},
issn = {1932-6203},
journal = {PloS one},
month = {jan},
number = {5},
pages = {e19779},
pmid = {21720544},
title = {{Statistical analyses support power law distributions found in neuronal avalanches.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3102672{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2011}
}
@article{Yajima1989,
abstract = {We consider a limiting distribution of the finite Fourier transforms of observations drawn from a strongly dependent stationary process. It is proved that the finite Fourier transforms at different frequencies are asymptotically independent and normally distributed. Our result can apply to a fractional autoregressive integrated moving-average process and a fractional Gaussian noise, two examples of strongly dependent stationary processes.},
author = {Yajima, Yoshihiro},
doi = {10.1111/j.1467-9892.1989.tb00036.x},
issn = {0143-9782},
journal = {Journal of Time Series Analysis},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {jul},
number = {4},
pages = {375--383},
title = {{A central limit theorem of Fourier transforms of strongly dependent stationary processes}},
url = {http://www3.interscience.wiley.com/journal/119845918/abstract},
volume = {10},
year = {1989}
}
@article{Gao2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1402.3811v1},
author = {Gao, Wei and Zhou, Zhi-hua},
eprint = {arXiv:1402.3811v1},
journal = {arXiv preprint arXiv:1402.3811},
keywords = {deep learning,generalization,neural network,overfitting,rademacher complexity},
title = {{Dropout Rademacher Complexity of Deep Neural Networks}},
url = {http://arxiv.org/abs/1402.3811},
year = {2014}
}
@book{BIL65,
address = {New York},
author = {Billingsley, P},
publisher = {Wiley},
title = {{Ergodic theory and information}},
year = {1965}
}
@article{RAB89,
annote = {

2010IIInum51},
author = {Rabiner, L R},
journal = {Proceedings of the IEEE},
keywords = {ion channel,math},
mendeley-tags = {ion channel,math},
number = {2},
pages = {257--286},
title = {{A tutorial on Hidden {\{}M{\}}arkov Models and selected applications in speech recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?isNumber=698{\&}prod=JNL{\&}arnumber=18626{\&}arSt=257{\&}ared=},
volume = {77},
year = {1989}
}
@article{HeinzCarney01b,
author = {Heinz, M G and Colburn, H S and Carney, L H},
journal = {Journal of The Acoustical Society Of America},
month = {oct},
number = {4},
pages = {2065--2084},
title = {{Rate and timing cues associated with the cochlear amplifier: level discrimination based on monaural cross-frequency coincidence detection}},
volume = {110},
year = {2001}
}
@misc{chparticledet,
annote = {This presentation goes over a variety of different particle detectors},
keywords = {astrophysics,atlas,bubble chambers,calorimeters,cryogenic,drift chambers,nuclear,opal,particle,particle detectors,physics,scintillators,silicon detectors},
title = {{Particle Detectors}}
}
@article{ozer2005effect,
annote = {2009num35{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Ozer, M. and Ekmekci, N.H. H},
journal = {Physics Letters A},
number = {2},
pages = {150--154},
publisher = {Elsevier},
title = {{Effect of channel noise on the time-course of recovery from inactivation of sodium channels}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S037596010500321X},
volume = {338},
year = {2005}
}
@article{Thorburn86,
author = {Thorburn, D},
journal = {Biometrika},
number = {1},
pages = {65--75},
title = {{A {\{}B{\}}ayesian approach to density estimation}},
volume = {73},
year = {1986}
}
@article{Taleyarkhan|2004|,
abstract = {Time spectra of neutron and sonoluminescence emissions were measured
in cavitation experiments with chilled deuterated acetone. Statistically
significant neutron and gamma ray emissions were measured with a
calibrated liquid-scintillation detector, and sonoluminescence emissions
were measured with a photomultiplier tube. The neutron and sonoluminescence
emissions were found to be time correlated over the time of significant
bubble cluster dynamics. The neutron emission energy was less than
2.5 MeV and the neutron emission rate was up to ;43105 n/s. Measurements
of tritium production were also performed and these data implied
a neutron emission rate due to D-D fusion which agreed with what
was measured. In contrast, control experiments using normal acetone
did not result in statistically significant tritium activity, or
neutron or gamma ray emissions.},
annote = {The paper details ongoing measurement for neurton flux from acoustic{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}cavitation in sonoluminescence claimed to indicate deuterium fusion{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}occuring in the buble.},
author = {Taleyarkhan, R P and Cho, J S and West, C D and Jr., R T Lahey and Nigmatulin, R I and Block, R C},
journal = {Physical review E},
keywords = {acoustic cavitation,fusion,physics,sonoluminescence},
pages = {36109},
title = {{Additional evidence of nuclear emissions during acoustic cavitation.}},
volume = {69}
}
@article{Petrusca07,
abstract = {The primate retina communicates visual information to the brain via a set of parallel pathways that originate from at least 22 anatomically distinct types of retinal ganglion cells. Knowledge of the physiological properties of these ganglion cell types is of critical importance for understanding the functioning of the primate visual system. Nonetheless, the physiological properties of only a handful of retinal ganglion cell types have been studied in detail. Here we show, using a newly developed multielectrode array system for the large-scale recording of neural activity, the existence of a physiologically distinct population of ganglion cells in the primate retina with distinctive visual response properties. These cells, which we will refer to as upsilon cells, are characterized by large receptive fields, rapid and transient responses to light, and significant nonlinearities in their spatial summation. Based on the measured properties of these cells, we speculate that they correspond to the smooth/large radiate cells recently identified morphologically in the primate retina and may therefore provide visual input to both the lateral geniculate nucleus and the superior colliculus. We further speculate that the upsilon cells may be the primate retina's counterparts of the Y-cells observed in the cat and other mammalian species.
},
author = {Petrusca, Dumitru and Grivich, Matthew I and Sher, Alexander and Field, Greg D and Gauthier, Jeffrey L and Greschner, Martin and Shlens, Jonathon and Chichilnisky, E J and Litke, Alan M},
doi = {10.1523/JNEUROSCI.2836-07.2007},
journal = {J. Neurosci.},
number = {41},
pages = {11019--11027},
title = {{Identification and Characterization of a {\{}Y{\}}-Like Primate Retinal Ganglion Cell Type}},
url = {http://www.jneurosci.org/cgi/content/abstract/27/41/11019},
volume = {27},
year = {2007}
}
@article{Coombes07,
author = {Coombes, S and Timofeeva, Y and Svensson, C -M. and Lord, G J and Josic, K and Cox, S J and Colbert, C M},
issn = {0340-1200},
journal = {Biological Cybernetics},
number = {2},
pages = {137--149},
title = {{Branching dendrites with resonant membrane: a sum-over-trips approach}},
volume = {97},
year = {2007}
}
@article{CB94,
author = {Clarke, B and Barron, A},
journal = {Journal of Statistical Planning Inference},
pages = {37--60},
title = {{Jeffreys' prior is asymptotically least favorable under entropy risk}},
volume = {41},
year = {1994}
}
@article{Wagenmakers2004,
abstract = {Recent analyses of serial correlations in cognitive tasks have provided preliminary evidence of the presence of a particular form of long-range serial dependence known as 1/f noise. It has been argued that long-range dependence has been largely ignored in mainstream cognitive psychology even though it accounts for a substantial proportion of variability in behavior (see, e.g., Gilden, 1997, 2001). In this article, we discuss the defining characteristics of long-range dependence and argue that claims about its presence need to be evaluated by testing against the alternative hypothesis of short-range dependence. For the data from three experiments, we accomplish such tests with autoregressive fractionally integrated moving-average time series modeling. We find that long-range serial dependence in these experiments can be explained by any of several mechanisms, including mixtures of a small number of short-range processes.},
author = {Wagenmakers, Eric-Jan and Farrell, Simon and Ratcliff, Roger},
issn = {1069-9384},
journal = {Psychonomic bulletin {\&} review},
keywords = {Auditory Perception,Cognition,Humans,Models, Statistical,Noise},
month = {aug},
number = {4},
pages = {579--615},
pmid = {15581115},
title = {{Estimation and interpretation of 1/falpha noise in human cognition.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1479451{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {11},
year = {2004}
}
@phdthesis{Risbo1994,
author = {Risbo, L},
school = {Technical Univ. Denmark},
title = {{Sigma Delta modulators - Stability and design optimization}},
year = {1994}
}
@article{ParkCasella08,
author = {Park, Trevor and Casella, George},
journal = {Journal of the American Statistical Association},
pages = {681--686},
title = {{The {\{}B{\}}ayesian {\{}L{\}}asso}},
volume = {103},
year = {2008}
}
@phdthesis{Fearnhead98,
author = {Fearnhead, P},
school = {University of Oxford},
title = {{Sequential Monte Carlo methods in filter theory}},
year = {1998}
}
@book{Wahba90,
author = {Wahba, G},
publisher = {SIAM},
title = {{Spline Models for Observational Data}},
year = {1990}
}
@article{Yamashita2008,
abstract = {It is generally thought that skilled behavior in human beings results from a functional hierarchy of the motor control system, within which reusable motor primitives are flexibly integrated into various sensori-motor sequence patterns. The underlying neural mechanisms governing the way in which continuous sensori-motor flows are segmented into primitives and the way in which series of primitives are integrated into various behavior sequences have, however, not yet been clarified. In earlier studies, this functional hierarchy has been realized through the use of explicit hierarchical structure, with local modules representing motor primitives in the lower level and a higher module representing sequences of primitives switched via additional mechanisms such as gate-selecting. When sequences contain similarities and overlap, however, a conflict arises in such earlier models between generalization and segmentation, induced by this separated modular structure. To address this issue, we propose a different type of neural network model. The current model neither makes use of separate local modules to represent primitives nor introduces explicit hierarchical structure. Rather than forcing architectural hierarchy onto the system, functional hierarchy emerges through a form of self-organization that is based on two distinct types of neurons, each with different time properties ("multiple timescales"). Through the introduction of multiple timescales, continuous sequences of behavior are segmented into reusable primitives, and the primitives, in turn, are flexibly integrated into novel sequences. In experiments, the proposed network model, coordinating the physical body of a humanoid robot through high-dimensional sensori-motor control, also successfully situated itself within a physical environment. Our results suggest that it is not only the spatial connections between neurons but also the timescales of neural activity that act as important mechanisms leading to functional hierarchy in neural systems.},
annote = {2011num32},
author = {Yamashita, Yuichi and Tani, Jun},
doi = {10.1371/journal.pcbi.1000220},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Generalization, Stimulus,Generalization, Stimulus: physiology,Higher Nervous Activity,Higher Nervous Activity: physiology,Humans,Models, Neurological,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Robotics,Robotics: methods,Synapses,Synapses: physiology,Systems Biology,Systems Biology: methods,Time Factors},
month = {nov},
number = {11},
pages = {e1000220},
pmid = {18989398},
title = {{Emergence of functional hierarchy in a multiple timescale neural network model: a humanoid robot experiment.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2570613{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2008}
}
@article{MurphyRieke06,
author = {Murphy, G and Rieke, F},
journal = {Neuron},
pages = {511--524},
title = {{Network variability limits stimulus-evoked spike timing precision in retinal ganglion cells}},
volume = {52},
year = {2006}
}
@article{Klein2010,
abstract = {In intact adult vertebrates, muscles can be activated with a high degree of specificity, so that even within a single traditionally defined muscle, groups of motor units can be differentially activated. Such differential activation might reflect detailed control by descending systems, potentially resulting from postnatal experience such that activation of motor units is precisely tailored to their mechanical actions. Here we examine the degree to which such specific activation can be seen in the rhythmic patterns produced by isolated spinal motor systems in neonates. We examined motor output produced by the in vitro neonatal rat spinal cord with hindlimb attached. We recorded the activity of different regions within the posterior portion of biceps femoris (BFp; i.e., excluding the anterior/vertebral head). We found that in the rhythms evoked by bath application of serotonin/N-methyl-d-aspartate (5-HT/NMDA), all regions of BFp were active during extension. However, the regions of BFp were activated in a specific sequence, with the activation of rostral regions consistently preceding those of more caudal regions in both afferented and deafferented preparations. In the rhythms evoked by cauda equina (CE) stimulation, rostral and middle regions of BFp remained active in extension, but the caudal region of BFp was usually active in flexion. Stimulation of L5 and S2 dorsal roots typically evoked rhythms with all regions of BFp active during extension; although the same rostral to caudal sequence of activation observed in 5-HT/NMDA evoked rhythms could also be observed in these rhythms, we also observed cases with reversed sequences, with activity proceeding from caudal to rostral. S2 dorsal root stimulation occasionally evoked rhythms with flexor activity in caudal BFp, similar to CE-evoked rhythms. Taken together, these results suggest a high degree of individuated control of muscles by spinal pattern generating networks, even at birth.},
author = {Klein, David a and Tresch, Matthew C},
doi = {10.1152/jn.00477.2010},
issn = {1522-1598},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Age Factors,Animals,Body Patterning,Body Patterning: physiology,Hindlimb,Hindlimb: innervation,Hindlimb: physiology,Muscle,Nerve Net,Nerve Net: physiology,Newborn,Periodicity,Rats,Skeletal,Skeletal: innervation,Skeletal: physiology,Spinal Cord,Spinal Cord: physiology},
month = {oct},
number = {4},
pages = {2158--2168},
pmid = {20660414},
title = {{Specificity of intramuscular activation during rhythms produced by spinal patterning systems in the in vitro neonatal rat with hindlimb attached preparation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2957453{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {104},
year = {2010}
}
@article{Murray1994,
author = {Murray, A F and Edwards, P J},
journal = {Neural Networks, IEEE Transactions on},
number = {5},
pages = {792--802},
publisher = {IEEE},
title = {{Enhanced MLP performance and fault tolerance resulting from synaptic weight noise during training}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=317730},
volume = {5},
year = {1994}
}
@book{Hastie2001,
author = {Hastie, T and Tibshirani, R and Friedman, J J H},
title = {{The elements of statistical learning}},
url = {http://www-stat.stanford.edu/{~}tibs/book/preface.ps},
year = {2001}
}
@article{Lina,
author = {Socher, R and Lin, CC C and Ng, A Y and Manning, C D},
journal = {Proceedings of the 26th {\ldots}},
pages = {7},
title = {{Parsing natural scenes and natural language with recursive neural networks}},
url = {http://www.socher.org/uploads/Main/SocherLinNgManning{\_}ICML2011.pdf http://fukushima.55-works.com/index/nlp.stanford.edu/pubs/SocherLinNgManning{\_}ICML2011.pdf},
volume = {2},
year = {2011}
}
@article{Kirschner1998,
author = {Kirschner, Marc and Gerhart, John},
journal = {Proceedings of the National {\ldots}},
number = {July},
pages = {8420--8427},
title = {{Evolvability}},
url = {http://www.pnas.org/content/95/15/8420.short},
volume = {95},
year = {1998}
}
@article{Dangerfield2012,
author = {Dangerfield, C E and Kay, D and Burrage, K},
journal = {Physical Review E},
keywords = {hodgkin-huxley model,ion channels,membrane noise,reflected stochastic differential equations},
title = {{Modeling ion channel dynamics through reflected stochastic differential equations}},
volume = {85},
year = {2012}
}
@article{Avrutin2000,
author = {Avrutin, V and Schanz, M},
doi = {10.1016/S0960-0779(99)00071-5},
issn = {09600779},
journal = {Chaos, Solitons {\&} Fractals},
month = {oct},
number = {13},
pages = {1949--1955},
title = {{On the scaling properties of the period-increment scenario in dynamical systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0960077999000715},
volume = {11},
year = {2000}
}
@article{Pradhan2008,
annote = {2011num12},
author = {Pradhan, P},
journal = {Physical Review E},
title = {{Nonequilibrium fluctuation theorems in the presence of local heating}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.77.041129},
year = {2008}
}
@article{McCammon|2002|,
abstract = {A high spectral resolution observation of the diffuse X-ray background
in the 60 - 1000 eV energy range has been made using an array of
thirty-six 1 mm2 microcalorimeters flown on a sounding rocket. Detector
energy resolution ranged from 5{\^{A}}–12 eV FWHM, and a composite spectrum
of {\~{}} 1 steradian of the background centered at l = 90{\^{A}}°, b = +60{\^{A}}°
was obtained with a net resolution of {\~{}} 9 eV. The target area includes
bright 1/4 keV regions, but avoids Loop I and the North Polar Spur.
Lines of C VI, O VII, and O VIII are clearly detected with intensities
of 5.4 {\^{A}}± 2.3, 4.8 {\^{A}}± 0.8, and 1.6 {\^{A}}± 0.4 photons cm{\^{A}}–2 s{\^{A}}–1 sr{\^{A}}–1,
respectively. The oxygen lines alone account for a majority of the
diffuse background observed in the ROSAT R4 band that is not due
to resolved extragalactic discrete sources. We also have a positive
detection of the Fe-M line complex near 70 eV at an intensity consistent
with previous upper limits that indicate substantial gas phase depletion
of iron. We include a detailed description of the instrument and
its detectors.},
annote = {This high-sensitivity experiment designed to look for X-ray soft{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}background from galaxy via calorimeter spectrometer, unintentionally{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}serves as the best up-to-date low-mass-range constraint on interacting{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}dark matter},
author = {McCammon, D and Almy, R and Apodaca, E and Tiest, W Bergmann and Cut, W and Deiker, S and Galeazzi, M and Juda, M and Lesser, A and Mihara, T and Morgenthaler, J P and Sanders, W T and Zhang, J and Figueroa-Feliciano, E and Kelley, R L and Moseley, S H and Mushotzky, R F and Porter, F S and Stahle, C K and Szymkowiak, A E},
journal = {arXiv},
keywords = {X-ray,astrophysics,dark matter,experiment,physics,spectrographs},
pages = {205012},
title = {{A High Spectral Resolution Observation of the Soft X-ray Diffuse Background with Thermal Detectors}},
volume = {astro-ph}
}
@article{Alibart2013,
abstract = {Memristors are memory resistors that promise the efficient implementation of synaptic weights in artificial neural networks. Whereas demonstrations of the synaptic operation of memristors already exist, the implementation of even simple networks is more challenging and has yet to be reported. Here we demonstrate pattern classification using a single-layer perceptron network implemented with a memrisitive crossbar circuit and trained using the perceptron learning rule by ex situ and in situ methods. In the first case, synaptic weights, which are realized as conductances of titanium dioxide memristors, are calculated on a precursor software-based network and then imported sequentially into the crossbar circuit. In the second case, training is implemented in situ, so the weights are adjusted in parallel. Both methods work satisfactorily despite significant variations in the switching behaviour of the memristors. These results give hope for the anticipated efficient implementation of artificial neuromorphic networks and pave the way for dense, high-performance information processing systems.},
author = {Alibart, Fabien and Zamanidoost, Elham and Strukov, Dmitri B},
doi = {10.1038/ncomms3072},
issn = {2041-1723},
journal = {Nature communications},
number = {May},
pages = {2072},
pmid = {23797631},
publisher = {Nature Publishing Group},
title = {{Pattern classification by memristive crossbar circuits using ex situ and in situ training.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23797631},
volume = {4},
year = {2013}
}
@article{Berry2004,
author = {Segev, R and Goodhouse, J and Puchalla, J and Berry, M},
journal = {Nature Neuroscience},
pages = {1154--1161},
title = {{Recording spikes from a large fraction of the ganglion cells in a retinal patch}},
volume = {7},
year = {2004}
}
@article{Minsky1991,
author = {Minsky, ML},
journal = {AI magazine},
number = {2},
title = {{Logical versus analogical or symbolic versus connectionist or neat versus scruffy}},
url = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/894},
volume = {12},
year = {1991}
}
@article{Eden04,
author = {Eden, Uri T and Frank, Loren M and Barbieri, Riccardo and Solo, Victor and Brown, Emery N},
journal = {Neural Computation},
pages = {971--998},
title = {{Dynamic analyses of neural encoding by point process adaptive filtering}},
volume = {16},
year = {2004}
}
@article{Welch1974,
abstract = {Some communication systems require sets of signals with impulse-like autocorrelation functions and small cross correlation. There is considerable literature on signals with impulse-like autocorrelation functions hut little on sets of signals with small cross correlation. A possible reason is that designers put too severe a restriction on cross correlation magnitudes. This correspondence establishes lower bounds on how small the cross correlation and autocorrelation can simultaneously be.},
author = {Welch, L.},
doi = {10.1109/TIT.1974.1055219},
isbn = {0018-9448},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {may},
number = {3},
pages = {397--399},
title = {{Lower bounds on the maximum cross correlation of signals}},
url = {http://ieeexplore.ieee.org/document/1055219/},
volume = {20},
year = {1974}
}
@article{Neal01,
author = {Neal, R M},
journal = {Statistics and Computing},
pages = {125--139},
title = {{Annealed importance sampling}},
volume = {11},
year = {2001}
}
@article{KrTr81,
author = {Krichevsky, R and Trofimov, V},
journal = {IEEE Transactions on Information Theory},
pages = {199--207},
title = {{The performance of universal encoding}},
volume = {27},
year = {1981}
}
@article{Roma1994,
author = {Amit, DJ and Fusi, Stefan},
journal = {Neural Computation},
pages = {957--982},
title = {{Learning in neural networks with material synapses}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1994.6.5.957},
volume = {982},
year = {1994}
}
@article{BriggsCallaway01,
author = {Briggs, F and Callaway, E M},
journal = {J Neurosci},
number = {10},
pages = {3600--8.},
title = {{Layer-specific input to distinct cell types in layer 6 of monkey primary visual cortex}},
volume = {21},
year = {2001}
}
@article{Tetzlaff2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1204.4393v2},
author = {Tetzlaff, Tom and Helias, Moritz},
eprint = {arXiv:1204.4393v2},
journal = {PLoS Computational {\ldots}},
title = {{Decorrelation of neural-network activity by inhibitory feedback}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002596},
year = {2012}
}
@article{Jordan,
author = {Jordan, DW and Smith, P},
title = {{Nonlinear ordinary differential equations}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Nonlinear+Ordinary+Differential+Equations{\#}0},
year = {1987}
}
@article{YuYoung00,
author = {Yu, J J and Young, E D},
journal = {Proceedings of The National Academy Of Sciences Of The United States Of America},
month = {oct},
number = {22},
pages = {11780--11786},
title = {{Linear and nonlinear pathways of spectral information transmission in the cochlear nucleus}},
volume = {97},
year = {2000}
}
@article{UM01,
author = {Usher, M and McClelland, J},
journal = {Psychological Review},
pages = {550--592},
title = {{On the Time Course of Perceptual choice: The leaky competing accumulator model}},
volume = {108},
year = {2001}
}
@book{KitagawaGersch96,
author = {Kitagawa, G and Gersch, W},
publisher = {Springer},
series = {Lecture notes in statistics},
title = {{Smoothness priors analysis of time series}},
volume = {116},
year = {1996}
}
@article{For,
author = {For, T},
title = {{Fraction phase lead after drug Fraction sAHP after drug T = 4 sec}}
}
@article{hanwell2002trafficking,
abstract = {The apically located epithelial Na(+) channel (alphabetagamma-ENaC) plays a key role in the regulation of salt and fluid transport in the kidney and other epithelia, yet its mode of trafficking to the plasma membrane and its cell surface stability in mammalian cells are poorly understood. Because the expression of ENaC in native tissues/cells is very low, we generated epithelial Madin-Darby canine kidney (MDCK) cells stably expressing alphabetagamma-ENaC, where each subunit is tagged differentially at the intracellular C terminus and the beta-subunit is also Myc-tagged at the ectodomain (alpha(HA)beta(Myc,T7)gamma(FLAG)). ENaC expression in these cells was verified by immunoblotting with antibodies to the tags, and patch clamp analysis has confirmed that the tagged channel is functional. Moreover, using electron microscopy, we demonstrated apical, but not basal, membrane localization of ENaC in these cells. The glycosylation pattern of the intracellular pool of ENaC revealed peptide N-glycosidase F and endoglycosidase H sensitivity. Surprisingly, the cell surface pool of ENaC, analyzed by surface biotinylation, was also core glycosylated and lacked detectable endoglycosidase H-resistant channels. Extraction of the channel from cells in Triton X-100 demonstrated that both intracellular and cell surface pools of ENaC are largely soluble. Moreover, floatation assays to analyze the presence of ENaC in lipid rafts showed that both intracellular and cell surface pools of this channel are not associated with rafts. We have shown previously that the total cellular pool of ENaC is turned over rapidly (t(1/2) approximately 1-2 h). Using cycloheximide treatment and surface biotinylation we now demonstrate that the cell surface pool of ENaC has a similarly short half-life (t(1/2) approximately 1 h), unlike the long half-life reported recently for the Xenopus A6 cells. Collectively, these results help elucidate key aspects of ENaC trafficking and turnover rates in mammalian kidney epithelial cells.},
author = {Hanwell, D and Ishikawa, T and Saleki, R and Rotin, D},
doi = {10.1074/jbc.M110904200},
issn = {0021-9258},
journal = {Journal of Biological Chemistry},
keywords = {Animals,Biotinylation,Cell Line,Cell Membrane,Cell Membrane: metabolism,Detergents,Detergents: pharmacology,Dogs,Dose-Response Relationship,Drug,Electron,Electrophysiology,Epithelial Cells,Epithelial Sodium Channel,Epitopes,Glycoside Hydrolases,Glycoside Hydrolases: metabolism,Glycosylation,Immunoblotting,Immunoelectron,Lipids,Lipids: chemistry,Membrane Microdomains,Membrane Microdomains: metabolism,Microscopy,Octoxynol,Octoxynol: pharmacology,Patch-Clamp Techniques,Protein Structure,Rats,Sodium Channels,Sodium Channels: metabolism,Tertiary,Time Factors,Xenopus},
month = {mar},
number = {12},
pages = {9772--9779},
pmid = {11773057},
publisher = {ASBMB},
title = {{Trafficking and cell surface stability of the epithelial Na+ channel expressed in epithelial Madin-Darby canine kidney cells}},
url = {http://www.jbc.org/cgi/content/abstract/277/12/9772 http://www.jbc.org/content/277/12/9772.short},
volume = {277},
year = {2002}
}
@article{Staring2003,
author = {St{\"{a}}ring, J. and Mehlig, B. and Fyodorov, Yan and Luck, J.},
doi = {10.1103/PhysRevE.67.047101},
issn = {1063-651X},
journal = {Physical Review E},
month = {apr},
number = {4},
pages = {1--4},
title = {{Random symmetric matrices with a constraint: The spectral density of random impedance networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.67.047101},
volume = {67},
year = {2003}
}
@inproceedings{Mohler2014,
author = {Mohler, G},
booktitle = {Neural Information Processing Systems},
pages = {1--9},
title = {{Learning convolution filters for inverse covariance estimation of neural network connectivity}},
year = {2014}
}
@article{SamejimaKimura04,
author = {Samejima, K and Doya, K and Ueda, Y and Kimura, M},
journal = {Advances in Neural Information Processing Systems},
title = {{Estimating internal variables and parameters of a learning agent by a particle filter}},
volume = {16},
year = {2004}
}
@article{Levitan2006,
abstract = {The pore-forming subunits of many ion channels exist in the membrane as one component of a regulatory protein complex, which may also contain one or more signaling proteins that contribute to the modulation of channel properties. Here I review this field, with emphasis on several different kinds of neuronal potassium channels for which the evidence for ion channel signaling complexes is most compelling. A key challenge for the future is to determine the roles of such signaling protein complexes in neuronal physiology and behavior.},
author = {Levitan, I B},
doi = {10.1038/nn1647},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Animals,Calcium Signaling,Calcium Signaling: physiology,Humans,Ion Channels,Ion Channels: metabolism,Macromolecular Substances,Membrane Proteins,Membrane Proteins: metabolism,Nervous System,Nervous System: metabolism,Neurons,Neurons: metabolism,Potassium Channels,Potassium Channels: metabolism,Protein Kinases,Protein Kinases: metabolism,Signal Transduction,Signal Transduction: physiology},
month = {mar},
number = {3},
pages = {305--10},
pmid = {16498425},
title = {{Signaling protein complexes associated with neuronal ion channels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16498425},
volume = {9},
year = {2006}
}
@article{Breiman2001,
author = {Breiman, L},
journal = {Machine learning},
keywords = {classification,ensemble,regression},
pages = {5--32},
title = {{Random forests}},
url = {http://link.springer.com/article/10.1023/A:1010933404324},
year = {2001}
}
@article{Ulgen1994,
author = {Ulgen, F and Akamatsu, Norio},
isbn = {078031865X},
journal = {Speech, Image Processing and Neural {\ldots}},
number = {April},
pages = {13--16},
title = {{Ternary synaptic weights algorithm: neural network training with don't care attributes}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=344783},
year = {1994}
}
@article{Tiburzi|2002|,
abstract = {We apply the light-front reduction of the Bethe-Salpeter equation
to matrix elements of the electromagnetic current between bound states.
Using a simple (1+1)-dimensional model to calculate form factors,
we focus on two cases. In one case, the interaction is dominated
by a term instantaneous in light-cone time. Here effects of higher
Fock states are negligible and the form factor can be effectively
expressed using non-wave function vertices and crossed interactions.
If the interaction is not instantaneous, non-wave function vertices
are replaced by contributions from higher Fock states. These higher
Fock components arise from the covariant formalism via the energy
poles of the Bethe-Salpeter vertex and the electromagnetic vertex.
The replacement of non-wave function vertices in time-ordered perturbation
theory is a theorem which directly extends to generalized parton
distributions, e.g., in (3 + 1) dimensions.},
annote = {This paper introduces effective treatment of non-wave function vertices{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}in nonvalence LF processes (such as nonvalence GPD part) via reduction{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of the former to LF wave-function and a Bethe-Salpeter kernel},
author = {Tiburzi, B C and Miller, G A},
journal = {arXiv},
keywords = {bethe-salpeter formalism,current,effective,generalized parton distribution,non-wave function vertex,perturbation theory,physics,quantum chromodynamics},
pages = {210304},
title = {{Current in the light-fron Bethe-Salpeter formalism I: Replacement of non-wave function vertices}},
volume = {hep-ph}
}
@article{Cook2013,
abstract = {Background: Seizure prediction would be clinically useful in patients with epilepsy and could improve safety, increase independence, and allow acute treatment. We did a multicentre clinical feasibility study to assess the safety and efficacy of a long-term implanted seizure advisory system designed to predict seizure likelihood and quantify seizures in adults with drug-resistant focal seizures. Methods: We enrolled patients at three centres in Melbourne, Australia, between March 24, 2010, and June 21, 2011. Eligible patients had between two and 12 disabling partial-onset seizures per month, a lateralised epileptogenic zone, and no history of psychogenic seizures. After devices were surgically implanted, patients entered a data collection phase, during which an algorithm for identification of periods of high, moderate, and low seizure likelihood was established. If the algorithm met performance criteria (ie, sensitivity of high-likelihood warnings greater than 65{\%} and performance better than expected through chance prediction of randomly occurring events), patients then entered an advisory phase and received information about seizure likelihood. The primary endpoint was the number of device-related adverse events at 4 months after implantation. Our secondary endpoints were algorithm performance at the end of the data collection phase, clinical effectiveness (measures of anxiety, depression, seizure severity, and quality of life) 4 months after iniation of the advisory phase, and longer-term adverse events. This trial is registered with ClinicalTrials.gov, number NCT01043406. Findings: We implanted 15 patients with the advisory system. 11 device-related adverse events were noted within four months of implantation, two of which were serious (device migration, seroma); an additional two serious adverse events occurred during the first year after implantation (device-related infection, device site reaction), but were resolved without further complication. The device met enabling criteria in 11 patients upon completion of the data collection phase, with high likelihood performance estimate sensitivities ranging from 65{\%} to 100{\%}. Three patients' algorithms did not meet performance criteria and one patient required device removal because of an adverse event before sufficient training data were acquired. We detected no significant changes in clinical effectiveness measures between baseline and 4 months after implantation. Interpretation: This study showed that intracranial electroencephalographic monitoring is feasible in ambulatory patients with drug-resistant epilepsy. If these findings are replicated in larger, longer studies, accurate definition of preictal electrical activity might improve understanding of seizure generation and eventually lead to new management strategies. Funding: NeuroVista. ?? 2013 Elsevier Ltd.},
author = {Cook, Mark J and O'Brien, Terence J and Berkovic, Samuel F and Murphy, Michael and Morokoff, Andrew and Fabinyi, Gavin and D'Souza, Wendyl and Yerra, Raju and Archer, John and Litewka, Lucas and Hosking, Sean and Lightfoot, Paul and Ruedebusch, Vanessa and Sheffield, W Douglas and Snyder, David and Leyde, Kent and Himes, David},
doi = {10.1016/S1474-4422(13)70075-9},
isbn = {1474-4465 (Electronic)$\backslash$n1474-4422 (Linking)},
issn = {14744422},
journal = {The Lancet Neurology},
number = {6},
pages = {563--571},
pmid = {23642342},
title = {{Prediction of seizure likelihood with a long-term, implanted seizure advisory system in patients with drug-resistant epilepsy: A first-in-man study}},
volume = {12},
year = {2013}
}
@article{DON02,
author = {Donoghue, J},
journal = {Nature Neuroscience},
pages = {1085--1088},
title = {{Connecting cortex to machines: recent advances in brain interfaces}},
volume = {5},
year = {2002}
}
@article{Elliott2010,
abstract = {A stochastic model of spike-timing-dependent plasticity (STDP) postulates that single synapses presented with a single spike pair exhibit all-or-none quantal jumps in synaptic strength. The amplitudes of the jumps are independent of spiking timing, but their probabilities do depend on spiking timing. By making the amplitudes of both upward and downward transitions equal, synapses then occupy only a discrete set of states of synaptic strength. We explore the impact of a finite, discrete set of strength states on our model, finding three principal results. First, a finite set of strength states limits the capacity of a single synapse to express the standard, exponential STDP curve. We derive the expression for the expected change in synaptic strength in response to a standard, experimental spike pair protocol, finding a deviation from exponential behavior. We fit our prediction to recent data from single dendritic spine heads, finding results that are somewhat better than exponential fits. Second, we show that the fixed-point dynamics of our model regulate the upward and downward transition probabilities so that these are on average equal, leading to a uniform distribution of synaptic strength states. However, third, under long-term potentiation (LTP) and long-term depression (LTD) protocols, these probabilities are unequal, skewing the distribution away from uniformity. If the number of states of strength is at least of order 10, then we find that three effective states of synaptic strength appear, consistent with some experimental data on ternary-strength synapses. On this view, LTP and LTD protocols may therefore be saturating protocols.},
annote = {

2010IInum12.26},
author = {Elliott, Terry},
doi = {10.1162/neco.2009.07-08-814},
issn = {1530-888X},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Brain,Brain: physiology,Computer Simulation,Dendritic Spines,Dendritic Spines: physiology,Long-Term Potentiation,Long-Term Potentiation: physiology,Long-Term Synaptic Depression,Long-Term Synaptic Depression: physiology,Mathematical Concepts,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Stochastic Processes,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
month = {jan},
number = {1},
pages = {1180--1230},
pmid = {19764870},
title = {{Discrete states of synaptic strength in a stochastic model of spike-timing-dependent plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19764870},
volume = {22},
year = {2010}
}
@article{Bourne|2007|,
abstract = {The hippocampal slice is a popular model system in which to study
the cellular properties of long-term potentiation (LTP). Synaptogenesis
induced by exposure to ice-cold artificial cerebrospinal fluid (ACSF),
however, raises the concern that morphological correlates of LTP
might be obscured, especially in mature slices. Here we demonstrate
that preparation of mature hippocampal slices at room temperature
(approximately 25 degrees C) maintains excellent ultrastructure and
a synapse density comparable to perfusion-fixed hippocampus. These
results suggest that slices prepared at room temperature might provide
a better basis from which to detect LTP-related changes in synapse
number and morphology.},
annote = {1T32NS045543/NS/United States NINDS K01MH02000/MH/United States NIMH
NS21184/NS/United States NINDS In Vitro Journal Article Research
Support, N.I.H., Extramural England},
author = {Bourne, J N and Kirov, S A and Sorra, K E and Harris, K M},
journal = {Neuropharmacology},
keywords = {Analysis of Variance Animals Dendritic Spines/radi,Electron,Three-Dimensional/methods Long-Term Potentiation/,Transmission/methods Organ Culture Techniques Rat},
number = {1},
pages = {55--59},
title = {{Warmer preparation of hippocampal slices prevents synapse proliferation that might obscure LTP-related structural plasticity.}},
volume = {52}
}
@article{Vogelstein2010a,
abstract = {Fluorescent calcium indicators are becoming increasingly popular as a means for observing the spiking activity of large neuronal populations. Unfortunately, extracting the spike train of each neuron from a raw fluorescence movie is a nontrivial problem. This work presents a fast nonnegative deconvolution filter to infer the approximately most likely spike train of each neuron, given the fluorescence observations. This algorithm outperforms optimal linear deconvolution (Wiener filtering) on both simulated and biological data. The performance gains come from restricting the inferred spike trains to be positive (using an interior-point method), unlike the Wiener filter. The algorithm runs in linear time, and is fast enough that even when simultaneously imaging {\textgreater}100 neurons, inference can be performed on the set of all observed traces faster than real time. Performing optimal spatial filtering on the images further refines the inferred spike train estimates. Importantly, all the parameters required to perform the inference can be estimated using only the fluorescence data, obviating the need to perform joint electrophysiological and imaging calibration experiments.},
author = {Vogelstein, JT Joshua T and Packer, AM Adam M and Machado, Timothy A and Sippy, Tanya and Babadi, Baktash and Yuste, R and Paninski, L},
doi = {10.1152/jn.01073.2009},
issn = {1522-1598},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Algorithms,Calcium Signaling,Computer Simulation,Computer-Assisted,Fluorescence,Fluorescent Dyes,Fluorescent Dyes: analysis,Microscopy,Models,Neurological,Neurons,Neurons: physiology,Normal Distribution,Poisson Distribution,Signal Processing,Time Factors,Video},
month = {dec},
number = {6},
pages = {3691--704},
pmid = {20554834},
title = {{Fast nonnegative deconvolution for spike train inference from population calcium imaging.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3007657{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pubmed/20554834 http://jn.physiology.org/content/104/6/3691.short},
volume = {104},
year = {2010}
}
@article{Posfai2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1203.5161v2},
author = {P{\'{o}}sfai, M and Liu, YY and Slotine, JJ and Barab{\'{a}}si, AL},
eprint = {arXiv:1203.5161v2},
journal = {arXiv preprint arXiv:1203.5161},
keywords = {Complex Networks},
mendeley-tags = {Complex Networks},
pages = {1--21},
title = {{Effect of correlations on network controllability}},
url = {http://arxiv.org/abs/1203.5161},
year = {2012}
}
@article{NBR04,
author = {Nemenman, Ilya and Bialek, William and {de Ruyter van Steveninck}, Rob},
journal = {Physical Review E},
pages = {56111},
title = {{Entropy and information in neural spike trains: Progress on the sampling problem}},
volume = {69},
year = {2004}
}
@article{Bassler2006,
author = {Bassler, K and Gunaratne, G and Mccauley, J},
doi = {10.1016/j.physa.2006.01.081},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {autocorrelations,fractional brownian motion,hurst exponent,markov process,scaling,stochastic calculus,tsallis model},
month = {sep},
number = {2},
pages = {343--353},
title = {{Markov processes, Hurst exponents, and nonlinear diffusion equations: With application to finance}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S037843710600149X},
volume = {369},
year = {2006}
}
@article{LorentedeNo22,
author = {de No, R},
journal = {Trab Lab Invest Bio},
pages = {41--78},
title = {{La corteza cerebral del raton}},
volume = {20},
year = {1922}
}
@article{Amit1992,
author = {Amit, DJ and Fusi, S},
journal = {Network: Computation in Neural Systems},
title = {{Constraints on learning in dynamic synapses}},
url = {http://informahealthcare.com/doi/abs/10.1088/0954-898X{\_}3{\_}4{\_}008},
year = {1992}
}
@article{Kasischke2004,
abstract = {We have found that two-photon fluorescence imaging of nicotinamide adenine dinucleotide (NADH) provides the sensitivity and spatial three-dimensional resolution to resolve metabolic signatures in processes of astrocytes and neurons deep in highly scattering brain tissue slices. This functional imaging reveals spatiotemporal partitioning of glycolytic and oxidative metabolism between astrocytes and neurons during focal neural activity that establishes a unifying hypothesis for neurometabolic coupling in which early oxidative metabolism in neurons is eventually sustained by late activation of the astrocyte-neuron lactate shuttle. Our model integrates existing views of brain energy metabolism and is in accord with known macroscopic physiological changes in vivo.},
author = {Kasischke, K A and Vishwasrao, HD D and Fisher, P J and Zipfel, W R and Webb, W W},
doi = {10.1126/science.1096485},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Animals,Astrocytes,Astrocytes: metabolism,Citric Acid Cycle,Cytoplasm,Dendrites,Dendrites: metabolism,Electron Transport,Fluorescence,Glycolysis,Hippocampus,Hippocampus: cytology,Hippocampus: metabolism,Lactic Acid,Lactic Acid: metabolism,Mitochondria,Mitochondria: metabolism,NAD,NAD: metabolism,Neurons,Neurons: metabolism,Oxidation-Reduction,Oxygen Consumption,Pyramidal Cells,Pyramidal Cells: metabolism,Rats,Spectrometry,Sprague-Dawley},
month = {jul},
number = {5680},
pages = {99--103},
pmid = {15232110},
title = {{Neural activity triggers neuronal oxidative metabolism followed by astrocytic glycolysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15232110},
volume = {305},
year = {2004}
}
@article{ColemanSarma07,
author = {Coleman, T and Sarma, S},
journal = {IEEE Conference on Decision and Control},
title = {{A Computationally Efficient Method for Modeling Neural Spiking Activity with Point Processes Nonparametrically}},
year = {2007}
}
@article{Angelino2007,
abstract = {We study how functional constraints bound and shape evolution through an analysis of mammalian voltage-gated sodium channels. The primary function of sodium channels is to allow the propagation of action potentials. Since Hodgkin and Huxley, mathematical models have suggested that sodium channel properties need to be tightly constrained for an action potential to propagate. There are nine mammalian genes encoding voltage-gated sodium channels, many of which are more than approximately 90{\%} identical by sequence. This sequence similarity presumably corresponds to similarity of function, consistent with the idea that these properties must be tightly constrained. However, the multiplicity of genes encoding sodium channels raises the question: why are there so many? We demonstrate that the simplest theoretical constraints bounding sodium channel diversity--the requirements of membrane excitability and the uniqueness of the resting potential--act directly on constraining sodium channel properties. We compare the predicted constraints with functional data on mammalian sodium channel properties collected from the literature, including 172 different sets of measurements from 40 publications, wild-type and mutant, under a variety of conditions. The data from all channel types, including mutants, obeys the excitability constraint; on the other hand, channels expressed in muscle tend to obey the constraint of a unique resting potential, while channels expressed in neuronal tissue do not. The excitability properties alone distinguish the nine sodium channels into four different groups that are consistent with phylogenetic analysis. Our calculations suggest interpretations for the functional differences between these groups.},
annote = {2010IIInum32},
author = {Angelino, Elaine and Brenner, Michael P},
doi = {10.1371/journal.pcbi.0030177},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Animals,Evolution,Humans,Ion Channel Gating,Ion Channel Gating: genetics,Membrane Potentials,Membrane Potentials: genetics,Molecular,Sodium Channels,Sodium Channels: physiology},
month = {sep},
number = {9},
pages = {1751--60},
pmid = {17892320},
title = {{Excitability constraints on voltage-gated sodium channels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17892320},
volume = {3},
year = {2007}
}
@article{Pfau2013,
author = {Pfau, David and Pnevmatikakis, E A and Paninski, L},
journal = {NIPS},
title = {{Robust learning of low dimensional dynamics from large neural ensembles}},
url = {http://www.stat.columbia.edu/{~}liam/research/abstracts/cosyne-13/pfau-abs.pdf},
year = {2013}
}
@article{Shalev-ShwartzSHAIS2010,
abstract = {The problem of characterizing learnability is the most basic question of statistical learning theory. A fun-damental and long-standing answer, at least for the case of supervised classification and regression, is that learnability is equivalent to uniform convergence of the empirical risk to the population risk, and that if a problem is learnable, it is learnable via empirical risk minimization. In this paper, we consider the General Learning Setting (introduced by Vapnik), which includes most statistical learning problems as special cases. We show that in this setting, there are non-trivial learning problems where uniform convergence does not hold, empirical risk minimization fails, and yet they are learnable using alternative mechanisms. Instead of uniform convergence, we identify stability as the key necessary and sufficient condition for learnability. More-over, we show that the conditions for learnability in the general setting are significantly more complex than in supervised classification and regression.},
author = {{Shalev-Shwartz SHAIS}, Shai and Shamir, Ohad and Srebro, Nathan and {Sridharan KARTHIK}, Karthik},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {learnability,stability,statistical learning theory,stochastic convex opti-mization,uniform convergence},
pages = {2635--2670},
title = {{Learnability, Stability and Uniform Convergence}},
volume = {11},
year = {2010}
}
@article{Fang1998,
author = {Fang, S C and Venkatesh, S S},
doi = {10.1002/(SICI)1098-2418(199801)12:1<83::AID-RSA5>3.3.CO;2-#},
issn = {10429832},
journal = {Random Structures and Algorithms},
keywords = {1,a,a problem in mathematical,binary integer programming,capacity,majority rule,n-dimensional cube,neuron,perceptron,programming,random polytopes,random polytopes in the,threshold function},
month = {jan},
number = {1},
pages = {83--109},
title = {{The capacity of majority rule}},
url = {http://doi.wiley.com/10.1002/(SICI)1098-2418(199801)12:1{\%}3C83::AID-RSA5{\%}3E3.3.CO;2-{\#}},
volume = {12},
year = {1998}
}
@article{HabetsBorst06,
abstract = {We studied the contribution of a change in presynaptic calcium influx

to posttetanic potentiation (PTP) in the calyx of Held synapse, an

axosomatic synapse in the auditory brain stem. We made whole cell

patch-clamp recordings of a principal cell after loading of the presynaptic

terminal with a calcium dye. After induction of PTP by a high-frequency

train of afferent stimuli, the Fluo-4 fluorescence transients evoked

by an action potential became on average 15 +/- 4{\%} larger (n = 7).

Model predictions did not match the fluorescence transients evoked

by trains of brief calcium currents unless the endogenous calcium

buffer had low affinity for calcium, making a contribution of saturation

of the endogenous buffer to the synaptic potentiation we observed

in the present experiments less likely. Our data therefore suggest

that the increase of release probability during PTP at the calyx

of Held synapse is largely explained by an increase in the calcium

influx per action potential.},
author = {Habets, Ron L P and Borst, J Gerard G},
doi = {10.1152/jn.00427.2006},
journal = {J Neurophysiol},
keywords = {Aniline Compounds; Animals; Calcium; Calcium Signa,Neurological; Neuronal Plasticity; Patch-Clamp Te,Statistical; Diagnostic Imaging; Electric Stimula},
month = {dec},
number = {6},
pages = {2868--2876},
pmid = {16899643},
title = {{An increase in calcium influx contributes to post-tetanic potentiation at the rat calyx of Held synapse.}},
url = {http://dx.doi.org/10.1152/jn.00427.2006},
volume = {96},
year = {2006}
}
@article{Snellings|2003|,
abstract = {Lattice QCD predicts a phase transition between hadronic matter and
a system of deconfined quarks and gluons (the Quark Gluon Plasma)
at high energy densities. Recent results from the Brookhaven Relativistic
Heavy Ion Collider (RHIC) dedicated to the study of QCD at extreme
densities will be discussed and compared to measurements obtained
at the CERN Super Proton Synchrotron (SPS).},
annote = {The paper introduces experimental observables in heavy ion collisions{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and status of QGP experiments for current period of time.},
author = {Snellings, R},
journal = {arXiv},
keywords = {experimental,heavy ion collisions,physics},
title = {{Heavy ion collisions}},
volume = {hep-ex/031}
}
@inproceedings{Bishop2014,
author = {Bishop, W E and Byron, M Y},
booktitle = {Neural Information Processing Systems},
pages = {1--9},
title = {{Deterministic Symmetric Positive Semidefinite Matrix Completion}},
year = {2014}
}
@article{Mokeichev2007,
abstract = {It was recently discovered that subthreshold membrane potential fluctuations of cortical neurons can precisely repeat during spontaneous activity, seconds to minutes apart, both in brain slices and in anesthetized animals. These repeats, also called cortical motifs, were suggested to reflect a replay of sequential neuronal firing patterns. We searched for motifs in spontaneous activity, recorded from the rat barrel cortex and from the cat striate cortex of anesthetized animals, and found numerous repeating patterns of high similarity and repetition rates. To test their significance, various statistics were compared between physiological data and three different types of stochastic surrogate data that preserve dynamical characteristics of the recorded data. We found no evidence for the existence of deterministically generated cortical motifs. Rather, the stochastic properties of cortical motifs suggest that they appear by chance, as a result of the constraints imposed by the coarse dynamics of subthreshold ongoing activity.},
annote = {2010IInum12.28a},
author = {Mokeichev, Alik and Okun, Michael and Barak, Omri and Katz, Yonatan and Ben-Shahar, Ohad and Lampl, Ilan},
doi = {10.1016/j.neuron.2007.01.017},
issn = {0896-6273},
journal = {Neuron},
keywords = {Algorithms,Animals,Cats,Cell Count,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Membrane Potentials,Membrane Potentials: physiology,Neuron Model,Neurons,Neurons: physiology,Patch-Clamp Techniques,Rats,Stochastic Processes,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
mendeley-tags = {Neuron Model},
month = {feb},
number = {3},
pages = {413--25},
pmid = {17270737},
title = {{Stochastic emergence of repeating cortical motifs in spontaneous membrane potential fluctuations in vivo.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17270737},
volume = {53},
year = {2007}
}
@article{Amaral|1991|,
abstract = {The organization of CA1 projections to the rat subiculum was investigated
with the anterograde tracer, Phaseolus vulgaris leucoagglutinin (PHA-L).
Discrete iontophoretic injections of PHA-L were placed into various
transverse positions of the CA1 field at different septotemporal
levels of the hippocampus. The distribution of CA1 projections was
observed in dissected and extended hippocampal preparations. CA1
cells located proximally in the field, i.e., close to the CA2 field,
gave rise to projections that terminated in the distal third of the
subiculum, i.e., close to the presubiculum. CA1 cells located distally
in the field, i.e., close to the subiculum, gave rise to projections
that terminated proximally in the subiculum, i.e., just across the
CA1/subiculum border. CA1 cells in the middle of the field projected
to a midtransverse portion of the subiculum. The same general pattern
of projections was observed at all septotemporal levels of the hippocampus.
Varicose fibers from the CA1 neurons terminated among the basal dendrites
of the subicular pyramidal cells, within the pyramidal cell layer,
and in the deep portion of the molecular layer. In addition to the
CA1 to subiculum projections, the discrete PHA-L injections provided
the opportunity of examining the extent of local and associational
connections within CA1. In general, associational connections in
CA1 are far less extensive than in CA3. CA1 is not entirely without
local connections, however. CA1 cells located close to the subicular
border, for example, originated axons that first innervated the proximal
subiculum and then reentered the CA1 field at the interface between
stratum radiatum and stratum lacunosum-moleculare. In most of the
experimental cases, there were collaterals located in stratum oriens
of CA1 that branched from the fibers directed toward the subiculum.
Thus, the basal dendrites of CA1 cells may receive associational
inputs. The organization of the CA1 projections to the subiculum
is discussed in relation to the organization of CA3 projections to
CA1 and the differential output of transverse regions of the subiculum.
The possibility is raised that information may be "channeled" through
the hippocampal formation via the transverse organization of these
connections and ultimately distributed to different recipients of
hippocampal efferent projections.},
annote = {16980/United States PHS Journal Article Research Support, Non-U.S.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Gov{\&}{\#}039;t Research Support, U.S. Gov{\&}{\#}039;t, P.H.S. United states},
author = {Amaral, D G and Dolorfo, C and Alvarez-Royo, P},
journal = {Hippocampus},
keywords = {Afferent Pathways/anatomy {\&} histology/physiology A,Sprague-Dawley Thalamus/physiology/ultrastructure},
number = {4},
pages = {415--435},
title = {{Organization of CA1 projections to the subiculum: a PHA-L analysis in the rat}},
volume = {1}
}
@article{Yu07b,
author = {Yu, Byron M and Cunningham, John P and Shenoy, Krishna V and Sahani, Maneesh},
journal = {ICONIP},
pages = {586--595},
title = {{Neural Decoding of Movements: From Linear to Nonlinear Trajectory Models}},
year = {2007}
}
@article{Wagenaar:2006kx,
abstract = {Three remarkable features of the nervous system--complex spatiotemporal
patterns, oscillations, and persistent activity--are fundamental
to such diverse functions as stereotypical motor behavior, working
memory, and awareness. Here we report that cultured cortical networks
spontaneously generate a hierarchical structure of periodic activity
with a strongly stereotyped population-wide spatiotemporal structure
demonstrating all three fundamental properties in a recurring pattern.
During these "superbursts," the firing sequence of the culture periodically
converges to a dynamic attractor orbit. Precursors of oscillations
and persistent activity have previously been reported as intrinsic
properties of the neurons. However, complex spatiotemporal patterns
that are coordinated in a large population of neurons and persist
over several hours--and thus are capable of representing and preserving
information--cannot be explained by known oscillatory properties
of isolated neurons. Instead, the complexity of the observed spatiotemporal
patterns implies large-scale self-organization of neurons interacting
in a precise temporal order even in vitro, in cultures usually considered
to have random connectivity.},
author = {Wagenaar, D A and Nadasdy, Zoltan and Potter, S M},
journal = {Physical Review B},
keywords = {networks},
mendeley-tags = {networks},
number = {5 Pt 1},
pages = {51907},
pmid = {16802967},
title = {{Persistent dynamic attractors in activity patterns of cultured neuronal networks}},
volume = {73},
year = {2006}
}
@article{Boyd1985,
author = {Boyd, Stephen and Chua, L},
journal = {Circuits and Systems, IEEE Transactions on},
number = {11},
pages = {1150--1161},
publisher = {IEEE},
title = {{Fading memory and the problem of approximating nonlinear operators with Volterra series}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1085649},
volume = {32},
year = {1985}
}
@article{Glass1979,
abstract = {A mathematical model is presented for phase locking of a biological oscillator to a sinusoidal stimulus. Analytical, numerical and topological considerations are used to discuss the patterns of phase locking as a function of amplitude of the sinusoidal stimulus and the relative frequencies of the osillator and the sinusoidal stimulus. The sorts of experimental data which are needed to make comparisons between theory and experiment are discussed.},
author = {Glass, L and Mackey, M C},
issn = {0303-6812},
journal = {Journal of mathematical biology},
keywords = {Biological Clocks,Mathematics,Models, Biological,Periodicity,Time Factors},
month = {may},
number = {4},
pages = {339--52},
pmid = {469413},
title = {{A simple model for phase locking of biological oscillators.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/469413},
volume = {7},
year = {1979}
}
@incollection{Bach2011,
author = {Bach, Francis and Jenatton, R and Mairal, J and Obozinski, G},
booktitle = {Optimization for Machine Learning},
chapter = {2},
editor = {Sra, S and Nowozin, S and Wright, SJ},
pages = {19--53},
publisher = {The MIT Press},
title = {{Convex optimization with sparsity-inducing norms}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=JPQx7s2L1A8C{\&}oi=fnd{\&}pg=PA19{\&}dq=Convex+optimization+with+sparsity-inducing+norms{\&}ots=vcdbBjj4I8{\&}sig=Xys5Ym6QE4eRoLfuH3TiBSKaRic},
year = {2012}
}
@article{GINZBURG94,
author = {Ginzburg, I and Sompolinsky, H},
journal = {Phys Rev E},
number = {4},
pages = {3171--3191},
title = {{{\{}T{\}}heory of correlations in stochastic neural networks}},
volume = {50},
year = {1994}
}
@book{Yamada1989,
author = {Koch, C and Segev, I},
booktitle = {Methods in Neuronal Modeling},
edition = {2nd},
editor = {Koch, C and Segev, I},
isbn = {0-262-11231-0},
pages = {97--134},
publisher = {MIT press, Cambridge},
title = {{Methods in Neuronal Modeling: from Ions to Networks}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=5GMV2onekvsC{\&}oi=fnd{\&}pg=PA1{\&}dq=Methods+in+Neuronal+Modeling+from+Ions+to+Networks{\&}ots=hSU1kw{\_}MOF{\&}sig=FpfQ6htuNz2DNvGhaagBJ3WPDN0 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.3083{\&}rep=rep1{\&}type=pdf},
volume = {484},
year = {1989}
}
@article{Medvedev2005,
author = {Medvedev, G},
doi = {10.1016/j.physd.2005.01.021},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
keywords = {neurons,one-dimensional map,singularly perturbed systems},
month = {mar},
number = {1-2},
pages = {37--59},
title = {{Reduction of a model of an excitable cell to a one-dimensional map}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167278905000564},
volume = {202},
year = {2005}
}
@article{FujinoOertel03,
author = {Fujino, Kiyohiro and Oertel, Donata},
journal = {Proceedings of The National Academy Of Sciences Of The United States Of America},
month = {jan},
number = {1},
pages = {265--270},
title = {{Bidirectional synaptic plasticity in the cerebellum-like mammalian dorsal cochlear nucleus}},
volume = {100},
year = {2003}
}
@article{Stability1990,
author = {Hein, S and Zakhor, A},
journal = {{\ldots} , 1991., IEEE International Sympoisum on},
pages = {1621--1624},
title = {{On the stability of interpolative sigma delta modulators}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=176693},
year = {1991}
}
@article{RobinsonLindquist08,
author = {Robinson, L and Wager, T and Lindquist, M},
journal = {Human Brain Mapping Annual Meeting},
title = {{Estimating Distributions of Onset Times and Durations from Multi-subject {\{}fMRI{\}} Studies}},
year = {2008}
}
@article{Card1991,
author = {Card, H and Schneider, C R and Moore, W R},
doi = {10.1049/ip-f-2.1991.0003},
issn = {0956375X},
journal = {IEEE Transactions on Audio and Electroacoustics},
month = {feb},
number = {1},
pages = {13--16},
title = {{Hebbian plasticity in mos synapses}},
url = {http://link.aip.org/link/IPFPEV/v138/i1/p13/s1{\&}Agg=doi},
volume = {138},
year = {1991}
}
@article{Kim2011,
abstract = {The lack of a deeper understanding of how olfactory sensory neurons (OSNs) encode odors has hindered the progress in understanding the olfactory signal processing in higher brain centers. Here we employ methods of system identification to investigate the encoding of time-varying odor stimuli and their representation for further processing in the spike domain by Drosophila OSNs. In order to apply system identification techniques, we built a novel low-turbulence odor delivery system that allowed us to deliver airborne stimuli in a precise and reproducible fashion. The system provides a 1{\%} tolerance in stimulus reproducibility and an exact control of odor concentration and concentration gradient on a millisecond time scale. Using this novel setup, we recorded and analyzed the in-vivo response of OSNs to a wide range of time-varying odor waveforms. We report for the first time that across trials the response of OR59b OSNs is very precise and reproducible. Further, we empirically show that the response of an OSN depends not only on the concentration, but also on the rate of change of the odor concentration. Moreover, we demonstrate that a two-dimensional (2D) Encoding Manifold in a concentration-concentration gradient space provides a quantitative description of the neuron's response. We then use the white noise system identification methodology to construct one-dimensional (1D) and two-dimensional (2D) Linear-Nonlinear-Poisson (LNP) cascade models of the sensory neuron for a fixed mean odor concentration and fixed contrast. We show that in terms of predicting the intensity rate of the spike train, the 2D LNP model performs on par with the 1D LNP model, with a root mean-square error (RMSE) increase of about 5 to 10{\%}. Surprisingly, we find that for a fixed contrast of the white noise odor waveforms, the nonlinear block of each of the two models changes with the mean input concentration. The shape of the nonlinearities of both the 1D and the 2D LNP model appears to be, for a fixed mean of the odor waveform, independent of the stimulus contrast. This suggests that white noise system identification of Or59b OSNs only depends on the first moment of the odor concentration. Finally, by comparing the 2D Encoding Manifold and the 2D LNP model, we demonstrate that the OSN identification results depend on the particular type of the employed test odor waveforms. This suggests an adaptive neural encoding model for Or59b OSNs that changes its nonlinearity in response to the odor concentration waveforms.},
author = {Kim, A J and Lazar, A A and Slutskiy, Yevgeniy B},
doi = {10.1007/s10827-010-0265-0},
isbn = {1082701002650},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Drosophila,Linear Models,Models,Neurological,Noise,Nonlinear Dynamics,Odors,Olfactory Pathways,Olfactory Pathways: cytology,Sensory Receptor Cells,Sensory Receptor Cells: physiology,Smell,Smell: physiology},
month = {feb},
number = {1},
pages = {143--61},
pmid = {20730480},
title = {{System identification of Drosophila olfactory sensory neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20730480},
volume = {30},
year = {2011}
}
@article{NR00,
author = {Ng, A Y and Russell, S},
journal = {ICML-17},
title = {{Algorithms for inverse reinforcement learning}},
year = {2000}
}
@article{Tiesinga|2005|,
abstract = {Recordings from area V4 of monkeys have revealed that when the focus
of attention is on a visual stimulus within the receptive field of
a cortical neuron, two distinct changes can occur: The firing rate
of the neuron can change and there can be an increase in the coherence
between spikes and the local field potential (LFP) in the gamma-frequency
range (30{\^{A}}–50 Hz). The hypothesis explored here is that these observed
effects of attention could be a consequence of changes in the synchrony
of local interneuron networks. We performed computer simulations
of a Hodgkin-Huxley type neuron driven by a constant depolarizing
current, I, representing visual stimulation and a modulatory inhibitory
input representing the effects of attention via local interneuron
networks. We observed that the neuron's firing rate and the coherence
of its output spike train with the synaptic inputs was modulated
by the degree of synchrony of the inhibitory inputs. When inhibitory
synchrony increased, the coherence of spiking model neurons with
the synaptic input increased, but the firing rate either increased
or remained the same. The mean number of synchronous inhibitory inputs
was a key determinant of the shape of the firing rate versus current
(f{\^{A}}–I) curves. For a large number of inhibitory inputs (50), the
f{\^{A}}–I curve saturated for large I and an increase in input synchrony
resulted in a shift of sensitivity{\^{A}}—the model neuron responded to
weaker inputs I. For a small number (10), the f{\^{A}}–I curves were non-saturating
and an increase in input synchrony led to an increase in the gain
of the response{\^{A}}—the firing rate in response to the same input was
multiplied by an approximately constant factor. The firing rate modulation
with inhibitory synchrony was highest when the input network oscillated
in the gamma frequency range. Thus, the observed changes in firing
rate and coherence of neurons in the visual cortex could be controlled
by top-down inputs that regulated the coherence in the activity of
a local inhibitory network discharging at gamma frequencies.},
author = {Tiesinga, P H and Fellous, J.-M. and Salinas, E and Jose, J V and Sejnowski, T J},
journal = {Journal of physiology},
keywords = {computer model,gain modulation,gamma oscillation,monkey,neurobiology,noise,synchrony,visual},
title = {{Inhibitory synchrony as a mechanism for attentional gain modulation}}
}
@article{DeWeese1998,
annote = {2009num32},
author = {DeWeese, M and Zador, A M},
doi = {10.1162/089976698300017403},
issn = {0899-7667},
journal = {Neural Computation},
month = {jul},
number = {5},
pages = {1179--1202},
title = {{Asymmetric Dynamics in Optimal Variance Adaptation}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976698300017403},
volume = {10},
year = {1998}
}
@article{Sacchi1995a,
abstract = {1. Adult and intact sympathetic neurones of the rat superior cervical ganglion maintained in vitro at 37 degrees C were analysed using the two-electrode voltage-clamp technique in order to investigate the slow component of the Ca(2+)-dependent K+ current, IAHP. 2. The relationship between the after-hyperpolarization (AHP) conductance, gAHP, and estimated Ca2+ influx resulting from short-duration calcium currents evoked at various voltages proved to be linear over a wide range of injected Ca2+ charge. An inflow of about 1.7 x 10(7) Ca2+ ions was required before significant activation of gAHP occurred. After priming, the gAHP sensitivity was about 0.3 nS pC-1 of Ca2+ inward charge. 3. IAHP was repeatedly measured at different membrane potentials; its amplitude decreased linearly with membrane hyperpolarization and was mostly abolished close to the K+ reversal potential, EK (-93 mV). The monoexponential decay rate of IAHP was a linear function of total Ca2+ entry and was not significantly altered by membrane potential in the -40 to -80 mV range. 4. Voltage-clamp tracings of IAHP could be modelled as a difference between two exponentials with tau on approximately 5 ms and tau off = 50-250 ms. 5. Sympathetic neurones discharged only once at the onset of a long-lasting depolarizing step. If IAHP was selectively blocked by apamin or D-tubocurarine treatments, accommodation was abolished and an unusual repetitive firing appeared. 6. Summation of IAHP was demonstrated under voltage-clamp conditions when the depolarizing steps were repeated sufficiently close to one another. Under current-clamp conditions the threshold depolarizing charge for action potential discharge significantly increased with progressive pulse numbers in the train, suggesting that an opposing conductance was accumulating with repetitive firing. This frequency-dependent spike firing ability was eliminated by pharmacological inhibition of the slow IAHP. 7. The IAHP was significantly activated by a single action potential; it was turned on cumulatively by Ca2+ load during successive action potential discharge and acted to further limit cell excitability.},
author = {Sacchi, O and Rossi, M L and Canella, R},
issn = {0022-3751},
journal = {The Journal of physiology},
keywords = {Animals,Apamin,Apamin: pharmacology,Calcium,Calcium: metabolism,Calcium: pharmacology,Curare,Curare: pharmacology,Ion Channels,Ion Channels: physiology,Membrane Potentials,Membrane Potentials: drug effects,Membrane Potentials: physiology,Models,Neurological,Neurons,Neurons: metabolism,Patch-Clamp Techniques,Potassium,Potassium: metabolism,Rats,Superior Cervical Ganglion,Superior Cervical Ganglion: physiology,Tubocurarine,Tubocurarine: pharmacology},
month = {feb},
pages = {15--27},
pmid = {7539840},
title = {{The slow Ca(2+)-activated K+ current, IAHP, in the rat sympathetic neurone.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1157868{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {483},
year = {1995}
}
@article{Franzius2007,
abstract = {We present a model for the self-organized formation of place cells, head-direction cells, and spatial-view cells in the hippocampal formation based on unsupervised learning on quasi-natural visual stimuli. The model comprises a hierarchy of Slow Feature Analysis (SFA) nodes, which were recently shown to reproduce many properties of complex cells in the early visual system []. The system extracts a distributed grid-like representation of position and orientation, which is transcoded into a localized place-field, head-direction, or view representation, by sparse coding. The type of cells that develops depends solely on the relevant input statistics, i.e., the movement pattern of the simulated animal. The numerical simulations are complemented by a mathematical analysis that allows us to accurately predict the output of the top SFA layer.},
author = {Franzius, Mathias and Sprekeler, Henning and Wiskott, Laurenz},
doi = {10.1371/journal.pcbi.0030166},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Animals,Computer Simulation,Head Movements,Head Movements: physiology,Hippocampus,Hippocampus: physiology,Models, Neurological,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurons, Afferent,Neurons, Afferent: classification,Neurons, Afferent: cytology,Neurons, Afferent: physiology,Orientation,Orientation: physiology,Rats,Space Perception,Space Perception: physiology},
month = {aug},
number = {8},
pages = {e166},
pmid = {17784780},
title = {{Slowness and sparseness lead to place, head-direction, and spatial-view cells.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1963505{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2007}
}
@inproceedings{BartlettBenDavid2002,
abstract = {We consider the problem of efficiently learning in two-layer neural networks. We investigate the computational complexity of agnostically learning with simple families of neural networks as the hypothesis classes. We show that it is NP-hard to find a linear threshold network of a fixed size that approximately minimizes the proportion of misclassified examples in a training set, even if there is a network that correctly classifies all of the training examples. In particular, for a training set that is correctly classified by some two-layer linear threshold network with k hidden units, it is NP-hard to find such a network that makes mistakes on a proportion smaller than c/k2 of the examples, for some constant c. We prove a similar result for the problem of approximately minimizing the quadratic loss of a two-layer network with a sigmoid output unit.},
author = {Bartlett, Peter L. and Ben-David, Shai},
booktitle = {Theoretical Computer Science},
doi = {10.1016/S0304-3975(01)00057-3},
isbn = {3540657010},
issn = {03043975},
number = {1},
pages = {53--66},
title = {{Hardness results for neural network approximation problems}},
volume = {284},
year = {2002}
}
@article{patlak1991molecular,
annote = {2010IIInum34},
author = {Patlak, J},
journal = {Physiological Reviews},
number = {4},
pages = {1047},
publisher = {Am Physiological Soc},
title = {{Molecular kinetics of voltage-dependent Na+ channels}},
volume = {71},
year = {1991}
}
@article{Donahue2016,
abstract = {The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.},
archivePrefix = {arXiv},
arxivId = {1605.09782},
author = {Donahue, Jeff and Kr{\"{a}}henb{\"{u}}hl, Philipp and Darrell, Trevor},
doi = {10.1038/nphoton.2013.187},
eprint = {1605.09782},
file = {::},
isbn = {2334-2536},
issn = {2334-2536},
month = {may},
pmid = {27377197},
title = {{Adversarial Feature Learning}},
url = {http://arxiv.org/abs/1605.09782},
year = {2016}
}
@article{HOCH06,
author = {Hochberg, L and Serruya, M and Friehs, G and Mukand, J and Saleh, M and Caplan, A and Branner, A and Chen, D and Penn, R and and Donoghue, J},
journal = {Nature},
pages = {164--171},
title = {{Neuronal ensemble control of prosthetic devices by a human with tetraplegia}},
volume = {442},
year = {2006}
}
@article{PanFerr08,
author = {Paninski, L and Ferreira, D},
journal = {COSYNE},
title = {{State-space methods for inferring synaptic inputs and weights}},
year = {2008}
}
@article{Park|2006|,
author = {Park, M and Salgado, J M and Ostroff, L E and Helton, T D and Robinson, C G and Harris, K M and Ehlers, M E},
journal = {Neuron},
number = {5},
pages = {817--830},
title = {{Plasticity-induced growth of dendritic spines by exocytic trafficking from recycling endosomes.}},
volume = {52}
}
@article{Frechette2004,
author = {Frechette, Eric S and Grivich, Matthew I and Kalmar, Rachel S and Litke, Alan M and Petrusca, Dumitru and Sher, Alexander and Chichilnisky, E J},
issn = {1534-7362},
journal = {J. Vis.},
number = {8},
pages = {570},
title = {{Retinal motion signals and limits on speed discrimination}},
volume = {4},
year = {2004}
}
@article{Cinlar1968,
author = {Cinlar, E and Agnew, R A},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
number = {3},
pages = {576--581},
publisher = {Royal Statistical Society},
title = {{On the superposition of point processes}},
url = {http://www.jstor.org/stable/2984262},
volume = {30},
year = {1968}
}
@article{Bento|2003|,
abstract = {he generalized Chaplygin gas (GCG) model explains the recent accelerated
expansion of the Universe via an exotic background fluid whose equation
of state is given by p ={\^{a}}ˆ'A/{\"{I}}�{\^{I}}±, where A is a positive constant
and 0{\textless}{\^{I}}± 1. The model is an interesting alternative to scenarios
involving scalar field potentials, with the ensuing unnatural fine
tuning conditions for the underlying particle physics theories. We
derive constraints on the parameter space of the model from bounds
on the location of the first few peaks and troughs of},
author = {Bento, M C and Bertolami, O and Sen, A A},
journal = {Physics Letters B},
keywords = {accelerated expansion,astrophysics,general relativity,physics},
pages = {172},
title = {{WMAP constraints on the generalized Chaplygin gas model}},
volume = {575}
}
@article{Shin2002,
abstract = {Cracking the neural code has long been a central issue in neuroscience. However, it has been proved difficult because there logically exist an infinite number of other models and interpretations that could account for the same data and phenomena (i.e. the problem of underdetermination). Therefore, I suggest that applying biologically realistic multiple constraints from ion-channel level to system level (e.g. cognitive neuroscience and human brain disorders) can only solve the problem of underdetermination. Here I have explored whether the noise shaping/predictive neural coding hypothesis can provide a unified view on following realistic multiple constraints: (1) cortical gain control mechanisms in vivo; (2) the relationships between acetylcholine, nicotine, dopamine, calcium-activated potassium ion-channel, and cognitive functions; (3) oscillations and synchrony; (4) why should spontaneous activity be irregular; (5) whether the cortical neurons in vivo are coincidence detectors or integrators; and (6) the causal relationship between theta oscillation, gamma band fluctuation, and P3 (or P300) ERP responses. Finally, recent experimental results supporting the unified view shall be discussed.},
author = {Shin, Jonghan},
doi = {10.1016/S0925-2312(02)00379-X},
issn = {0303-2647},
journal = {Neurocomputing},
keywords = {Action Potentials,Action Potentials: physiology,Electroencephalography,Electroencephalography: methods,Electroencephalography: statistics {\&} numerical dat,Evoked Potentials,Evoked Potentials: physiology,Forecasting,Models,Neurological,attention,eeg,neural coding,noise shaping and predictive,oscillations,spike,synchrony},
month = {jun},
number = {1-3},
pages = {167--175},
pmid = {12459305},
title = {{A unifying theory on the relationship between spike trains, EEG, and ERP based on the noise shaping/predictive neural coding hypothesis.}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S092523120200379X http://www.ncbi.nlm.nih.gov/pubmed/12459305},
volume = {67},
year = {2002}
}
@article{Chavas2005,
author = {Chavas, Jo{\"{e}}l and Furtlehner, Cyril and M{\'{e}}zard, Marc and Zecchina, R},
doi = {10.1088/1742-5468/2005/11/P11016},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
month = {nov},
number = {11},
pages = {P11016--P11016},
title = {{Survey-propagation decimation through distributed local computations}},
url = {http://stacks.iop.org/1742-5468/2005/i=11/a=P11016?key=crossref.b5eb5aedd3ebad06d4fba12a72c78d3d},
volume = {2005},
year = {2005}
}
@article{Lepage|1980|,
abstract = {We present a systematic analysis in perturbative quantum chromodynamics
(QCD) of large-momentum-transfer exclusive processes. Predictions
are given for the scaling behavior, angular dependence, helicity
structure, and normalization of elastic and inelastic form factors
and large-angle exclusive scattering amplitudes for hadrons and photons.
We prove that these reactions are dominated by quark and gluon subprocesses
at short distances, and thus that the dimensional-counting rules
for the power-law falloff of these amplitudes with momentum transfer
are rigorous predictions of QCD, modulo calculable logarithmic corrections
from the behavior of the hadronic wave functions at short distances.
These animalous-dimension corrections are determined by evolution
equations for process-independent meson and baryon "distribution
amplitudes" phi(x{\_}i,Q) which control the valence-quark distributions
in high-momentum-transfer exclusive reactions. The analysis can be
carried out systematically in powers of alpha{\_}s(Q{\^{}}2), the QCD running
coupling constant. Although the calculations are most conveniently
carried out using light-cone perturbation theory and the light-cone
gauge, we also present a gauge-independent analysis and relate the
distribution amplitude to a gauge-invariant Bethe-Salpeter amplitude.},
annote = {This is quite fundamental paper on use of LF-perturbation theory{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}in QCD.},
author = {Lepage, G P and Brodsky, S J},
journal = {Physical Review D},
keywords = {exclusive processes,large-momentum-transfer processes,light-front dynamics,perturbation theory,physics,quantum chromodynamics},
number = {9},
pages = {2157},
title = {{Exclusive processes in perturbative quantum chromodynamics}},
volume = {22}
}
@article{PP05,
author = {Ahmadian, Y and Pillow, J W and Paninski, L},
journal = {Under review, Neural Computation},
title = {{Model-based decoding, information estimation, and change-point detection in multi-neuron spike trains}},
year = {2009}
}
@article{Transactions1966,
author = {III, H Spang and Schultheiss, P},
journal = {Communications Systems, IRE {\ldots}},
title = {{Reduction of quantizing noise by use of feedback}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1088681},
volume = {2},
year = {1962}
}
@article{Lalor08,
author = {Lalor, E and Ahmadian, Y and Paninski, L},
journal = {Journal of Vision},
title = {{Optimal decoding of stimulus velocity using a probabilistic model of ganglion cell populations in primate retina}},
volume = {Under revi},
year = {2008}
}
@article{Sorra|2006|,
author = {Sorra, K E and Mishra, A and Kirov, S A and Harris, K M},
journal = {Neuroscience},
pages = {2097--2106},
title = {{Dense core vesicles resemble active-zone transport vesicles and are diminished following synaptogenesis in mature hippocampal slices.}},
volume = {141}
}
@article{Pan2009a,
abstract = {Some synapses transmit strongly to action potentials (APs), but weaken with repeated activation; others transmit feebly at first, but strengthen with sustained activity. We measured synchronous and asynchronous transmitter release at "phasic" crayfish neuromuscular junctions (NMJs) showing depression and at facilitating "tonic" junctions, and define the kinetics of depression and facilitation. We offer a comprehensive model of presynaptic processes, encompassing mobilization of reserve vesicles, priming of docked vesicles, their association with Ca(2+) channels, and refractoriness of release sites, while accounting for data on presynaptic buffers governing Ca(2+) diffusion. Model simulations reproduce many experimentally defined aspects of transmission and plasticity at these synapses. Their similarity to vertebrate central synapses suggests that the model might be of general relevance to synaptic transmission.},
author = {Pan, Bin and Zucker, Robert S},
doi = {10.1016/j.neuron.2009.03.025},
issn = {1097-4199},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Astacoidea,Biological,Biophysics,Calcium,Calcium: metabolism,Cesium,Cesium: pharmacology,Computer Simulation,Electric Stimulation,Electric Stimulation: methods,Models,Neuromuscular Junction,Neuromuscular Junction: drug effects,Neuromuscular Junction: physiology,Neuronal Plasticity,Neuronal Plasticity: drug effects,Neuronal Plasticity: physiology,Neurotransmitter Agents,Neurotransmitter Agents: metabolism,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
month = {may},
number = {4},
pages = {539--54},
pmid = {19477155},
publisher = {Elsevier Ltd},
title = {{A general model of synaptic transmission and short-term plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19477155},
volume = {62},
year = {2009}
}
@article{Gutig2006,
abstract = {The timing of action potentials in sensory neurons contains substantial information about the eliciting stimuli. Although the computational advantages of spike timing-based neuronal codes have long been recognized, it is unclear whether, and if so how, neurons can learn to read out such representations. We propose a new, biologically plausible supervised synaptic learning rule that enables neurons to efficiently learn a broad range of decision rules, even when information is embedded in the spatiotemporal structure of spike patterns rather than in mean firing rates. The number of categorizations of random spatiotemporal patterns that a neuron can implement is several times larger than the number of its synapses. The underlying nonlinear temporal computation allows neurons to access information beyond single-neuron statistics and to discriminate between inputs on the basis of multineuronal spike statistics. Our work demonstrates the high capacity of neural systems to learn to decode information embedded in distributed patterns of spike synchrony.},
annote = {2010IIInum62},
author = {G{\"{u}}tig, R and Sompolinsky, H},
doi = {10.1038/nn1643},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Afferent Pathways,Afferent Pathways: physiology,Algorithms,Animals,Brain,Brain: physiology,Humans,Learning,Learning: physiology,Models, Neurological,Nerve Net,Nerve Net: physiology,Neurons, Afferent,Neurons, Afferent: classification,Neurons, Afferent: physiology,Reaction Time,Reaction Time: physiology,Signal Processing, Computer-Assisted,Spike time neural coding,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
mendeley-tags = {Spike time neural coding},
month = {mar},
number = {3},
pages = {420--8},
pmid = {16474393},
title = {{The tempotron: a neuron that learns spike timing-based decisions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16474393},
volume = {9},
year = {2006}
}
@article{Parnas1979a,
author = {Parnas, B Y I and Segev, I and August, Received},
pages = {323--343},
title = {{(Received 4 August 1978)}},
year = {1979}
}
@article{Brette2005,
abstract = {We introduce a two-dimensional integrate-and-fire model that combines an exponential spike mechanism with an adaptation equation, based on recent theoretical findings. We describe a systematic method to estimate its parameters with simple electrophysiological protocols (current-clamp injection of pulses and ramps) and apply it to a detailed conductance-based model of a regular spiking neuron. Our simple model predicts correctly the timing of 96{\%} of the spikes (+/-2 ms) of the detailed model in response to injection of noisy synaptic conductances. The model is especially reliable in high-conductance states, typical of cortical activity in vivo, in which intrinsic conductances were found to have a reduced role in shaping spike trains. These results are promising because this simple model has enough expressive power to reproduce qualitatively several electrophysiological classes described in vitro.},
author = {Brette, Romain and Gerstner, Wulfram},
doi = {10.1152/jn.00686.2005},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Animals,Cell Membrane,Cell Membrane: physiology,Computer Simulation,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Humans,Membrane Potentials,Membrane Potentials: physiology,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Physiological,Physiological: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {nov},
number = {5},
pages = {3637--42},
pmid = {16014787},
title = {{Adaptive exponential integrate-and-fire model as an effective description of neuronal activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16014787},
volume = {94},
year = {2005}
}
@article{Dorval2005,
abstract = {Previous experimental and computational work (for review, see White et al., 2000) has suggested that channel noise, generated by the stochastic flicker of voltage-gated ion channels, can be a major contributor to electrical membrane noise in neurons. In spiny stellate neurons of the entorhinal cortex, we remove the primary source of channel noise by pharmacologically blocking the native persistent Na+ conductance. Via the dynamic-clamp technique (Robinson and Kawai, 1993; Sharp et al., 1993), we then introduce virtual persistent Na+ channels into the membranes of the stellate neurons. By altering the mathematical properties of these virtual "knock-ins," we demonstrate that stochastic flicker of persistent Na+ channels is necessary for the existence of slow perithreshold oscillations that characterize stellate neurons. Channel noise also alters the ability of stellate neurons to phase lock to weak sinusoidal stimuli. These results provide the first direct demonstration that physiological levels of channel noise can produce qualitative changes in the integrative properties of neurons.},
author = {Dorval, A D and White, J A},
doi = {10.1523/JNEUROSCI.3557-05.2005},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Cell Count,Dose-Response Relationship,Electric Stimulation,Electric Stimulation: methods,Entorhinal Cortex,Entorhinal Cortex: cytology,Excitatory Amino Acid Antagonists,Excitatory Amino Acid Antagonists: pharmacology,Membrane Potentials,Membrane Potentials: drug effects,Membrane Potentials: physiology,Membrane Potentials: radiation effects,Models,Neurological,Neurons,Neurons: physiology,Newborn,Noise,Patch-Clamp Techniques,Radiation,Rats,Riluzole,Riluzole: pharmacology,Sodium Channel Blockers,Sodium Channel Blockers: pharmacology,Sodium Channels,Sodium Channels: physiology,Tetrodotoxin,Tetrodotoxin: pharmacology},
month = {oct},
number = {43},
pages = {10025--8},
pmid = {16251451},
title = {{Channel noise is essential for perithreshold oscillations in entorhinal stellate neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16251451},
volume = {25},
year = {2005}
}
@article{Oja1982,
author = {Oja, E},
journal = {Journal of mathematical biology},
keywords = {neuron models - synaptic,plasticity - stochastic approxmaation},
number = {3},
pages = {267--273},
title = {{Simplified neuron model as a principal component analyzer}},
url = {http://www.springerlink.com/index/u9u6120r003825u1.pdf},
volume = {15},
year = {1982}
}
@article{Mezard2009,
abstract = {A new field of research is rapidly expanding at the crossroad between statistical physics, information theory and combinatorial optimization. In particular, the use of cutting edge statistical physics concepts and methods allow one to solve very large constraint satisfaction problems like random satisfiability, coloring, or error correction. Several aspects of these developments should be relevant for the understanding of functional complexity in neural networks. On the one hand the message passing procedures which are used in these new algorithms are based on local exchange of information, and succeed in solving some of the hardest computational problems. On the other hand some crucial inference problems in neurobiology, like those generated in multi-electrode recordings, naturally translate into hard constraint satisfaction problems. This paper gives a non-technical introduction to this field, emphasizing the main ideas at work in message passing strategies and their possible relevance to neural networks modelling. It also introduces a new message passing algorithm for inferring interactions between variables from correlation data, which could be useful in the analysis of multi-electrode recording data.},
author = {M{\'{e}}zard, Marc and Mora, Thierry},
doi = {10.1016/j.jphysparis.2009.05.013},
issn = {1769-7115},
journal = {Journal of physiology, Paris},
keywords = {Algorithms,Animals,Computer Simulation,Humans,Message passing,Models,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology},
mendeley-tags = {Message passing},
number = {1-2},
pages = {107--13},
pmid = {19616623},
publisher = {Elsevier Ltd},
title = {{Constraint satisfaction problems and neural networks: A statistical physics perspective.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19616623},
volume = {103},
year = {2009}
}
@article{RyugoWillard85,
author = {Ryugo, D K and Willard, F H},
journal = {Journal of Comparative Neurology},
number = {3},
pages = {381--396},
title = {{The dorsal cochlear nucleus of the mouse: a light microscopic analysis of neurons that project to the inferior colliculus}},
volume = {242},
year = {1985}
}
@techreport{Nir2012,
author = {Nir, I and Shafir, M},
title = {{EE student project: History dependent adaptation in a neuron cell}},
year = {2012}
}
@article{Rudelson2010,
abstract = {The classical random matrix theory is mostly focused on asymptotic spectral properties of random matrices as their dimensions grow to infinity. At the same time many recent applications from convex geometry to functional analysis to information theory operate with random matrices in fixed dimensions. This survey addresses the non-asymptotic theory of extreme singular values of random matrices with independent entries. We focus on recently developed geometric methods for estimating the hard edge of random matrices (the smallest singular value).},
archivePrefix = {arXiv},
arxivId = {1003.2990},
author = {Rudelson, Mark and Vershynin, Roman},
doi = {10.1142/9789814324359_0111},
eprint = {1003.2990},
isbn = {9789814324304},
journal = {Proceedings of the International Congress of Mathematicians},
keywords = {1,asymptotic and non-asymptotic problems,hard edge,littlewood-offord problem,on ran-,random matrices,singular values,small ball probability},
pages = {1576--1602},
title = {{Non-asymptotic Theory of Random Matrices: Extreme Singular Values}},
url = {http://eproceedings.worldscinet.com/9789814324359/9789814324359{\_}0111.html},
year = {2010}
}
@article{VIC00b,
author = {Victor, J},
journal = {Brain Research},
pages = {33--46},
title = {{How the brain uses time to represent and process visual information}},
volume = {886},
year = {2000}
}
@article{Sporns2005,
abstract = {The connection matrix of the human brain (the human "connectome") represents an indispensable foundation for basic and applied neurobiological research. However, the network of anatomical connections linking the neuronal elements of the human brain is still largely unknown. While some databases or collations of large-scale anatomical connection patterns exist for other mammalian species, there is currently no connection matrix of the human brain, nor is there a coordinated research effort to collect, archive, and disseminate this important information. We propose a research strategy to achieve this goal, and discuss its potential impact.},
author = {Sporns, Olaf and Tononi, Giulio and K{\"{o}}tter, Rolf},
doi = {10.1371/journal.pcbi.0010042},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Animals,Brain,Brain: anatomy {\&} histology,Brain: cytology,Brain: metabolism,Humans,Nerve Net,Neurons,Neurons: metabolism,Synapses,Synapses: metabolism},
month = {sep},
number = {4},
pages = {e42},
pmid = {16201007},
publisher = {Public Library of Science},
title = {{The human connectome: A structural description of the human brain.}},
url = {http://dx.plos.org/10.1371/journal.pcbi.0010042},
volume = {1},
year = {2005}
}
@article{KampaStuart07,
abstract = {The ability of neurons to modulate the strength of their synaptic

connections has been shown to depend on the relative timing of pre-

and postsynaptic action potentials. This form of synaptic plasticity,

called spike-timing-dependent plasticity (STDP), has become an attractive

model for learning at the single-cell level. Yet, despite its popularity

in experimental and theoretical neuroscience, the influence of dendritic

mechanisms in the induction of STDP has been largely overlooked.

Several recent studies have investigated how active dendritic properties

and synapse location within the dendritic tree influence STDP. These

studies suggest the existence of learning rules that depend on firing

mode and subcellular input location, adding unanticipated complexity

to STDP. Here, we propose a new look at STDP that is focused on processing

at the postsynaptic site in the dendrites, rather than on spike-timing

at the cell body.},
author = {Kampa, Bj�rn M and Letzkus, Johannes J and Stuart, Greg J},
doi = {10.1016/j.tins.2007.06.010},
journal = {Trends Neurosci},
month = {sep},
number = {9},
pages = {456--463},
pmid = {17765330},
title = {{Dendritic mechanisms controlling spike-timing-dependent synaptic plasticity.}},
url = {http://dx.doi.org/10.1016/j.tins.2007.06.010},
volume = {30},
year = {2007}
}
@article{Care2013,
author = {Care, Cheaptickets Traveler},
pages = {2--5},
title = {{Prepare for your trip Prepare for your trip Traveler information Flight itinerary}},
year = {2013}
}
@article{levine2007stochastic,
annote = {2010IIInum53},
author = {Levine, E. and Hwa, T.},
journal = {Proceedings of the National Academy of Sciences},
keywords = {correlations,networks},
mendeley-tags = {correlations,networks},
number = {22},
pages = {9224},
publisher = {National Acad Sciences},
title = {{Stochastic fluctuations in metabolic pathways}},
url = {http://www.pnas.org/content/104/22/9224.full},
volume = {104},
year = {2007}
}
@article{Rieke08,
author = {Khuc-Trong, P and Rieke, F},
journal = {Nature Neuroscience},
pages = {1343--1351},
title = {{Origin of correlated activity between parasol retinal ganglion cells}},
volume = {11},
year = {2008}
}
@article{Scroggs2008a,
annote = {2010IInum12.19},
author = {Scroggs, Reese S},
doi = {10.1113/jphysiol.2008.150821},
issn = {1469-7793},
journal = {The Journal of physiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Nerve Tissue Proteins,Nerve Tissue Proteins: drug effects,Nerve Tissue Proteins: physiology,Neuron Model,Nociceptors,Nociceptors: physiology,Rats,Sodium Channels,Sodium Channels: drug effects,Sodium Channels: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Tetrodotoxin,Tetrodotoxin: pharmacology},
mendeley-tags = {Neuron Model},
month = {feb},
number = {4},
pages = {923},
pmid = {18287386},
title = {{Evidence of a physiological role for use-dependent inactivation of NaV1.8 sodium channels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18287386 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2375632{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {586},
year = {2008}
}
@book{Cover2012,
author = {Cover, T M and Thomas, JA},
isbn = {9780471241959},
title = {{Elements of information theory}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=VWq5GG6ycxMC{\&}oi=fnd{\&}pg=PT10{\&}dq=ELEMENTS+OF+information+Theory{\&}ots=bX4gL3S8XU{\&}sig=O5GY-3V16{\_}qcuJdCwzih7ODc6UE},
year = {2012}
}
@book{PRE92,
annote = {This is chapeter 19 of the above mentioned book on partial differential
equations and chapter 7 on monte-carlo methods.},
author = {Press, W H and Teukolsky, S A and Vetterling, W T and Flannery, B P},
keywords = {computational,mathematics,monte carlo,numerical methods,partial differential equations,physics},
publisher = {Cambridge University Press},
title = {{Numerical recipes in {\{}C{\}}}},
year = {1992}
}
@article{Sontag1981,
author = {Sontag, E.},
doi = {10.1109/TAC.1981.1102596},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
month = {apr},
number = {2},
pages = {346--358},
title = {{Nonlinear regulation: The piecewise linear approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1102596},
volume = {26},
year = {1981}
}
@article{Millhauser1988a,
annote = {2009num1},
author = {Millhauser, G L and Salpeter, E E and Oswald, R E},
journal = {PNAS},
number = {5},
pages = {1503},
publisher = {National Acad Sciences},
title = {{Diffusion models of ion-channel gating and the origin of power-law distributions from single-channel recording}},
url = {http://www.pnas.org/cgi/content/abstract/85/5/1503},
volume = {85},
year = {1988}
}
@article{MaYoung06,
author = {Ma, Wei-Li Diana and Young, Eric D},
journal = {Hearing Research},
month = {jun},
pages = {176--188},
title = {{Dorsal cochlear nucleus response properties following acoustic trauma: response maps and spontaneous activity}},
volume = {216-217},
year = {2006}
}
@article{Kumar1985,
author = {Kumar, PR R},
journal = {SIAM Journal on Control and Optimization},
keywords = {adaptive control,adaptive control of linear,bandit problems,bayesian adaptive control,bayesian control of markov,chains,non-bayesian adaptive control,self-optimizing systems,self-tuning regulators,stochastic adaptive control,systems},
number = {3},
pages = {329},
title = {{A survey of some results in stochastic adaptive control}},
url = {http://link.aip.org/link/?SJCODC/23/329/1},
volume = {23},
year = {1985}
}
@article{Mazzoni2007,
abstract = {Most neuronal networks, even in the absence of external stimuli, produce spontaneous bursts of spikes separated by periods of reduced activity. The origin and functional role of these neuronal events are still unclear. The present work shows that the spontaneous activity of two very different networks, intact leech ganglia and dissociated cultures of rat hippocampal neurons, share several features. Indeed, in both networks: i) the inter-spike intervals distribution of the spontaneous firing of single neurons is either regular or periodic or bursting, with the fraction of bursting neurons depending on the network activity; ii) bursts of spontaneous spikes have the same broad distributions of size and duration; iii) the degree of correlated activity increases with the bin width, and the power spectrum of the network firing rate has a 1/f behavior at low frequencies, indicating the existence of long-range temporal correlations; iv) the activity of excitatory synaptic pathways mediated by NMDA receptors is necessary for the onset of the long-range correlations and for the presence of large bursts; v) blockage of inhibitory synaptic pathways mediated by GABA(A) receptors causes instead an increase in the correlation among neurons and leads to a burst distribution composed only of very small and very large bursts. These results suggest that the spontaneous electrical activity in neuronal networks with different architectures and functions can have very similar properties and common dynamics.},
annote = {2010IInum10.5},
author = {Mazzoni, Alberto and Broccard, Fr{\'{e}}d{\'{e}}ric D and Garcia-Perez, Elizabeth and Bonifazi, Paolo and Ruaro, Maria Elisabetta and Torre, Vincent},
doi = {10.1371/journal.pone.0000439},
issn = {1932-6203},
journal = {PloS one},
number = {5},
pages = {e439},
pmid = {17502919},
title = {{On the dynamics of the spontaneous activity in neuronal networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17502919},
volume = {2},
year = {2007}
}
@article{Kleiss|2005|,
abstract = {While the Quasi-Monte Carlo method of numerical integration achieves
smaller integration error than standardMonte Carlo, its use in particle
physics phenomenology has been hindered by the abscence of a reliable
way to estimate that error. The standard Monte Carlo error estimator
relies on the assumption that the points are generated independently
of each other and, therefore, fails to account for the error improvement
advertised by the Quasi- Monte Carlo method. We advocate the construction
of an estimator of stochastic nature, based on the ensemble of pointsets
with a particular discrepancy value. We investigate the consequences
of this choice and give some first empirical results on the suggested
estimators.},
annote = {The paper introduces error estimator for quasi monte carlo method{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}with linear computational cost.},
author = {Kleiss, R and Lazopoulos, A},
journal = {arXiv},
keywords = {computational,mathematics,monte carlo method,physics,quantum monte carlo},
pages = {504085},
title = {{Error in monte carlo, quasi-error in quasi-monte carlo}},
volume = {hep-ph}
}
@article{Ostroff|2002|,
abstract = {The presence of polyribosomes in dendritic spines suggests a potential
involvement of local protein synthesis in the modification of synapses.
Dendritic spine and synapse ultrastructure were compared after low-frequency
control or tetanic stimulation in hippocampal slices from postnatal
day (P)15 rats. The percentage of spines containing polyribosomes
increased from 12{\%} +/- 4{\%} after control stimulation to 39{\%} +/- 4{\%}
after tetanic stimulation, with a commensurate loss of polyribosomes
from dendritic shafts at 2 hr posttetanus. Postsynaptic densities
on spines containing polyribosomes were larger after tetanic stimulation.
Local protein synthesis might therefore serve to stabilize stimulation-induced
growth of the postsynaptic density. Furthermore, coincident polyribosomes
and synapse enlargement might indicate spines that are expressing
long-term potentiation induced by tetanic stimulation.},
annote = {DA 57351/DA/United States NIDA NS 33574/NS/United States NINDS Journal{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Article Research Support, U.S. Gov{\&}{\#}039;t, P.H.S. United States},
author = {Ostroff, L E and Fiala, J C and Allwardt, B and Harris, K M},
journal = {Neuron},
keywords = {Animals Cell Compartmentation/physiology Cell Diff,Electron Nerve Tissue Proteins/biosynthesis Organ,Long-Evans Synapses/*metabolism/ultrastructure Sy},
number = {3},
pages = {535--545},
title = {{Polyribosomes redistribute from dendritic shafts into spines with enlarged synapses during LTP in developing rat hippocampal slices}},
volume = {35}
}
@article{BorgGraham96,
author = {Borg-Graham, L and Monier, C and Fregnac, Y},
journal = {J. Physiology [Paris]},
pages = {185--188},
title = {{Voltage-clamp measurements of visually-evoked conductances with whole-cell patch recordings in primary visual cortex}},
volume = {90},
year = {1996}
}
@article{Olsen1978,
author = {Olsen, Randall J},
journal = {Econometrica},
pages = {1211--1215},
title = {{Note on the Uniqueness of the Maximum Likelihood Estimator for the Tobit Model}},
volume = {46},
year = {1978}
}
@article{Carbonetto2012,
abstract = {The Bayesian approach to variable selection in regression is a powerful tool for tackling many scientific problems. Inference for variable selection models is usually implemented using Markov chain Monte Carlo ({\{}MCMC{\}}). Because {\{}MCMC{\}} can impose a high computational cost in studies with a large number of variables, we assess an alternative to {\{}MCMC{\}} based on a simple variational approximation. Our aim is to retain useful features of Bayesian variable selection at a reduced cost. Using simulations designed to mimic genetic association studies, we show that this simple variational approximation yields posterior inferences in some settings that closely match exact values. In less restrictive (and more realistic) conditions, we show that posterior probabilities of inclusion for individual variables are often incorrect, but variational estimates of other useful quantities�including posterior distributions of the hyperparameters�are remarkably accurate. We illustrate how these results guide the use of variational inference for a genome-wide association study with thousands of samples and hundreds of thousands of variables.},
author = {Carbonetto, Peter and Stephens, Matthew},
doi = {10.1214/12-BA703},
issn = {1931-6690},
journal = {Bayesian Analysis},
keywords = {bayesian,genetic association studies,gwas,modeling,quantitative{\_}genetics,variable selection,variable{\_}selection,variational inference,variational{\_}inference},
number = {1},
pages = {73--108},
title = {{Scalable Variational Inference for Bayesian Variable Selection in Regression, and its Accuracy in Genetic Association Studies}},
url = {http://dx.doi.org/10.1214/12-ba703 http://ba.stat.cmu.edu/journal/2012/vol07/issue01/carbonetto.pdf},
volume = {7},
year = {2012}
}
@article{Alvarez2002,
abstract = {Ion channels open and close in a stochastic fashion, following the laws of probability. However, distinct from tossing a coin or a die, the probability of finding the channel closed or open is not a fixed number but can be modified (i.e., we can cheat) by some external stimulus, such as the voltage. Single-channel records can be obtained using the appropriate electrophysiological technique (e.g., patch clamp), and from these records the open probability and the channel conductance can be calculated. Gathering these parameters from a membrane containing many channels is not straightforward, as the macroscopic current I = iNP(o), where i is the single-channel current, N the number of channels, and P(o) the probability of finding the channel open, cannot be split into its individual components. In this tutorial, using the probabilistic nature of ion channels, we discuss in detail how i, N, and P(o max) (the maximum open probability) can be obtained using fluctuation (nonstationary noise) analysis (Sigworth FJ. G Gen Physiol 307: 97-129, 1980). We also analyze the sources of possible artifacts in the determination of i and N, such as channel rundown, inadequate filtering, and limited resolution of digital data acquisition by use of a simulation computer program (available at www.cecs.cl).},
author = {Alvarez, Osvaldo and Gonzalez, Carlos and Latorre, Ramon},
issn = {1043-4046},
journal = {Advances in physiology education},
keywords = {Animals,Artifacts,Cell Membrane,Cell Membrane: metabolism,Electrophysiology,Humans,Ion Channels,Ion Channels: physiology,Patch-Clamp Techniques,Physiology,Physiology: education,Teaching},
month = {dec},
number = {1-4},
pages = {327--41},
pmid = {12444005},
title = {{Counting channels: a tutorial guide on ion channel fluctuation analysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12444005},
volume = {26},
year = {2002}
}
@article{Hasegawa2011a,
author = {Hasegawa, Tsuyoshi and Itoh, Yaomi and Tanaka, Hirofumi and Hino, Takami and Tsuruoka, Tohru and Terabe, Kazuya and Miyazaki, Hisao and Tsukagoshi, Kazuhito and Ogawa, Takuji and Yamaguchi, Shu and Aono, Masakazu},
doi = {10.1143/APEX.4.015204},
issn = {1882-0778},
journal = {Applied Physics Express},
month = {jan},
number = {1},
pages = {015204},
title = {{Volatile/Nonvolatile Dual-Functional Atom Transistor}},
url = {http://apex.jsap.jp/link?APEX/4/015204/},
volume = {4},
year = {2011}
}
@article{Kole2008,
abstract = {The axon initial segment (AIS) is a specialized region in neurons where action potentials are initiated. It is commonly assumed that this process requires a high density of voltage-gated sodium (Na(+)) channels. Paradoxically, the results of patch-clamp studies suggest that the Na(+) channel density at the AIS is similar to that at the soma and proximal dendrites. Here we provide data obtained by antibody staining, whole-cell voltage-clamp and Na(+) imaging, together with modeling, which indicate that the Na(+) channel density at the AIS of cortical pyramidal neurons is approximately 50 times that in the proximal dendrites. Anchoring of Na(+) channels to the cytoskeleton can explain this discrepancy, as disruption of the actin cytoskeleton increased the Na(+) current measured in patches from the AIS. Computational models required a high Na(+) channel density (approximately 2,500 pS microm(-2)) at the AIS to account for observations on action potential generation and backpropagation. In conclusion, action potential generation requires a high Na(+) channel density at the AIS, which is maintained by tight anchoring to the actin cytoskeleton.},
author = {Kole, M H P and Ilschner, S U and Kampa, B M and Williams, S R and Ruben, P C and Stuart, G J},
doi = {10.1038/nn2040},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Action Potentials: radiation effects,Animals,Axons,Axons: drug effects,Axons: metabolism,Axons: radiation effects,Benzofurans,Benzofurans: metabolism,Computer Simulation,Cyclic,Cyclic: metabolism,Cytochalasin B,Cytochalasin B: pharmacology,Drug Interactions,Electric Stimulation,Electric Stimulation: methods,Ethers,Ion Channel Gating,Ion Channel Gating: drug effects,Models,Neurological,Neurons,Neurons: cytology,Neurons: drug effects,Neurons: radiation effects,Patch-Clamp Techniques,Patch-Clamp Techniques: methods,Phalloidine,Phalloidine: pharmacology,Rats,Sodium,Sodium Channel Blockers,Sodium Channel Blockers: pharmacology,Sodium Channels,Sodium Channels: metabolism,Sodium: metabolism,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology,Tetrodotoxin,Tetrodotoxin: pharmacology,Wistar},
month = {feb},
number = {2},
pages = {178--86},
pmid = {18204443},
title = {{Action potential generation requires a high sodium channel density in the axon initial segment.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18204443},
volume = {11},
year = {2008}
}
@article{Contou-Carrere2011,
author = {Contou-Carrere, MN},
doi = {10.1016/j.sysconle.2010.10.011},
issn = {01676911},
journal = {Systems {\&} control letters},
month = {jan},
number = {1},
pages = {75--86},
publisher = {Elsevier B.V.},
title = {{Model reduction of multi-scale chemical Langevin equations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167691110001611 http://www.sciencedirect.com/science/article/pii/S0167691110001611},
volume = {60},
year = {2011}
}
@article{Westrum|1962|,
annote = {Journal Article Not Available},
author = {Westrum, L E and Blackstad, T W},
journal = {J Comp Neurol},
keywords = {*Hippocampus},
pages = {281--309},
title = {{An electron microscopic study of the stratum radiatum of the rat hippocampus (regio superior, CA 1) with particular emphasis on synaptology}},
volume = {119}
}
@book{NORR04,
author = {Norris, J},
publisher = {Cambridge University Press},
title = {{Markov Chains}},
year = {2004}
}
@article{THEU01,
author = {Theunissen, F and David, S and Singh, N and Hsu, A and Vinje, W and Gallant, J},
journal = {Network: Computation in Neural Systems},
pages = {289--316},
title = {{Estimating spatio-temporal receptive fields of auditory and visual neurons from their responses to natural stimuli}},
volume = {12},
year = {2001}
}
@article{HNT01,
author = {Haskell, E and Nykamp, D Q and Tranchina, D},
journal = {Network: Computation in Neural Systems},
pages = {141--174},
title = {{Population density methods for large-scale modelling of neuronal networks with realistic synaptic kinetics}},
volume = {12},
year = {2001}
}
@article{Mcdonnell2011,
annote = {2011num34},
author = {McDonnell, M.D. D and Ward, L.M. M},
journal = {Nature Reviews Neuroscience},
number = {7},
pages = {415--426},
publisher = {Nature Publishing Group},
title = {{The benefits of noise in neural systems: bridging theory and experiment}},
url = {http://dx.doi.org/10.1038/nrn3061 http://www.nature.com/nrn/journal/v12/n7/abs/nrn3061.html},
volume = {12},
year = {2011}
}
@article{Lowe02,
author = {Lowe, G},
journal = {Journal of Neurophysiolog},
pages = {64--85},
title = {{Inhibition of Backpropagating Action Potentials in Mitral Cell Secondary Dendrites}},
volume = {88},
year = {2002}
}
@article{CW91,
author = {Clevenson, M and Watkins, W},
journal = {Mathematics Magazine},
pages = {183--188},
title = {{Majorization and the Birthday Inequality}},
volume = {64},
year = {1991}
}
@article{Ermentrout1996,
annote = {2010num7.4},
author = {Ermentrout, B},
journal = {Neural computation},
number = {5},
pages = {979--1001},
publisher = {MIT Press},
title = {{Type I membranes, phase resetting curves, and synchrony}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1996.8.5.979},
volume = {8},
year = {1996}
}
@article{SabatiniRegehr98,
abstract = {Measurements of presynaptic calcium currents are vital to understanding

the control of transmitter release. However, most presynaptic boutons

in the vertebrate central nervous system are too small to allow electrical

recordings of presynaptic calcium currents (I(Ca)pre). We therefore

tested the possibility of measuring I(Ca)pre optically in boutons

loaded with calcium-sensitive fluorophores. From a theoretical treatment

of a system containing an endogenous buffer and an indicator, we

determined the conditions necessary for the derivative of the stimulus-evoked

change in indicator fluorescence to report I(Ca)pre accurately. Matching

the calcium dissociation rates of the endogenous buffer and indicator

allows the most precise optical measurements of I(Ca)pre. We tested

our ability to measure I(Ca)pre in granule cells in rat cerebellar

slices. The derivatives of stimulus-evoked fluorescence transients

from slices loaded with the low-affinity calcium indicators magnesium

green and mag-fura-5 had the same time courses and were unaffected

by changes in calcium influx or indicator concentration. Thus both

of these indicators were well suited to measuring I(Ca)pre. In contrast,

the high-affinity indicator fura-2 distorted I(Ca)pre. The optically

determined I(Ca)pre was well approximated by a Gaussian with a half-width

of 650 micros at 24 degrees C and 340 micros at 34 degrees C.},
author = {Sabatini, B L and Regehr, W G},
journal = {Biophys J},
keywords = {Action Potentials; Animals; Calcium; Calcium Chann,Chemical; Nerve Fibers; Presynaptic Terminals; Ra,Fluorescence; Temperature,Sprague-Dawley; Spectrometry},
month = {mar},
number = {3},
pages = {1549--1563},
pmid = {9512051},
title = {{Optical measurement of presynaptic calcium currents.}},
volume = {74},
year = {1998}
}
@article{Jacobs2009,
abstract = {The subject of neural coding has generated much debate. A key issue is whether the nervous system uses coarse or fine coding. Each has different strengths and weaknesses and, therefore, different implications for how the brain computes. For example, the strength of coarse coding is that it is robust to fluctuations in spike arrival times; downstream neurons do not have to keep track of the details of the spike train. The weakness, though, is that individual cells cannot carry much information, so downstream neurons have to pool signals across cells and/or time to obtain enough information to represent the sensory world and guide behavior. In contrast, with fine coding, individual cells can carry much more information, but downstream neurons have to resolve spike train structure to obtain it. Here, we set up a strategy to determine which codes are viable, and we apply it to the retina as a model system. We recorded from all the retinal output cells an animal uses to solve a task, evaluated the cells' spike trains for as long as the animal evaluates them, and used optimal, i.e., Bayesian, decoding. This approach makes it possible to obtain an upper bound on the performance of codes and thus eliminate those that are insufficient, that is, those that cannot account for behavioral performance. Our results show that standard coarse coding (spike count coding) is insufficient; finer, more information-rich codes are necessary.},
author = {Jacobs, A L and Fridman, G and Douglas, R M and Alam, N M and Latham, P E and Prusky, G T and Nirenberg, S},
doi = {10.1073/pnas.0900573106},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Electrophysiology,Mice,Models,Neurological,Nonlinear Dynamics,Retina,Retina: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
number = {14},
pages = {5936--5941},
pmid = {19297621},
title = {{Ruling out and ruling in neural codes}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2657589{\&}tool=pmcentrez{\&}rendertype=abstract http://www.pnas.org/content/106/14/5936.short},
volume = {3},
year = {2009}
}
@article{NURIYA06,
author = {Nuriya, M and Jiang, J and Nemet, B and Eisenthal, K and Yuste, R},
journal = {PNAS},
pages = {786--790},
title = {{Imaging membrane potential in dendritic spines}},
volume = {103},
year = {2006}
}
@article{Baldovin2007,
abstract = {We derive a central limit theorem for the probability distribution of the sum of many critically correlated random variables. The theorem characterizes a variety of different processes sharing the same asymptotic form of anomalous scaling and is based on a correspondence with the L{\'{e}}vy-Gnedenko uncorrelated case. In particular, correlated anomalous diffusion is mapped onto L{\'{e}}vy diffusion. Under suitable assumptions, the nonstandard multiplicative structure used for constructing the characteristic function of the total sum allows us to determine correlations of partial sums exclusively on the basis of the global anomalous scaling.},
author = {Baldovin, Fulvio and Stella, Attilio L},
issn = {1539-3755},
journal = {Physical Review E},
keywords = {central limit theorem,strongly dependent processes},
month = {feb},
number = {2 Pt 1},
pages = {020101},
pmid = {17358300},
title = {{Central limit theorem for anomalous scaling due to correlations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20033692},
volume = {75},
year = {2007}
}
@article{Verd2004,
author = {Verd, Editor-in-chief Sergio and Notredame, Daniel Costello and Stanford, Thomas Cover and Maryland, Anthony Ephremides and Stanford, Andrea Goldsmith and Mit, Dave Forney},
number = {1},
title = {{Foundations and Trends TM in}},
volume = {1},
year = {2004}
}
@book{SilvapulleSen04,
author = {Silvapulle, M and Sen, P},
publisher = {Wiley-Interscience},
title = {{Constrained Statistical Inference: Inequality, Order, and Shape Restrictions}},
year = {2004}
}
@article{Mensi2011,
abstract = {Cortical information processing originates from the exchange of action potentials between many cell types. In order to capture the essence of these interactions it is of critical importance to build mathematical models that reflect the characteristic features of spike generation in individual neurons. We propose a framework to automatically extract such features from current-clamp experiments, in particular the passive properties of a neuron (i.e. membrane time constant, reversal potential and capacitance), the spike-triggered adaptation currents, as well as the dynamics of the action potential threshold. The stochastic model that results from our maximum likelihood approach accurately predicts the spike times, the subthreshold voltage, the firing patterns, and the type of frequency-current curve. Extracting the model parameters for three cortical cell types revealed that cell types show highly significant differences in the time course of the spike-triggered currents and moving threshold, that is, in their adaptation and refractory properties, but not in their passive properties. In particular, GABAergic fast-spiking neurons mediate weak adaptation through spike-triggered currents only, whereas regular spiking excitatory neurons mediate adaptation with both moving threshold and spike-triggered currents. GABAergic non-fast-spiking neurons combine the two distinct adaptation mechanisms with reduced strength. Differences between cell types are large enough to enable automatic classification of neurons into three different classes. Parameter extraction is performed for individual neurons so that we find not only the mean parameter values for each neuron type, but also the spread of parameters within a group of neurons, which will be useful for future large-scale computer simulations.},
author = {Mensi, S and Naud, R and Pozzorini, C and Avermann, M and Petersen, C C H and Gerstner, W},
doi = {10.1152/jn.00408.2011},
issn = {1522-1598},
journal = {Journal of neurophysiology},
month = {dec},
pages = {1756--1775},
pmid = {22157113},
title = {{Parameter Extraction and Classification of Three Cortical Neuron Types Reveals Two Distinct Adaptation Mechanisms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22157113},
year = {2011}
}
@article{Dickinson|1994|,
annote = {The paper discusses a methodology allowing to track 3D objects during{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}their shape morphing caused by 3D movement and change of orientation;{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}without specifying definite shape model (?) using so called adaptive{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}adjucency graph and aspects prediction graph},
author = {Dickinson, S J and Jasiobedzki, P and Olofsson, G and Christensen, H I},
journal = {IEEE},
keywords = {3D,active controur,computational,graph,image processing,predictive,qualitative,trackng},
pages = {812},
title = {{Qualitative Tracking of 3-D Objects using Active Controur Networks}}
}
@article{Kingma2013,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound with an independent noise variable yields a lower bound estimator that can be jointly optimized w.r.t. variational and generative parameters using standard gradient-based stochastic optimization methods. Second, we show that posterior inference can be made especially efficient by optimizing a probabilistic encoder (also called a recognition model) to approximate the intractable posterior, using the proposed estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6114v1},
author = {Kingma, DP and Welling, Max},
eprint = {arXiv:1312.6114v1},
journal = {arXiv preprint arXiv:1312.6114},
month = {dec},
number = {Ml},
pages = {1--9},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114 http://xxx.tau.ac.il/pdf/1312.6114v1.pdf{\%}5Cnhttp://arxiv.org/abs/1312.6114},
year = {2013}
}
@article{Baum70,
author = {Baum, L E and Petrie, T and Soules, G and Weiss, N and Petrie, L},
journal = {Annals of Mathematical Statistics},
number = {1},
pages = {164--171},
publisher = {JSTOR},
title = {{A maximization technique occuring in the statistical analysis of probabilistic functions of {\{}M{\}}arkov chains}},
volume = {41},
year = {1970}
}
@article{Naundorf2006,
abstract = {Neurons process and encode information by generating sequences of action potentials. For all spiking neurons, the encoding of single-neuron computations into sequences of spikes is biophysically determined by the cell's action-potential-generating mechanism. It has recently been discovered that apparently minor modifications of this mechanism can qualitatively change the nature of neuronal encoding. Here we quantitatively analyse the dynamics of action potential initiation in cortical neurons in vivo, in vitro and in computational models. Unexpectedly, key features of the initiation dynamics of cortical neuron action potentials--their rapid initiation and variable onset potential--are outside the range of behaviours described by the classical Hodgkin-Huxley theory. We propose a new model based on the cooperative activation of sodium channels that reproduces the observed dynamics of action potential initiation. This new model predicts that Hodgkin-Huxley-type dynamics of action potential initiation can be induced by artificially decreasing the effective density of sodium channels. In vitro experiments confirm this prediction, supporting the hypothesis that cooperative sodium channel activation underlies the dynamics of action potential initiation in cortical neurons.},
author = {Naundorf, B and Wolf, F and Volgushev, M},
doi = {10.1038/nature04610},
issn = {1476-4687},
journal = {Nature},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cats,Cerebral Cortex,Cerebral Cortex: cytology,Computer Simulation,Ion Channel Gating,Mice,Models,Neocortex,Neocortex: cytology,Neurological,Neurons,Neurons: physiology,Rats,Sodium Channels,Sodium Channels: metabolism,Time Factors,Visual Cortex,Visual Cortex: cytology},
month = {apr},
number = {7087},
pages = {1060--3},
pmid = {16625198},
title = {{Unique features of action potential initiation in cortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16625198},
volume = {440},
year = {2006}
}
@article{DoucetRyugo99,
abstract = {Multipolar cells in the ventral cochlear nucleus (VCN) are a structurally

and functionally diverse group of projection neurons. Understanding

their role in the ascending pathway involves partitioning multipolar

cells into distinct populations and determining where in the brain

each sends its coded messages. In this study, we used retrograde

labeling techniques in rats to identify multipolar neurons that project

their axons to the ipsilateral dorsal cochlear nucleus (DCN), the

contralateral CN, or both structures. Three rats received injections

of biotinylated dextran amine in the ipsilateral DCN and diamidino

yellow in the contralateral CN. Several radiate multipolar neurons

(defined by their axonal projections to the ipsilateral DCN and their

dendrites that traverse VCN isofrequency sheets) were double-labeled

but over 70{\%} were not. This result suggests two distinct populations:

(1) radiate-commissural (RC) multipolar cells that project to the

ipsilateral DCN and the contralateral CN, and (2) radiate multipolar

cells that project exclusively (in this context) to the ipsilateral

DCN. In a different group of animals, we retrogradely labeled multipolar

neurons that project their axons to the contralateral CN and measured

the size of their cell bodies. The mean size of this population (266

+/- 156 microm2) was significantly smaller than those of RC-multipolar

cells (418 +/- 140 microm2). We conclude that the CN commissural

pathway is composed of at least two components: (1) RC multipolar

cells and (2) commissural multipolar cells that are small- and medium-sized

neurons that project exclusively (in this context) to the contralateral

CN. These results identify separate structural groups of multipolar

cells that may correspond to physiological unit types described in

the literature. They also provide protocols for isolating and studying

different populations of multipolar cells to determine the neural

mechanisms that govern their responses to sound.},
author = {Doucet, John R and Ryugo, David K},
doi = {10.1002/ar.a.20294},
journal = {Anat Rec A Discov Mol Cell Evol Biol},
keywords = {Amidines; Animals; Auditory Pathways; Axons; Cats;,Extramural; Staining and Labeling,N.I.H.,Sprague-Dawley; Research Support},
month = {apr},
number = {4},
pages = {331--344},
pmid = {16550550},
title = {{Structural and functional classes of multipolar cells in the ventral cochlear nucleus.}},
url = {http://dx.doi.org/10.1002/ar.a.20294},
volume = {288},
year = {2006}
}
@article{DeCharms1996,
annote = {2010IIInum58},
author = {DeCharms, R Christopher and Merzenich, MM M},
journal = {Nature},
keywords = {Spike time neural coding},
mendeley-tags = {Spike time neural coding},
title = {{Primary cortical representation of sounds by the coordination of action-potential timing}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:primary+cortical+representation+of+sounds{\#}0},
year = {1996}
}
@article{Tsodyks1998,
abstract = {Transmission across neocortical synapses depends on the frequency of presynaptic activity (Thomson {\&} Deuchars, 1994). Interpyramidal synapses in layer V exhibit fast depression of synaptic transmission, while other types of synapses exhibit facilitation of transmission. To study the role of dynamic synapses in network computation, we propose a unified phenomenological model that allows computation of the postsynaptic current generated by both types of synapses when driven by an arbitrary pattern of action potential (AP) activity in a presynaptic population. Using this formalism, we analyze different regimes of synaptic transmission and demonstrate that dynamic synapses transmit different aspects of the presynaptic activity depending on the average presynaptic frequency. The model also allows for derivation of mean-field equations, which govern the activity of large, interconnected networks. We show that the dynamics of synaptic transmission results in complex sets of regular and irregular regimes of network activity.},
author = {Tsodyks, M and Pawelzik, K and Markram, H},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Excitatory Postsynaptic Potentials,Neocortex,Neocortex: physiology,Nerve Net,Neuronal Plasticity,Neuronal Plasticity: physiology,Poisson Distribution,Reproducibility of Results,Signal Transduction,Signal Transduction: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
number = {4},
pages = {821--35},
pmid = {9573407},
title = {{Neural networks with dynamic synapses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9573407},
volume = {10},
year = {1998}
}
@article{PDZ03,
author = {Pouget, A and Dayan, P and Zemel, R},
journal = {Annual Reviews of Neuroscience},
pages = {381--410},
title = {{Computation and inference with population codes}},
volume = {26},
year = {2003}
}
@article{Lin1913,
author = {Lin, P},
journal = {Circuit Theory, IEEE Transactions on},
number = {6},
pages = {732--737},
title = {{A survey of applications of symbolic network functions}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1083770},
volume = {C},
year = {1973}
}
@article{Deisseroth05,
author = {Boyden, Edward S and Zhang, Feng and Bamberg, Ernst and Nagel, Georg and Deisseroth, Karl},
journal = {Nat Neurosci},
month = {sep},
number = {9},
pages = {1263--1268},
title = {{Millisecond-timescale, genetically targeted optical control of neural activity}},
volume = {8},
year = {2005}
}
@article{Osen90,
author = {Osen, K K and Ottersen, O P and Storm-Mathisen, J},
editor = {Ottersen, O P and Storm-Mathisen, J},
journal = {Glycine Neurotransmission},
pages = {417--451},
publisher = {John Wiley {\&} Sons},
title = {{Colocalization of glycine-like and GABA-like immunoreactivities A semiquantitative study of individual neurons in the dorsal cochlear nucleus of cat}},
year = {1990}
}
@incollection{Maass2010,
author = {Maass, W},
booktitle = {World Scientific Review},
keywords = {Reservoir Computing},
mendeley-tags = {Reservoir Computing},
title = {{Liquid State Machines : Motivation , Theory , and Applications}},
year = {2010}
}
@article{jimbo2000dynamics,
author = {Jimbo, Y and Kawana, A and Parodi, P and Torre, V},
journal = {Biological Cybernetics},
keywords = {networks},
mendeley-tags = {networks},
number = {1},
pages = {1--20},
publisher = {Springer},
title = {{The dynamics of a neuronal culture of dissociated cortical neurons of neonatal rats}},
volume = {83},
year = {2000}
}
@article{Kochanek|2000|,
abstract = {We study the evolution of Hernquist profile {\"{i}}¾“galaxies{\"{i}}¾” in the
presence of self-interacting dark mat- ter (SIDM), where the properties
of the dark matter can be parameterized by one number, {\"{E}}†{\"{I}}ƒDM = {\"{I}}ƒDMMT
/a2 for a halo of mass MT and break radius a. While the halos form
constant density cores of size {\^{a}}ˆ¼ a/2 on the core radius relaxation
time scale (trc approx 1.7tdyn/{\"{I}}ƒDM) core collapse begins shortly
thereafter and a steeper 1/r2 central density cusp starts forming
faster than predicted by 2-body relaxation. The formation of the
steeper central cusp is accelerated if the cooling baryons adiabatically
compress the dark matter. The natural consequence of SIDM is to exacerbate
rather than to mitigate astrophysical problems created by dark matter
density cusps.},
annote = {This paper apparently points toward effect of cooling of interacting{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}dark matter halo in its center, thus leading to core collapse.},
author = {Kochanek, C S and White, Martin},
journal = {arXiv},
keywords = {astrophysics,cooling,cusp,dark matter,interaction,physics,simulation,strongly interacting dark matter},
pages = {3483},
title = {{A quantitative study of interacting dark matter in halos}},
volume = {astro-ph}
}
@inproceedings{Ghosh2016,
author = {Ghosh, S and Maria, F and Fave, D and Yedidia, J},
booktitle = {Thirtieth AAAI Conference on Artificial Intelligence},
title = {{Assumed Density Filtering Methods for Learning Bayesian Neural Networks}},
year = {2016}
}
@article{BROWN09a,
author = {Brown, L and Cai, T and Zhang, R and Zhao, L and Zhou, H},
journal = {Probability Theory and Related Fields. To appear.},
title = {{The Root-unroot Algorithm for Density Estimation as Implemented via Wavelet Block Thresholding}},
year = {2009}
}
@article{BC99,
author = {Burkitt, A and Clark, G},
journal = {Neural Computation},
pages = {871--901},
title = {{Analysis of Integrate-and-Fire Neurons: Synchronization of Synaptic Input and Spike Output}},
volume = {11},
year = {1999}
}
@article{Thomas2013,
author = {Thomas, Andy},
doi = {10.1088/0022-3727/46/9/093001},
issn = {0022-3727},
journal = {Journal of Physics D: Applied Physics},
month = {mar},
number = {9},
pages = {093001},
title = {{Memristor-based neural networks}},
url = {http://stacks.iop.org/0022-3727/46/i=9/a=093001?key=crossref.80cf1dbb7fea7f4ed8c46bd8d3fbf158},
volume = {46},
year = {2013}
}
@article{Romo|2002|,
abstract = {Humans and monkeys have similar abilities to discriminate the difference
in frequency between two consecutive mechanical vibrations applied
to their fingertips. This task can be conceived as a chain of neural
operations: encoding the two consecutive stimuli, maintaining the
first stimulus in working memory, comparing the second stimulus with
the memory trace left by the first stimulus and communicating the
result of the comparison to the motor apparatus. We studied this
chain of neural operations by recording and manipulating neurons
from different areas of the cerebral cortex while monkeys performed
the task. The results indicate that neurons of the primary somatosensory
cortex (S1) generate a neural representation of vibrotactile stimuli
which correlates closely with psychophysical performance. Discrimination
based on microstimulation patterns injected into clusters of S1 neurons
is indistinguishable from that produced by natural stimuli. Neurons
from the secondary somatosensory cortex (S2), prefrontal cortex and
medial premotor cortex (MPC) display at different times the trace
of the first stimulus during the workingmemory component of the task.
Neurons from S2 and MPC appear to show the comparison between the
two stimuli and correlate with the behavioural decisions. These neural
operations may contribute to the sensory-discrimination process studied
here.},
author = {Romo, R and Hernandez, A and Zainos, A and Brody, C and Salinas, E},
journal = {Philosophical transactions of the royal society B},
keywords = {behaving monkeys,cerebral cortex,decision making,neurobiology,psychology,sensory discrimination},
pages = {1039},
title = {{Exploring the cortical evidence of a sensory-discrimination process}},
volume = {357}
}
@book{Angrist2008,
author = {Angrist, JD and Pischke, JS},
number = {March},
title = {{Mostly harmless econometrics: An empiricist's companion}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=ztXL21Xd8v8C{\&}oi=fnd{\&}pg=PR8{\&}dq=Mostly+Harmless+Econometrics+:+An+Empiricist+'+s+Companion{\&}ots=Ui39UA-JvP{\&}sig=ym35sB-t0J9fuHfj1phsEL5eI5s http://books.google.com/books?hl=en{\&}lr={\&}id=ztXL21Xd8v8C{\&}oi=fnd{\&}pg=PR8{\&}dq=Mostly+harmless+econometrics:+An+empiricist{\%}27s+companion{\&}ots=Ui42VC6QyU{\&}sig=HwnnalH13pTtPXNK3Eps4iSXdjg},
year = {2008}
}
@book{ASYMPTOPIA,
author = {Pollard, D},
publisher = {www.stat.yale.edu/{\~{}}pollard},
title = {{Asymptopia}},
year = {2003}
}
@article{Milescu2010,
abstract = {We examined the kinetic properties of voltage-gated Na(+) channels and their contribution to the repetitive spiking activity of medullary raph{\'{e}} neurons, which exhibit slow pacemaking and strong spiking adaptation. The study is based on a combination of whole-cell patch-clamp, modeling and real-time computation. Na(+) currents were recorded from neurons in brain slices obtained from male and female neonatal rats, using voltage-clamp protocols designed to reduce space-clamp artifacts and to emphasize functionally relevant kinetic features. A detailed kinetic model was formulated to explain the broad range of transient and stationary voltage-dependent properties exhibited by Na(+) currents. The model was tested by injecting via dynamic clamp a model-based current as a substitute for the native TTX-sensitive Na(+) currents, which were pharmacologically blocked. The model-based current reproduced well the native spike shape and spiking frequency. The dynamics of Na(+) channels during repetitive spiking were indirectly examined through this model. By comparing the spiking activities generated with different kinetic models in dynamic-clamp experiments, we determined that state-dependent slow inactivation contributes significantly to spiking adaptation. Through real-time manipulation of the model-based current, we established that suprathreshold Na(+) current mainly controls spike shape, whereas subthreshold Na(+) current modulates spiking frequency and contributes to the pacemaking mechanism. Since the model-based current was injected in the soma, the results also suggest that somatic Na(+) channels are sufficient to establish the essential spiking properties of raph{\'{e}} neurons in vitro.},
author = {Milescu, L S and Yamanishi, T and Ptak, K and Smith, J C},
doi = {10.1523/JNEUROSCI.0445-10.2010},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {3-dione,3-dione: pharmacology,6-Cyano-7-nitroquinoxaline-2,Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Animals,Biological Clocks,Biological Clocks: physiology,Biophysical Processes,Biophysical Processes: physiology,Cadmium Chloride,Cadmium Chloride: pharmacology,Excitatory Amino Acid Antagonists,Excitatory Amino Acid Antagonists: pharmacology,Models,Neurological,Neurons,Neurons: physiology,Newborn,Nonlinear Dynamics,Patch-Clamp Techniques,Patch-Clamp Techniques: methods,Probability,Raphe Nuclei,Raphe Nuclei: cytology,Rats,Sodium Channel Blockers,Sodium Channel Blockers: pharmacology,Sodium Channels,Sodium Channels: drug effects,Sodium Channels: physiology,Sprague-Dawley,Tetrodotoxin,Tetrodotoxin: pharmacology,Time Factors,slow sodium inactivation},
mendeley-tags = {slow sodium inactivation},
number = {36},
pages = {12113--27},
pmid = {20826674},
title = {{Kinetic properties and functional dynamics of sodium channels during repetitive spiking in a slow pacemaker neuron.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2945634{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {30},
year = {2010}
}
@article{Dityatev2003,
annote = {2010IIInum66},
author = {Dityatev, Alexander and Schachner, Melitta},
doi = {10.1038/nrn1115},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Extracellular Matrix Proteins,Extracellular Matrix Proteins: physiology,Humans,Neuroglia,Neuroglia: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology},
month = {jun},
number = {6},
pages = {456--68},
pmid = {12778118},
title = {{Extracellular matrix molecules and synaptic plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12778118},
volume = {4},
year = {2003}
}
@book{MM78,
address = {New York},
author = {Marmarelis, P and Marmarelis, V},
publisher = {Plenum Press},
title = {{Analysis of physiological systems: the white-noise approach}},
year = {1978}
}
@article{Wired_Ng,
author = {Hernandez, D},
journal = {Wired},
month = {jun},
title = {{Now You Can Build Google's 1M Artificial Brain on the Cheap}},
url = {http://www.wired.com/wiredenterprise/2013/06/andrew{\_}ng/},
year = {2013}
}
@book{DL93,
address = {New York},
author = {Devore, R and Lorentz, G},
publisher = {Springer},
title = {{Constructive approximation}},
year = {1993}
}
@article{Hern2013,
author = {Hern{\'{a}}ndez-Lobato, D},
journal = {The Journal of Machine {\ldots}},
pages = {1891--1945},
title = {{Generalized spike-and-slab priors for Bayesian group feature selection using expectation propagation}},
url = {http://dl.acm.org/citation.cfm?id=2567724},
volume = {14},
year = {2013}
}
@article{Choi2016,
abstract = {In massive multiple-input multiple-output (MIMO) systems that operate with high bandwidths, it may not be power efficient to have a high-resolution analog-to-digital converter (ADC) for each antenna element. In this paper, a near maximum likelihood (nML) detector for uplink multiuser massive MIMO systems is proposed where each antenna is connected to a pair of one-bit ADCs, i.e., one for each real and imaginary component of the baseband signal. To achieve low complexity in the proposed nML detector, a strict constraint on the possible transmitted symbols in the original maximum likelihood (ML) detection problem is relaxed to formulate an ML estimation problem. Then, the ML estimation problem is converted into a convex optimization problem which can be efficiently solved. After obtaining the ML estimate by solving the convex problem, the base station can perform simple symbol-by-symbol detection for the transmitted signals from multiple users. The minimum required number of receive antennas for detectors using one-bit ADCs to work is also discussed. Numerical results show that the proposed nML detector is efficient enough to simultaneously support multiple uplink users adopting higher-order constellations, e.g., 16 quadrature amplitude modulation. Since our detector makes use of the channel as part of the decoding, an ML channel estimation technique with one-bit ADCs that shares the same structure with our proposed nML detector is also developed. The proposed detector and channel estimator provide a complete low power solution for the uplink of a massive MIMO system.},
archivePrefix = {arXiv},
arxivId = {1507.04452},
author = {Choi, Junil and Mo, Jianhua and Heath, Robert W.},
doi = {10.1109/TCOMM.2016.2545666},
eprint = {1507.04452},
isbn = {0090-6778},
issn = {00906778},
journal = {IEEE Transactions on Communications},
number = {5},
pages = {2005--2018},
title = {{Near Maximum-Likelihood Detector and Channel Estimator for Uplink Multiuser Massive MIMO Systems with One-Bit ADCs}},
volume = {64},
year = {2016}
}
@article{Stevenson2011,
abstract = {Over the last five decades, progress in neural recording techniques has allowed the number of simultaneously recorded neurons to double approximately every 7 years, mimicking Moore's law. Such exponential growth motivates us to ask how data analysis techniques are affected by progressively larger numbers of recorded neurons. Traditionally, neurons are analyzed independently on the basis of their tuning to stimuli or movement. Although tuning curve approaches are unaffected by growing numbers of simultaneously recorded neurons, newly developed techniques that analyze interactions between neurons become more accurate and more complex as the number of recorded neurons increases. Emerging data analysis techniques should consider both the computational costs and the potential for more accurate models associated with this exponential growth of the number of recorded neurons.},
author = {Stevenson, I H and Kording, Konrad P},
doi = {10.1038/nn.2731},
journal = {Nature neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Electrophysiology,Electrophysiology: methods,Models,Neurological,Neurons,Neurons: physiology,Neurophysiology,Neurophysiology: methods},
month = {feb},
number = {2},
pages = {139--142},
pmid = {21270781},
publisher = {Nature Publishing Group},
title = {{How advances in neural recording affect data analysis.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3410539{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2011}
}
@book{CST00,
author = {Cristianini, N and Shawe-Taylor, J},
publisher = {Cambridge University Press},
title = {{An introduction to support vector machines}},
year = {2000}
}
@article{Last2009,
author = {Last, Mendeley and Pdfs, Add and Search, Google Scholar and Importer, One-click Web and Pdfs, Synchronize and Web, Mendeley and Pdfs, Annotate and Organizer, File and Collections, Public and Collections, Shared},
number = {November},
title = {{Getting started with Mendeley}},
year = {2009}
}
@article{GIR98,
author = {Girosi, F},
journal = {Neural Computation},
pages = {1455--1480},
title = {{An equivalence between sparse approximation and support vector machines}},
volume = {10},
year = {1998}
}
@article{Ni2000,
author = {Ni, Zhongren and Kedem, Benjamin},
doi = {10.1006/jmaa.2000.6803},
issn = {0022247X},
journal = {Journal of Mathematical Analysis and Applications},
keywords = {differential equation,expansion,quadratic form},
month = {jun},
number = {1},
pages = {280--295},
title = {{Normal Orthant Probabilities in the Equicorrelation Case}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022247X00968033},
volume = {246},
year = {2000}
}
@article{Kim2005,
annote = {2010num2.7},
author = {Kim, SIL and Jeong, J and Kwak, Y and Kim, YI and Jung, SH},
journal = {Journal of Computational Neuroscience},
title = {{Fractal stochastic modeling of spiking activity in suprachiasmatic nucleus neurons}},
url = {http://www.springerlink.com/index/LP14323006Q81706.pdf},
year = {2005}
}
@article{SmithRhode89,
author = {Smith, P H and Rhode, W S},
journal = {Journal of Comparative Neurology},
month = {apr},
number = {4},
pages = {595--616},
title = {{Structural and functional properties distinguish two types of multipolar cells in the ventral cochlear nucleus}},
volume = {282},
year = {1989}
}
@inproceedings{Le2012,
address = {Edinburgh},
author = {Le, Q V and Ranzato, M and Monga, R and Devin, M and Chen, K and Corrado, G S and Dean, J and Ng, A Y},
booktitle = {ICML '12},
month = {jun},
pages = {81--88},
title = {{Building high-level features using large scale unsupervised learning}},
year = {2012}
}
@article{NEL94,
author = {Nelken, I and Prut, Y and Vaadia, E and Abeles, M},
journal = {Hearing Res.},
pages = {237--253},
title = {{In Search of the Best Stimulus: an Optimization Procedure for Finding Efficient Stimuli in the Cat Auditory Cortex}},
volume = {72},
year = {1994}
}
@article{Prescott2008,
abstract = {Spike-frequency adaptation causes reduced spiking during prolonged stimulation, but the full impact of adaptation on neural coding is far more complex, especially if one takes into account the diversity of biophysical mechanisms mediating adaptation and the different ways in which neural information can be encoded. Here, we show that adaptation has opposite effects depending on the neural coding strategy and the biophysical mechanism responsible for adaptation. Under noisy conditions, calcium-activated K(+) current (I(AHP)) improved efficient spike-rate coding at the expense of spike-time coding by regularizing the spike train elicited by slow or constant inputs; noise power was increased at high frequencies but reduced at low frequencies, consistent with noise shaping that improves coding of low- frequency signals. In contrast, voltage-activated M-type K(+) current (I(M)) improved spike-time coding at the expense of spike-rate coding by stopping the neuron from spiking repetitively to slow inputs so that it could generate isolated, well timed spikes in response to fast inputs. Using dynamical systems analysis, we demonstrate how I(AHP) minimizes perturbation of the interspike interval caused by high- frequency noise, whereas I(M) minimizes disruption of spike-timing accuracy caused by repetitive spiking. The dichotomous outcomes are related directly to the distinct activation requirements for I(AHP) and I(M), which in turn dictate whether those currents mediate negative feedback onto spiking or membrane potential. Thus, based on their distinct activation properties, I(AHP) implements noise shaping that improves spike-rate coding of low-frequency signals, whereas I(M) implements high-pass filtering that improves spike-time coding of high- frequency signals.},
author = {Prescott, S A and Sejnowski, T J},
doi = {10.1523/JNEUROSCI.1792-08.2008},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Algorithms,Models,Neurological,Neurons,Neurons: physiology,Physiological,Theoretical},
month = {dec},
number = {50},
pages = {13649--61},
pmid = {19074038},
title = {{Spike-rate coding and spike-time coding are affected oppositely by different adaptation mechanisms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19074038},
volume = {28},
year = {2008}
}
@article{Fernando2017,
abstract = {For artificial general intelligence (AGI) it would be efficient if multiple users trained the same giant neural network, permitting parameter reuse, without catastrophic forgetting. PathNet is a first step in this direction. It is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re-use for new tasks. Agents are pathways (views) through the network which determine the subset of parameters that are used and updated by the forwards and backwards passes of the backpropogation algorithm. During learning, a tournament selection genetic algorithm is used to select pathways through the neural network for replication and mutation. Pathway fitness is the performance of that pathway measured according to a cost function. We demonstrate successful transfer learning; fixing the parameters along a path learned on task A and re-evolving a new population of paths for task B, allows task B to be learned faster than it could be learned from scratch or after fine-tuning. Paths evolved on task B re-use parts of the optimal path evolved on task A. Positive transfer was demonstrated for binary MNIST, CIFAR, and SVHN supervised learning classification tasks, and a set of Atari and Labyrinth reinforcement learning tasks, suggesting PathNets have general applicability for neural network training. Finally, PathNet also significantly improves the robustness to hyperparameter choices of a parallel asynchronous reinforcement learning algorithm (A3C).},
archivePrefix = {arXiv},
arxivId = {1701.08734},
author = {Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A. and Pritzel, Alexander and Wierstra, Daan},
eprint = {1701.08734},
file = {::},
month = {jan},
title = {{PathNet: Evolution Channels Gradient Descent in Super Neural Networks}},
url = {http://arxiv.org/abs/1701.08734},
year = {2017}
}
@article{Chandrasekar08,
author = {Chandrasekar, J and Kim, I S and Bernstein, D S and Ridley, A J},
journal = {American Control Conference},
pages = {3987--3992},
title = {{Cholesky-based reduced-rank square-root {\{}K{\}}alman filtering}},
year = {2008}
}
@article{Bak1987,
author = {Bak, Per and Tang, Chao and Wiesenfeld, K.},
journal = {Physical Review Letters},
number = {4},
pages = {381--384},
publisher = {APS},
title = {{Self-organized criticality: An explanation of the 1/f noise}},
url = {http://chaos.swarthmore.edu/courses/Physics120{\_}2008/docs/btw.pdf http://link.aps.org/doi/10.1103/PhysRevLett.59.381},
volume = {59},
year = {1987}
}
@article{Tsien83,
author = {Tsien, R Y},
journal = {Annu Rev Biophys Bioeng},
pages = {91--116},
title = {{Intracellular measurements of ion activities.}},
volume = {12},
year = {1983}
}
@book{Gardiner,
address = {Verlag Berlin Heidelberg},
author = {Gardiner, C W},
booktitle = {Springer Series in Synergetics},
edition = {3rd},
pages = {111},
publisher = {Springer},
title = {{Handbook of stochastic methods}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Handbook+of+stochastic+methods{\#}8},
year = {2004}
}
@article{Harris|2006|,
author = {Harris, K M and Perry, E and Bourne, J and Feinberq, M D and Ostroff, L E and Hurlburt, J},
journal = {J Neurosci},
number = {47},
pages = {12101--12103},
title = {{Uniform serial sectioning for transmission electron microscopy.}},
volume = {26}
}
@article{McGuire|2001|,
abstract = {In the early 1990{\"{i}}¾'s, an analysis was completed by several theorists
of the available mass/cross-section parameter space for unusual particle
candidates to solve the dark matter problem, e.g. strongly interacting
massive particles (SIMPs). This analysis found several unconstrained
windows, such that for SIMP masses and cross-sections within these
windows, SIMPs could still be the dominant dark matter in our Galactic
halo. Since the early 1990{\"{i}}¾'s, some of these windows have been narrowed
or closed, and some of these windows have been widened further by
more careful analysis. We summarize the present state of the SIMP
parameter space, and point to the cosmological salience of SIMPs
as dark matter, given some of the present inadequacies of the WIMP
solution to the dark matter problem.},
annote = {This is an important paper reviewing and correcting exclusion ranges{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}on the mass-cross-section parameters for interacting dark matter.},
author = {McGuire, P C and Steinhardt, P J},
journal = {arXiv},
keywords = {astrophysics,cross-section,dark matter,experimental,interaction,mass,physics,strongly interacting dark matter},
pages = {105567},
title = {{Cracking open the window for strongly interacting massive particles as the halo dark matter}},
volume = {astro-ph}
}
@article{SH97,
author = {Shapley, R},
journal = {Current Biology},
pages = {421--423},
title = {{Retinal physiology: Adapting to the changing scene}},
volume = {7},
year = {1997}
}
@article{Deng2012,
author = {Hinton, G E and Deng, L and Yu, D and Dahl, G E and Mohamed, A R and Jaitly, N and Senior, A and Vanhoucke, V and Nguyen, P and Sainath, T N and Kingsbury, B},
journal = {Signal Processing Magazine, IEEE},
number = {6},
pages = {82--97},
title = {{Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6296526},
volume = {29},
year = {2012}
}
@incollection{YoungOertel03,
author = {Young, Eric D and Oertel, Donata},
booktitle = {The Synaptic Organization of the Brain},
chapter = {4},
edition = {Fifth},
editor = {Shepherd, Gordon M},
pages = {125--164},
publisher = {Oxford Press: New York},
title = {{The Cochlear Nucleus}},
year = {2004}
}
@article{Hubara2016,
abstract = {We introduce a method to train Quantized Neural Networks (QNNs) --- neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At train-time the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves {\$}51\backslash{\%}{\$} top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online.},
archivePrefix = {arXiv},
arxivId = {arXiv:1609.07061v1},
author = {Hubara, I and Courbariaux, M and Soudry, D. and El-yaniv, R and Bengio, Y},
eprint = {arXiv:1609.07061v1},
journal = {Accepted to JMLR},
title = {{Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations}},
url = {http://arxiv.org/abs/1609.07061},
year = {2016}
}
@article{Farkhooi2011,
author = {Farkhooi, F and Muller, E and Nawrot, M},
doi = {10.1103/PhysRevE.83.050905},
issn = {1539-3755},
journal = {Physical Review E},
month = {may},
number = {5},
pages = {1--4},
title = {{Adaptation reduces variability of the neuronal population code}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.83.050905},
volume = {83},
year = {2011}
}
@article{Peckol1999,
abstract = {The simple nervous system of the nematode C. elegans consists of 302 neurons with highly reproducible morphologies, suggesting a hard-wired program of axon guidance. Surprisingly, we show here that sensory activity shapes sensory axon morphology in C. elegans. A class of mutants with deformed sensory cilia at their dendrite endings have extra axon branches, suggesting that sensory deprivation disrupts axon outgrowth. Mutations that alter calcium channels or membrane potential cause similar defects. Cell-specific perturbations of sensory activity can cause cell-autonomous changes in axon morphology. Although the sensory axons initially reach their targets in the embryo, the mutations that alter sensory activity cause extra axon growth late in development. Thus, perturbations of activity affect the maintenance of sensory axon morphology after an initial pattern of innervation is established. This system provides a genetically tractable model for identifying molecular mechanisms linking neuronal activity to nervous system structure.},
author = {Peckol, E L and Zallen, J a and Yarrow, J C and Bargmann, C I},
issn = {0950-1991},
journal = {Development (Cambridge, England)},
keywords = {Afferent,Afferent: physiology,Afferent: ultrastructure,Animals,Axons,Axons: physiology,Axons: ultrastructure,Caenorhabditis elegans,Caenorhabditis elegans Proteins,Caenorhabditis elegans: embryology,Caenorhabditis elegans: genetics,Chemotaxis,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Developmental,Gene Expression Regulation,Genetically Modified,Green Fluorescent Proteins,Helminth Proteins,Helminth Proteins: genetics,Ion Channels,Ion Channels: genetics,Kv1.1 Potassium Channel,Kv1.2 Potassium Channel,Luminescent Proteins,Luminescent Proteins: biosynthesis,Luminescent Proteins: genetics,Morphogenesis,Nervous System,Nervous System: embryology,Neurons,Potassium Channels,Potassium Channels: genetics,Recombinant Fusion Proteins,Recombinant Fusion Proteins: biosynthesis,Voltage-Gated},
month = {may},
number = {9},
pages = {1891--1902},
pmid = {10101123},
title = {{Sensory activity affects sensory axon development in C. elegans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10101123},
volume = {126},
year = {1999}
}
@article{HelmchenWaters02,
abstract = {Changes in intracellular free calcium ion concentration ([{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i)

have been visualized over more than two decades using fluorescent

dyes and optical microscopy. So far, however, most imaging studies

have been performed on isolated cells or brain tissue. Here, we review

approaches to measure cellular [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i changes in vivo,

i.e. within the intact brain of a living animal. In particular we

describe the application of two-photon microscopy to the mammalian

central nervous system, which has recently enabled studies of {\{}Ca{\}}{\^{}}{\{}2+{\}}

dynamics in individual dendrites in anaesthetized rats. New developments

in microscopy and labeling techniques are creating further opportunities

to study {\{}Ca{\}}{\^{}}{\{}2+{\}} dynamics in vivo and are likely to make measurements

of spatio-temporal [{\{}Ca{\}}{\^{}}{\{}2+{\}}]{\_}i distributions feasible even

in awake, behaving mammals.},
author = {Helmchen, Fritjof and Waters, Jack},
journal = {Eur J Pharmacol},
keywords = {Animals; Brain; Calcium; Dendrites; Diagnostic Ima},
month = {jul},
number = {2-3},
pages = {119--129},
pmid = {12151004},
title = {{{\{}Ca{\}}{\^{}}{\{}2+{\}} imaging in the mammalian brain in vivo.}},
volume = {447},
year = {2002}
}
@article{SD03,
author = {Sahani, M and Dayan, P},
journal = {Neural Computation},
pages = {2255--2279},
title = {{Doubly Distributional Population Codes: Simultaneous Representation of Uncertainty and Multiplicity}},
volume = {15},
year = {2003}
}
@article{GentleEM,
author = {Bilmes, J A},
journal = {International Computer Science Institute},
pages = {1--13},
title = {{A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation for Gaussian Mixture and Hidden Markov Models}},
volume = {4},
year = {1998}
}
@book{FahrmeirTutz94,
author = {Fahrmeir, L and Tutz, G},
publisher = {Springer},
title = {{Multivariate Statistical Modelling Based on Generalized Linear Models}},
year = {1994}
}
@article{YasharSFN08,
author = {Ahmadian, Y and Pillow, J W and Kulkarni, J and Shlens, J and Simoncelli, E and Chichilnisky, E and Paninski, L},
journal = {SFN Abstract},
title = {{Analyzing the neural code in the primate retina using efficient model-based decoding techniques}},
year = {2008}
}
@article{WAR97,
author = {Warland, D and Reinagel, P and Meister, M},
journal = {Journal of Neurophysiology},
pages = {2336--2350},
title = {{Decoding visual information from a population of retinal ganglion cells}},
volume = {78},
year = {1997}
}
@article{Briggman2005,
author = {Briggman, KL and Abarbanel, HDI and Kristan, WB},
journal = {Science},
number = {265},
pages = {896--901},
title = {{Optical imaging of neuronal populations during decision-making}},
url = {http://www.sciencemag.org/content/307/5711/896.short},
volume = {307},
year = {2005}
}
@article{Rad2010,
abstract = {Estimating two-dimensional firing rate maps is a common problem, arising in a number of contexts: the estimation of place fields in hippocampus, the analysis of temporally nonstationary tuning curves in sensory and motor areas, the estimation of firing rates following spike-triggered covariance analyses, etc. Here we introduce methods based on Gaussian process nonparametric Bayesian techniques for estimating these two-dimensional rate maps. These techniques offer a number of advantages: the estimates may be computed efficiently, come equipped with natural errorbars, adapt their smoothness automatically to the local density and informativeness of the observed data, and permit direct fitting of the model hyperparameters (e.g., the prior smoothness of the rate map) via maximum marginal likelihood. We illustrate the method's flexibility and performance on a variety of simulated and real data.},
annote = {2011num50},
author = {Rad, Kamiar Rahnama and Paninski, L},
doi = {10.3109/0954898X.2010.532288},
issn = {1361-6536},
journal = {Network (Bristol, England)},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Bayes Theorem,Brain,Brain: cytology,Computer Simulation,Humans,Models,Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Normal Distribution},
month = {jan},
number = {3-4},
pages = {142--68},
pmid = {21138363},
title = {{Efficient, adaptive estimation of two-dimensional firing rate surfaces via Gaussian process methods}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21138363},
volume = {21},
year = {2010}
}
@article{BS76,
author = {Bryant, H and Segundo, J},
journal = {Journal of Physiology},
pages = {279--314},
title = {{Spike initiation by transmembrane current: a white-noise analysis}},
volume = {260},
year = {1976}
}
@article{O'MalleyFetcho96,
abstract = {Although vertebrate hindbrains are segmented structures, the functional

significance of the segmentation is unknown. In zebrafish, the hindbrain

segments contain serially repeated classes of individually identifiable

neurons. We took advantage of the transparency of larval zebrafish

and used confocal calcium imaging in the intact fish to study the

activity of one set of individually identified, serially homologous

reticulospinal cells (the Mauthner cell, MID2cm, and MID3cm) during

behavior. Behavioral studies predicted that differential activity

in this set of serially homologous neurons might serve to control

the directionality of the escape behavior that fish use to avoid

predators. We found that the serially homologous cells are indeed

activated during escapes and that the combination of cells activated

depends upon the location of the sensory stimulus used to elicit

the escape. The patterns of activation we observed were exactly those

predicted by behavioral studies. The data suggest that duplication

of ancestral hindbrain segments, and subsequent functional diversification,

resulted in sets of related neurons whose activity patterns create

behavioral variability.},
author = {O'Malley, D M and Kao, Y H and Fetcho, J R},
journal = {Neuron},
keywords = {Animals; Calcium; Differential Threshold; Electrop},
month = {dec},
number = {6},
pages = {1145--1155},
pmid = {8982162},
title = {{Imaging the functional organization of zebrafish hindbrain segments during escape behaviors.}},
volume = {17},
year = {1996}
}
@article{MorestBohne98,
abstract = {Adult chinchillas were exposed once to an octave-band noise, centered

at 4 kHz, and allowed to survive for 16 days or for 1, 2, 4, and

8 months. Axonal degeneration was mapped in the cochlear nucleus,

using the Nauta-Rasmussen silver method, and related to hair cell

damage and to loss of myelinated nerve fibers in the osseous spiral

lamina of the cochlea. Axonal degeneration in the dorsal cochlear

nucleus had already reached a peak by 16 days and disappeared after

1 month. Meanwhile, myelinated nerve fiber degeneration in the cochlea

extended basally, followed 2 weeks to 2 months later by spread of

axonal degeneration into the corresponding high-frequency region

of the ventral cochlear nucleus. Axonal degeneration occurred early

in the low-frequency region of the ventral cochlear nucleus, followed

2-4 weeks later by spread of myelinated fiber degeneration into more

apical regions of the cochlea. New degeneration of axons in the cochlear

nerve and in the ventral cochlear nucleus continued to occur for

up to 8 months after stimulation. These findings imply that plastic

changes in the central auditory pathways could play a role in the

long-term effects of cochlear damage and acoustic overstimulation,

possibly leading to a chronic neurodegenerative condition in the

ear and in the brain.},
author = {Morest, D K and Kim, J and Potashner, S J and Bohne, B A},
doi = {3.0.CO;2-S},
journal = {Microscopy Research and Technique},
keywords = {Acoustic Stimulation; Animals; Chinchilla; Cochlea,P.H.S.; Silver Staining; Time Factors,U.S. Gov't},
month = {may},
number = {3},
pages = {205--216},
pmid = {9605338},
title = {{Long-term degeneration in the cochlear nerve and cochlear nucleus of the adult chinchilla following acoustic overstimulation.}},
url = {http://dx.doi.org/3.0.CO;2-S},
volume = {41},
year = {1998}
}
@article{LAKSH06,
author = {Srinivasan, L and Eden, U and Willsky, A and Brown, E},
journal = {Neural Computation},
pages = {2465--2494},
title = {{A state-space analysis for reconstruction of goal-directed movements using neural signals}},
volume = {18},
year = {2006}
}
@book{BenderOrszagBook78,
address = {New York},
author = {Bender, C and Orszag, S},
publisher = {McGraw Hill},
title = {{Advance mathematical methods for scientists and engineers}},
year = {1978}
}
@article{Nikolenko08,
author = {Nikolenko, V and Watson, B and Araya, R and Woodruff, A and Peterka, D and Yuste, R},
journal = {Frontiers in Neural Circuits},
pages = {5},
title = {{SLM microscopy: scanless two-photon imaging and photostimulation using spatial light modulators}},
volume = {2},
year = {2008}
}
@article{Pemantle2007,
author = {Pemantle, Robin},
doi = {10.1214/07-PS094},
issn = {1549-5787},
journal = {Probability Surveys},
keywords = {agent-based model,and phrases,dynamical system,errw,evo-,exchangeability,learning,lyapunov function,olya,p,reinforced random walk,s urn,stochas-,tic approximation,urn model,urn scheme,vrrw},
pages = {1--79},
title = {{A survey of random processes with reinforcement}},
url = {http://www.i-journals.org/ps/viewarticle.php?id=94{\&}layout=abstract},
volume = {4},
year = {2007}
}
@article{Wu|2006|,
author = {Wu, J S and Luo, L},
journal = {Nature Protocols},
pages = {2583--2589},
title = {{A protocol for mosaic analysis with a repressible cell marker (MARCM) in Drosophila}},
volume = {1}
}
@article{Kr98,
author = {Krichevsky, R},
journal = {IEEE Transactions on Information Theory},
pages = {296--303},
title = {{Laplace's law of succession and universal encoding}},
volume = {44},
year = {1998}
}
@article{PanYajima08,
author = {Paninski, L and Yajima, M},
journal = {IEEE Transactions on Information Theory},
pages = {4384--4388},
title = {{Undersmoothed kernel entropy estimators}},
volume = {54},
year = {2008}
}
@inproceedings{Vinagre2002,
author = {Vinagre, B.M. and Chen, Y.Q.},
booktitle = {Lecture Notes Prepared for The Tutorial Workshop},
keywords = {Fractional Calculus},
mendeley-tags = {Fractional Calculus},
title = {{Fractional calculus applications in automatic control and robotics}},
url = {http://mechatronics.ece.usu.edu/foc/cdc02tw/cdrom/Slides/Presentacion/overview{\_}tw2{\_}cdc02.pdf},
volume = {2},
year = {2002}
}
@book{McLachlanPeel00,
author = {McLachlan, G and Peel, D},
publisher = {Wiley-Interscience},
title = {{Finite Mixture Models}},
year = {2000}
}
@article{Un-natural1998,
author = {Un-natural, Free Will Is and Bargh, John A},
pages = {128--154},
title = {{Free Will Is Un-natural}},
year = {1998}
}
@article{Shah2010,
abstract = {Dendritic ion channels are essential for the regulation of intrinsic excitability as well as modulating the shape and integration of synaptic signals. Changes in dendritic channel function have been associated with many forms of synaptic plasticity. Recent evidence suggests that dendritic ion channel modulation and trafficking could contribute to plasticity-induced alterations in neuronal function. In this review we discuss our current knowledge of dendritic ion channel modulation and trafficking and their relationship to cellular and synaptic plasticity. We also consider the implications for neuronal function. We argue that to gain an insight into neuronal information processing it is essential to understand the regulation of dendritic ion channel expression and properties.},
annote = {2010IInum12.31},
author = {Shah, Mala M and Hammond, Rebecca S and Hoffman, Dax a},
doi = {10.1016/j.tins.2010.03.002},
issn = {1878-108X},
journal = {Trends in Neurosciences},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
month = {apr},
pages = {1--10},
pmid = {20363038},
publisher = {Elsevier Ltd},
title = {{Dendritic ion channel trafficking and plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20363038},
year = {2010}
}
@article{Canepari08,
author = {Canepari, M and Vogt, K and Zecevic, D},
journal = {Cellular and Molecular Neurobiology},
title = {{Combining Voltage and Calcium Imaging from Neuronal Dendrites}},
year = {2008}
}
@article{Lewi06,
abstract = {We apply an adaptive approach to optimal experimental design in the

context of estimating the unknown parameters of a model of a neuron's

response. We present an algorithm to choose the optimal (most informative)

stimulus on each trial; this algorithm can be implemented efficiently

even for high-dimensional stimulus and parameter spaces (in particular,

no high-dimensional numerical optimizations or integrations are required).

Our simulation results show that model parameters can be estimated

much more efficiently using this adaptive algorithm rather than random

sampling. We also show that this adaptive approach leads to superior

performance in the case that the model parameters are nonstationary,

as would be expected in real experiments.},
author = {Lewi, J and Butera, R and Paninski, L},
doi = {10.1109/IEMBS.2006.260690},
journal = {NIPS},
pages = {599--602},
pmid = {17945990},
title = {{Real-time adaptive information-theoretic optimization of neurophysiological experiments}},
url = {http://dx.doi.org/10.1109/IEMBS.2006.260690},
volume = {1},
year = {2006}
}
@article{Manuscript2008,
author = {Manuscript, Author},
keywords = {agency,bereitschaftspotential,consciousness,decision,free will,magnetic stimulation,movement,movement related cortical potential,transcranial,volition},
number = {6},
pages = {1179--1192},
title = {{NIH Public Access}},
volume = {118},
year = {2008}
}
@article{Dudman2009,
abstract = {The transformation of synaptic input into patterns of spike output is a fundamental operation that is determined by the particular complement of ion channels that a neuron expresses. Although it is well established that individual ion channel proteins make stochastic transitions between conducting and non-conducting states, most models of synaptic integration are deterministic, and relatively little is known about the functional consequences of interactions between stochastically gating ion channels. Here, we show that a model of stellate neurons from layer II of the medial entorhinal cortex implemented with either stochastic or deterministically gating ion channels can reproduce the resting membrane properties of stellate neurons, but only the stochastic version of the model can fully account for perithreshold membrane potential fluctuations and clustered patterns of spike output that are recorded from stellate neurons during depolarized states. We demonstrate that the stochastic model implements an example of a general mechanism for patterning of neuronal output through activity-dependent changes in the probability of spike firing. Unlike deterministic mechanisms that generate spike patterns through slow changes in the state of model parameters, this general stochastic mechanism does not require retention of information beyond the duration of a single spike and its associated afterhyperpolarization. Instead, clustered patterns of spikes emerge in the stochastic model of stellate neurons as a result of a transient increase in firing probability driven by activation of HCN channels during recovery from the spike afterhyperpolarization. Using this model, we infer conditions in which stochastic ion channel gating may influence firing patterns in vivo and predict consequences of modifications of HCN channel function for in vivo firing patterns.},
author = {Dudman, Joshua T and Nolan, M F},
doi = {10.1371/journal.pcbi.1000290},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cyclic Nucleotide-Gated Cation Channels,Cyclic Nucleotide-Gated Cation Channels: physiolog,Entorhinal Cortex,Entorhinal Cortex: physiology,Humans,Ion Channel Gating,Ion Channel Gating: physiology,Ion Transport,Ion Transport: physiology,Models, Neurological,Neural Conduction,Neural Conduction: physiology,Potassium Channels,Potassium Channels: physiology,Stochastic Processes,Synaptic Transmission,Synaptic Transmission: physiology},
month = {feb},
number = {2},
pages = {e1000290},
pmid = {19214199},
title = {{Stochastically gating ion channels enable patterned spike firing through activity-dependent modulation of spike probability.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19214199},
volume = {5},
year = {2009}
}
@article{Kohn2007a,
abstract = {Recent sensory experience affects both perception and the response properties of visual neurons. Here I review a rapid form of experience-dependent plasticity that follows adaptation, the presentation of a particular stimulus or ensemble of stimuli for periods ranging from tens of milliseconds to minutes. Adaptation has a rich history in psychophysics, where it is often used as a tool for dissecting the perceptual mechanisms of vision. Although we know comparatively little about the neurophysiological effects of adaptation, work in the last decade has revealed a rich repertoire of effects. This review focuses on this recent physiological work, the cellular and biophysical mechanisms that may underlie the observed effects, and the functional benefit that they may afford. I conclude with a brief discussion of some important open questions in the field.},
annote = {2009num46},
author = {Kohn, Adam},
doi = {10.1152/jn.00086.2007},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Adaptation,Animals,Biophysical Phenomena,Biophysics,Humans,Neurons,Neurons: physiology,Photic Stimulation,Physiological,Time Factors,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = {may},
number = {5},
pages = {3155--64},
pmid = {17344377},
title = {{Visual adaptation: physiology, mechanisms, and functional benefits.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17344377 http://jn.physiology.org/cgi/content/abstract/97/5/3155},
volume = {97},
year = {2007}
}
@techreport{Zakai1965a,
address = {Waltham, Massachusetts},
annote = {2010num1.2},
author = {Zakai, M},
institution = {Sylvania Electronic System},
number = {563},
title = {{THE OPTIMAL FILTERING OF MARKOV JUMP}},
year = {1965}
}
@article{Seung2014,
author = {Seung, H. Sebastian and S{\"{u}}mb{\"{u}}l, Uygar},
doi = {10.1016/j.neuron.2014.08.054},
issn = {08966273},
journal = {Neuron},
month = {sep},
number = {6},
pages = {1262--1272},
title = {{Neuronal Cell Types and Connectivity: Lessons from the Retina}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627314007843},
volume = {83},
year = {2014}
}
@article{Purvis2012,
abstract = {Cells transmit information through molecular signals that often show complex dynamical patterns. The dynamic behavior of the tumor suppressor p53 varies depending on the stimulus; in response to double-strand DNA breaks, it shows a series of repeated pulses. Using a computational model, we identified a sequence of precisely timed drug additions that alter p53 pulses to instead produce a sustained p53 response. This leads to the expression of a different set of downstream genes and also alters cell fate: Cells that experience p53 pulses recover from DNA damage, whereas cells exposed to sustained p53 signaling frequently undergo senescence. Our results show that protein dynamics can be an important part of a signal, directly influencing cellular fate decisions.},
author = {Purvis, Jeremy E and Karhohs, Kyle W and Mock, Caroline and Batchelor, Eric and Loewer, Alexander and Lahav, Galit},
doi = {10.1126/science.1218351},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
month = {jun},
number = {6087},
pages = {1440--4},
pmid = {22700930},
title = {{P53 Dynamics Control Cell Fate.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22700930},
volume = {336},
year = {2012}
}
@article{KEN05,
author = {Kennel, M and Shlens, J and Abarbanel, H and Chichilnisky, E J},
journal = {Neural Computation},
pages = {1531--1576},
title = {{Estimating Entropy Rates with {\{}B{\}}ayesian Confidence Intervals}},
volume = {17},
year = {2005}
}
@article{Ma|1997|,
abstract = {A novel boundary detection scheme based on {\"{i}}¾“edge flow{\"{i}}¾” is proposed
in this paper. This scheme utilizes a predictive coding model to
identify the direction of change in color and texture at each image
location at a given scale, and constructs an edge flow vector. By
iteratively propagating the edge flow, the boundaries can be detected
at image locations which encounter two opposite directions of flow
in the stable state. A user defined image scale is the only significant
control parameter that is needed by the algorithm. The scheme facilitates
integration of color and texture into a single framework for boundary
detection.},
annote = {The paper introduces a method of edge construction based on "Edge{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}flow", which is essentially a piece-by-piece reconstruction of the{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}edge based on its likely direction and strength. Directionality and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}strength of edge at given point is determined via "predictive" power{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}or constancy of intensity in the direction of the edge, smoothed{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}with a gaussian kernel.},
author = {Ma, W Y and Manjynath, S},
journal = {IEEE},
keywords = {computational,edge-detection,image processing,segmentation},
title = {{Edge Flow: A Framework of Boundary Detection and Image Segmentation}}
}
@article{Bender|2004|,
abstract = {It has recently been shown that, when properly defined, a -gx{\^{}}4 potential
in quantum mechanics possesses a positive definite spectrum. The
positivity of the spectrum is apparently due to the PT symmetry of
the Hamiltonian. Furthermore, for such a theory the expectation value
{\textless}x{\textgreater} is not zero. This paper extends these results to a -gf{\^{}}4 quantum
field theory in D-dimensional Euclidean space. The value of the one-point
Green{\"{i}}¾'s function G{\_}1={\textless}phi{\textgreater} in this field theory is calculated in
the weak-coupling and strong-coupling regimes. Nonperturbative techniques
must be used in both of these regimes. For small g, the value of
G{\_}1 is dominated by a classical soliton. Strong-coupling graphical
methods are used to calculate G{\_}1 for large g.},
annote = {The paper discusses 1-point Green{\&}{\#}039;s function for a unstable phi{\^{}}4{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}theory with negative coupling. Meaningful definition to the theory{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}is given by integrating in path integral along complex coordinate{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}dimensions and using analytic properties of the integral.},
author = {Bender, Carl M and Meisinger, Peter N and Yang, Haitang},
journal = {Physical Review D},
keywords = {green's function,ground state,negative coupling,phi{\^{}}4,physics,quantum field theory,symmetry breaking},
pages = {45001},
title = {{Calculation of the one-point Green's function for a -g phi{\^{}}4 quantum field theory}},
volume = {63}
}
@book{Abeles91,
author = {Abeles, M},
publisher = {Cambridge University Press},
title = {{Corticonics}},
year = {1991}
}
@article{SF89,
author = {Smith, W and Fetz, E},
journal = {Neuroscience Letters},
pages = {76--81},
title = {{Effects of synchrony between primate corticomotoneuronal cells on post-spike facilitation of muscles and motor units}},
volume = {96},
year = {1989}
}
@article{Anderson00,
author = {Anderson, Jeffrey S and Carandini, Matteo and Ferster, David},
journal = {J. Neurophysiol},
pages = {909--926},
title = {{Orientation Tuning of Input Conductance, Excitation, and Inhibition in Cat Primary Visual Cortex}},
volume = {84},
year = {2000}
}
@article{Zhang2015,
abstract = {We study the improper learning of multi-layer neural networks. Suppose that the neural network to be learned has {\$}k{\$} hidden layers and that the {\$}\backslashell{\_}1{\$}-norm of the incoming weights of any neuron is bounded by {\$}L{\$}. We present a kernel-based method, such that with probability at least {\$}1 - \backslashdelta{\$}, it learns a predictor whose generalization error is at most {\$}\backslashepsilon{\$} worse than that of the neural network. The sample complexity and the time complexity of the presented method are polynomial in the input dimension and in {\$}(1/\backslashepsilon,\backslashlog(1/\backslashdelta),F(k,L)){\$}, where {\$}F(k,L){\$} is a function depending on {\$}(k,L){\$} and on the activation function, independent of the number of neurons. The algorithm applies to both sigmoid-like activation functions and ReLU-like activation functions. It implies that any sufficiently sparse neural network is learnable in polynomial time.},
archivePrefix = {arXiv},
arxivId = {1510.03528},
author = {Zhang, Yuchen and Lee, Jason D. and Jordan, Michael I.},
eprint = {1510.03528},
journal = {arXiv},
title = {{L1-regularized Neural Networks are Improperly Learnable in Polynomial Time}},
url = {http://arxiv.org/abs/1510.03528},
year = {2015}
}
@article{Vasilkov2012,
author = {Vasilkov, Viacheslav and Tikidji-Hamburyan, Ruben},
doi = {10.1103/PhysRevLett.108.138104},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {mar},
number = {13},
pages = {1--5},
title = {{Accurate Detection of Interaural Time Differences by a Population of Slowly Integrating Neurons}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.108.138104},
volume = {108},
year = {2012}
}
@article{Shilnikov2005,
annote = {2010IIInum76},
author = {Shilnikov, Andrey and Cymbalyuk, Gennady},
doi = {10.1103/PhysRevLett.94.048101},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {jan},
number = {4},
pages = {2--5},
title = {{Transition between Tonic Spiking and Bursting in a Neuron Model via the Blue-Sky Catastrophe}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.94.048101},
volume = {94},
year = {2005}
}
@article{BFSS02,
author = {Braess, D and Forster, J and Sauer, T and Simon, H},
journal = {Algorithmic Learning Theory},
pages = {380--394},
title = {{How to achieve minimax {\{}K{\}}ullback-{\{}L{\}}eibler distance from an unknown finite distribution}},
volume = {13},
year = {2002}
}
@incollection{Bottou2011,
address = {Cambridge},
author = {Bottou, L and Bousquet, Olivier},
booktitle = {Optimization for Machine Learning},
editor = {Sra, Suvrit and Nowozin, Sebastian and Wright, Stephen J.},
pages = {351},
publisher = {MIT press},
title = {{The Tradeoffs of Large-Scale Learning}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=JPQx7s2L1A8C{\&}oi=fnd{\&}pg=PA351{\&}dq=The+Tradeoffs+of+Large+Scale+Learning{\&}ots=vbh7zgi9Fb{\&}sig=y2ZTOtVuZMk2HLo4Emp3hLeeujs},
year = {2011}
}
@article{Adhikari2012,
author = {Adhikari, S P and Yang, C and Kim, H and Chua, L},
doi = {10.1109/TNNLS.2012.2204770},
issn = {2162-237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems.},
month = {sep},
number = {9},
pages = {1426--1435},
title = {{Memristor Bridge Synapse-Based Neural Network and Its Learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6232461 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6232461},
volume = {23},
year = {2012}
}
@article{Platkiewicz2010,
abstract = {In central neurons, the threshold for spike initiation can depend on the stimulus and varies between cells and between recording sites in a given cell, but it is unclear what mechanisms underlie this variability. Properties of ionic channels are likely to play a role in threshold modulation. We examined in models the influence of Na channel activation, inactivation, slow voltage-gated channels and synaptic conductances on spike threshold. We propose a threshold equation which quantifies the contribution of all these mechanisms. It provides an instantaneous time-varying value of the threshold, which applies to neurons with fluctuating inputs. We deduce a differential equation for the threshold, similar to the equations of gating variables in the Hodgkin-Huxley formalism, which describes how the spike threshold varies with the membrane potential, depending on channel properties. We find that spike threshold depends logarithmically on Na channel density, and that Na channel inactivation and K channels can dynamically modulate it in an adaptive way: the threshold increases with membrane potential and after every action potential. Our equation was validated with simulations of a previously published multicompartemental model of spike initiation. Finally, we observed that threshold variability in models depends crucially on the shape of the Na activation function near spike initiation (about -55 mV), while its parameters are adjusted near half-activation voltage (about -30 mV), which might explain why many models exhibit little threshold variability, contrary to experimental observations. We conclude that ionic channels can account for large variations in spike threshold.},
annote = {2010IIInum25},
author = {Platkiewicz, J and Brette, R},
doi = {10.1371/journal.pcbi.1000850},
editor = {Graham, Lyle J.},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Computational Biology/Computational Neuroscience,Neuron Model,Neuroscience/Theoretical Neuroscience,Research Article},
mendeley-tags = {Neuron Model},
month = {jul},
number = {7},
pages = {e1000850},
pmid = {20628619},
publisher = {Public Library of Science},
title = {{A threshold equation for action potential initiation.}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1000850},
volume = {6},
year = {2010}
}
@article{French2008,
abstract = {The power law of sensory adaptation was introduced more than 50 years ago. It is characterized by action potential adaptation that follows fractional powers of time or frequency, rather than exponential decays and corresponding frequency responses. Power law adaptation describes the responses of a range of vertebrate and invertebrate sensory receptors to deterministic stimuli, such as steps or sinusoids, and to random (white noise) stimulation. Hypotheses about the physical basis of power law adaptation have existed since its discovery. Its cause remains enigmatic, but the site of power law adaptation has been located in the conversion of receptor potentials into action potentials in some preparations. Here, we used pseudorandom noise stimulation and direct spectral estimation to show that simulations containing only two voltage activated currents can reproduce the power law adaptation in two types of spider mechanoreceptors. Identical simulations were previously used to explain the different responses of these two types of sensory neurons to step inputs. We conclude that power law adaptation results during action potential encoding by nonlinear combination of a small number of activation and inactivation processes with different exponential time constants.},
annote = {2009num33},
author = {French, Andrew S and Torkkeli, P{\"{a}}ivi H},
doi = {10.1007/s10439-007-9392-9},
issn = {1521-6047},
journal = {Annals of biomedical engineering},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Animals,Computer Simulation,Mechanoreceptors,Mechanoreceptors: physiology,Models,Neurological,Neurons,Neurons: physiology,Physiological,Physiological: physiology,Sensory Thresholds,Sensory Thresholds: physiology,Spiders,Spiders: physiology,Touch,Touch: physiology},
number = {1},
pages = {153--161},
pmid = {17952602},
title = {{The power law of sensory adaptation: simulation by a model of excitability in spider mechanoreceptor neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17952602},
volume = {36},
year = {2008}
}
@book{Bellac2007,
author = {Bellac, Michel Le and Lin, Institut Non},
title = {{Non equilibrium statistical mechanics - Lecture Notes}},
year = {2007}
}
@article{Grossman1979,
annote = {2010IInum12.23

2010IInum12.15},
author = {Grossman, B Y Y and Parnas, I and Spira, M E},
journal = {The Journal of Physiology},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
pages = {307--322},
title = {{Differential conduction block in branches of a bifurcating axon}},
volume = {295},
year = {1979}
}
@article{SB03,
author = {Smith, A and Brown, E},
journal = {Neural Computation},
pages = {965--991},
title = {{Estimating a state-space model from point process observations}},
volume = {15},
year = {2003}
}
@article{RB95,
author = {{de Ruyter van Steveninck}, R and Bialek, W},
journal = {Phil Trans R Soc Lond Ser B},
pages = {321--340},
title = {{Reliability and statistical efficiency of a blowfly movement-sensitive neuron}},
volume = {348},
year = {1995}
}
@book{Shenoy2011,
author = {Shenoy, Konchady Gautam},
booktitle = {Idea},
number = {March},
pages = {1--4},
title = {{The derivation of Sylvesters Determinant Theorem}},
year = {2011}
}
@article{Ahrens,
author = {Ahrens, M B and Huys, Quentin J M and Paninski, L},
journal = {Advances in Neural Information Processing Systems},
keywords = {neuron},
mendeley-tags = {neuron},
title = {{Large-scale biophysical parameter estimation in single neurons via constrained linear regression}},
year = {2005}
}
@article{DG05,
author = {David, S and Gallant, J},
journal = {Network: Computation in Neural Systems},
pages = {239},
title = {{Predicting neuronal responses during natural vision}},
volume = {16},
year = {2005}
}
@article{FlusbergSchnitzer05a,
abstract = {Optical fibers guide light between separate locations and enable new

types of fluorescence imaging. Fiber-optic fluorescence imaging systems

include portable handheld microscopes, flexible endoscopes well suited

for imaging within hollow tissue cavities and microendoscopes that

allow minimally invasive high-resolution imaging deep within tissue.

A challenge in the creation of such devices is the design and integration

of miniaturized optical and mechanical components. Until recently,

fiber-based fluorescence imaging was mainly limited to epifluorescence

and scanning confocal modalities. Two new classes of photonic crystal

fiber facilitate ultrashort pulse delivery for fiber-optic two-photon

fluorescence imaging. An upcoming generation of fluorescence imaging

devices will be based on microfabricated device components.},
author = {Flusberg, Benjamin A and Cocker, Eric D and Piyawattanametha, Wibool and Jung, Juergen C and Cheung, Eunice L M and Schnitzer, Mark J},
doi = {10.1038/nmeth820},
journal = {Nat Methods},
keywords = {Animals; Fiber Optics; Humans; Microscopy,Fluorescence},
month = {dec},
number = {12},
pages = {941--950},
pmid = {16299479},
title = {{Fiber-optic fluorescence imaging.}},
url = {http://dx.doi.org/10.1038/nmeth820},
volume = {2},
year = {2005}
}
@article{pawlak2008dopamine,
annote = {2008num14},
author = {Pawlak, V and Kerr, J N D},
journal = {Journal of Neuroscience},
number = {10},
pages = {2435},
publisher = {Soc Neuroscience},
title = {{Dopamine receptor activation is required for corticostriatal spike-timing-dependent plasticity}},
volume = {28},
year = {2008}
}
@article{Theunissen06,
author = {Woolley, Sarah M N and Gill, Patrick R and Theunissen, Frederic E},
journal = {Journal of Neuroscience},
month = {mar},
number = {9},
pages = {2499--2512},
title = {{Stimulus-dependent auditory tuning results in synchronous population coding of vocalizations in the songbird midbrain}},
volume = {26},
year = {2006}
}
@article{Haykin2008,
author = {Haykin, S.},
journal = {Mc Millan, New Jersey},
publisher = {Prentice Hall},
title = {{Neural networks: a comprehensive foundation}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=K7P36lKzI{\_}QC{\&}oi=fnd{\&}pg=PR11{\&}dq=Neural+Networks+-+A+Comprehensive+Foundation{\&}ots=gltF1vDtEY{\&}sig=3Ov8fNGbrd5AadSk1GtnweU1nuw http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle},
year = {2008}
}
@article{Pena00,
author = {{Pe{\~{n}}a, J.-L.} and {Konishi, M.}},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
pages = {11787--11792},
publisher = {National Academy of Sciences},
title = {{Cellular Mechanisms for Resolving Phase Ambiguity in the Owl's Inferior Colliculus}},
volume = {97},
year = {2000}
}
@article{Pozzorini2013,
author = {Pozzorini, C and Naud, R and Mensi, S and Gerstner, W},
journal = {Nature Neuroscience},
pages = {942--948},
title = {{Temporal whitening by power-law adaptation in neocortical neurons}},
url = {http://infoscience.epfl.ch/record/186650/files/Preprint.pdf},
volume = {16},
year = {2013}
}
@article{Tiesinga2008,
abstract = {A train of action potentials (a spike train) can carry information in both the average firing rate and the pattern of spikes in the train. But can such a spike-pattern code be supported by cortical circuits? Neurons in vitro produce a spike pattern in response to the injection of a fluctuating current. However, cortical neurons in vivo are modulated by local oscillatory neuronal activity and by top-down inputs. In a cortical circuit, precise spike patterns thus reflect the interaction between internally generated activity and sensory information encoded by input spike trains. We review the evidence for precise and reliable spike timing in the cortex and discuss its computational role.},
author = {Tiesinga, Paul and Fellous, Jean-Marc and Sejnowski, T J},
doi = {10.1038/nrn2315},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Biological Clocks,Biological Clocks: physiology,Humans,Neurons,Neurons: physiology,Reaction Time,Reaction Time: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Pathways,Visual Pathways: cytology,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = {feb},
number = {2},
pages = {97--107},
pmid = {18200026},
title = {{Regulation of spike timing in visual cortical circuits.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2868969{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2008}
}
@article{Kriegstein1983,
author = {Kriegstein, A.R. and Dichter, M.A.},
journal = {The Journal of Neuroscience},
number = {8},
pages = {1634},
publisher = {Soc Neuroscience},
title = {{Morphological classification of rat cortical neurons in cell culture}},
url = {http://www.jneurosci.org/content/3/8/1634.short},
volume = {3},
year = {1983}
}
@article{Mccauley2007,
author = {Mccauley, J and Gunaratne, G and Bassler, K},
doi = {10.1016/j.physa.2006.12.028},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {fractional brownian motion,hurst exponents,markov processes,scaling,stationary and nonstationary increments},
month = {jun},
number = {1},
pages = {1--9},
title = {{Hurst exponents, Markov processes, and fractional Brownian motion}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378437106013483},
volume = {379},
year = {2007}
}
@article{GoldShadlen02,
author = {Gold, J and Shadlen, M},
journal = {Neuron},
pages = {299--308},
title = {{Banburismus and the brain: decoding the relationship between sensory stimuli, decisions, and reward}},
volume = {36},
year = {2002}
}
@article{WW94,
author = {Weisberg, S and Welsh, A},
journal = {Annals of Statistics},
pages = {1674--1700},
title = {{Adapting for the missing link}},
volume = {22},
year = {1994}
}
@article{Bureau2004,
author = {Bureau, I and Shepherd, G M and Svoboda, K},
journal = {Neuron},
number = {5},
pages = {789--801.},
title = {{Precise development of functional and anatomical columns in the neocortex.}},
volume = {42},
year = {2004}
}
@article{Vakorin09,
author = {Vakorin, Vasily A and Krakovska, Olga A and Mcintosh, Anthony R},
journal = {Journal of Neuroscience Methods},
pages = {152--160},
title = {{Confounding effects of indirect connections on causality estimation}},
volume = {184},
year = {2009}
}
@article{Long06,
author = {Long, C J and Purdon, R L and Temereanca, S and Desai, N U and H{\"{a}}m{\"{a}}l{\"{a}}inen, M and Brown, E N},
journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title = {{Large scale {\{}K{\}}alman filtering solutions to the electrophysiological source localization problem--a {\{}MEG{\}} case study.}},
volume = {1},
year = {2006}
}
@article{Boukhobza2011,
author = {Boukhobza, T. and Hamelin, F.},
doi = {10.1016/j.automatica.2010.11.003},
issn = {00051098},
journal = {Automatica},
keywords = {Reservoir Computing,switching linear systems},
mendeley-tags = {Reservoir Computing},
month = {feb},
number = {2},
pages = {395--402},
publisher = {Elsevier Ltd},
title = {{Observability of switching structured linear systems with unknown input. A graph-theoretic approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0005109810004863},
volume = {47},
year = {2011}
}
@article{AdelsonBergen85,
author = {Adelson, E and Bergen, J},
journal = {J. Opt. Soc. Am. A},
pages = {284--299},
title = {{Spatiotemporal energy models for the perception of motion}},
volume = {2},
year = {1985}
}
@article{Beck07,
author = {Beck, J and Ma, W and Latham, P and Pouget, A},
journal = {Prog Brain Res},
pages = {509--519},
title = {{Probabilistic population codes and the exponential family of distributions}},
volume = {165},
year = {2007}
}
@book{Higham08,
author = {Higham, N},
publisher = {SIAM},
title = {{Functions of matrices: theory and computation}},
year = {2008}
}
@article{ZhangOertel94,
author = {Zhang, S and Oertel, D},
journal = {Journal of Neurophysiology},
month = {mar},
number = {3},
pages = {914--930},
title = {{Neuronal circuits associated with the output of the dorsal cochlear nucleus through fusiform cells}},
volume = {71},
year = {1994}
}
@article{Brodsky|2000|,
abstract = {We give a complete representation of virtual Compton scattering gamma*p-{\textgreater}gamma
p at large initial photon virtuality Q2 and small momentum transfer
squared t in terms of the light-cone wavefunctions of the target
proton. We verify the identities between the skewed parton distributions
H(x; zeta; t) and E(x; zeta; t) which appear in deeply virtual Compton
scattering and the corresponding integrands of the Dirac and Pauli
form factors F1(t) and F2(t) and the gravitational form factors A{\_}q(t)
and B{\_}q(t) for each quark and anti-quark constituent. We illustrate
the general formalism for the case of deeply virtual Compton scattering
on the quantum uctuations of a fermion in quantum electrodynamics
at one loop.},
annote = {The paper discusses general derivation of GPD in LF Fock space formalism{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and some first order perturbative calculations.},
author = {Brodsky, S J and Diehl, M and Hwang, D Sung},
journal = {arXiv},
keywords = {fock space,generalized parton distribution,light front dynamics,nonvalence,perturbation theory,physics,quantum chromodynamics,valence},
pages = {9254},
title = {{Light-cone wavefunction representation of deeply virtual compton scattering}},
volume = {hep-ph}
}
@article{Liberty07,
author = {Liberty, Edo and Woolfe, Franco and Martinsson, Per-Gunnar and Rokhlin, Vladimir and Tygert, Mark},
journal = {Proceedings of the National Academy of Sciences},
pages = {20167--20172},
title = {{Randomized algorithms for the low-rank approximation of matrices}},
volume = {104},
year = {2007}
}
@article{Mainen1996a,
abstract = {Neocortical neurons display a wide range of dendritic morphologies, ranging from compact arborizations to highly elaborate branching patterns. In vitro electrical recordings from these neurons have revealed a correspondingly diverse range of intrinsic firing patterns, including non-adapting, adapting and bursting types. This heterogeneity of electrical responsivity has generally been attributed to variability in the types and densities of ionic channels. We show here, using compartmental models of reconstructed cortical neurons, that an entire spectrum of firing patterns can be reproduced in a set of neurons that share a common distribution of ion channels and differ only in their dendritic geometry. The essential behaviour of the model depends on partial electrical coupling of fast active conductances localized to the soma and axon and slow active currents located throughout the dendrites, and can be reproduced in a two-compartment model. The results suggest a causal relationship for the observed correlations between dendritic structure and firing properties and emphasize the importance of active dendritic conductances in neuronal function.},
author = {Mainen, Zachary F and Sejnowski, T J},
doi = {10.1038/382363a0},
issn = {0028-0836},
journal = {Nature},
keywords = {Action Potentials,Calcium Channels,Calcium Channels: metabolism,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Dendrites,Dendrites: physiology,Models,Neurological,Neurons,Neurons: cytology,Neurons: physiology,Potassium Channels,Potassium Channels: metabolism},
month = {jul},
number = {6589},
pages = {363--6},
pmid = {8684467},
title = {{Influence of dendritic structure on firing pattern in model neocortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8684467},
volume = {382},
year = {1996}
}
@incollection{HAWK04,
author = {Hawkes, A},
booktitle = {Computational Neuroscience: a comprehensive approach},
editor = {Feng, J},
pages = {131--158},
publisher = {CRC Press},
title = {{Stochastic modelling of single ion channels}},
year = {2004}
}
@article{James|1980|,
abstract = {The Monte Carlo method has long been recognised as a powerful technique
for performing certain calculations, generally those too complicated
for a more classical approach. Since the use of high-speed computers
became widespread in the 1950s, a great deal of theoretical investigation
has been undertaken and practical experience has been gained in the
Monte Carlo approach. The aim of this review is, first, to lay a
theoretical basis for both the {\"{i}}¾‘traditional{\"{i}}¾' Monte Carlo and
quasi- Monte Carlo methods, and, secondly, to present some practical
aspects of when and how to use them. An important theme of this review
will be the comparison of Monte Carlo, quasi-Monte Carlo and numerical
quadrature for the integration of functions, especially in many dimensions.},
annote = {This great review discusses monte carlo integration and in particular,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}quasi-monte-carlo approach and gives mention to Hlawka{\&}{\#}039;s theorem,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}stating that error of integral estimate by average of a number of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}points is bounded by the product of integral variation and so called{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}discrepancy of the point{\&}{\#}039;s sequence (which is a measure of sequence{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}uniformity and is often defined via function of x which measures{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the number of hits within a [centered] volume bound by point x and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}actual number of hits from the sequence, maximum of this function{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}over all points x may be taken as discrepancy measure) and Korobov{\&}{\#}039;s{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}theorem which states that discrepancy of the first n points of a{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}sequence cannot decrease faster than 1/n for large n.},
author = {James, F},
journal = {Reports on progress in physics},
keywords = {computational,mathematics,monte carlo method,physics,quantum monte carlo},
pages = {73},
title = {{Monte Carlo theory and practice}},
volume = {43}
}
@article{Last,
abstract = {Most real-world databases include a certain amount of exceptional
values, generally termed as {\"{i}}¾“outliers{\"{i}}¾”. The isolation of outliers
is important both for improving the quality of original data and
for reducing the impact of outlying values in the process of knowledge
discovery in databases. Most existing methods of outlier detection
are based on manual inspection of graphically represented data. In
this paper, we present a new approach to automating the process of
detecting and isolating outliers. The process is based on modeling
the human perception of exceptional values by using the fuzzy set
theory. Separate procedures are developed for detecting outliers
in discrete and continuous univariate data. The outlier detection
procedures are demonstrated on several standard datasets of varying
data quality.},
author = {Last, M and Kandel, A},
keywords = {automated,data mining,data preparation,data quality,fuzzy set theory,knowledge discovery in databases,mathematics,outliers detection,statistics},
title = {{Automated Detection of Outliers in Real-World Data}}
}
@article{Shima1992,
author = {Shima, Takeshi and Kimura, Tomohisa},
journal = {IEEE Journal of Solid-State Circuits},
month = {dec},
number = {12},
pages = {1868--1876},
title = {{Neuro chips with on-chip back-propagation and/or Hebbian learning}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=173117},
volume = {27},
year = {1992}
}
@article{Ceperley|1984|,
abstract = {A random walk algorithm is presented which exactly calculates the
properties of a many-electron system. For that purpose both the Green's
function Monte Carlo method and nodal relaxation have been employed
and both are described in detail. The scheme is applied to several
small molecules, (H{\_}3, LiH,Li{\_}2,H{\_}2O) and with modest computational
effort and simple importance functions, ground state energies are
obtained which agree with experimental energies within statistical
error bars. The small energy decrease due to nodal release is accurately
evalueated by a difference method.},
annote = {The paper describes diffusion monte carlo supplemented with released{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}node corrections.},
author = {Ceperley, D M and Alder, B J},
journal = {Journal of Chemical Physics},
keywords = {diffusion monte carlo,fermion sign problem,physics,release node},
number = {12},
pages = {5833},
title = {{Quantum monte carlo for molecules: green's function and nodal release}},
volume = {81}
}
@article{MUSS03,
author = {Mussa-Ivaldi, F and Miller, L},
journal = {Trends in Neurosciences},
pages = {329--334},
title = {{Brain-machine interfaces: computational demands and clinical needs meet basic neuroscience}},
volume = {26},
year = {2003}
}
@article{Schulz2007,
abstract = {The postdevelopmental basis of cellular identity and the unique cellular output of a particular neuron type are of particular interest in the nervous system because a detailed understanding of circuits responsible for complex processes in the brain is impeded by the often ambiguous classification of neurons in these circuits. Neurons have been classified by morphological, electrophysiological, and neurochemical techniques. More recently, molecular approaches, particularly microarray, have been applied to the question of neuronal identity. With the realization that proteins expressed exclusively in only one type of neuron are rare, expression profiles obtained from neuronal subtypes are analyzed to search for diagnostic patterns of gene expression. However, this expression profiling hinges on one critical and implicit assumption: that neurons of the same type in different animals achieve their conserved functional output via conserved levels and quantitative relationships of gene expression. Here we exploit the unambiguously identifiable neurons in the crab stomatogastric ganglion to investigate the precise quantitative expression profiling of neurons at the level of single-cell ion channel expression. By measuring absolute mRNA levels of six different channels in the same individually identified neurons, we demonstrate that not only do individual cell types possess highly variable levels of channel expression but that this variability is constrained by unique patterns of correlated channel expression.},
author = {Schulz, D J and Goaillard, J M and Marder, E},
doi = {10.1073/pnas.0705827104},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Base Sequence,Brachyura,Gene Expression Profiling,Ion Channels,Ion Channels: genetics,Molecular Sequence Data,Neurons,Neurons: metabolism},
month = {aug},
number = {32},
pages = {13187--91},
pmid = {17652510},
title = {{Quantitative expression profiling of identified neurons reveals cell-specific constraints on highly variable levels of gene expression.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1933263{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {104},
year = {2007}
}
@techreport{Kakade2008,
author = {Kakade, Sham and Tewari, Ambuj},
title = {{Lecture Notes: Concentration, ERM, and Compression Bounds}},
year = {2008}
}
@book{Tuck88,
author = {Tuckwell, H},
publisher = {Cambridge University Press},
title = {{Introduction to theoretical neurobiology}},
year = {1988}
}
@article{Rubin87,
author = {Rubin, D B},
journal = {Journal of the American Statistical Association},
number = {398},
pages = {543--546},
title = {{A noniterative sampling/importance resampling alternative to the data augmentation algorithm for creating a few imputations when fractions of missing information are modest: The SIR algorithm}},
volume = {82},
year = {1987}
}
@book{duda2001pattern,
address = {New York, NY, USA},
author = {Duda, R O and Hart, P E and Stork, D G},
edition = {2nd},
publisher = {John Wiley {\&} Sons Inc},
title = {{Pattern Classification}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Pattern+Classification{\#}5},
year = {2001}
}
@article{Attwell|2001|,
author = {Attwell, D and Laughlin, S B},
journal = {J Cereb Blood Flow Metab},
keywords = {Action Potentials/physiology Animals Brain/*physio},
number = {10},
pages = {1133--1145},
title = {{An energy budget for signaling in the grey matter of the brain}},
volume = {21}
}
@article{Jim1996,
author = {Jim, K C and Giles, C L and Horne, B G},
journal = {Neural Networks, IEEE Transactions on},
number = {6},
pages = {1424--1438},
publisher = {IEEE},
title = {{An analysis of noise in recurrent neural networks: Convergence and generalization}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=548170},
volume = {7},
year = {1996}
}
@article{Soudry2012a,
abstract = {The evolution of a continuous time Markov process with a finite number of states is usually calculated by the Master equation - a linear differential equations with a singular generator matrix. We derive a general method for reducing the dimensionality of the Master equation by one by using the probability normalization constraint, thus obtaining a affine differential equation with a (non-singular) stable generator matrix. Additionally, the reduced form yields a simple explicit expression for the stationary probability distribution, which is usually derived implicitly. Finally, we discuss the application of this method to stochastic differential equations.},
archivePrefix = {arXiv},
arxivId = {1207.4436v1},
author = {Soudry, D. and Meir, R},
eprint = {1207.4436v1},
journal = {ArXiv},
title = {{An exact reduction of the master equation to a strictly stable system with an explicit expression for the stationary distribution}},
year = {2012}
}
@article{Deco2009,
abstract = {The relatively random spiking times of individual neurons are a source of noise in the brain. We show that in a finite-sized cortical attractor network, this can be an advantage, for it leads to probabilistic behavior that is advantageous in decision-making, by preventing deadlock, and is important in signal detectability. We show how computations can be performed through stochastic dynamical effects, including the role of noise in enabling probabilistic jumping across barriers in the energy landscape describing the flow of the dynamics in attractor networks. The results obtained in neurophysiological studies of decision-making and signal detectability are modelled by the stochastical neurodynamics of integrate-and-fire networks of neurons with probabilistic neuronal spiking. We describe how these stochastic neurodynamical effects can be analyzed, and their importance in many aspects of brain function, including decision-making, memory recall, short-term memory, and attention.},
author = {Deco, Gustavo and Rolls, Edmund T and Romo, Ranulfo},
doi = {10.1016/j.pneurobio.2009.01.006},
issn = {1873-5118},
journal = {Progress in neurobiology},
keywords = {Animals,Brain,Brain: physiology,Decision Making,Decision Making: physiology,Humans,Models, Neurological,Neural Networks (Computer),Stochastic Processes},
month = {may},
number = {1},
pages = {1--16},
pmid = {19428958},
title = {{Stochastic dynamics as a principle of brain function.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19428958},
volume = {88},
year = {2009}
}
@article{Pecevski2011,
abstract = {An important open problem of computational neuroscience is the generic organization of computations in networks of neurons in the brain. We show here through rigorous theoretical analysis that inherent stochastic features of spiking neurons, in combination with simple nonlinear computational operations in specific network motifs and dendritic arbors, enable networks of spiking neurons to carry out probabilistic inference through sampling in general graphical models. In particular, it enables them to carry out probabilistic inference in Bayesian networks with converging arrows ("explaining away") and with undirected loops, that occur in many real-world tasks. Ubiquitous stochastic features of networks of spiking neurons, such as trial-to-trial variability and spontaneous activity, are necessary ingredients of the underlying computational organization. We demonstrate through computer simulations that this approach can be scaled up to neural emulations of probabilistic inference in fairly large graphical models, yielding some of the most complex computations that have been carried out so far in networks of spiking neurons.},
author = {Pecevski, Dejan and Buesing, Lars and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1002294},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Bayes Theorem,Brain,Brain: physiology,Computer Graphics,Computer Simulation,Humans,Markov Chains,Models, Neurological,Models, Statistical,Models, Theoretical,Neurons,Neurons: metabolism,Neurons: physiology,Probability,Stochastic Processes},
month = {dec},
number = {12},
pages = {e1002294},
pmid = {22219717},
title = {{Probabilistic inference in general graphical models through sampling in stochastic networks of spiking neurons.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3240581{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2011}
}
@article{KenjiOkajima03012001,
author = {Okajima, Kenji and Imaoka, Hitoshi},
journal = {Neural Computation},
number = {3},
pages = {547--562},
title = {{A Complex Cell-Like Receptive Field Obtained by Information Maximization}},
volume = {13},
year = {2001}
}
@book{Walnut02,
author = {Walnut, D},
publisher = {Springer},
title = {{An introduction to wavelet analysis}},
year = {2002}
}
@article{JMA06,
author = {Bezdudnaya, T and Cano, M and Bereshpolova, Y and Stoelzel, C and J.-M., Alonso and Swadlow, H},
journal = {Neuron},
pages = {421--432},
title = {{Thalamic Burst Mode and Inattention in the Awake {\{}LGN{\}}d}},
volume = {49},
year = {2006}
}
@article{WLH05,
author = {Weiland, J and Liu, W and Humayun, M},
journal = {Annual Review of Biomedical Engineering},
pages = {361--401},
title = {{RETINAL PROSTHESIS}},
volume = {7},
year = {2005}
}
@article{Fiete2006,
author = {Fiete, I.R. and Seung, H S},
doi = {10.1103/PhysRevLett.97.048104},
issn = {0031-9007},
journal = {Physical review letters},
month = {jul},
number = {4},
pages = {48104},
publisher = {APS},
title = {{Gradient learning in spiking neural networks by dynamic perturbation of conductances}},
url = {http://prl.aps.org/abstract/PRL/v97/i4/e048104 http://link.aps.org/doi/10.1103/PhysRevLett.97.048104},
volume = {97},
year = {2006}
}
@article{Imennov2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1009.4172v1},
author = {Imennov, Nikita S and Famulare, Michael and Shea-brown, Eric},
eprint = {arXiv:1009.4172v1},
pages = {21--24},
title = {neurons},
year = {2010}
}
@article{Yang|2002|,
abstract = {The two loop effective potential of massless 4 theory is presented
in several reg- ularization and renormalization prescriptions and
the dynamical symmetry breaking solution is obtained in the strong-coupling
situation in several prescriptions except the Coleman-Weinberg prescription.
The beta function in the broken phase becomes neg- ative and the
UV fixed point turns out to be a strong-coupling one, and its numeric
value varies with the renormalization prescriptions, a detail which
is different from the asymptotic free solution in the one loop case.
The symmetry breaking phase is shown to be an entirely strong-coupling
phase. The reason of the relevance of the renormalization prescriptions
is shown to be due to the nonperturbative nature of the effective
potential. We also reanalyzed the two loop effective potential by
adopting a differential equation approach based on the understanding
that takes all the QFT{\"{i}}¾'s as the ill-defined formulations of the
{\"{i}}¾'low energy{\"{i}}¾' effective theories of a complete under- lying theory.
Then the relevance of the prescriptions of fixing the local ambiguities
to physical properties like symmetry breaking is further emphasized.
We also tenta- tively proposed a rescaling insensitivity argument
for fixing the quadratic ambiguities. Some detailed properties of
the strongly coupled broken phase and related issues were discussed.},
author = {Yang, J.-F. and Ruan, J.-H.},
journal = {arXiv},
keywords = {effective potential,phi-4,physics,quantum field theory,two loops},
pages = {201255},
title = {{Dynamical symmetry breaking of lambda phi{\^{}}4 theory in two loop effective potential}},
volume = {hep-ph}
}
@article{Hoerzer2012,
author = {Hoerzer, G. M. and Legenstein, R. and Maass, W},
doi = {10.1093/cercor/bhs348},
issn = {1047-3211},
journal = {Cerebral Cortex},
keywords = {cortical microcircuit model,cortical plasticity,generation,pattern,working memory},
month = {nov},
title = {{Emergence of Complex Computational Structures From Chaotic Neural Networks Through Reward-Modulated Hebbian Learning}},
url = {http://www.cercor.oxfordjournals.org/cgi/doi/10.1093/cercor/bhs348},
year = {2012}
}
@article{GP04,
author = {Garcia-Perez, M},
journal = {Journal of Computational Neuroscience},
pages = {289--325},
title = {{A Nonlinear Model of the Behavior of Simple Cells in Visual Cortex}},
volume = {17},
year = {2004}
}
@article{RegehrAtluri95,
abstract = {Calcium ions act presynaptically to modulate synaptic strength and

to trigger neurotransmitter release. Here we detect stimulus-evoked

changes in residual free calcium ([Ca2+]i) in rat cerebellar granule

cell presynaptic terminals. Granule cell axons, known as parallel

fibers, and their associated boutons, were labeled with several calcium

indicators. When parallel fibers were extracellularly activated with

stimulus trains, calcium accumulated in the terminals, producing

changes in the fluorescence of the indicators. During the stimulus

train, the fluorescence change per pulse became progressively smaller

with the high affinity indicators Fura-2 and calcium green-2 but

remained constant with the low affinity dyes BTC and furaptra. In

addition, fluorescence transients of high affinity dyes were slower

than those of low affinity indicators, which appear to accurately

report the time course of calcium transients. Simulations show that

differences in the observed transients can be explained by the different

affinities and off rates of the fluorophores. The return of [Ca2+]i

to resting levels can be approximated by an exponential decay with

a time constant of 150 ms. On the basis of the degree of saturation

in the response of high affinity dyes observed during trains, we

estimate that each action potential increases [Ca2+]i in the terminal

by several hundred nanomolar. These findings indicate that in these

terminals [Ca2+]i transients are much larger and faster than those

observed in larger boutons, such as those at the neuromuscular junction.

Such rapid [Ca2+]i dynamics may be found in many of the terminals

in the mammalian brain that are similar in size to parallel fiber

boutons.},
author = {Regehr, W G and Atluri, P P},
journal = {Biophys J},
keywords = {Animals; Benzofurans; Calcium; Cerebellum; Coumari,Fluorescence; Synapses; Tetrodotoxin; Time Factor},
month = {may},
number = {5},
pages = {2156--2170},
pmid = {7612860},
title = {{Calcium transients in cerebellar granule cell presynaptic terminals.}},
volume = {68},
year = {1995}
}
@article{Poirazi2001,
annote = {

2010IInum12.46},
author = {Poirazi, Panayiota and Mel, BW},
doi = {10.1016/S0896-6273(01)00252-5},
issn = {08966273},
journal = {Neuron},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
month = {mar},
number = {3},
pages = {779--796},
title = {{Impact of Active Dendrites and Structural Plasticity on the Memory Capacity of Neural Tissue}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627301002525 http://www.sciencedirect.com/science/article/pii/S0896627301002525},
volume = {29},
year = {2001}
}
@article{NagaiMiyawaki01,
abstract = {To visualize {\{}Ca{\}}{\^{}}{\{}2+{\}}-dependent protein-protein interactions in

living cells by fluorescence readouts, we used a circularly permuted

green fluorescent protein (cpGFP), in which the amino and carboxyl

portions had been interchanged and reconnected by a short spacer

between the original termini. The cpGFP was fused to calmodulin and

its target peptide, M13. The chimeric protein, which we have named

"pericam," was fluorescent and its spectral properties changed reversibly

with the amount of {\{}Ca{\}}{\^{}}{\{}2+{\}}, probably because of the interaction

between calmodulin and M13 leading to an alteration of the environment

surrounding the chromophore. Three types of pericam were obtained

by mutating several amino acids adjacent to the chromophore. Of these,

"flash-pericam" became brighter with {\{}Ca{\}}{\^{}}{\{}2+{\}}, whereas "inverse-pericam"

dimmed. On the other hand, "ratiometric-pericam" had an excitation

wavelength changing in a {\{}Ca{\}}{\^{}}{\{}2+{\}}-dependent manner. All of the

pericams expressed in HeLa cells were able to monitor free {\{}Ca{\}}{\^{}}{\{}2+{\}}

dynamics, such as {\{}Ca{\}}{\^{}}{\{}2+{\}} oscillations in the cytosol and the

nucleus. {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging using high-speed confocal line-scanning

microscopy and a flash-pericam allowed to detect the free propagation

of {\{}Ca{\}}{\^{}}{\{}2+{\}} ions across the nuclear envelope. Then, free {\{}Ca{\}}{\^{}}{\{}2+{\}}

concentrations in the nucleus and mitochondria were simultaneously

measured by using ratiometric-pericams having appropriate localization

signals, revealing that extra-mitochondrial {\{}Ca{\}}{\^{}}{\{}2+{\}} transients

caused rapid changes in the concentration of mitochondrial {\{}Ca{\}}{\^{}}{\{}2+{\}}.

Finally, a "split-pericam" was made by deleting the linker in the

flash-pericam. The {\{}Ca{\}}{\^{}}{\{}2+{\}}-dependent interaction between calmodulin

and M13 in HeLa cells was monitored by the association of the two

halves of GFP, neither of which was fluorescent by itself.},
author = {Nagai, T and Sawano, A and Park, E S and Miyawaki, A},
doi = {10.1073/pnas.051636098},
journal = {Proc Natl Acad Sci U S A},
keywords = {Calcium; Calmodulin; Cations,Divalent; Dimerization; Gene Expression; Genes,Reporter; Genetic Engineering; Green Fluorescent},
month = {mar},
number = {6},
pages = {3197--3202},
pmid = {11248055},
title = {{Circularly permuted green fluorescent proteins engineered to sense {\{}Ca{\}}{\^{}}{\{}2+{\}}.}},
url = {http://dx.doi.org/10.1073/pnas.051636098},
volume = {98},
year = {2001}
}
@article{NordeenKitzes83,
abstract = {We evaluated the consequences of neonatal cochlear destruction upon

ascending projections to the inferior colliculi. Unilateral cochlear

ablations were performed in both neonatal and adult gerbils. Four

to 12 months later, the inferior colliculus (IC) was examined physiologically

and injected unilaterally with horseradish peroxidase (HRP). The

number of labeled cells was determined bilaterally in all three divisions

of cochlear nucleus (CN) and in the medial superior olive (MSO).

In both experimental groups, transneuronal changes within the deafferented

CN were greater in the ventral divisions than in the dorsal division.

On the unoperated side the magnitude of projections from CN to the

inferior colliculi was altered in animals lesioned as neonates. Following

HRP injections into the IC on the unoperated side, the number of

ipsilaterally labeled cells in CN (unoperated side) was significantly

greater in the neonatal experimental group than in adult experimental

and control animals. These anatomical changes were accompanied by

increased ipsilaterally evoked excitatory activity recorded in the

IC on the unoperated side. Following HRP injections into the IC on

the ablated side, the number of contralaterally labeled cells in

CN (unoperated side) was significantly reduced in animals lesioned

as neonates as compared with control animals. The number of labeled

cells in ipsilateral MSO was not significantly different across groups.

Our interpretation is that unilateral cochlear ablation in neonatal

gerbils results in an increase in the magnitude of ipsilateral projections

and a decrease in the magnitude of contralateral projections from

CN on the unoperated side to the inferior colliculi. These data suggest

that the normal pattern of innervation of the IC results, in part,

from interactions among afferent projections.},
author = {Nordeen, K W and Killackey, H P and Kitzes, L M},
doi = {10.1002/cne.902140204},
journal = {Journal of Comparative Neurology},
keywords = {Animals; Animals,Newborn; Auditory Pathways; Brain Mapping; Brain,Non-U.S. Gov't; Research Support,P.H.S.,U.S. Gov't},
month = {feb},
number = {2},
pages = {144--153},
pmid = {6841682},
title = {{Ascending projections to the inferior colliculus following unilateral cochlear ablation in the neonatal gerbil, Meriones unguiculatus.}},
url = {http://dx.doi.org/10.1002/cne.902140204},
volume = {214},
year = {1983}
}
@article{Taylor1999,
author = {Taylor, J H},
number = {April},
title = {{Describing functions}},
url = {http://onlinelibrary.wiley.com/mrw{\_}content/eeee/articles/W2409/W2409.pdf},
year = {1999}
}
@article{Kanning2010a,
abstract = {Although often considered as a group, spinal motor neurons are highly diverse in terms of their morphology, connectivity, and functional properties and differ significantly in their response to disease. Recent studies of motor neuron diversity have clarified developmental mechanisms and provided novel insights into neurodegeneration in amyotrophic lateral sclerosis (ALS). Motor neurons of different classes and subtypes--fast/slow, alpha/gamma--are grouped together into motor pools, each of which innervates a single skeletal muscle. Distinct mechanisms regulate their development. For example, glial cell line-derived neurotrophic factor (GDNF) has effects that are pool-specific on motor neuron connectivity, column-specific on axonal growth, and subtype-specific on survival. In multiple degenerative contexts including ALS, spinal muscular atrophy (SMA), and aging, fast-fatigable (FF) motor units degenerate early, whereas motor neurons innervating slow muscles and those involved in eye movement and pelvic sphincter control are strikingly preserved. Extrinsic and intrinsic mechanisms that confer resistance represent promising therapeutic targets in these currently incurable diseases.},
author = {Kanning, Kevin C and Kaplan, Artem and Henderson, Christopher E},
doi = {10.1146/annurev.neuro.051508.135722},
issn = {1545-4126},
journal = {Annual review of neuroscience},
keywords = {Animals,Cell Differentiation,Cell Differentiation: physiology,Humans,Motor Neuron Disease,Motor Neuron Disease: metabolism,Motor Neuron Disease: pathology,Motor Neuron Disease: physiopathology,Motor Neurons,Motor Neurons: classification,Motor Neurons: cytology,Motor Neurons: pathology,Motor Neurons: physiology},
month = {jan},
pages = {409--40},
pmid = {20367447},
title = {{Motor neuron diversity in development and disease.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20367447},
volume = {33},
year = {2010}
}
@article{CJU90,
author = {Caminiti, R and Johnson, P and Urbano, A},
journal = {Journal of Neuroscience},
pages = {2039--2058},
title = {{Making arm movements within different parts of space: Dynamic aspects in the primate motor cortex}},
volume = {10},
year = {1990}
}
@article{Frasconi1997,
author = {Frasconi, P and Gori, Marco and Tesi, Alberto},
journal = {Progress in Neural Networks},
title = {{Successes and failures of backpropagation: a theoretical investigation (to appear)}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:successes+and+failures+of+backpropagation+a+theoretical+investigation{\#}0},
year = {1997}
}
@article{Fee2012,
abstract = {In its simplest formulation, reinforcement learning is based on the idea that if an action taken in a particular context is followed by a favorable outcome, then, in the same context, the tendency to produce that action should be strengthened, or reinforced. While reinforcement learning forms the basis of many current theories of basal ganglia (BG) function, these models do not incorporate distinct computational roles for signals that convey context, and those that convey what action an animal takes. Recent experiments in the songbird suggest that vocal-related BG circuitry receives two functionally distinct excitatory inputs. One input is from a cortical region that carries context information about the current "time" in the motor sequence. The other is an efference copy of motor commands from a separate cortical brain region that generates vocal variability during learning. Based on these findings, I propose here a general model of vertebrate BG function that combines context information with a distinct motor efference copy signal. The signals are integrated by a learning rule in which efference copy inputs gate the potentiation of context inputs (but not efference copy inputs) onto medium spiny neurons in response to a rewarded action. The hypothesis is described in terms of a circuit that implements the learning of visually guided saccades. The model makes testable predictions about the anatomical and functional properties of hypothesized context and efference copy inputs to the striatum from both thalamic and cortical sources.},
author = {Fee, Michale S},
doi = {10.3389/fncir.2012.00038},
issn = {1662-5110},
journal = {Frontiers in neural circuits},
keywords = {context,context, corticostriatal, efference copy, motor le,corticostriatal,efference copy,motor learning,songbird,striatum,thalamostriatal},
month = {jan},
number = {June},
pages = {38},
pmid = {22754501},
title = {{Oculomotor learning revisited: a model of reinforcement learning in the basal ganglia incorporating an efference copy of motor actions.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3385561{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2012}
}
@article{IRVINE1999,
abstract = {A Markov model of the cardiac sodium channel is presented. The model is similar to the CA1 hippocampal neuron sodium channel model developed by Kuo and Bean (1994. Neuron. 12:819829) with the following modifications: 1) an additional open state is added; 2) open-inactivated transitions are made voltage-dependent; and 3) channel rate constants are exponential functions of enthalpy, entropy, and voltage and have explicit temperature dependence. Model parameters are determined using a simulated annealing algorithm to minimize the error between model responses and various experimental data sets. The model reproduces a wide range of experimental data including ionic currents, gating currents, tail currents, steady-state inactivation, recovery from inactivation, and open time distributions over a temperature range of 10°C to 25°C. The model also predicts measures of single channel activity such as first latency, probability of a null sweep, and probability of reopening.},
author = {IRVINE, L},
doi = {10.1016/S0006-3495(99)77346-7},
issn = {00063495},
journal = {Biophysical Journal},
number = {4},
pages = {1868--1885},
title = {{Cardiac Sodium Channel Markov Model with Temperature Dependence and Recovery from Inactivation}},
url = {http://dx.doi.org/10.1016/S0006-3495(99)77346-7},
volume = {76},
year = {1999}
}
@article{Hansen|1999|,
abstract = {We introduce an image enhancement method referred to as the watershed-based
maximum-homogeneity filter. This method first uses watershed analysis
to subdivide the image into homogeneous pixel clusters called catchment
basins. Next, using an adaptive, local, catchment-basin selection
scheme, similar neighboring catchment basins are combined together
to produce an enhanced image. Because the method starts with watershed
analysis, it can preserve edge information and run with high computational
efficiency. Illustrative results show that the method performs well
relative to other popular nonlinear filters.},
annote = {The paper introduces a concept of nonlinear edge-preserving fitler{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}using watershed. The main idea is to region-grow segmentation formed{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}by watershed avoiding merging over a pronounced edge, based on maximal{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}homogeneity of growing object.},
author = {Hansen, M W and Higgins, W E},
journal = {IEEE transactions on image processing},
keywords = {computational,edge-detection,edge-preserving filters,image enhancement,image processing,nonlinear filters,segmentation,watershed},
number = {7},
pages = {982},
title = {{Watershed-Based Maximum-Homogeneity Filtering}},
volume = {8}
}
@article{HDSS03,
author = {Hwang, E and Donchin, O and Smith, M and Shadmehr, R},
journal = {PLOS Biology},
title = {{A Gain-Field Encoding of Limb Position and Velocity in the Internal Model of Arm Dynamics}},
volume = {1},
year = {2003}
}
@article{Rue01,
author = {Rue, H},
journal = {Journal of the Royal Statistical Society: Series B},
pages = {325--338},
title = {{Fast sampling of {\{}Gaussian Markov{\}} random fields}},
volume = {63},
year = {2001}
}
@article{Higley2006,
abstract = {In layer 4 (L4) of the rat barrel cortex, a single whisker deflection evokes a stereotyped sequence of excitation followed by inhibition, hypothesized to result in a narrow temporal window for spike output. However, awake rats sweep their whiskers across objects, activating the cortex at frequencies known to induce short-term depression at both excitatory and inhibitory synapses within L4. Although periodic whisker deflection causes a frequency-dependent reduction of the cortical response magnitude, whether this adaptation involves changes in the relative balance of excitation and inhibition and how these changes might impact the proposed narrow window of spike timing in L4 is unknown. Here, we demonstrate for the first time that spike output in L4 is determined precisely by the dynamic interaction of excitatory and inhibitory conductances. Furthermore, we show that periodic whisker deflection results in balanced adaptation of the magnitude and timing of excitatory and inhibitory input to L4 neurons. This balanced adaptation mediates a reduction in spike output while preserving the narrow time window of spike generation, suggesting that L4 circuits are calibrated to maintain relative levels of excitation and inhibition across varying magnitudes of input.},
author = {Higley, Michael J and Contreras, Diego},
doi = {10.1523/JNEUROSCI.3506-05.2006},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Adaptation,Animals,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Male,Neurons,Neurons: physiology,Patch-Clamp Techniques,Physiological,Rats,Reaction Time,Somatosensory Cortex,Somatosensory Cortex: physiology,Sprague-Dawley,Synaptic Transmission,Synaptic Transmission: physiology,Touch,Touch: physiology,Vibrissae,Vibrissae: physiology},
month = {jan},
number = {2},
pages = {448--57},
pmid = {16407542},
title = {{Balanced excitation and inhibition determine spike timing during frequency adaptation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16407542},
volume = {26},
year = {2006}
}
@article{Gerhard2011,
annote = {2011num37},
author = {Gerhard, F and Pipa, Gordon and Lima, Bruss and Neuenschwander, Sergio and Gerstner, W},
doi = {10.3389/fncom.2011.00004},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {awake monkey recordings,effective connectivity,generalized linear models,network topology,random sampling,scale-free networks,small-world networks,visual system},
number = {February},
pages = {1--13},
title = {{Extraction of Network Topology From Multi-Electrode Recordings: Is there a Small-World Effect?}},
url = {http://www.frontiersin.org/Computational{\_}Neuroscience/10.3389/fncom.2011.00004/abstract},
volume = {5},
year = {2011}
}
@article{Pascanu2012,
abstract = {There are two widely known issues with prop- erly training Recurrent Neural Networks, the vanishing and the exploding gradient prob- lems detailed in Bengio et al. (1994). In this paper we attempt to improve the under- standing of the underlying issues by explor- ing these problems from an analytical, a geo- metric and a dynamical systems perspective. Our analysis is used to justify a simple yet ef- fective solution. We propose a gradient norm clipping strategy to deal with exploding gra- dients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
archivePrefix = {arXiv},
arxivId = {arXiv:1211.5063v2},
author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
eprint = {arXiv:1211.5063v2},
journal = {Proceedings of The 30th International Conference on Machine Learning},
number = {2},
pages = {1310--1318},
title = {{On the difficulty of training recurrent neural networks}},
url = {http://jmlr.org/proceedings/papers/v28/pascanu13.pdf},
year = {2012}
}
@article{Hutcheon2000,
abstract = {The realization that different behavioural and perceptual states of the brain are associated with different brain rhythms has sparked growing interest in the oscillatory behaviours of neurons. Recent research has uncovered a close association between electrical oscillations and resonance in neurons. Resonance is an easily measurable property that describes the ability of neurons to respond selectively to inputs at preferred frequencies. A variety of ionic mechanisms support resonance and oscillation in neurons. Understanding the basic principles involved in the production of resonance allows for a simplified classification of these mechanisms. The characterization of resonance and frequency preference captures those essential properties of neurons that can serve as a substrate for coordinating network activity around a particular frequency in the brain.},
author = {Hutcheon, B},
doi = {10.1016/S0166-2236(00)01547-2},
issn = {01662236},
journal = {Trends in Neurosciences},
month = {may},
number = {5},
pages = {216--222},
title = {{Resonance, oscillation and the intrinsic frequency preferences of neurons}},
url = {http://dx.doi.org/10.1016/S0166-2236(00)01547-2},
volume = {23},
year = {2000}
}
@book{DZ93,
address = {New York},
author = {Dembo, A and Zeitouni, O},
publisher = {Springer},
title = {{Large deviations techniques and applications}},
year = {1993}
}
@inproceedings{Ciresan2012,
address = {Providence, RI},
author = {Ciresan, D},
booktitle = {CVPR '12},
month = {jun},
pages = {3642--3649},
title = {{Multi-column deep neural networks for image classification}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6248110},
year = {2012}
}
@article{Marder1996,
annote = {2010num4.6},
author = {Marder, E and Abbott, L F},
journal = {Proceedings of the {\ldots}},
title = {{Memory from the dynamics of intrinsic membrane currents}},
url = {http://www.pnas.org/content/93/24/13481.full http://www.pnas.org/content/93/24/13481.short},
year = {1996}
}
@article{Kitagawa96,
author = {Kitagawa, G},
journal = {Journal of Computational and Graphical Statistics},
number = {1},
pages = {1--25},
publisher = {JSTOR},
title = {{Monte Carlo Filter and Smoother for Non-Gaussian Nonlinear State Space Models}},
volume = {5},
year = {1996}
}
@article{Chao1989,
author = {Chao, HJ and Johnston, CA},
journal = {Solid-State Circuits, IEEE Journal of},
number = {5},
pages = {1454--1458},
title = {{Behavior analysis of CMOS D flip-flops}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=572637},
volume = {24},
year = {1989}
}
@article{goychuk2003non,
annote = {2009num26},
author = {Goychuk, Igor and H{\"{a}}nggi, P.},
journal = {Physical Review Letters},
number = {7},
pages = {70601},
publisher = {APS},
title = {{Non-Markovian stochastic resonance}},
volume = {91},
year = {2003}
}
@article{Johnson2010a,
abstract = {This study was designed to test two hypotheses about binaural hearing: (1) that binaural cues are primarily processed in the hemisphere contralateral to the perceived location of a sound; and (2) that the two main binaural cues, interaural timing differences and interaural level differences, are processed in separate channels in the auditory cortex. Magnetoencephalography was used to measure brain responses to dichotic pitches - a perception of pitch created by segregating a narrow band of noise from a wider band of noise - derived from interaural timing or level disparities. Our results show a strong modulation of interhemispheric M100 amplitudes by ITD cues. When these cues simulated source presentation unilaterally from the right hemispace, M100 amplitude changed from a predominant right hemisphere pattern to a bilateral pattern. In contrast, ILD cues lacked any capacity to alter the right hemispheric distribution. These data indicate that intrinsic hemispheric biases are large in comparison to any contralaterality biases in the auditory system. Importantly, both types of binaural cue elicited a circa 200ms latency object-related negativity component, believed to reflect automatic cortical processes involved in distinguishing concurrent auditory objects. These results support the conclusion that ITDs and ILDs are processed by distinct neuronal populations to relatively late stages of cortical processing indexed by the M100. However information common to the two cues seems to be extracted for use in a subsequent stage of auditory scene segregation indexed by the object related negativity. This may place a new bound on the extent to which sound location cues are processed in separate channels of the auditory cortex.},
author = {Johnson, Blake W and H{\"{a}}usser, M},
doi = {10.1016/j.neuropsychologia.2010.05.008},
issn = {1873-3514},
journal = {Neuropsychologia},
month = {may},
number = {2},
pages = {653--666},
pmid = {20466010},
title = {{Processing of binaural spatial information in human auditory cortex: Neuromagnetic responses to interaural timing and level differences.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20541185},
volume = {56},
year = {2010}
}
@article{Bock2011,
abstract = {In the cerebral cortex, local circuits consist of tens of thousands of neurons, each of which makes thousands of synaptic connections. Perhaps the biggest impediment to understanding these networks is that we have no wiring diagrams of their interconnections. Even if we had a partial or complete wiring diagram, however, understanding the network would also require information about each neuron's function. Here we show that the relationship between structure and function can be studied in the cortex with a combination of in vivo physiology and network anatomy. We used two-photon calcium imaging to characterize a functional property--the preferred stimulus orientation--of a group of neurons in the mouse primary visual cortex. Large-scale electron microscopy of serial thin sections was then used to trace a portion of these neurons' local network. Consistent with a prediction from recent physiological experiments, inhibitory interneurons received convergent anatomical input from nearby excitatory neurons with a broad range of preferred orientations, although weak biases could not be rejected.},
annote = {2011num46},
author = {Bock, Davi D and Lee, Wei-Chung Allen and Kerlin, Aaron M and Andermann, Mark L and Hood, Greg and Wetzel, Arthur W and Yurgenson, Sergey and Soucy, Edward R and Kim, Hyon Suk and Reid, R Clay},
doi = {10.1038/nature09802},
issn = {1476-4687},
journal = {Nature},
keywords = {Animals,Calcium Signaling,Electron,Fluorescence,Interneurons,Interneurons: physiology,Male,Mice,Microscopy,Microtomy,Nerve Net,Nerve Net: anatomy {\&} histology,Nerve Net: cytology,Nerve Net: physiology,Nerve Net: ultrastructure,Neural Inhibition,Neural Inhibition: physiology,Neurons,Neurons: physiology,Neurons: ultrastructure,Pyramidal Cells,Pyramidal Cells: physiology,Pyramidal Cells: ultrastructure,Synapses,Synapses: physiology,Transmission,Visual Cortex,Visual Cortex: anatomy {\&} histology,Visual Cortex: cytology,Visual Cortex: physiology,Visual Cortex: ultrastructure,networks},
mendeley-tags = {networks},
month = {mar},
number = {7337},
pages = {177--82},
pmid = {21390124},
publisher = {Nature Publishing Group},
title = {{Network anatomy and in vivo physiology of visual cortical neurons.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3095821{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {471},
year = {2011}
}
@article{Usrey2000,
author = {Usrey, WM M},
journal = {The Journal of Neuroscience},
number = {14},
pages = {5461--5467},
title = {{Synaptic interactions between thalamic inputs to simple cells in cat visual cortex}},
url = {http://neuro.cjb.net/content/20/14/5461.short},
volume = {20},
year = {2000}
}
@article{FOL01,
author = {Foldiak, P},
journal = {Neurocomputing},
pages = {1217--1222},
title = {{Stimulus optimisation in primary visual cortex}},
volume = {38--40},
year = {2001}
}
@article{DOWLING1963,
abstract = {The effects of light adaptation on the increment threshold, rhodopsin content, and dark adaptation have been studied in the rat eye over a wide range of intensities. The electroretinogram threshold was used as a measure of eye sensitivity. With adapting intensities greater than 1.5 log units above the absolute ERG threshold, the increment threshold rises linearly with increasing adapting intensity. With 5 minutes of light adaptation, the rhodopsin content of the eye is not measurably reduced until the adapting intensity is greater than 5 log units above the ERG threshold. Dark adaptation is rapid (i.e., completed in 5 to 10 minutes) until the eye is adapted to lights strong enough to bleach a measurable fraction of the rhodopsin. After brighter light adaptations, dark adaptation consists of two parts, an initial rapid phase followed by a slow component. The extent of slow adaptation depends on the fraction of rhodopsin bleached. If all the rhodopsin in the eye is bleached, the slow fall of threshold extends over 5 log units and takes 2 to 3 hours to complete. The fall of ERG threshold during the slow phase of adaptation occurs in parallel with the regeneration of rhodopsin. The slow component of dark adaptation is related to the bleaching and resynthesis of rhodopsin; the fast component of adaptation is considered to be neural adaptation.},
author = {Dowling, J E},
doi = {10.1085/jgp.46.6.1287},
isbn = {0028-0836 (Print)$\backslash$n0028-0836 (Linking)},
issn = {0022-1295},
journal = {The Journal of general physiology},
keywords = {Adaptation, Ocular,Dark Adaptation,Electroretinography,Light,Ocular,Rats,Research,Retinal Pigments,Rhodopsin,Sensory Receptor Cells,Vision, Ocular},
pages = {1287--301},
pmid = {14043003},
title = {{Neural and Photochemical Mechanisms of Visual Adaptation in the Rat.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2195321{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {46},
year = {1963}
}
@inproceedings{Simoncelli96c,
address = {Lausanne},
author = {Simoncelli, E P and Adelson, E H},
booktitle = {Third Int'l Conf on Image Proc},
pages = {379--382},
publisher = {IEEE Sig Proc Society},
title = {{Noise Removal via {\{}Bayesian{\}} Wavelet Coring}},
volume = {I},
year = {1996}
}
@article{Polytechnique,
author = {Polytechnique, Doctorale D E L Ecole},
title = {{par De l ' al ´ ea dans les neurones : une analyse probabiliste multi- ´ echelle}}
}
@article{Chang2011,
author = {Chang, Ting and Jo, Sung-Hyun and Kim, Kuk-Hwan and Sheridan, Patrick and Gaba, Siddharth and Lu, Wei},
doi = {10.1007/s00339-011-6296-1},
issn = {0947-8396},
journal = {Applied Physics A},
month = {feb},
number = {4},
pages = {857--863},
title = {{Synaptic behaviors and modeling of a metal oxide memristive device}},
url = {http://www.springerlink.com/index/10.1007/s00339-011-6296-1},
volume = {102},
year = {2011}
}
@phdthesis{Friedlander2009a,
author = {Friedlander, T},
booktitle = {Complexity},
number = {November},
title = {{Protein Distributions and Their Role in Cell Population Functionality Degree of Doctor of Philosophy}},
year = {2009}
}
@article{Galka08,
author = {Galka, Andreas and Ozaki, Tohru and Muhle, Hiltrud and Stephani, Ulrich and Siniatchkin, Michael},
journal = {Cognitive Neurodynamics},
number = {2},
pages = {101--113},
title = {{A data-driven model of the generation of human {\{}EEG{\}} based on a spatially distributed stochastic wave equation}},
volume = {2},
year = {2008}
}
@article{BRIL88,
author = {Brillinger, D},
journal = {Biological Cyberkinetics},
pages = {189--200},
title = {{Maximum likelihood analysis of spike trains of interacting nerve cells}},
volume = {59},
year = {1988}
}
@article{Debanne2011,
annote = {2011num53},
author = {Debanne, D and Campanac, E and Bialowas, A and Carlier, E},
doi = {10.1152/physrev.00048.2009.},
journal = {Physiological Reviews},
number = {2},
pages = {555--602},
title = {{Axon Physiology}},
volume = {91},
year = {2011}
}
@article{Wu1989,
author = {Wu, Jinn-Wen},
journal = {Journal of Mathematical Analysis and Applications},
number = {x},
pages = {224--227},
title = {{Global Asymptotic Stability in Discrete Systems}},
year = {1989}
}
@article{Green1975,
abstract = {Electrical potentials were recorded from different levels within the skate retina. Comparing the adaptive properties of the various responses revealed that the isolated receptor potential and the S-potential always exhibited similar changes in sensitivity, and that the b-wave and ganglion-cell thresholds acted in concert. However, the two sets of responses behaved differently under certain conditions. For example, a dimly iluminated background that had no measurable effect on the senitivities of either of the distal responses, raised significantly the thresholds of both the b-wave and the ganglion cell responses. In addition, the rate of recovery during the early, "neural" phase of dark adaptation was significantly faster for the receptor and S-potentials than for the b-wave or ganglion cell discharge. These results indicate that there is an adaptive ("network") mechanism in the retina which can influence significantly b-wave and gaglion cell activity and which behaves independently of the receptors and horizontal cells. We conclude that visual adaptation in the skate retina is regulated by a combination of receptoral and network mechanisms.},
author = {Green, D G and Dowling, J E and Siegel, I M and Ripps, H},
doi = {10.1085/jgp.65.4.483},
isbn = {0022-1295 (Print)},
issn = {0022-1295},
journal = {The Journal of general physiology},
keywords = {Animals,Dark Adaptation,Electrophysiology,Fishes,Fishes: physiology,Light,Photoreceptor Cells,Photoreceptor Cells: metabolism,Retina,Retina: physiology,Retinal Pigments,Retinal Pigments: metabolism,Rhodopsin,Rhodopsin: metabolism,Time Factors},
number = {4},
pages = {483--502},
pmid = {1151323},
title = {{Retinal mechanisms of visual adaptation in the skate.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2214926{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {65},
year = {1975}
}
@techreport{Technion2009,
author = {Technion, EE},
title = {{Random Signal 044202}},
volume = {456},
year = {2009}
}
@inproceedings{Hu2011,
address = {Yokohama},
author = {Hu, M and Li, H and Chen, Yi and Wang, Xi and Pino, R E},
booktitle = {Proceedings of the 16th Asia and South Pacific design automation conference},
doi = {10.1109/ASPDAC.2011.5722193},
isbn = {978-1-4244-7515-5},
month = {jan},
pages = {25--30},
publisher = {IEEE},
title = {{Geometry variations analysis of TiO2 thin-film and spintronic memristors}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5722193},
year = {2011}
}
@article{SdrullaLinden07,
abstract = {Experiments in hippocampal area CA1 suggest that long-term potentiation

could be associated with spine addition and enlargement, and long-term

depression (LTD) with spine shrinkage and loss. Is this a general

principle of synaptic plasticity? We used two-photon microscopy to

measure dendritic spines in rat cerebellar Purkinje cells. Neither

local synaptic induction of LTD nor global chemical induction of

LTD changed spine number or size. Conversely, a manipulation that

evoked persistent dendritic spine retraction did not alter parallel

fiber-evoked excitatory postsynaptic currents.},
author = {Sdrulla, Andrei D and Linden, David J},
doi = {10.1038/nn1889},
journal = {Nat Neurosci},
keywords = {Animals; Animals,Chemical; Time Factors,Newborn; Calcium; Cerebellum; Dendritic Spines; E,Nonparametric; Stimulation,Sprague-Dawley; Statistics},
month = {may},
number = {5},
pages = {546--548},
pmid = {17435753},
title = {{Double dissociation between long-term depression and dendritic spine morphology in cerebellar Purkinje cells.}},
url = {http://dx.doi.org/10.1038/nn1889},
volume = {10},
year = {2007}
}
@article{Blasone|1998|,
abstract = {We present the exact formula for neutrino oscillations. By resorting
to recent results of Quantum Field Theory of fermion mixing, we work
out the Green{\"{i}}¾'s function formalism for mixed neutrinos. The usual
quantum mechanical Pon- tecorvo formula is recovered in the relativistic
limit.},
author = {Blasone, M and Henning, P A and Vitiello, G},
journal = {arXiv},
keywords = {neutrino oscillations,physics,quantum field theory},
pages = {9803157},
title = {{The exact formula for neutrino oscillations}},
volume = {hep-th}
}
@article{Abdi|1994|,
abstract = {Neural networks are composed of basic units somewhat analogous to
neurons. These units are linked to each other by connections whose
strength is modifiable as a result of a learning process or algorithm.
Each of these units integrates independently (in parallel) the information
provided by its synapses in order to evaluate its state of activation.
The unit response is then a linear or nonlinear function of its activation.
Linear algebra concepts are used, in general, to analyze linear units,
with eigenvectirs and eigenvalues being the core concepts involved.
This analysis makes clear the strong similarite between linear neural
networks and the general linear model developed by statisticians.
The linar models presented here are the perceptron, and the linear
associator. The behavior of nonlinear networks can be described within
the framework of optimization and approximation techniques with dynamical
systems (e.g., like those used to model spin glasses). One of the
main notions used with nonlinear unit networks is the notioon of
attractor. When the task of the network is to associate a response
with some specific input patterns, the most popular nonlinear technique
consists of using hidden layers of neurons trained with back-propagation
of error. The nonlinear models presented are the Hopfield network,
the Boltzmann machine, the back-propagation network, and the radial
basis function network.},
annote = {This paper provides excellent coverage of linear discriminators,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}including linear associator, simple perceptron, Widrow-Hoff leaining{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}rule for perceptrons and its translation in W=GF{\^{}}+ weight matrix{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}for general linear associator. It also considers Hopfield net and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}multilayer perceptron, and back-propagation training. Finally, it{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}considers radial basis networks as alternative to multilayer nonlinear{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}nets trained with back-propagation.},
author = {Abdi, Herve},
journal = {Journal of Biological Systems},
keywords = {artificial neural networks,back-propagation,boltzmann machine,classificator,computational,general linear model,hopfield,learning,linear associator,multilayer,perceptron,radial basis},
number = {3},
pages = {247},
title = {{A neural network primer}},
volume = {2}
}
@article{Litvak2003,
abstract = {The capability of feedforward networks composed of multiple layers of integrate-and-fire neurons to transmit rate code was examined. Synaptic connections were made only from one layer to the next, and excitation was balanced by inhibition. When time is discrete and the synaptic potentials rise instantaneously, we show that, for random uncorrelated input to layer one, the mean rate of activity in deep layers is essentially independent of input firing rate. This implies that the input rate cannot be transmitted reliably in such feedforward networks because neurons in a given layer tend to synchronize partially with each other because of shared inputs. As a result of this synchronization, the average firing rate in deep layers will either decay to zero or reach a stable fixed point, depending on model parameters. When time is treated continuously and the synaptic potentials rise instantaneously, these effects develop slowly, and rate transmission over a limited number of layers is possible. However, the correlations among neurons at the same layer hamper reliable assessment of firing rate by averaging over 100 msec (or less). When the synaptic potentials develop gradually, as is the realistic case, transmission of rate code fails. In a network in which inhibition only balances the mean excitation but is not timed precisely with it, neurons in each layer fire together, and this volley successively propagates from layer to layer. We conclude that the transmission of rate code in feedforward networks is highly unlikely.},
annote = {2010IInum9.9},
author = {Litvak, Vladimir and Sompolinsky, H and Segev, I and Abeles, Moshe},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Computer Simulation,Excitatory Postsynaptic Potentials,Kinetics,Membrane Potentials,Models,Nerve Net,Neural Inhibition,Neurological,Neurons,Neurons: physiology,Periodicity,Synaptic Transmission},
month = {apr},
number = {7},
pages = {3006--15},
pmid = {12684488},
title = {{On the transmission of rate code in long feedforward networks with excitatory-inhibitory balance.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12684488},
volume = {23},
year = {2003}
}
@article{MichevaSmith07,
author = {Micheva, K D and Smith, S J},
journal = {Neuron},
number = {1},
pages = {25--36},
title = {{Array Tomography: A New Tool for Imaging the Molecular Architecture and Ultrastructure of Neural Circuits}},
volume = {55},
year = {2007}
}
@article{Bouchard2015,
abstract = {We report a three-dimensional microscopy technique—swept, confocally-aligned planar excitation (SCAPE) microscopy—that allows volumetric imaging of living samples at ultrahigh speeds. Although confocal and two-photon microscopy have revolutionized biomedical research, current implementations are costly, complex and limited in their ability to image three-dimensional volumes at high speeds. Light-sheet microscopy techniques using two-objective, orthogonal illumination and detection require a highly constrained sample geometry and either physical sample translation or complex synchronization of illumination and detection planes. In contrast, SCAPE microscopy acquires images using an angled, swept light sheet in a single-objective, en face geometry. Unique confocal descanning and image rotation optics map this moving plane onto a stationary high-speed camera, permitting completely translationless three-dimensional imaging of intact samples at rates exceeding 20 volumes per second. We demonstrate SCAPE microscopy by imaging spontaneous neuronal firing in the intact brain of awake behaving mice, as well as freely moving transgenic Drosophila larvae.},
author = {Bouchard, Matthew B. and Voleti, Venkatakaushik and Mendes, C{\'{e}}sar S. and Lacefield, Clay and Grueber, Wesley B. and Mann, Richard S. and Bruno, Randy M. and Hillman, Elizabeth M. C.},
doi = {10.1038/nphoton.2014.323},
issn = {1749-4885},
journal = {Nature Photonics},
month = {jan},
number = {2},
pages = {113--119},
publisher = {Nature Publishing Group},
shorttitle = {Nat Photon},
title = {{Swept confocally-aligned planar excitation (SCAPE) microscopy for high-speed volumetric imaging of behaving organisms}},
url = {http://dx.doi.org/10.1038/nphoton.2014.323},
volume = {9},
year = {2015}
}
@article{mitchell1988bayesian,
author = {Mitchell, Toby J and Beauchamp, John J},
journal = {Journal of the American Statistical Association},
number = {404},
pages = {1023--1032},
publisher = {Taylor {\&} Francis},
title = {{Bayesian variable selection in linear regression}},
volume = {83},
year = {1988}
}
@article{Srivastava2014a,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets},
archivePrefix = {arXiv},
arxivId = {1102.4807},
author = {Srivastava, Nitish and Hinton, Geoffrey E. and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
doi = {10.1214/12-AOS1000},
eprint = {1102.4807},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research (JMLR)},
keywords = {deep learning,model combination,neural networks,regularization},
pages = {1929--1958},
title = {{Dropout : A Simple Way to Prevent Neural Networks from Overfitting}},
volume = {15},
year = {2014}
}
@article{Acharya|1998|,
abstract = {The phase transition between the nuclear matter and the quark matter
is examined. The relativistic mean field theory(RMF) is consider
with interacting nucleons and mesons using TM1 parameter set for
the nuclear matter equations of state. It is found that the trasition
point depends on coupling constant s and bag pressure. From the study
of the structure of a hybrid neutron star, it is observed that the
star contains quark matter in the interior and neutron matter on
the outer perifery.},
author = {Acharya, S and Maharana, L and Mohanty, R and Panda, P K},
journal = {arXiv},
keywords = {hybrid star,nonlinear sigma-model,phase transition,physics,quantum field theory},
pages = {9811041},
title = {{Phase transition and hybrid star in a nonlinear sigma-omega model}},
volume = {nucl-th}
}
@book{LEC86,
address = {New York},
author = {LeCam, L},
publisher = {Springer},
title = {{Asymptotic Methods in Statistical Decision Theory}},
year = {1986}
}
@article{Wittman|2006|,
abstract = {We discuss the problem of interpolating visually acceptable images
at a higher resolution. We first present the interpolation problem
and why linear interpolation filters are inadequate for image data.
To represent the major mathematical ap- proaches to image processing,
we discuss and evaluate five different image interpo- lation methods.
First, we present a PDE-based method derived from the anisotropic
heat equation. Next, we discuss the extension of Mumford-Shah inpainting
to im- age interpolation. A wavelet-based method that detects edges
based on correlations across sub-bands is discussed. To represent
the machine learning community, we discuss a method inspired by Locally
Linear Embedding (LLE) that interpolates im- age patches by finding
close matches in a training set. Finally, we present a novel statistical
filter based on Non Local (NL) Means denoising that interpolates
and removes noise by using global image information.},
annote = {The paper discusses mathematical approaches to interpolation of images{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}primarily for reduction of size/resolution.},
author = {Wittman, T},
keywords = {computational,image processing,interpolation,smoothing},
title = {{Mathematical Techniques for Image Interpolation}}
}
@article{London2005,
abstract = {One of the central questions in neuroscience is how particular tasks, or computations, are implemented by neural networks to generate behavior. The prevailing view has been that information processing in neural networks results primarily from the properties of synapses and the connectivity of neurons within the network, with the intrinsic excitability of single neurons playing a lesser role. As a consequence, the contribution of single neurons to computation in the brain has long been underestimated. Here we review recent work showing that neuronal dendrites exhibit a range of linear and nonlinear mechanisms that allow them to implement elementary computations. We discuss why these dendritic properties may be essential for the computations performed by the neuron and the network and provide theoretical and experimental examples to support this view.},
annote = {2010IInum12.44},
author = {London, M and H{\"{a}}usser, M},
doi = {10.1146/annurev.neuro.28.061604.135703},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {Animals,Computer Simulation,Dendrites,Dendrites: physiology,Diagnostic Imaging,Diagnostic Imaging: methods,Humans,Membrane Potentials,Membrane Potentials: physiology,Models,Nerve Net,Nerve Net: physiology,Neurological,Neuron Model,Neurons,Neurons: cytology,Neurons: physiology,Nonlinear Dynamics,Synapses,Synapses: physiology},
mendeley-tags = {Neuron Model},
month = {jan},
pages = {503--32},
pmid = {16033324},
title = {{Dendritic computation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16033324},
volume = {28},
year = {2005}
}
@article{caporale2008spike,
annote = {2008num15},
author = {Caporale, N and Dan, Y},
publisher = {Annual Reviews},
title = {{Spike Timing--Dependent Plasticity: A Hebbian Learning Rule}},
year = {2008}
}
@article{FuEb95,
author = {Fu, Q and Flament, D and Coltz, J and and Ebner, T},
journal = {Journal of Neurophysiology},
pages = {836--854},
title = {{Temporal encoding of movement kinematics in the discharge of primate primary motor and premotor neurons}},
volume = {73},
year = {1995}
}
@article{Prevedel2014,
abstract = {High-speed, large-scale three-dimensional (3D) imaging of neuronal activity poses a major challenge in neuroscience. Here we demonstrate simultaneous functional imaging of neuronal activity at single-neuron resolution in an entire Caenorhabditis elegans and in larval zebrafish brain. Our technique captures the dynamics of spiking neurons in volumes of ∼700 $\mu$m × 700 $\mu$m × 200 $\mu$m at 20 Hz. Its simplicity makes it an attractive tool for high-speed volumetric calcium imaging.},
author = {Prevedel, Robert and Yoon, Young-Gyu and Hoffmann, Maximilian and Pak, Nikita and Wetzstein, Gordon and Kato, Saul and Schr{\"{o}}del, Tina and Raskar, Ramesh and Zimmer, Manuel and Boyden, Edward S and Vaziri, Alipasha},
doi = {10.1038/nmeth.2964},
issn = {1548-7105},
journal = {Nature methods},
month = {may},
number = {May},
pmid = {24836920},
title = {{Simultaneous whole-animal 3D imaging of neuronal activity using light-field microscopy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24836920},
year = {2014}
}
@book{RWRB97,
address = {Cambridge},
author = {Rieke, F and Warland, D and {de Ruyter van Steveninck}, R and Bialek, W},
publisher = {MIT Press},
title = {{Spikes: {\{}E{\}}xploring the neural code}},
year = {1997}
}
@inproceedings{Chierichetti2010,
author = {Chierichetti, Flavio and Lattanzi, Silvio and Panconesi, Alessandro and {Universita Di Roma}, S.},
booktitle = {Proceedings of the 21st ACM-SIAM Symposium on Discrete Algorithms (SODA)},
keywords = {Network functionality},
mendeley-tags = {Network functionality},
pages = {1657--1663},
title = {{Rumour spreading and graph conductance}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Rumour+spreading+and+graph+conductance{\#}0},
year = {2010}
}
@article{sokolov2000modulation,
annote = {2009num13},
author = {Sokolov, S and Wei{\ss}, R G and Timin, E N and Hering, S},
journal = {The Journal of Physiology},
number = {3},
pages = {445},
publisher = {Physiological Soc},
title = {{Modulation of slow inactivation in class A Ca2+ channels by $\beta$-subunits}},
volume = {527},
year = {2000}
}
@article{Davidson2005,
author = {Davidson, Eric and Levin, Michael},
doi = {10.1073/pnas.0502024102},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Biological Evolution,Gene Expression Regulation, Developmental,Genes,Genes, Regulator,Genomics},
month = {apr},
number = {14},
pages = {4935},
pmid = {15809445},
title = {{Gene regulatory networks.}},
url = {http://www.pnas.org/content/102/14/4935.full},
volume = {102},
year = {2005}
}
@article{Feinberg2006,
author = {Feinberg, Joshua},
doi = {10.1088/0305-4470/39/32/S07},
issn = {0305-4470},
journal = {Journal of Physics A: Mathematical and General},
month = {aug},
number = {32},
pages = {10029--10056},
title = {{Non-Hermitian random matrix theory: summation of planar diagrams, the ‘single-ring' theorem and the disc–annulus phase transition}},
url = {http://stacks.iop.org/0305-4470/39/i=32/a=S07?key=crossref.a299737dac03de21e5e33890482ea219},
volume = {39},
year = {2006}
}
@article{Montalvo1997,
abstract = {This paper describes elements necessary for a general-purpose low-cost very large scale integration (VLSI) neural network. By choosing a learning algorithm that is tolerant of analog nonidealities, the promise of high-density analog VLSI is realized. A 64-synapse, 8-neuron proof-of-concept chip is described. The synapse, which occupies only 4900 mum(2) in a 2-mum technology, includes a hybrid of nonvolatile and dynamic weight storage that provides fast and accurate learning as well as reliable long-term storage with no refreshing. The architecture is user-configurable in any one-hidden-layer topology. The user-interface is fully microprocessor compatible. Learning is accomplished with minimal external support; the user need only present inputs, targets, and a clock. Learning is fast and reliable. The chip solves four-bit parity in an average of 680 ms and is successful in about 96{\%} of the trials.},
author = {Montalvo, a J and Gyurcsik, R S and Paulos, J J},
doi = {10.1109/72.557695},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
month = {jan},
number = {2},
pages = {413--23},
pmid = {18255643},
title = {{Toward a general-purpose analog VLSI neural network with on-chip learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255643},
volume = {8},
year = {1997}
}
@article{Yu2005,
author = {Yu, Yuguo and Romero, Richard and Lee, Tai},
doi = {10.1103/PhysRevLett.94.108103},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {mar},
number = {10},
pages = {108103},
title = {{Preference of Sensory Neural Coding for 1/f Signals}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.94.108103},
volume = {94},
year = {2005}
}
@article{BFD97,
author = {Baker, J and Fellows, M and Donoghue, J},
journal = {Society for Neuroscience Abstracts},
title = {{Directional Tuning Rotations in Motor Cortical Neurons during Radial Arm Movements}},
year = {1997}
}
@article{Martel|1998|,
abstract = {A set of cosmological variables, which we shall refer to as {\"{i}}¾‘supercomoving
variables{\"{i}}¾', are presented which are an alternative to the standard
comoving variables, particularly useful for describing the gas dynamics
of cosmic structure formation. For an ideal gas with a ratio of specific
heats g {\^{A}}¼ 5=3, the supercomoving position, velocity and thermodynamic
properties (i.e. density, temperature and pressure) of matter are
constant in time in a uniform, isotropic, adiabatically expanding
universe. Expressed in terms of these supercomoving variables, the
non-relativistic, cosmological fluid conservation equations of the
Newtonian approximation and the Poisson equation closely resemble
their non-cosmological counterparts. This makes it possible to generalize
non-cosmological results and techniques to address problems involving
departures from uniform, adiabatic Hubble expansion in a straightforward
way, for a wide range of cosmological models. These variables were
initially introduced by Shandarin to describe structure formation
in matter-dominated models. In this paper, we generalize supercomoving
variables to models with a uniform contribution to the energy density
corresponding to a non-zero cosmological constant, domain walls,
cosmic strings, a nonclumping form of non-relativistic matter (e.g.
massive neutrinos in the presence of primordial density fluctuations
of small wavelength) or a radiation background. Each model is characterized
by the value of the density parameter Q0 of the non-relativistic
matter component in which density fluctuation is possible, and the
density parameter QX0 of the additional nonclumping component. For
each type of non-clumping background, we identify families within
which different values of Q0 and QX0 lead to fluid equations and
solutions in supercomoving variables which are independent of the
cosmological parameters Q0 and QX0. We also generalize the description
to include the effects of non-adiabatic processes such as heating,
radiative cooling, thermal conduction and viscosity, as well as magnetic
fields in the MHD approximation. As an illustration, we describe
three familiar cosmological problems in supercomoving variables:
the growth of linear density fluctuations, the non-linear collapse
of a 1D plane-wave density fluctuation leading to pancake formation,
and the well-known Zel{\"{i}}¾'dovich approximation for extrapolating the
linear growth of density fluctuations in three dimensions to the
non-linear stage.},
author = {Martel, H and Shapiro, P R},
journal = {Monthly Notices of the Royal Astronomical Society},
keywords = {astrophysics,comoving variables,cosmology,cosmology: theory,dark matter,hydrodynamics,intergalactic medium,large scale structure,physics},
pages = {467},
title = {{A convenient set of comoving cosmological variables and their applications}},
volume = {297}
}
@book{Cesa-Bianchi2006,
author = {Cesa-Bianchi, N. and Lugosi, G. and Meth-, Combinatorial},
booktitle = {Statistics},
isbn = {9780521841085},
publisher = {Cambridge Univ Pr},
title = {{Prediction, learning, and games}},
url = {http://www.researchgate.net/publication/220690817{\_}Prediction{\_}learning{\_}and{\_}games/file/d912f50eae7fc7be04.pdf http://books.google.com/books?hl=en{\&}lr={\&}id=zDnRBlazhfYC{\&}oi=fnd{\&}pg=PA361{\&}dq=prediction+learning+and+games{\&}ots=6xVvbUDRwG{\&}amp},
year = {2006}
}
@article{Poirazi1996,
author = {Poirazi, Panayiota and Mel, Bartlett W},
pages = {1--33},
title = {{Impact of Active Dendrites and Structural Plasticity on the Storage Capacity of Neural Tissue}},
year = {1996}
}
@article{Helias2010,
abstract = {The integrate-and-fire neuron with exponential postsynaptic potentials is a frequently employed model to study neural networks. Simulations in discrete time still have highest performance at moderate numerical errors, which makes them first choice for long-term simulations of plastic networks. Here we extend the population density approach to investigate how the equilibrium and response properties of the leaky integrate-and-fire neuron are affected by time discretization. We present a novel analytical treatment of the boundary condition at threshold, taking both discretization of time and finite synaptic weights into account. We uncover an increased membrane potential density just below threshold as the decisive property that explains the deviations found between simulations and the classical diffusion approximation. Temporal discretization and finite synaptic weights both contribute to this effect. Our treatment improves the standard formula to calculate the neuron's equilibrium firing rate. Direct solution of the Markov process describing the evolution of the membrane potential density confirms our analysis and yields a method to calculate the firing rate exactly. Knowing the shape of the membrane potential distribution near threshold enables us to devise the transient response properties of the neuron model to synaptic input. We find a pronounced non-linear fast response component that has not been described by the prevailing continuous time theory for Gaussian white noise input.},
author = {Helias, Moritz and Deger, Moritz and Diesmann, Markus and Rotter, Stefan},
doi = {10.3389/neuro.10.029.2009},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {discrete time,equilibrium properties,fi nite synaptic weights,immediate fi ring,leaky integrate-and-fi re neuron,membrane potential distribution,non-linear response,perturbation theory,rate response},
month = {jan},
number = {January},
pages = {29},
pmid = {20130755},
title = {{Equilibrium and Response Properties of the Integrate-and-Fire Neuron in Discrete Time.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2805428{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2805428/ http://www.ncbi.nlm.nih.gov/pubmed/20130755},
volume = {3},
year = {2010}
}
@book{HIDA80,
address = {New York},
author = {Hida, T},
publisher = {Springer-Verlag},
title = {{Brownian Motion}},
year = {1980}
}
@article{MossopMoore00,
abstract = {Physiological and neurochemical experiments described here suggest

that unilateral deafening causes a reduction in inhibition in the

adult gerbil inferior colliculus (IC) contralateral to the deafened

ear. Multiple-unit recordings were made from single electrode penetrations

in the IC prior to and directly after contralateral cochlear ablation.

These recordings showed up to 60{\%} increases in the proportion of

sampled loci at which neural activity excited by ipsilateral stimulation

was observed after the ablation. Novel excitatory responses were

evident within minutes of the ablation. Western blotting for glutamic

acid decarboxylase protein levels showed significant decreases in

the IC contralateral to cochlear ablation, relative to those in the

ipsilateral IC, at 24 h and 7 days survival after the ablation. Four

hour or 1 year survival post-ablation did not produce significant

contralateral/ipsilateral differences in relation to the control

group. Taken together, these results suggest the presence of at least

two, short-term mechanisms involved in the central response to cochlear

removal, both of which appear to implicate a decreased inhibitory

influence. One is a very rapid, stimulus-related, functional unmasking.

The other is a more delayed reduction in the capacity of gamma-aminobutyric

acid synthesis in the IC.},
author = {Mossop, J E and Wilson, M J and Caspary, D M and Moore, D R},
journal = {Hearing Research},
keywords = {Animals; Cochlea; Deafness; Down-Regulation; Evok;,Auditory,Non-U.S. Gov't; Research Support,P.H.S.; ed Potentials,U.S. Gov't},
month = {sep},
number = {1-2},
pages = {183--187},
pmid = {10962184},
title = {{Down-regulation of inhibition following unilateral deafening.}},
volume = {147},
year = {2000}
}
@article{Gong2015,
abstract = {Genetically encoded voltage indicators (GEVIs) are a promising technology for fluorescence readout of millisecond-scale neuronal dynamics. Prior GEVIs had insufficient signaling speed and dynamic range to resolve action potentials in live animals. We coupled fast voltage-sensing domains from a rhodopsin protein to bright fluorophores via resonance energy transfer. The resulting GEVIs are sufficiently bright and fast to report neuronal action potentials and membrane voltage dynamics in awake mice and flies, resolving fast spike trains with 0.2-millisecond timing precision at spike detection error rates orders of magnitude better than prior GEVIs. In vivo imaging revealed sensory-evoked responses, including somatic spiking, dendritic dynamics, and intracellular voltage propagation. These results empower in vivo optical studies of neuronal electrophysiology and coding and motivate further advancements in high-speed microscopy.},
author = {Gong, Yiyang and Huang, Cheng and Li, Jin Zhong and Grewe, Benjamin F. and Zhang, Yanping and Eismann, Stephan and Schnitzer, Mark J},
doi = {10.1126/science.aab0810},
issn = {1095-9203},
journal = {Sciencexpress},
number = {November},
pages = {1--11},
pmid = {26586188},
title = {{High-speed recording of neural spikes in awake mice and flies with a fluorescent voltage sensor}},
volume = {350},
year = {2015}
}
@article{Fiorillo2008,
abstract = {Although there has been tremendous progress in understanding the mechanics of the nervous system, there has not been a general theory of its computational function. Here I present a theory that relates the established biophysical properties of single generic neurons to principles of Bayesian probability theory, reinforcement learning and efficient coding. I suggest that this theory addresses the general computational problem facing the nervous system. Each neuron is proposed to mirror the function of the whole system in learning to predict aspects of the world related to future reward. According to the model, a typical neuron receives current information about the state of the world from a subset of its excitatory synaptic inputs, and prior information from its other inputs. Prior information would be contributed by synaptic inputs representing distinct regions of space, and by different types of non-synaptic, voltage-regulated channels representing distinct periods of the past. The neuron's membrane voltage is proposed to signal the difference between current and prior information ("prediction error" or "surprise"). A neuron would apply a Hebbian plasticity rule to select those excitatory inputs that are the most closely correlated with reward but are the least predictable, since unpredictable inputs provide the neuron with the most "new" information about future reward. To minimize the error in its predictions and to respond only when excitation is "new and surprising," the neuron selects amongst its prior information sources through an anti-Hebbian rule. The unique inputs of a mature neuron would therefore result from learning about spatial and temporal patterns in its local environment, and by extension, the external world. Thus the theory describes how the structure of the mature nervous system could reflect the structure of the external world, and how the complexity and intelligence of the system might develop from a population of undifferentiated neurons, each implementing similar learning algorithms.},
annote = {2010IIInum11},
author = {Fiorillo, Christopher D},
doi = {10.1371/journal.pone.0003298},
issn = {1932-6203},
journal = {PloS one},
keywords = {Algorithms,Biological,Models,Neurons,Neurons: physiology},
month = {jan},
number = {10},
pages = {e3298},
pmid = {18827880},
title = {{Towards a general theory of neural computation based on prediction by single neurons.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2553191{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {3},
year = {2008}
}
@article{Kobayashi2010,
annote = {2011num30},
author = {Kobayashi, Tetsuya J.},
doi = {10.1103/PhysRevLett.104.228104},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {jun},
number = {22},
pages = {1--4},
title = {{Implementation of Dynamic Bayesian Decision Making by Intracellular Kinetics}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.104.228104},
volume = {104},
year = {2010}
}
@article{Gielen1994,
author = {Gielen, G. and Wambacq, P. and Sansen, W.M. M},
doi = {10.1109/5.265355},
issn = {00189219},
journal = {Proceedings of the IEEE},
number = {2},
pages = {287--304},
title = {{Symbolic analysis methods and applications for analog circuits: a tutorial overview}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=265355},
volume = {82},
year = {1994}
}
@article{Bourne|2007|a,
author = {Bourne, J and Sorra, K E and Hurlburt, J and Harris, K M},
journal = {Hippocampus},
number = {1},
pages = {1--4},
title = {{Polyribosomes are increased in spines of CA1 dendrites 2 h after the induction of LTP in mature rat hippocampal slices.}},
volume = {17}
}
@article{RB88,
author = {{de Ruyter van Steveninck}, R and Bialek, W},
journal = {Proc. R. Soc. Lond. B},
pages = {379--414},
title = {{Real-time performance of a movement-senstivive neuron in the blowfly visual system: coding and information transmission in short spike sequences.}},
volume = {234},
year = {1988}
}
@article{Goldman1943,
abstract = {Impedance and potential measurements have been made on a number of artificial membranes. Impedance changes were determined as functions of current and of the composition of the environmental solutions. It was shown that rectification is present in asymmetrical systems and that it increases with the membrane potential. The behavior in pairs of solutions of the same salt at different concentrations has formed the basis for the studies although a few experiments with different salts at the same concentrations gave results consistent with the conclusions drawn.A theoretical picture has been presented based on the use of the general kinetic equations for ion motion under the influence of diffusion and electrical forces and on a consideration of possible membrane structures. The equations have been solved for two very simple cases; one based on the assumption of microscopic electroneutrality, and the other on the assumption of a constant electric field. The latter was found to give better results than the former in interpreting the data on potentials and rectification, showing agreement, however, of the right order of magnitude only. Although the indications are that a careful treatment of boundary conditions may result in better agreement with experiment, no attempt has been made to carry this through since the data now available are not sufficiently complete or reproducible. Applications of the second theoretical case to the squid giant axon have been made showing qualitative agreement with the rectification properties and very good agreement with the membrane potential data.},
author = {Goldman, D. E.},
doi = {10.1085/jgp.27.1.37},
issn = {0022-1295},
journal = {The Journal of General Physiology},
month = {sep},
number = {1},
pages = {37--60},
title = {{POTENTIAL, IMPEDANCE, AND RECTIFICATION IN MEMBRANES}},
url = {http://jgp.rupress.org/cgi/content/abstract/27/1/37},
volume = {27},
year = {1943}
}
@article{Chklovskii|2002|,
author = {Chklovskii, D and Schikorski, T and Stevens, C},
journal = {Neuron},
pages = {341--347},
title = {{Wiring optimization in cortical circuits}},
volume = {34}
}
@book{laing2009stochastic,
author = {Laing, C. and Lord, G.J.},
isbn = {0199235074},
publisher = {Oxford University Press, USA},
title = {{Stochastic Methods in Neuroscience}},
url = {http://www.google.com/books?hl=iw{\&}lr={\&}id=wcEUM615iRIC{\&}oi=fnd{\&}pg=PR5{\&}dq=Stochastic+Methods+in+Neuroscience{\&}ots=Byxcts72g1{\&}sig=KcML{\_}XLOBalEpQvm1CUewBVvZiM},
year = {2009}
}
@article{Richardson2010,
annote = {2011num24},
author = {Richardson, M J E and Swarbrick, R},
issn = {1079-7114},
journal = {Physical Review Letters},
number = {17},
pages = {178102},
publisher = {APS},
title = {{Firing-rate response of a neuron receiving excitatory and inhibitory synaptic shot noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.105.178102},
volume = {105},
year = {2010}
}
@incollection{SPPS04,
author = {Simoncelli, E and Paninski, L and Pillow, J W and Schwartz, O},
booktitle = {The Cognitive Neurosciences},
edition = {3rd},
publisher = {MIT Press},
title = {{Characterization of neural responses with stochastic stimuli}},
year = {2004}
}
@article{NG04,
author = {Ng, A Y},
journal = {ICML},
title = {{Feature selection, {\{}L{\}}{\_}1 vs. {\{}L{\}}{\_}2 regularization, and rotational invariance}},
volume = {21},
year = {2004}
}
@article{HARR03,
author = {Harris, K and Csicsvari, J and Hirase, H and Dragoi, G and Buzsaki, G},
journal = {Nature},
pages = {552--556},
title = {{Organization of cell assemblies in the hippocampus}},
volume = {424},
year = {2003}
}
@article{RajanHeil93,
abstract = {We examined the effect of unilateral restricted cochlear lesions in

adult cats on the topographic representations ("maps") of the lesioned

and unlesioned cochleas in the primary auditory cortex (AI) contralateral

to the lesioned cochlea. Frequency (tonotopic) maps were derived

by conventional multineuron mapping procedures in anesthetized animals.

In confirmation of a study in adult guinea pigs (Robertson and Irvine

[1989] J. Comp. Neurol. 282:456-471), we found that 2-11 months after

the unilateral cochlear lesion the map of the lesioned cochlea in

the contralateral AI was altered so that the AI region in which frequencies

with lesion-induced elevations in cochlear neural sensitivity would

have been represented was occupied by an enlarged representation

of lesion-edge frequencies (i.e., frequencies adjacent to those with

elevated cochlear neural sensitivity). Along the tonotopic axis of

AI the total representation of lesion-edge frequencies could extend

up to approximately 2.6 mm rostal to the area of normal representation

of these frequencies. There was no topographic order within this

enlarged representation. Examination of threshold sensitivity at

the characteristic frequency (CF, frequency to which the neurons

were most sensitive) in the reorganized regions of the map of the

lesioned cochlea established that the changes in the map reflected

a plastic reorganization rather than simply reflecting the residue

of prelesion input. In contrast to the change in the map of the lesioned

contralateral cochlea, the map of the unlesioned ipsilateral cochlea

did not differ from those in normal animals. Thus, in contrast to

the normal very good congruency between ipsilateral and contralateral

AI maps, in the lesioned animals ipsilateral and contralateral maps

differed in the region of AI in which there had been a reorganization

of the map of the lesioned cochlea. Outside the region of contralateral

map reorganization, ipsilateral and contralateral AI maps remained

congruent within normal limits. The difference between the two maps

in the region of contralateral map reorganization suggested, in light

of the physiology of binaural interactions in the auditory pathway,

that the cortical reorganization reflected subcortical changes. Finally,

response properties of neuronal clusters within the reorganized map

of the lesioned cochlea were compared to normative data with respect

to threshold sensitivity at CF, the size of frequency "response areas,"

and response latencies. In the majority of cases, CF thresholds were

similar to normative data. The frequency "response areas" were slightly

less sharply tuned than normal, but not significantly. Response latencies

were significantly shorter than normal in three animals and significantly

longer in one animal.},
author = {Rajan, R and Irvine, D R and Wise, L Z and Heil, P},
doi = {10.1002/cne.903380104},
journal = {Journal of Comparative Neurology},
keywords = {Animals; Auditory Cortex; Auditory Pathways; Brain},
month = {dec},
number = {1},
pages = {17--49},
pmid = {8300898},
title = {{Effect of unilateral partial cochlear lesions in adult cats on the representation of lesioned and unlesioned cochleas in primary auditory cortex.}},
url = {http://dx.doi.org/10.1002/cne.903380104},
volume = {338},
year = {1993}
}
@article{Fazel,
author = {Fazel, M and Hindi, H and Boyd, S P},
doi = {10.1109/ACC.2001.945730},
isbn = {0-7803-6495-3},
journal = {American Control Conference},
pages = {4734--4739},
publisher = {Ieee},
title = {{A rank minimization heuristic with application to minimum order system approximation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=945730 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=945730},
volume = {6},
year = {2001}
}
@article{PAN03,
author = {Paninski, L},
journal = {Neural Computation},
pages = {1191--1253},
title = {{Estimation of entropy and mutual information}},
volume = {15},
year = {2003}
}
@article{RG01,
author = {Rasmussen, C and Ghahramani, Z},
journal = {NIPS},
pages = {294--300},
title = {{Occam's Razor}},
volume = {13},
year = {2001}
}
@article{Wickersham07,
author = {Wickersham, I and Lyon, D and Barnard, R and Mori, T and Finke, S and Conzelmann, K.-K. and Young, J and Callaway, E},
journal = {Neuron},
pages = {639--647},
title = {{Monosynaptic Restriction of Transsynaptic Tracing from Single, Genetically Targeted Neurons}},
volume = {53},
year = {2007}
}
@article{Harris|1988|,
author = {Harris, K M and Stevens, J K},
journal = {J Neurosci},
pages = {4455--4469},
title = {{Dendritic spines of rat cerebellar Purkinje cells: Serial electron microscopy with reference to their biophysical characteristics.}},
volume = {8}
}
@misc{McCammon|2006|,
annote = {This is screen thickness diagram for different directions in x-calorimeter{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}experiment of McCammon},
author = {McCammon, D},
keywords = {astrophysics,interacting dark matter,physics,screen thickness,x-calorimeter},
title = {{Mass-vs-Angle screen thickness}}
}
@article{Milescu2005,
abstract = {We describe a maximum likelihood method for direct estimation of rate constants from macroscopic ion channel data for kinetic models of arbitrary size and topology. The number of channels in the preparation, and the mean and standard deviation of the unitary current can be estimated, and a priori constraints can be imposed on rate constants. The method allows for arbitrary stimulation protocols, including stimuli with finite rise time, trains of ligand or voltage steps, and global fitting across different experimental conditions. The initial state occupancies can be optimized from the fit kinetics. Utilizing arbitrary stimulation protocols and using the mean and the variance of the current reduce or eliminate problems of model identifiability (Kienker, 1989). The algorithm is faster than a recent method that uses the full autocovariance matrix (Celentano and Hawkes, 2004), in part due to the analytical calculation of the likelihood gradients. We tested the method with simulated data and with real macroscopic currents from acetylcholine receptors, elicited in response to brief pulses of carbachol. Given appropriate stimulation protocols, our method chose a reasonable model size and topology.},
annote = {2010num3.5},
author = {Milescu, L S and Akk, G and Sachs, F},
doi = {10.1529/biophysj.104.053256},
issn = {0006-3495},
journal = {Biophysical Journal},
number = {4},
pages = {2494--515},
pmid = {15681642},
title = {{Maximum likelihood estimation of ion channel kinetics from macroscopic currents.}},
url = {http://dx.doi.org/10.1529/biophysj.104.053256},
volume = {88},
year = {2005}
}
@article{GK96,
author = {Gabbiani, F and Koch, C},
journal = {Neural Computation},
pages = {44--66},
title = {{Coding of Time-Varying Signals In Spike Trains of Integrate-and-Fire Neurons With Random Threshold}},
volume = {8},
year = {1996}
}
@article{ES81,
author = {Efron, B and Stein, C},
journal = {Annals of Statistics},
pages = {586--596},
title = {{The jackknife estimate of variance}},
volume = {9},
year = {1981}
}
@article{Beggs2004,
abstract = {A major goal of neuroscience is to elucidate mechanisms of cortical information processing and storage. Previous work from our laboratory (Beggs and Plenz, 2003) revealed that propagation of local field potentials (LFPs) in cortical circuits could be described by the same equations that govern avalanches. Whereas modeling studies suggested that these "neuronal avalanches" were optimal for information transmission, it was not clear what role they could play in information storage. Work from numerous other laboratories has shown that cortical structures can generate reproducible spatiotemporal patterns of activity that could be used as a substrate for memory. Here, we show that although neuronal avalanches lasted only a few milliseconds, their spatiotemporal patterns were also stable and significantly repeatable even many hours later. To investigate these issues, we cultured coronal slices of rat cortex for 4 weeks on 60-channel microelectrode arrays and recorded spontaneous extracellular LFPs continuously for 10 hr. Using correlation-based clustering and a global contrast function, we found that each cortical culture spontaneously produced 4736 +/- 2769 (mean +/- SD) neuronal avalanches per hour that clustered into 30 +/- 14 statistically significant families of spatiotemporal patterns. In 10 hr of recording, over 98{\%} of the mutual information shared by these avalanche patterns were retained. Additionally, jittering analysis revealed that the correlations between avalanches were temporally precise to within +/-4 msec. The long-term stability, diversity, and temporal precision of these avalanches indicate that they fulfill many of the requirements expected of a substrate for memory and suggest that they play a central role in both information transmission and storage within cortical networks.},
author = {Beggs, John M and Plenz, D},
doi = {10.1523/JNEUROSCI.0540-04.2004},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Cluster Analysis,Memory,Memory: physiology,Microelectrodes,Models, Neurological,Neostriatum,Neostriatum: physiology,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Rats,Rats, Sprague-Dawley,Reproducibility of Results,Signal Processing, Computer-Assisted,Substantia Nigra,Substantia Nigra: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
month = {jun},
number = {22},
pages = {5216--29},
pmid = {15175392},
title = {{Neuronal avalanches are diverse and precise activity patterns that are stable for many hours in cortical slice cultures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15175392},
volume = {24},
year = {2004}
}
@article{Nuno-maganda2007,
author = {Nuno-maganda, Marco Aurelio and Arias-estrada, Miguel and Torres-huitzil, Cesar},
isbn = {1424406064},
pages = {167--170},
title = {{AN EFFICIENT SCALABLE PARALLEL HARDWARE ARCHITECTURE FOR Recallr resourtes hae paraeismp ofmAnt modemn uder-a Yk (}},
year = {2007}
}
@article{Monteforte,
archivePrefix = {arXiv},
arxivId = {arXiv:1102.5428v1},
author = {Monteforte, Michael and Wolf, Fred},
doi = {10.1103/PhysRevX.2.041007},
eprint = {arXiv:1102.5428v1},
keywords = {biological physics,interdisciplinary physics},
pages = {1--4},
title = {{Reservoirs of Stability: Flux Tubes in the Dynamics of Cortical Circuits}},
volume = {041007},
year = {2012}
}
@article{BRG05,
author = {Badel, Laurent and Gerstner, Wulfram and Richardson, Magnus J E},
journal = {Physical Review E (Statistical, Nonlinear, and Soft Matter Physics)},
pages = {11914},
title = {{Spike-triggered averages for passive and resonant neurons receiving filtered excitatory and inhibitory synaptic drive}},
volume = {78},
year = {2008}
}
@article{Frieden1994,
annote = {Information theory and statistical mechanics course},
author = {Frieden, B R and Hughes, RJ},
journal = {Physical Review E},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
title = {{Spectral 1/f noise derived from extremized physical information}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.49.2644},
year = {1994}
}
@article{Kumar,
author = {Kumar, Vipin and Shekhar, S and Amin, MB},
journal = {Parallel and Distributed {\ldots}},
pages = {1--28},
title = {{A scalable parallel formulation of the backpropagation algorithm for hypercubes and related architectures}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=313123},
year = {1994}
}
@article{Deger2011,
abstract = {The Poisson process is an often employed model for the activity of neuronal populations. It is known, though, that superpositions of realistic, non- Poisson spike trains are not in general Poisson processes, not even for large numbers of superimposed processes. Here we construct superimposed spike trains from intracellular in vivo recordings from rat neocortex neurons and compare their statistics to specific point process models. The constructed superimposed spike trains reveal strong deviations from the Poisson model. We find that superpositions of model spike trains that take the effective refractoriness of the neurons into account yield a much better description. A minimal model of this kind is the Poisson process with dead-time (PPD). For this process, and for superpositions thereof, we obtain analytical expressions for some second-order statistical quantities-like the count variability, inter-spike interval (ISI) variability and ISI correlations-and demonstrate the match with the in vivo data. We conclude that effective refractoriness is the key property that shapes the statistical properties of the superposition spike trains. We present new, efficient algorithms to generate superpositions of PPDs and of gamma processes that can be used to provide more realistic background input in simulations of networks of spiking neurons. Using these generators, we show in simulations that neurons which receive superimposed spike trains as input are highly sensitive for the statistical effects induced by neuronal refractoriness.},
author = {Deger, Moritz and Helias, Moritz and Boucsein, Clemens and Rotter, Stefan},
doi = {10.1007/s10827-011-0362-8},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {network simulation,point process,population activity,serial interval correlations,spike train simulation,spike train variability},
month = {oct},
pages = {443--463},
pmid = {21964584},
title = {{Statistical properties of superimposed stationary spike trains.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21964584},
year = {2011}
}
@article{Gelfand1990,
author = {Gelfand, A E and Smith, A F M},
journal = {Journal of the American Stat. Assoc.},
pages = {398--409},
title = {{Sampling-based approaches to calculating marginal densities}},
volume = {85},
year = {1990}
}
@article{HelmchenDenk05,
abstract = {With few exceptions biological tissues strongly scatter light, making

high-resolution deep imaging impossible for traditional-including

confocal-fluorescence microscopy. Nonlinear optical microscopy, in

particular two photon-excited fluorescence microscopy, has overcome

this limitation, providing large depth penetration mainly because

even multiply scattered signal photons can be assigned to their origin

as the result of localized nonlinear signal generation. Two-photon

microscopy thus allows cellular imaging several hundred microns deep

in various organs of living animals. Here we review fundamental concepts

of nonlinear microscopy and discuss conditions relevant for achieving

large imaging depths in intact tissue.},
author = {Helmchen, Fritjof and Denk, W},
doi = {10.1038/nmeth818},
journal = {Nat Methods},
keywords = {Animals; Fluorescent Dyes; Humans; Imaging,Confocal; Microscopy,Fluorescence,Multiphoton,Three-Dimensional; Microscopy},
month = {dec},
number = {12},
pages = {932--940},
pmid = {16299478},
title = {{Deep tissue two-photon microscopy.}},
url = {http://dx.doi.org/10.1038/nmeth818},
volume = {2},
year = {2005}
}
@article{Salakhutdinov08,
author = {Salakhutdinov, Ruslan and Mnih, Andriy},
journal = {ICML},
title = {{Bayesian Probabilistic Matrix Factorization using {\{}MCMC{\}}}},
year = {2008}
}
@book{DeFelice81,
author = {{DeFelice, L.}},
publisher = {Plenum Press},
title = {{Introduction to Membrane Noise}},
year = {1981}
}
@article{Goodman|1985|,
abstract = {We consider the possibility that the neutral-current neutrino detector
recently proposed by Drukier and Stodolsky could be used to detect
some possible candidates for the dark matter in galactic halos. This
may be feasible if the galactic halos are made of particles with
coherent weak interactions and masses 1-10{\^{}}6 GeV; particles with
spin-dependent interactions of typical weak strength and masses 1-10{\^{}}2
GeV; or strongly interacting particles of masses 1-10{\^{}}13 GeV},
annote = {This important paper discusses exclusion ranges on interacting dark{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}matter particles},
author = {Goodman, M W and Witten, E},
journal = {Physical Review D},
keywords = {astrophysics,cold dark matter,detection,detector,exclusion limits,physics},
number = {12},
pages = {3059},
title = {{Detectability of certain dark-matter candidates}},
volume = {31}
}
@article{Petreanu09,
author = {Petreanu, L and Mao, T and Sternson, S and and Svoboda, K},
journal = {Nature},
pages = {1142--1145},
title = {{The subcellular organization of neocortical excitatory connections}},
volume = {457},
year = {2009}
}
@article{Shepherd|1998|,
abstract = {Physiological studies of CA3--{\textgreater}CA1 synaptic transmission and plasticity
have revealed both pre- and postsynaptic effects. Understanding the
extent to which individual presynaptic axonal boutons could provide
local compartments for control of synaptic efficacy and microconnectivity
requires knowledge of their three-dimensional morphology and composition.
In hippocampal slices, serial electron microscopy was used to examine
a nearly homogeneous population of CA3--{\textgreater}CA1 axons in the middle
of stratum radiatum of area CA1. The locations of postsynaptic densities
(PSDs), vesicles, and mitochondria were determined along 75 axon
segments (9.1 +/- 2.0 micrometer in length). Synapses, defined by
the colocalization of PSDs and vesicles, occurred on average at 2.7
micrometer intervals along the axons. Most varicosities (68{\%}) had
one PSD, 19{\%} had 2-4 PSDs, and 13{\%} had none. Synaptic vesicles occurred
in 90{\%} of the varicosities. One-half (53{\%}) of the varicosities lacked
mitochondria, raising questions about their regulation of ATP and
Ca2+, and 8{\%} of varicosities contained only mitochondria. Eleven
axons were reconstructed fully. The varicosities were oblong and
varied greatly in both length (1.1 +/- 0.7 micrometer) and volume
(0.13 +/- 0.14 micrometer 3), whereas the intervaricosity shafts
were narrow, tubular, and similar in diameter (0.17 +/- 0.04 micrometer)
but variable in length (1.4 +/- 1.2 micrometer). The narrow axonal
shafts resemble dendritic spine necks and thus could promote biochemical
compartmentalization of individual axonal varicosities. The findings
raise the intriguing possibility of localized differences in metabolism
and connectivity among different axons, varicosities, and synapses.},
annote = {MH/DA57351/MH/United States NIMH NS21184/NS/United States NINDS P30-HD18655/HD/United{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}States NICHD Journal Article Research Support, U.S. Gov{\&}{\#}039;t, P.H.S.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}United states the official journal of the Society for Neuroscience},
author = {Shepherd, G M and Harris, K M},
journal = {J Neurosci},
keywords = {Animals Cell Communication/physiology Cell Compart,Computer-Assisted Interneurons/cytology/physiolog,Electron Mitochondria/ultrastructure Organ Cultur,Long-Evans Synaptic Vesicles/physiology/ultrastru},
number = {20},
pages = {8300--8310},
title = {{Three-dimensional structure and composition of CA3--{\textgreater}CA1 axons in rat hippocampal slices: implications for presynaptic connectivity and compartmentalization}},
volume = {18}
}
@article{Bloch1976,
annote = {2011num6},
author = {Bloch, Felix},
doi = {10.1063/1.3024633},
issn = {00319228},
journal = {Physics Today},
keywords = {interesting},
mendeley-tags = {interesting},
number = {12},
pages = {23},
title = {{Heisenberg and the early days of quantum mechanics}},
url = {http://people.westminstercollege.edu/faculty/ccline/courses/phys425/PT{\_}29(12){\_}p23.pdf http://link.aip.org/link/PHTOAD/v29/i12/p23/s1{\&}Agg=doi},
volume = {29},
year = {1976}
}
@article{OheimCharpak01,
author = {Oheim, M and Beaurepaire, E and Chaigneau, E and Mertz, J and Charpak, S},
journal = {Journal of neuroscience methods},
number = {1},
pages = {29--37},
publisher = {Elsevier Science},
title = {{Two-photon microscopy in brain tissue: parameters influencing the imaging depth}},
volume = {111},
year = {2001}
}
@inproceedings{KlaasDoucet05,
address = {Arlington, Virginia},
author = {Klaas, Mike and de Freitas, Nando and Doucet, Arnaud},
booktitle = {Proceedings of the 21th Annual Conference on Uncertainty in Artificial Intelligence (UAI-05)},
pages = {308--331},
publisher = {AUAI Press},
title = {{Toward Practical N2 Monte Carlo: the Marginal Particle Filter}},
year = {2005}
}
@misc{Soudry2013c,
author = {Soudry, D. and {Di Castro}, D. and Gal, A. and Kolodny, A. and Kvatinsky, S.},
publisher = {US Patent 62/317,665, Filed},
title = {{Analog Multiplier Using Memristor a Memristive Device and Methods for Implementing Hebbian Learning Rules Using Memristor Arrays}},
year = {2013}
}
@article{Freestone2011,
author = {Freestone, D R and Aram, P and Dewar, M and Scerri, K and Grayden, D B and Kadirkamanathan, V},
journal = {NeuroImage},
title = {{A data-driven framework for neural field modeling}},
volume = {In Press},
year = {2011}
}
@article{bonifazi2005statistical,
author = {Bonifazi, Paolo and Ruaro, M E and Torre, V},
journal = {European Journal of Neuroscience},
keywords = {networks},
mendeley-tags = {networks},
number = {11},
pages = {2953--2964},
publisher = {Oxford, UK: Published on behalf of the European Neuroscience Association by Oxford University Press, c1989-},
title = {{Statistical properties of information processing in neuronal networks}},
volume = {22},
year = {2005}
}
@article{Meng-Wong96,
author = {Meng, X L and Wong, W H},
journal = {Statistica Sinica},
pages = {831--860},
title = {{Simulating ratios of normalizing constants via a simple identity: A theoretical exploration}},
volume = {6},
year = {1996}
}
@article{Harris|2003|,
author = {Harris, K M and Fiala, J C and Ostroff, L E},
journal = {Philos Trans R Soc Lond B Biol Sci},
pages = {745--748},
title = {{Structural changes at dendritic spine synapses during long-term potentiation.}},
volume = {358}
}
@article{BR01,
annote = {2009num28},
author = {Brenner, N and Bialek, W and {de Ruyter van Steveninck}, R R},
journal = {Neuron},
number = {3},
pages = {695--702},
publisher = {Elsevier},
title = {{Adaptive rescaling optimizes information transmission}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627300812052},
volume = {26},
year = {2001}
}
@article{Roudi2011,
author = {Roudi, Y and Hertz, John},
doi = {10.1103/PhysRevLett.106.048702},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {jan},
number = {4},
pages = {048702},
title = {{Mean Field Theory for Nonequilibrium Network Reconstruction}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.106.048702},
volume = {106},
year = {2011}
}
@article{Berger2011,
abstract = {A primary objective in developing a neural prosthesis is to replace neural circuitry in the brain that no longer functions appropriately. Such a goal requires artificial reconstruction of neuron-to-neuron connections in a way that can be recognized by the remaining normal circuitry, and that promotes appropriate interaction. In this study, the application of a specially designed neural prosthesis using a multi-input/multi-output (MIMO) nonlinear model is demonstrated by using trains of electrical stimulation pulses to substitute for MIMO model derived ensemble firing patterns. Ensembles of CA3 and CA1 hippocampal neurons, recorded from rats performing a delayed-nonmatch-to-sample (DNMS) memory task, exhibited successful encoding of trial-specific sample lever information in the form of different spatiotemporal firing patterns. MIMO patterns, identified online and in real-time, were employed within a closed-loop behavioral paradigm. Results showed that the model was able to predict successful performance on the same trial. Also, MIMO model-derived patterns, delivered as electrical stimulation to the same electrodes, improved performance under normal testing conditions and, more importantly, were capable of recovering performance when delivered to animals with ensemble hippocampal activity compromised by pharmacologic blockade of synaptic transmission. These integrated experimental-modeling studies show for the first time that, with sufficient information about the neural coding of memories, a neural prosthesis capable of real-time diagnosis and manipulation of the encoding process can restore and even enhance cognitive, mnemonic processes.},
annote = {2011num33},
author = {Berger, T W and Hampson, R E and Song, D and Goonawardena, A and Marmarelis, V Z and Deadwyler, S A},
doi = {10.1088/1741-2560/8/4/046017},
issn = {1741-2552},
journal = {Journal of neural engineering},
month = {jun},
number = {4},
pages = {046017},
pmid = {21677369},
title = {{A cortical neural prosthesis for restoring and enhancing memory.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21677369},
volume = {8},
year = {2011}
}
@inproceedings{Boukhobza2008a,
author = {Boukhobza, Taha and Hamelin, Fr{\'{e}}d{\'{e}}ric},
booktitle = {17th IFAC World Congress},
keywords = {Reservoir Computing,generic state and input,graph theory,observability,structured bilinear systems},
mendeley-tags = {Reservoir Computing},
title = {{State and input observability for structured bilinear systems : A graph-theoretic approach}},
year = {2008}
}
@article{Blackstad|1956|,
annote = {Journal Article Not Available},
author = {Blackstad, T W},
journal = {J Comp Neurol},
keywords = {*Hippocampus},
number = {3},
pages = {417--537},
title = {{Commissural connections of the hippocampal region in the rat, with special reference to their mode of termination}},
volume = {105}
}
@article{LimHW2002,
abstract = {Red-cell shape is encoded in the mechanical properties of the membrane. The plasma membrane contributes bending rigidity; the protein-based membrane skeleton contributes stretch and shear elasticity. When both effects are included, membrane mechanics can reproduce in detail the full stomatocyte-discocyte-echinocyte sequence by variation of a single parameter related to the bilayer couple originally introduced by Sheetz and Singer [Sheetz, M. P. {\&} Singer, S. J. (1974) Proc. Natl. Acad. Sci. USA 71, 4457-4461].},
author = {{Lim H  W}, Gerald and Wortis, Michael and Mukhopadhyay, Ranjan and W, Gerald Lim H and {Lim H W}, Gerald},
doi = {10.1073/pnas.202617299},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Biomechanics,Erythrocyte Membrane,Erythrocyte Membrane: chemistry,Erythrocytes,Erythrocytes: cytology,Humans,Lipid Bilayers,Lipid Bilayers: chemistry},
month = {dec},
number = {26},
pages = {16766--9},
pmid = {12471152},
title = {{Stomatocyte-discocyte-echinocyte sequence of the human red blood cell: evidence for the bilayer- couple hypothesis from membrane mechanics.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=139218{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {99},
year = {2002}
}
@article{WeiTanner90,
author = {Wei, G and Tanner, M},
journal = {Journal of the American Statistical Association},
pages = {699--704},
title = {{A {\{}Monte Carlo{\}} Implementation of the {\{}EM{\}} Algorithm and the Poor Man's Data Augmentation Algorithms}},
volume = {85},
year = {1990}
}
@article{Pachitariu,
author = {Pachitariu, Marius and Packer, Adam and Pettit, Noah and Dagleish, Henry and Hausser, Michael and Sahani, Maneesh},
pages = {1--9},
title = {{Extracting regions of interest from biological images with convolutional sparse block coding}},
volume = {1}
}
@article{MugnainiKorte80,
author = {Mugnaini, E and Osen, K K and Dahl, A L and Friedrich, V L Jr and Korte, G},
journal = {Journal of Neurocytology},
month = {aug},
number = {4},
pages = {537--570},
title = {{Fine structure of granule cells and related interneurons (termed {\{}G{\}}olgi cells) in the cochlear nuclear complex of cat, rat and mouse}},
volume = {9},
year = {1980}
}
@article{Poczos2009,
abstract = {We introduce novel online Bayesian methods for the identification of a family of noisy recurrent neural networks (RNNs). We present Bayesian active learning techniques for stimulus selection given past experiences. In particular, we consider the unknown parameters as stochastic variables and use A-optimality and D-optimality principles to choose optimal stimuli. We derive myopic cost functions in order to maximize the information gain concerning network parameters at each time step. We also derive the A-optimal and D-optimal estimations of the additive noise that perturbs the dynamical system of the RNN. Here we investigate myopic as well as non-myopic estimations, and study the problem of simultaneous estimation of both the system parameters and the noise. Employing conjugate priors our derivations remain approximation-free and give rise to simple update rules for the online learning of the parameters. The efficiency of our method is demonstrated for a number of selected cases, including the task of controlled independent component analysis.},
author = {P{\'{o}}czos, Barnab{\'{a}}s and Lorincz, Andr{\'{a}}s},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {a optimality,active learning,d,infomax control,online bayesian learning,optimal design,optimality,system identification},
pages = {515--554},
title = {{Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques}},
url = {http://portal.acm.org/citation.cfm?id=1577069.1577087},
volume = {10},
year = {2009}
}
@article{Vogelstein07,
author = {Vogelstein, J and Watson, B and Packer, A and Jedynak, B and Yuste, R and Paninski, L},
journal = {Biophysical Journal},
pages = {636--655},
title = {{Model-based optimal inference of spike times and calcium dynamics given noisy and intermittent calcium-fluorescence imaging}},
volume = {97},
year = {2009}
}
@article{BL73,
author = {Blake, I and Lindsey, W},
journal = {IEEE Transactions on Information Theory},
pages = {295--315},
title = {{Level-crossing problems for random processes}},
volume = {19},
year = {1973}
}
@article{Cunningham08,
author = {Cunningham, John P and Shenoy, Krishna V and Sahani, Maneesh},
journal = {ICML},
pages = {192--199},
title = {{Fast {\{}G{\}}aussian process methods for point process intensity estimation}},
year = {2008}
}
@article{Opper1996,
author = {Opper, M and Winther, O},
issn = {1079-7114},
journal = {Physical review letters},
number = {11},
pages = {1964--1967},
pmid = {10060565},
title = {{Mean field approach to Bayes learning in feed-forward neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10060565},
volume = {76},
year = {1996}
}
@article{Millhauser1988,
annote = {2009num2},
author = {Millhauser, G L and Salpeter, E E and Oswald, R E},
journal = {Biophysical Journal},
number = {6},
pages = {1165--1168},
publisher = {Elsevier},
title = {{Rate-amplitude correlation from single-channel records. A hidden structure in ion channel gating kinetics?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349588830510},
year = {1988}
}
@book{Siu1995,
address = {Uppder Saddle Rive, NJ},
author = {Siu, K Y and Roychowdhury, V and Kailath, T},
publisher = {Prentice Hall},
title = {{Discrete Neural Computation: A Theoretical Foundation}},
url = {http://dl.acm.org/citation.cfm?id=SERIES10047.202229},
year = {1995}
}
@article{Johnson2010b,
author = {Johnson, Don H},
number = {2},
pages = {653--666},
title = {{Processing}},
volume = {56},
year = {2010}
}
@article{deBono2005,
author = {de Bono, M and V., Maricq A},
journal = {Annu. Rev. Neurosci.},
pages = {451--501},
title = {{Neuronal substrates of complex behaviors in C. elegans}},
volume = {28},
year = {2005}
}
@article{Silver1997,
abstract = {Intracellular concentrations of sodium, potassium and calcium together with membrane potentials were measured in cultured murine cortical neurons and glial cells under conditions which mimicked in vivo hypoxia, ischemia and hypoglycemia. These included; glucose omission with and without added pyruvate, addition of rotenone in the presence and absence of glucose and substitution of 2-deoxyglucose for glucose with and without rotenone. Cellular energy levels ([ATP], [ADP], [phosphocreatine], [creatine]) were measured in suspensions of C6 cells incubated in parallel under identical conditions. [Na+]i and [Ca2+]i rose while [K+]i fell and plasma membrane depolarized when energy production was limited. Intracellular acidification was observed when glycolysis was the sole source for ATP synthesis. There was a positive correlation between the extent of energy depletion in glial cells and the magnitude and velocity of alterations in ion levels. Neither glycolysis alone nor oxidative phosphorylation alone were able to ensure unaltered ion gradients. Since oxidative phosphorylation is much more efficient in generating ATP than glycolysis, this finding suggests a specific requirement of the Na pump for ATP generated by glycolysis. Changes in [Na+]i and [K+]i observed during energy depletion were gradual and progressive whereas those in [Ca2+]i were initially slow and moderate with large elevations occurring only as a late event. Increases in [Na+]i were usually smaller than reductions in [K+]i, particularly in the glia, suggestive of cellular swelling. Glia were less sensitive to identical insults than were neurons under all conditions. Results presented in this study lead to the conclusion that the response to energy deprivation of the two main types of brain cells, neurons and astrocytes, is a complex function of their capacity to produce ATP and the activities of various pathways which are involved in ion homeostasis.},
author = {Silver, I A and Deas, J and Erecinska, M},
issn = {0306-4522},
journal = {Neuroscience},
keywords = {Adenosine Triphosphate,Adenosine Triphosphate: biosynthesis,Animals,Astrocytes,Astrocytes: metabolism,Brain,Brain Chemistry,Brain Chemistry: physiology,Brain: cytology,Cells,Culture Media,Cultured,Energy Metabolism,Energy Metabolism: physiology,Female,Glioma,Glioma: metabolism,Homeostasis,Homeostasis: physiology,Immunohistochemistry,Membrane Potentials,Membrane Potentials: physiology,Mice,Neuroglia,Neuroglia: metabolism,Neurons,Neurons: metabolism,Nucleotides,Nucleotides: metabolism,Oxidative Phosphorylation,Tumor Cells},
month = {may},
number = {2},
pages = {589--601},
pmid = {9145812},
title = {{Ion homeostasis in brain cells: differences in intracellular ion responses to energy limitation between cultured neurons and glial cells.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9145812},
volume = {78},
year = {1997}
}
@article{DeSchutter2008,
abstract = {Despite similar computational approaches, there is surprisingly little interaction between the computational neuroscience and the systems biology research communities. In this review I reconstruct the history of the two disciplines and show that this may explain why they grew up apart. The separation is a pity, as both fields can learn quite a bit from each other. Several examples are given, covering sociological, software technical, and methodological aspects. Systems biology is a better organized community which is very effective at sharing resources, while computational neuroscience has more experience in multiscale modeling and the analysis of information processing by biological systems. Finally, I speculate about how the relationship between the two fields may evolve in the near future.},
author = {{De Schutter}, E},
doi = {10.1371/journal.pcbi.1000078},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Computer Simulation,Models,Neurological,Neurosciences,Neurosciences: trends,Systems Biology,Systems Biology: trends},
month = {may},
number = {5},
pages = {e1000078},
pmid = {18516226},
title = {{Why are computational neuroscience and systems biology so separate?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2367448{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2008}
}
@book{Godsil2001,
author = {Godsil, C D and Royle, G},
publisher = {Springer New York},
title = {{Algebraic graph theory}},
url = {http://www.cs.cmu.edu/afs/cs/user/glmiller/public/Scientific-Computing/F-11/RelatedWork/GodsilRoyle/GodsilRoyle163-179.pdf},
volume = {8},
year = {2001}
}
@article{Velliste08,
author = {Velliste, M and Perel, S and Spalding, M C and Whitford, A S and Schwartz, A B},
journal = {Nature},
pages = {1098--1101},
title = {{Cortical control of a prosthetic arm for self-feeding.}},
volume = {453},
year = {2008}
}
@article{Gutig2009,
abstract = {Fluctuations in the temporal durations of sensory signals constitute a major source of variability within natural stimulus ensembles. The neuronal mechanisms through which sensory systems can stabilize perception against such fluctuations are largely unknown. An intriguing instantiation of such robustness occurs in human speech perception, which relies critically on temporal acoustic cues that are embedded in signals with highly variable duration. Across different instances of natural speech, auditory cues can undergo temporal warping that ranges from 2-fold compression to 2-fold dilation without significant perceptual impairment. Here, we report that time-warp-invariant neuronal processing can be subserved by the shunting action of synaptic conductances that automatically rescales the effective integration time of postsynaptic neurons. We propose a novel spike-based learning rule for synaptic conductances that adjusts the degree of synaptic shunting to the temporal processing requirements of a given task. Applying this general biophysical mechanism to the example of speech processing, we propose a neuronal network model for time-warp-invariant word discrimination and demonstrate its excellent performance on a standard benchmark speech-recognition task. Our results demonstrate the important functional role of synaptic conductances in spike-based neuronal information processing and learning. The biophysics of temporal integration at neuronal membranes can endow sensory pathways with powerful time-warp-invariant computational capabilities.},
author = {G{\"{u}}tig, R and Sompolinsky, H},
doi = {10.1371/journal.pbio.1000141},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Acoustic Stimulation,Auditory Pathways,Auditory Pathways: physiology,Female,Humans,Learning,Learning: physiology,Male,Mental Processes,Mental Processes: physiology,Neural Conduction,Neural Conduction: physiology,Neural Networks (Computer),Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Reaction Time,Reaction Time: physiology,Sound Spectrography,Speech Perception,Speech Perception: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time},
month = {jul},
number = {7},
pages = {e1000141},
pmid = {19582146},
title = {{Time-warp-invariant neuronal processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19582146},
volume = {7},
year = {2009}
}
@article{Fusi|2002|,
abstract = {Synaptic plasticity is believed to underlie the formation of appropriate
patterns of connectivity that stabilize stimulus-selective reverberations
in the cortex. Here we present a general quantitative framework for
studying the process of learning and memorizing of patterns of mean
spike rates. General considerations based on the limitations of material
(biological or electronic)synaptic devices show that most learning
networks share the palimpsest property: old stimuli are forgotten
to make room for the new ones. In order to prevent too-fast forgetting,
one can introduce a stochastic mechanism for selecting only a small
fraction of synapses to be changed upon the presentation of a stimulus.
Such a mechanism can be easily implemented by exploiting the noisy
fluctuations in the pre- and postsynaptic activities to be encoded.
The spike-driven synaptic dynamics described here can implement such
a selection mechanism to achieve slow learning, which is shown to
maximize the performance of the network as an associative memory.},
annote = {The paper presents stochastic memory model in some detail. Fast forgetting{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}is derived /clearly due to translational invariance of learning process/.},
author = {Fusi, S},
journal = {Biological Cybernetics},
keywords = {forgetting,memory limit,memory model,neurobiology,stochastic learning,unread},
pages = {459},
title = {{Hebbian spike-driven synaptic plasticity for learning patterns of mean firing rates}},
volume = {87}
}
@misc{Han|2005|,
abstract = {Active contour and surface models, also known as deformable models,
are powerful image segmentation techniques. Geometric deformable
models implemented using level set methods have advantages over parametric
models due to their intrinsic behavior, parameterization independence,
and ease of implementation. However, a long claimed advantage of
geometric deformable models --- the ability to automatically handle
topology changes --- turns out to be a liability in applications
where the object to be segmented has a known topology that must be
preserved. In this project, we develop a new class of geometric deformable
models designed using a novel topologypreserving level set method,
which achieves topology preservation by applying the simple point
concept from digital topology. These new models maintain the other
advantages of standard geometric deformable models including subpixel
accuracy and production of non-intersecting curves or surfaces. Moreover,
since the topology-preserving constraint is enforced efficiently
through local computations, the resulting algorithm incurs only nominal
computational overhead over standard geometric deformable models.},
annote = {This note describes a modification of level set approach using prohibition{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of distance function sign flips in so-called simple point that does{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}not allow level set contours to change topology.},
author = {Han, X and Xu, C and Prince, J L},
title = {{Topology preserving geometric deformable models}}
}
@article{Ioannidis2005,
abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
author = {Ioannidis, John P a},
doi = {10.1371/journal.pmed.0020124},
issn = {1549-1676},
journal = {PLoS medicine},
keywords = {Bias (Epidemiology),Data Interpretation,Likelihood Functions,Meta-Analysis as Topic,Odds Ratio,Publishing,Reproducibility of Results,Research Design,Sample Size,Statistical},
month = {aug},
number = {8},
pages = {e124},
pmid = {16060722},
title = {{Why most published research findings are false.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16060722},
volume = {2},
year = {2005}
}
@article{Lazar2007,
author = {Lazar, A A},
doi = {10.1016/j.neucom.2006.10.128},
issn = {09252312},
journal = {Neurocomputing},
keywords = {1,a review of information,been extensively investi-,ensemble encoding,gated in the literature,hodgkin,huxley neuron,i,information representation,introduction and overview,neural population codes have,o equivalence,representa-,stimulus recovery},
month = {jun},
number = {10-12},
pages = {1764--1771},
title = {{Information representation with an ensemble of Hodgkin Huxley neurons}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231206003900},
volume = {70},
year = {2007}
}
@book{KOL93,
address = {Boston},
author = {Kolmogorov, A},
publisher = {Kluwer},
title = {{Information theory and the theory of algorithms}},
year = {1993}
}
@article{YaksiFriedrich06,
author = {Yaksi, Emre and Friedrich, Rainer W},
journal = {Nature Methods},
month = {may},
number = {5},
pages = {377--383},
title = {{Reconstruction of firing rate changes across neuronal populations by temporally deconvolved {\{}Ca{\^{}}{\{}2+{\}}{\}} imaging}},
volume = {3},
year = {2006}
}
@article{Morgan2005,
abstract = {In recent years, retinal research has benefited from major advances in optical imaging approaches. Investigations of the structural and functional organization of the vertebrate retina using live preparations have been facilitated by improvements in cell labeling methods, and by microscopy techniques that permit high-resolution of cells in vitro and in vivo. In particular, the generation of transgenic animals with fluorescently labeled retinal cells has permitted real-time visualization of cell generation, migration, differentiation and growth in the developing retina. Neuronal activity can also be examined by optical imaging using activity reporters directed to specific retinal cell types. Optical techniques such as multiphoton microscopy and total internal reflection fluorescence microscopy (TIRFM) have helped unravel the physiological properties and function of retinal cells. Here, we focus on the latest cell labeling methods that have proven highly useful in many aspects of retinal research. We also highlight several examples of how newly developed imaging technology itself has facilitated investigations that have advanced our understanding of retinal circuits and their development. ?? 2005 Elsevier Ltd. All rights reserved.},
author = {Morgan, Josh and Huckfeldt, Rachel and Wong, Rachel O L},
doi = {10.1016/j.exer.2004.12.010},
isbn = {0014-4835 (Print)},
issn = {00144835},
journal = {Experimental Eye Research},
keywords = {Cell labeling methods,Fluorescent proteins,Live cell imaging,Optical imaging,Retinal development,Retinal function},
pages = {297--306},
pmid = {15721612},
title = {{Imaging techniques in retinal research}},
volume = {80},
year = {2005}
}
@article{Lennart1999,
author = {Ljung, L},
journal = {PTR Prentice Hall, Upper Saddle River, NJ},
title = {{System identification: theory for the user}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:System+Identification+?+Theory+For+the+User{\#}1},
year = {1999}
}
@article{Bedard2006,
author = {B{\'{e}}dard, C. and Kr{\"{o}}ger, H. and Destexhe, a.},
doi = {10.1103/PhysRevLett.97.118102},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {sep},
number = {11},
pages = {118102},
title = {{Does the 1/f Frequency Scaling of Brain Signals Reflect Self-Organized Critical States?}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.97.118102},
volume = {97},
year = {2006}
}
@article{Langford2005,
abstract = {We discuss basic prediction theory and its impact on classification success evaluation, implications for learning algorithm design, and uses in learning algorithm execution. This tutorial is meant to be a comprehensive compilation of results which are both theoretically rigorous and quantitatively useful. There are two important implications of the results presented here. The first is that common practices for reporting results in classification should change to use the test set bound. The second is that train set bounds can sometimes be used to directly motivate learning algorithms.},
author = {Langford, John},
isbn = {1533-7928},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {classification,quantitative bounds,sample complexity bounds},
pages = {273--306},
title = {{Tutorial on Practical Prediction Theory for Classification}},
volume = {6},
year = {2005}
}
@article{Author,
author = {Author, Anonymous and Address, Affiliation},
title = {{Variational Bayes Backpropgation : scalable training of multilayer neural networks with binary weights}},
volume = {004}
}
@article{Phelps|1998|,
author = {Phelps, C B and Brand, A H},
journal = {Methods},
pages = {367--379},
title = {{Ectopic gene expression in Drosophila using GAL4 system.}},
volume = {4}
}
@article{Paige1975,
author = {Paige, CC C and Styan, GPH P H and Wachter, PG G},
doi = {10.1080/00949657508810122},
issn = {0094-9655},
journal = {Journal of Statistical Computation and Simulation},
keywords = {stationary distribution},
mendeley-tags = {stationary distribution},
month = {jan},
number = {3},
pages = {173--186},
publisher = {Taylor {\&} Francis},
title = {{Computation of the stationary distribution of a Markov chain}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00949657508810122},
volume = {4},
year = {1975}
}
@article{Lesica05,
author = {Lesica, N A and Stanley, G B},
journal = {IEEE Transactions On Neural Systems And Rehabilitation Engineering},
number = {2},
pages = {194--200},
title = {{Improved tracking of time-varying encoding properties of visual neurons by extended recursive least-squares}},
volume = {13},
year = {2005}
}
@article{Diaconis1984,
author = {Diaconis, P and Freedman, David},
journal = {The annals of statistics},
number = {3},
pages = {793--815},
title = {{Asymptotics of graphical projection pursuit}},
url = {http://www.jstor.org/stable/2240961},
volume = {12},
year = {1984}
}
@article{Hendel2008,
author = {Hendel, T and Mank, M},
journal = {The Journal of  {\ldots}},
title = {{Fluorescence changes of genetic calcium indicators and OGB-1 correlated with neural activity and calcium in vivo and in vitro}},
url = {http://www.jneurosci.org/content/28/29/7399.short},
year = {2008}
}
@book{Risken96,
author = {Risken, H},
publisher = {Springer},
title = {{The Fokker-Planck Equation}},
year = {1996}
}
@article{TFS03,
author = {Tiesinga, P and Fellous, J and Sejnowski, T},
journal = {Neural Computation},
pages = {1629--1650},
title = {{Attractor Reliability Reveals Deterministic Structure in Neuronal Spike Trains}},
volume = {14},
year = {2003}
}
@article{turrigiano1994activity,
annote = {2009num39},
author = {Turrigiano, G G and Abbott, L F and Marder, E},
journal = {Science},
number = {5161},
pages = {974},
publisher = {AAAS},
title = {{Activity-dependent changes in the intrinsic properties of cultured neurons}},
volume = {264},
year = {1994}
}
@misc{Svoboda|PersonalCommunication|,
author = {Svoboda, K},
title = {{Cajal 2.0 Cajal 2.0 optical mapping of mouse brain.}}
}
@book{PanBook,
author = {Paninski, L and Kass, R and Eden, U and Brown, E},
publisher = {Book under review},
title = {{Statistical analysis of neurophysiological data}},
year = {2008}
}
@article{Roxin08,
author = {Roxin, Alex and Hakim, Vincent and Brunel, Nicolas},
journal = {J. Neurosci.},
number = {42},
pages = {10734--10745},
title = {{The Statistics of Repeating Patterns of Cortical Activity Can Be Reproduced by a Model Network of Stochastic Binary Neurons}},
volume = {28},
year = {2008}
}
@article{Esposti2008,
abstract = {Nowadays many methods for the estimation of self-similarity (Hurst coefficient, H) in time series are available. Most of them, even if very effective, need some a priori information to be applied. We analyzed the eight most used methods for H estimation (working both in time and in frequency). We tested these methods on data generated with four kinds of time series models (fBm and fGn generated iteratively with Feder algorithm, 1f(alpha), and the fractional autoregressive integrated moving-average) in the range 0.1{\textless}or=H{\textless}or=0.9. We evaluated the performances of each method in terms of accuracy (bias) and precision [standard deviation (STD)] of the deviation from the expected value. The paper proposes a procedure useful for a reliable estimation of H, using these existing methods, without any assumptions on the stationarity/nonstationarity of the time series, where for these types of processes the "nonstationarity" is mainly caused by the divergence of the variance with time. This procedure suggests that one performs, as a first step, the detrended fluctuations analysis, which provides an indication about stationarity of the series and is related to the properties of self-similarity and long correlations. The procedure then identifies the best method for the estimation of H, depending on this first estimation. As an example application, we use our procedure to evaluate the Hurst coefficient in microelectrode array neuronal recordings.},
annote = {2010num2.9},
author = {Esposti, Federico and Ferrario, Manuela and Signorini, Maria Gabriella},
doi = {10.1063/1.2976187},
issn = {1089-7682},
journal = {Chaos (Woodbury, N.Y.)},
number = {3},
pages = {033126},
pmid = {19045464},
title = {{A blind method for the estimation of the Hurst exponent in time series: theory and application.}},
url = {http://chaos.aip.org/chaoeh/v18/i3/p033126{\_}s1?isAuthorized=no},
volume = {18},
year = {2008}
}
@article{Nesterov2012,
author = {Nesterov, Y},
journal = {Mathematical Programming},
number = {2012},
title = {{Subgradient methods for huge-scale optimization problems}},
url = {http://xxpt.ynjgy.com/resource/data/20100601/U/stanford201001010/02-subgrad{\_}method{\_}notes.pdf http://link.springer.com/article/10.1007/s10107-013-0686-4},
volume = {2},
year = {2012}
}
@article{Haseltine2002,
author = {Haseltine, Eric L. and Rawlings, James B.},
doi = {10.1063/1.1505860},
issn = {00219606},
journal = {The Journal of Chemical Physics},
number = {15},
pages = {6959},
title = {{Approximate simulation of coupled fast and slow reactions for stochastic chemical kinetics}},
url = {http://link.aip.org/link/JCPSA6/v117/i15/p6959/s1{\&}Agg=doi},
volume = {117},
year = {2002}
}
@article{Iyer2013,
abstract = {The manner in which different distributions of synaptic weights onto cortical neurons shape their spiking activity remains open. To characterize a homogeneous neuronal population, we use the master equation for generalized leaky integrate-and-fire neurons with shot-noise synapses. We develop fast semi-analytic numerical methods to solve this equation for either current or conductance synapses, with and without synaptic depression. We show that its solutions match simulations of equivalent neuronal networks better than those of the Fokker-Planck equation and we compute bounds on the network response to non-instantaneous synapses. We apply these methods to study different synaptic weight distributions in feed-forward networks. We characterize the synaptic amplitude distributions using a set of measures, called tail weight numbers, designed to quantify the preponderance of very strong synapses. Even if synaptic amplitude distributions are equated for both the total current and average synaptic weight, distributions with sparse but strong synapses produce higher responses for small inputs, leading to a larger operating range. Furthermore, despite their small number, such synapses enable the network to respond faster and with more stability in the face of external fluctuations.},
author = {Iyer, Ramakrishnan and Menon, Vilas and Buice, Michael and Koch, C and Mihalas, Stefan},
doi = {10.1371/journal.pcbi.1003248},
editor = {Sporns, Olaf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Research Article},
month = {oct},
number = {10},
pages = {e1003248},
pmid = {24204219},
publisher = {Public Library of Science},
title = {{The influence of synaptic weight distribution on neuronal population dynamics.}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1003248},
volume = {9},
year = {2013}
}
@article{Mohanty08,
author = {Mohanty, Samarendra K and Reinscheid, Rainer K and Liu, Xiaobin and Okamura, Naoe and Krasieva, Tatiana B and Berns, Michael W},
journal = {Biophys. J.},
number = {8},
pages = {3916--3926},
title = {{In-Depth Activation of Channelrhodopsin 2-Sensitized Excitable Cells with High Spatial Resolution Using Two-Photon Excitation with a Near-Infrared Laser Microbeam}},
volume = {95},
year = {2008}
}
@article{KR95,
author = {Kass, R and Raftery, A},
journal = {Journal of the American Statistical Association},
pages = {773--795},
title = {{Bayes Factors}},
volume = {90},
year = {1995}
}
@article{Grossman1979b,
author = {Grossman, B Y Y and Parnas, I and Spira, M E},
pages = {283--305},
title = {{By y. grossman*,}},
year = {1979}
}
@article{BrockwellKass04,
abstract = {The population vector (PV) algorithm and optimal linear estimation

(OLE) have been used to reconstruct movement by combining signals

from multiple neurons in the motor cortex. While these linear methods

are effective, recursive Bayesian decoding schemes, which are nonlinear,

can be more powerful when probability model assumptions are satisfied.

We have implemented a recursive Bayesian algorithm for reconstructing

hand movement from neurons in the motor cortex. The algorithm uses

a recently developed numerical method known as "particle filtering"

and follows the same general strategy as that used by Brown et al.

to reconstruct the path of a foraging rat from hippocampal place

cells. We investigated the method in a numerical simulation study

in which neural firing rate was assumed to be positive, but otherwise

a linear function of movement velocity, and preferred directions

were not uniformly distributed. In terms of mean-squared error, the

approach was approximately 10 times more efficient than the PV algorithm

and 5 times more efficient than OLE. Thus use of recursive Bayesian

decoding can achieve the accuracy of the PV algorithm (or OLE) with

approximately 10 times (or 5 times) fewer neurons. The method was

also used to reconstruct hand movement in an ellipse-drawing task

from 258 cells in the ventral premotor cortex. Recursive Bayesian

decoding was again more efficient than the PV and OLE methods, by

factors of roughly seven and three, respectively.},
author = {Brockwell, A E and Rojas, A L and Kass, R E},
doi = {10.1152/jn.00438.2003},
journal = {J Neurophysiol},
keywords = {Algorithms; Animals; Bayes Theorem; Computer Simul,Neurological; Motor Cortex; Movement; Neurons; Si},
month = {apr},
number = {4},
pages = {1899--1907},
pmid = {15010499},
title = {{Recursive Bayesian decoding of motor cortical signals by particle filtering.}},
url = {http://dx.doi.org/10.1152/jn.00438.2003},
volume = {91},
year = {2004}
}
@article{Jaynes1957,
abstract = {Information theory provides a constructive criterion for setting up probability distributions on the basis of partial knowledge, and leads to a type of statistical inference which is called the maximum-entropy estimate. It is the least biased estimate possible on the given information; i.e., it is maximally noncommittal with regard to missing information. If one considers statistical mechanics as a form of statistical inference rather than as a physical theory, it is found that the usual computational rules, starting with the determination of the partition function, are an immediate consequence of the maximum-entropy principle. In the resulting "subjective statistical mechanics," the usual rules are thus justified independently of any physical argument, and in particular independently of experimental verification; whether or not the results agree with experiment, they still represent the best estimates that could have been made on the basis of the information available.It is concluded that statistical mechanics need not be regarded as a physical theory dependent for its validity on the truth of additional assumptions not contained in the laws of mechanics (such as ergodicity, metric transitivity, equal a priori probabilities, etc.). Furthermore, it is possible to maintain a sharp distinction between its physical and statistical aspects. The former consists only of the correct enumeration of the states of a system and their properties; the latter is a straightforward example of statistical inference.},
annote = {2010IIInum31},
author = {Jaynes, E.},
doi = {10.1103/PhysRev.106.620},
issn = {0031-899X},
journal = {Physical Review},
month = {may},
number = {4},
pages = {620--630},
publisher = {American Physical Society},
shorttitle = {Phys. Rev.},
title = {{Information Theory and Statistical Mechanics}},
url = {http://link.aps.org/doi/10.1103/PhysRev.106.620},
volume = {106},
year = {1957}
}
@inproceedings{Soudry2014,
abstract = {Multilayer Neural Networks (MNNs) are commonly trained using gradient descent-based methods, such as BackPropagation (BP). Inference in probabilistic graphical models is often done using variational Bayes methods, such as Expectation Propagation (EP). We show how an EP based approach can also be used to train deterministic MNNs. Specifically, we approximate the posterior of the weights given the data using a "mean-field" factorized distribution, in an online setting. Using online EP and the central limit theorem we find an analytical approximation to the Bayes update of this posterior, as well as the resulting Bayes estimates of the weights and outputs. Despite a different origin, the resulting algorithm, Expectation BackPropagation (EBP), is very similar to BP in form and efficiency. However, it has several additional advantages: (1) Training is parameter-free, given initial conditions (prior) and the MNN architecture. This is useful for large-scale problems, where parameter tuning is a major challenge. (2) The weights can be restricted to have discrete values. This is especially useful for implementing trained MNNs in precision limited hardware chips, thus improving their speed and energy efficiency by several orders of magnitude. We test the EBP algorithm numerically in eight binary text classification tasks. In all tasks, EBP outperforms: (1) standard BP with the optimal constant learning rate (2) previously reported state of the art. Interestingly, EBP-trained MNNs with binary weights usually perform better than MNNs with continuous (real) weights - if we average the MNN output using the inferred posterior.},
address = {Montreal},
author = {Soudry, D. and Hubara, I and Meir, R.},
booktitle = {Neural Information Processing Systems},
issn = {10495258},
month = {dec},
number = {January},
pages = {963--971},
title = {{Expectation backpropagation: parameter-free training of multilayer neural networks with continuous or discrete weights}},
volume = {2},
year = {2014}
}
@article{Yoshimura05,
author = {Yoshimura, Y and Dantzker, J L and Callaway, E M},
journal = {Nature},
number = {7028},
pages = {868--873},
title = {{Excitatory cortical neurons form fine-scale functional networks}},
volume = {433},
year = {2005}
}
@article{Cover1965,
author = {Cover, T M},
journal = {Electronic Computers, IEEE Transactions on},
number = {3},
pages = {326--334},
publisher = {IEEE},
title = {{Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4038449},
year = {1965}
}
@article{Szymanski2007,
author = {Szymanski, B. K. and Chen, G. G.},
doi = {10.1093/comjnl/bxm109},
issn = {0010-4620},
journal = {The Computer Journal},
keywords = {computing paradigm,neural network,received 14 november 2007,revised 14 november 2007,routing,sensor network},
month = {sep},
number = {4},
pages = {511--522},
title = {{Computing with Time: From Neural Networks to Sensor Networks}},
url = {http://comjnl.oxfordjournals.org/cgi/doi/10.1093/comjnl/bxm109},
volume = {51},
year = {2007}
}
@article{Rubin88,
author = {Rubin, D B},
journal = {Bayesian Statistics},
pages = {395--402},
title = {{Using the SIR algorithm to simulate posterior distributions}},
volume = {3},
year = {1988}
}
@article{Gasthaus09,
author = {Gasthaus, J and Wood, F and Gorur, D and Teh, Y.-W.},
journal = {NIPS},
pages = {497--504},
title = {{Dependent Dirichlet process spike sorting}},
year = {2009}
}
@article{Escola08,
author = {Escola, S and Eisele, M and Miller, K and Paninski, L},
journal = {Neural Computation},
title = {{Maximally reliable {\{}M{\}}arkov chains under energy constraints}},
volume = {Accepted p},
year = {2008}
}
@article{Assaf2006,
annote = {2010num1.7},
author = {Assaf, Michael and Meerson, Baruch},
doi = {10.1103/PhysRevE.74.041115},
issn = {1539-3755},
journal = {Physical Review E},
number = {4},
pages = {1--10},
title = {{Spectral formulation and WKB approximation for rare-event statistics in reaction systems}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.74.041115},
volume = {74},
year = {2006}
}
@article{CAR03,
author = {Cossart, R and Aronov, D and Yuste, R},
journal = {Nature},
pages = {283--288},
title = {{Attractor dynamics of network UP states in the neocortex}},
volume = {423},
year = {2003}
}
@article{Johnston2017,
abstract = {We propose a method for lossy image compression based on recurrent, convolutional neural networks that outperforms BPG (4:2:0 ), WebP, JPEG2000, and JPEG as measured by MS-SSIM. We introduce three improvements over previous research that lead to this state-of-the-art result. First, we show that training with a pixel-wise loss weighted by SSIM increases reconstruction quality according to several metrics. Second, we modify the recurrent architecture to improve spatial diffusion, which allows the network to more effectively capture and propagate image information through the network's hidden state. Finally, in addition to lossless entropy coding, we use a spatially adaptive bit allocation algorithm to more efficiently use the limited number of bits to encode visually complex image regions. We evaluate our method on the Kodak and Tecnick image sets and compare against standard codecs as well recently published methods based on deep neural networks.},
archivePrefix = {arXiv},
arxivId = {1703.10114},
author = {Johnston, Nick and Vincent, Damien and Minnen, David and Covell, Michele and Singh, Saurabh and Chinen, Troy and Hwang, Sung Jin and Shor, Joel and Toderici, George},
eprint = {1703.10114},
journal = {arXiv:1703.10114},
title = {{Improved Lossy Image Compression with Priming and Spatially Adaptive Bit Rates for Recurrent Networks}},
url = {http://arxiv.org/abs/1703.10114},
year = {2017}
}
@article{Guo2008,
annote = {2011num27},
author = {Guo, Dongning and {Shamai (Shitz)}, Shlomo and Verdu, Sergio},
doi = {10.1109/TIT.2008.920206},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {may},
number = {5},
pages = {1837--1849},
title = {{Mutual Information and Conditional Mean Estimation in Poisson Channels}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4494688},
volume = {54},
year = {2008}
}
@article{Hassabis2017,
author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
doi = {10.1016/j.neuron.2017.06.011},
issn = {0896-6273},
journal = {Neuron},
number = {2},
pages = {245--258},
pmid = {28728020},
publisher = {Elsevier Inc.},
title = {{Review Neuroscience-Inspired Artificial Intelligence}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.06.011},
volume = {95},
year = {2017}
}
@article{SHO03,
author = {Shoham, S and Paninski, L and Fellows, M and Hatsopoulos, N and Donoghue, J and Normann, R},
journal = {IEEE Transactions on Biomedical Engineering},
pages = {1312--1322},
title = {{Optimal decoding for a primary motor cortical brain-computer interface}},
volume = {52},
year = {2005}
}
@article{Torrezan2011,
abstract = {We report sub-nanosecond switching of a metal-oxide-metal memristor utilizing a broadband 20 GHz experimental setup developed to observe fast switching dynamics. Set and reset operations were successfully performed in the tantalum oxide memristor using pulses with durations of 105 and 120 ps, respectively. Reproducibility of the sub-nanosecond switching was also confirmed as the device switched over consecutive cycles.},
author = {Torrezan, Antonio C and Strachan, John Paul and Medeiros-Ribeiro, Gilberto and Williams, R Stanley},
doi = {10.1088/0957-4484/22/48/485203},
issn = {1361-6528},
journal = {Nanotechnology},
month = {dec},
number = {48},
pages = {485203},
pmid = {22071289},
title = {{Sub-nanosecond switching of a tantalum oxide memristor.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22071289},
volume = {22},
year = {2011}
}
@article{BU52,
author = {Bussgang, J},
journal = {RLE Technical Reports},
title = {{Crosscorrelation functions of amplitude-distorted {\{}G{\}}aussian signals}},
volume = {216},
year = {1952}
}
@article{DeOliveira2007,
abstract = {In this letter, we study online learning in neural networks (NNs) obtained by approximating Bayesian learning. The approach is applied to Gibbs learning with the Rosenblatt potential in a nonstationary environment. The online scheme is obtained by the minimization (maximization) of the Kullback-Leibler divergence (cross entropy) between the true posterior distribution and the parameterized one. The complexity of the learning algorithm is further decreased by projecting the posterior onto a Gaussian distribution and imposing a spherical covariance matrix. We study in detail the particular case of learning linearly separable rules. In the case of a fixed rule, we observe an asymptotic generalization error e(g) infinity alpha(-1) for both the spherical and the full covariance matrix approximations. However, in the case of drifting rule, only the full covariance matrix algorithm shows a good performance. This good performance is indeed a surprise since the algorithm is obtained by projecting without the benefit of the extra information on drifting.},
author = {de Oliveira, Evaldo Ara{\'{u}}jo},
doi = {10.1109/TNN.2006.889943},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Algorithms,Artificial Intelligence,Bayes Theorem,Computer Simulation,Feedback,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models, Theoretical,Neural Networks (Computer),Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Stochastic Processes},
month = {mar},
number = {2},
pages = {584--8},
pmid = {17385642},
title = {{The Rosenblatt Bayesian algorithm learning in a nonstationary environment.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17385642},
volume = {18},
year = {2007}
}
@article{thurner1997analysis,
archivePrefix = {arXiv},
arxivId = {arXiv:adap-org/9709006v1},
author = {Thurner, S and Lowen, S B and Feurstein, M C and Heneghan, C and Feichtinger, H G and Teich, M C},
eprint = {9709006v1},
journal = {Arxiv preprint adap-org/9709006},
primaryClass = {arXiv:adap-org},
title = {{Analysis, synthesis, and estimation of fractal-rate stochastic point processes}},
url = {http://arxiv.org/abs/adap-org/9709006},
year = {1997}
}
@article{Thiruvarudchelvan,
author = {Thiruvarudchelvan, Vaenthan and Crane, JW and Bossomaier, Terry},
journal = {vthiru.com},
title = {{Analysis of SpikeProp Convergence with Alternative Spike Response Functions}},
url = {https://vthiru.com/publications/foci13.pdf}
}
@misc{Wandelt|2000|,
annote = {This presentation provides nice overview of the problem of interacting{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}dark matter.},
author = {Wandelt, B D and Steinhardt, P J and Spergel, D and Dave, R},
keywords = {astrophysics,dark matter,interaction,physics,strongly interacting dark matter},
title = {{Is there Life in the Dark Matter?}}
}
@article{FelicianoMugnaini95,
author = {Feliciano, E and Saldana, E and Mugnaini, E},
journal = {Aud Neurosci},
pages = {287--308},
title = {{Direct projections from the rat primary auditory neocortex to nucleus sagulum, paralemniscal regions, superior olivary complex, and cochlear nuclei}},
volume = {1},
year = {1995}
}
@article{Barkai1991,
author = {Barkai, E and Kanter, I},
journal = {EPL (Europhysics Letters)},
title = {{Storage capacity of a multilayer neural network with binary weights}},
url = {http://iopscience.iop.org/0295-5075/14/2/003},
volume = {107},
year = {1991}
}
@article{Jacques2013,
abstract = {In this work, we show that reconstructing a sparse signal from quantized compressive measurement can be achieved in an unified formalism whatever the (scalar) quantization resolution, i.e., from 1-bit to high resolution assumption. This is achieved by generalizing the iterative hard thresholding (IHT) algorithm and its binary variant (BIHT) introduced in previous works to enforce the consistency of the reconstructed signal with respect to the quantization model. The performance of this algorithm, simply called quantized IHT (QIHT), is evaluated in comparison with other approaches (e.g., IHT, basis pursuit denoise) for several quantization scenarios.},
archivePrefix = {arXiv},
arxivId = {cs.IT/1305.1786},
author = {Jacques, Laurent and Degraux, K{\'{e}}vin and {De Vleeschouwer}, Christophe},
eprint = {1305.1786},
journal = {Proceedings of the 10th International Conference on Sampling Theory and Applications},
pages = {105--108},
primaryClass = {cs.IT},
title = {{Quantized Iterative Hard Thresholding: Bridging 1-bit and High-Resolution Quantized Compressed Sensing}},
year = {2013}
}
@article{Bell94,
author = {Bell, Bradley M},
journal = {SIAM Journal on Optimization},
pages = {626--636},
publisher = {SIAM},
title = {{The Iterated {\{}K{\}}alman Smoother as a {\{}Gauss--Newton{\}} Method}},
volume = {4},
year = {1994}
}
@article{ChibGreenberg95,
author = {Chib, Siddhartha and Greenberg, Edward},
journal = {The American Statistician},
pages = {327--335},
title = {{Understanding the Metropolis-Hastings Algorithm}},
volume = {49},
year = {1995}
}
@book{Absil2009,
author = {Absil, PA and Mahony, R and Sepulchre, R},
file = {::},
title = {{Optimization algorithms on matrix manifolds}},
url = {https://books.google.com/books?hl=en{\&}lr={\&}id=NSQGQeLN3NcC{\&}oi=fnd{\&}pg=PR11{\&}dq=optimization+Algorithms+on+Matrix+Manifolds{\&}ots=GspqUAQKcO{\&}sig=em65hjGwgfzWdBUhFpSEP96RXJ0},
year = {2009}
}
@article{Sorra|1998|,
abstract = {Long-term potentiation (LTP) is an important model for examining synaptic
mechanisms of learning and memory. A key question is whether the
enhanced synaptic transmission occurring with LTP involves the addition
of new synapses, the enlargement of existing synapses, or a redistribution
in synaptic weight among synapses. Two experimental designs were
used to address this question. In the first experimental design three
conditions were evaluated across hippocampal slices maintained in
vitro, including slices with LTP analyzed at 2 hr post-tetanus, slices
tetanized in the presence of APV, and control slices receiving test
stimulation only. In the second experimental design independent LTP
and control (low-frequency stimulation) sites were examined. Synapse
density was estimated by an unbiased volume sampling procedure. Synapse
size was computed by three-dimensional reconstruction from serial
electron microscopy (EM). Serial EM also was used to compute synapse
number per unit length of dendrite. In both experimental designs
there were no significant effects of LTP on total synapse number,
on the distribution of different types of synapses (thin, mushroom,
stubby, or branched dendritic spines and macular, perforated, or
segmented postsynaptic densities), on the frequency of shaft synapses,
nor on the relative proportion of single or multiple synapse axonal
boutons. There was also no increase in synapse size. These results
suggest that LTP does not cause an overall formation of new synapses
nor an enlargement of synapses at 2 hr post-tetanus in hippocampal
area CA1, and these results support the hypothesis that LTP could
involve a redistribution of synaptic weights among existing synapses.},
annote = {NS21184/NS/United States NINDS NS33574/NS/United States NINDS P30-HD18655/HD/United{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}States NICHD Journal Article Research Support, Non-U.S. Gov{\&}{\#}039;t Research{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Support, U.S. Gov{\&}{\#}039;t, P.H.S. United states the official journal of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the Society for Neuroscience},
author = {Sorra, K E and Harris, K M},
journal = {J Neurosci},
keywords = {Animals Dendrites/ultrastructure Hippocampus/*cyto,Electron Neuropil/*physiology/ultrastructure Rats},
number = {2},
pages = {658--671},
title = {{Stability in synapse number and size at 2 hr after long-term potentiation in hippocampal area CA1}},
volume = {18}
}
@article{KFCH05,
author = {Krishnapuram, B and Figueiredo, M and Carin, L and Hartemink, A},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
pages = {957--968},
title = {{Sparse Multinomial Logistic Regression: Fast Algorithms and Generalization Bounds}},
volume = {27},
year = {2005}
}
@article{Beloozerova2010,
abstract = {What are the differences in mechanics, muscle, and motor cortex activity between accurate and nonaccurate movements? We addressed this question in relation to walking. We assessed full-body mechanics (229 variables), activity of 8 limb muscles, and activity of 63 neurons from the motor cortex forelimb representation during well-trained locomotion with different demands on the accuracy of paw placement in cats: during locomotion on a continuous surface and along horizontal ladders with crosspieces of different widths. We found that with increasing accuracy demands, cats assumed a more bent-forward posture (by lowering the center of mass, rotating the neck and head down, and by increasing flexion of the distal joints) and stepped on the support surface with less spatial variability. On the ladder, the wrist flexion moment was lower throughout stance, whereas ankle and knee extension moments were higher and hip moment was lower during early stance compared with unconstrained locomotion. The horizontal velocity time histories of paws were symmetric and smooth and did not differ among the tasks. Most of the other mechanical variables also did not depend on accuracy demands. Selected distal muscles slightly enhanced their activity with increasing accuracy demands. However, in a majority of motor cortex cells, discharge rate means, peaks, and depths of stride-related frequency modulation changed dramatically during accurate stepping as compared with simple walking. In addition, in 30{\%} of neurons periods of stride-related elevation in firing became shorter and in 20-25{\%} of neurons activity or depth of frequency modulation increased, albeit not linearly, with increasing accuracy demands. Considering the relatively small changes in locomotor mechanics and substantial changes in motor cortex activity with increasing accuracy demands, we conclude that during practiced accurate stepping the activity of motor cortex reflects other processes, likely those that involve integration of visual information with ongoing locomotion.},
author = {Beloozerova, Irina N and Farrell, Bradley J and Sirota, Mikhail G and Prilutsky, Boris I},
doi = {10.1152/jn.00360.2009},
issn = {1522-1598},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Animal,Animal: physiology,Animals,Behavior,Biomechanics,Cats,Cats: physiology,Electromyography,Female,Forelimb,Forelimb: innervation,Forelimb: physiology,Hindlimb,Hindlimb: innervation,Hindlimb: physiology,Locomotion,Locomotion: physiology,Male,Models,Motor Cortex,Motor Cortex: physiology,Muscle,Skeletal,Skeletal: innervation,Skeletal: physiology,motor control},
mendeley-tags = {motor control},
month = {apr},
number = {4},
pages = {2285--2300},
pmid = {20164404},
title = {{Differences in movement mechanics, electromyographic, and motor cortex activity between accurate and nonaccurate stepping.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2853277{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pubmed/20164404},
volume = {103},
year = {2010}
}
@article{Battiti1995,
abstract = {In this paper the task of training subsymbolic systems is considered as a combinatorial optimization problem and solved with the heuristic scheme of the reactive tabu search (RTS). An iterative optimization process based on a "modified local search" component is complemented with a meta-strategy to realize a discrete dynamical system that discourages limit cycles and the confinement of the search trajectory in a limited portion of the search space. The possible cycles are discouraged by prohibiting (i.e., making tabu) the execution of moves that reverse the ones applied in the most recent part of the search. The prohibition period is adapted in an automated way. The confinement is avoided and a proper exploration is obtained by activating a diversification strategy when too many configurations are repeated excessively often. The RTS method is applicable to nondifferentiable functions, is robust with respect to the random initialization, and effective in continuing the search after local minima. Three tests of the technique on feedforward and feedback systems are presented.},
author = {Battiti, R and Tecchiolli, G},
doi = {10.1109/72.410361},
issn = {1045-9227},
journal = {IEEE transactions on neural networks},
number = {5},
pages = {1185--200},
pmid = {18263407},
title = {{Training neural nets with the reactive tabu search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18263407},
volume = {6},
year = {1995}
}
@article{Feldmeyer2006,
abstract = {Synaptically coupled layer 2/3 (L2/3) pyramidal neurones located above the same layer 4 barrel ('barrel-related') were investigated using dual whole-cell voltage recordings in acute slices of rat somatosensory cortex. Recordings were followed by reconstructions of biocytin-filled neurones. The onset latency of unitary EPSPs was 1.1 +/- 0.4 ms, the 20-80{\%} rise time was 0.7 +/- 0.2 ms, the average amplitude was 1.0 +/- 0.7 mV and the decay time constant was 15.7 +/- 4.5 ms. The coefficient of variation (c.v.) of unitary EPSP amplitudes decreased with increasing EPSP peak and was 0.33 +/- 0.18. Bursts of APs in the presynaptic pyramidal cell resulted in EPSPs that, over a wide range of frequencies (5-100 Hz), displayed amplitude depression. Anatomically the barrel-related pyramidal cells in the lower half of layer 2/3 have a long apical dendrite with a small terminal tuft, while pyramidal cells in the upper half of layer 2/3 have shorter and often more 'irregularly' shaped apical dendrites that branch profusely in layer 1. The number of putative excitatory synaptic contacts established by the axonal collaterals of a L2/3 pyramidal cell with a postsynaptic pyramidal cell in the same column varied between 2 and 4, with an average of 2.8 +/- 0.7 (n = 8 pairs). Synaptic contacts were established predominantly on the basal dendrites at a mean geometric distance of 91 +/- 47 mum from the pyramidal cell soma. L2/3-to-L2/3 connections formed a blob-like innervation domain containing 2.8 mm of the presynaptic axon collaterals with a bouton density of 0.3 boutons per mum axon. Within the supragranular layers of its home column a single L2/3 pyramidal cell established about 900 boutons suggesting that 270 pyramidal cells in layer 2/3 are innervated by an individual pyramidal cell. In turn, a single pyramidal cell received synaptic inputs from 270 other L2/3 pyramidal cells. The innervation domain of L2/3-to-L2/3 connections superimposes almost exactly with that of L4-to-L2/3 connections. This suggests that synchronous feed-forward excitation of L2/3 pyramidal cells arriving from layer 4 could be potentially amplified in layer 2/3 by feedback excitation within a column and then relayed to the neighbouring columns.},
author = {Feldmeyer, Dirk and L{\"{u}}bke, Joachim and Sakmann, B},
doi = {10.1113/jphysiol.2006.105106},
issn = {0022-3751},
journal = {The Journal of physiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Cell Communication,Cell Communication: physiology,Dendrites,Dendrites: physiology,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Neurons,Neurons: cytology,Neurons: physiology,Newborn,Newborn: anatomy {\&} histology,Newborn: physiology,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Rats,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors,Wistar},
month = {sep},
number = {Pt 2},
pages = {583--602},
pmid = {16793907},
title = {{Efficacy and connectivity of intracolumnar pairs of layer 2/3 pyramidal cells in the barrel cortex of juvenile rats.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1819447{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {575},
year = {2006}
}
@article{Farrar|2004|,
abstract = {We present a mechanism to generate the baryon asymmetry of the Universe
which preserves the net baryon number created in the Big Bang. If
dark matter particles carry baryon number B{\_}X, and sigma{\^{}}ann{\_}X {\textless}
sigma{\^{}}ann{\_}X , the anti X{\"{i}}¾'s freeze out at a higher temperature and
have a larger relic density than X{\"{i}}¾'s. If m{\_}X {\textless} 4.5B{\_}X GeV and the
annihilation cross sections differ by O(10{\%}) or more, this type of
scenario naturally explains the observed Omega{\_}DM approx 5 Omega{\_}b.},
annote = {This paper puts forward interesting hypothesis relating observed{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}DM/barion ratio to freeze-out of antybarrions at higher temperature{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}during big-bang.},
author = {Farrar, G R and Zaharijas, G},
journal = {arXiv},
keywords = {QCD,astrophysics,baryon assymetry,candidate,dark matter,physics,superconductor},
pages = {406281},
title = {{Dark Matter and the Baryon Assymetry of the Universe}},
volume = {hep-ph}
}
@book{RC05,
author = {Robert, C and Casella, G},
publisher = {Springer},
title = {{Monte {\{}C{\}}arlo Statistical Methods}},
year = {2005}
}
@article{BrozoskiCaspary02,
author = {Brozoski, T J and Bauer, C A and Caspary, D M},
journal = {Journal of Neuroscience},
month = {mar},
number = {6},
pages = {2383--2390},
title = {{Elevated fusiform cell activity in the dorsal cochlear nucleus of chinchillas with psychophysical evidence of tinnitus}},
volume = {22},
year = {2002}
}
@misc{Zaytsev2015,
abstract = {Dynamics and function of neuronal networks are determined by their synaptic connectivity. Current experimental methods to analyze synaptic network structure on the cellular level, however, cover only small fractions of functional neuronal circuits, typically without a simultaneous record of neuronal spiking activity. Here we present a method for the reconstruction of large recurrent neuronal networks from thousands of parallel spike train recordings. We employ maximum likelihood estimation of a generalized linear model of the spiking activity. For this model the point process likelihood is concave, such that a global optimum of the parameters can be obtained by gradient ascent. Previous methods, including those of the same class, did not allow recurrent networks of that order of magnitude to be reconstructed due to prohibitive computational cost and numerical instabilities. We describe a minimal model that is optimized for large networks and an efficient scheme for its parallelized numerical optimization on generic computing clusters. For a simulated balanced random network of 1000 neurons, synaptic connectivity is recovered with a misclassification error rate of less than 1{\%} under ideal conditions. We show that the error rate remains low in a series of example cases under progressively less ideal conditions. Finally, we successfully reconstruct the connectivity of a hidden synfire chain that is embedded in a random network, which requires clustering of the network connectivity to reveal the synfire groups. Our results demonstrate how synaptic connectivity could be inferred from large-scale parallel spike train recordings.},
archivePrefix = {arXiv},
arxivId = {1502.04993},
author = {Zaytsev, Yury V. and Morrison, Abigail and Deger, Moritz},
booktitle = {arXiv preprint},
eprint = {1502.04993},
howpublished = {http://arxiv.org/abs/1502.04993},
month = {feb},
title = {{Reconstruction of recurrent synaptic connectivity of thousands of neurons from simulated spiking activity}},
url = {http://arxiv.org/abs/1502.04993},
urldate = {2015-02-24},
year = {2015}
}
@article{Nikitchenko07,
author = {Nikitchenko, M and Paninski, L},
journal = {COSYNE},
title = {{An expectation-maximization {\{}F{\}}okker-{\{}P{\}}lanck algorithm for the noisy integrate-and-fire model}},
year = {2007}
}
@book{DoucetGordon01,
author = {Smith, A and Doucet, Arnaud and de Freitas, Nando and Gordon, Neil},
publisher = {Springer},
title = {{Sequential Monte Carlo Methods in Practice}},
year = {2001}
}
@article{Roth2001,
abstract = {1. Simultaneous dendritic and somatic patch-clamp recordings were made from Purkinje cells in cerebellar slices from 12- to 21-day-old rats. Voltage responses to current impulses injected via either the dendritic or the somatic pipette were obtained in the presence of the selective I(h) blocker ZD 7288 and blockers of spontaneous synaptic input. Neurons were filled with biocytin for subsequent morphological reconstruction. 2. Four neurons were reconstructed and converted into detailed compartmental models. The specific membrane capacitance (C(m)), specific membrane resistance (R(m)) and intracellular resistivity (R(i)) were optimized by direct fitting of the model responses to the electrophysiological data from the same cell. Mean values were: C(m), 0.77 +/- 0.17 microF cm(-2) (mean +/- S.D.; range, 0.64-1.00 microF cm(-2)), R(m), 122 +/- 18 kOmega cm(2) (98-141 kOmega cm(2)) and R(i), 115 +/- 20 Omega cm (93-142 Omega cm). 3. The steady-state electrotonic architecture of these cells was compact under the experimental conditions used. However, somatic voltage-clamp recordings of parallel fibre and climbing fibre synaptic currents were substantially filtered and attenuated. 4. The detailed models were compared with a two-compartment model of Purkinje cells. The range of synaptic current kinetics that can be faithfully recorded using somatic voltage clamp is predicted fairly well by the two-compartment model, even though some of its underlying assumptions are violated. 5. A model of I(h) was constructed based on voltage-clamp data, and inserted into the passive compartmental models. Somatic EPSP amplitude was substantially attenuated compared to the amplitude of dendritic EPSPs at their site of generation. However, synaptic efficacy of the same quantal synaptic conductance, as measured by the somatic EPSP amplitude, was only weakly dependent on synaptic location on spiny branchlets. 6. The passive electrotonic structure of Purkinje cells is unusual in that the steady-state architecture is very compact, while voltage transients such as synaptic potentials and action potentials are heavily filtered.},
author = {Roth, A and H{\"{a}}usser, M},
issn = {0022-3751},
journal = {The Journal of physiology},
keywords = {3-dione,3-dione: pharmacology,4-Aminopyridine,4-Aminopyridine: pharmacology,6-Cyano-7-nitroquinoxaline-2,Animals,Cadmium Chloride,Cadmium Chloride: pharmacology,Cations,Cations: metabolism,Cell Compartmentation,Cell Compartmentation: physiology,Cell Size,Cell Size: physiology,Dendrites,Dendrites: physiology,Excitatory Amino Acid Antagonists,Excitatory Amino Acid Antagonists: pharmacology,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: drug effects,Excitatory Postsynaptic Potentials: physiology,GABA Antagonists,GABA Antagonists: pharmacology,Membrane Potentials,Membrane Potentials: drug effects,Membrane Potentials: physiology,Patch-Clamp Techniques,Potassium Channel Blockers,Potassium Channel Blockers: pharmacology,Purkinje Cells,Purkinje Cells: physiology,Purkinje Cells: ultrastructure,Pyridazines,Pyridazines: pharmacology,Rats,Tetraethylammonium,Tetraethylammonium: pharmacology,Tetrodotoxin,Tetrodotoxin: pharmacology,Wistar},
month = {sep},
number = {Pt 2},
pages = {445--72},
pmid = {11533136},
title = {{Compartmental models of rat cerebellar Purkinje cells based on simultaneous somatic and dendritic patch-clamp recordings.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2278793{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {535},
year = {2001}
}
@article{Wang|2001|,
abstract = {Unsupervised segmentation of images with low depth of field (DOF)
is highly useful in various applications including image enhancement
for digital cameras, target recognition, image indexing for content-based
retrieval, and 3D microscopic image analysis. This paper describes
a novel multiresolution image segmentation algorithm for low DOF
images. The algorithm is designed to separate a sharply focused object-of-interest
from other foreground or background objects. The algorithm is fully
automatic in that all parameters are image independent. A multiscale
approach based on high frequency wavelet coefficients and their statistics
is used to perform context-dependent classification of individual
blocks of the image. Unlike other edge-based approaches, our algorithm
does not rely on the process of connecting object boundaries. The
algorithm has achieved high accuracy when tested on more than 100
low DOF images, many with inhomogeneous foreground or background
distractions. Compared with the state of the art algorithms, this
new algorithm provides better accuracy at higher speed.},
annote = {Paper deals with mutiscale analysis of photographic images with low{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}depth of field.},
author = {Wang, J Z and Li, J and Gray, R M and Wiederhold, G},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {computational,content-based image retrieval,image processing,image region segmentation,low depth-of-field,multi-scale,multiresolution image analysis,segmentation,unread,unsupervised,wavelet},
number = {1},
pages = {85},
title = {{Unsupervised multiresolution segmentation for images with low depth of field}},
volume = {23}
}
@article{Abdi|2003|,
annote = {This is a short overview note covering basics of the architecture{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of neural networks and their learning.},
author = {Abdi, Herve},
keywords = {artificial neural networks,back-propagation,computational,learning,multilayer,perceptron,widrow-hoff},
title = {{Neural Networks}}
}
@article{Tsybakov2004,
abstract = {Classification can be considered as nonparametric estimation of sets, where the risk is defined by means of a specific distance between sets associated with misclassification error. It is shown that the rates of convergence of classifiers depend on two parameters: the complexity of the class of candidate sets and the margin parameter. The dependence is explicitly given, indicating that optimal fast rates approaching O(n-1) can be attained, where n is the sample size, and that the proposed classifiers have the property of robustness to the margin. The main result of the paper concerns optimal aggregation of classifiers: we suggest a classifier that automatically adapts both to the complexity and to the margin, and attains the optimal fast rates, up to a logarithmic factor.},
author = {Tsybakov, A B},
doi = {10.1214/aos/1079120131},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Aggregation of classifiers,Classification,Complexity of classes of sets,Empirical processes,Margin,Optimal rates,Statistical learning},
number = {1},
pages = {135--166},
title = {{Optimal aggregation of classifiers in statistical learning}},
volume = {32},
year = {2004}
}
@article{Socher2011,
author = {Socher, R and Huang, E H},
journal = {Advances in Neural Information Processing Systems},
pages = {801--809},
title = {{Dynamic pooling and unfolding recursive autoencoders for paraphrase detection}},
url = {http://www.robotics.stanford.edu/{~}ang/papers/nips11-DynamicPoolingUnfoldingRecursiveAutoencoders.pdf},
volume = {24},
year = {2011}
}
@incollection{SA01,
author = {Salinas, E and Abbott, L F},
booktitle = {Principles of Neural Ensemble and Distributed Coding in the Nervous System},
pages = {175--190},
publisher = {Elsevier},
title = {{Coordinate transformations in the visual system: {\{}H{\}}ow to generate gain fields and what to compute with them}},
year = {2001}
}
@book{Gutnick1995,
abstract = {To understand how the cerebral cortex functions requires knowledge of single cells in this region and of their organization into cortical networks. Looking beyond the classical "wiring diagram" description of the organization of cortical cells into circuits, this innovative work focuses on dynamic aspects of cerebral cortical physiology, both at the single-neuron and network levels. Recent years have seen a remarkable expansion of knowledge about the basic cellular physiology and molecular biology of cortical neurons--their membrane properties, their synaptic characteristics, their functional connectivity, their development, and the mechanisms of their response to injury. This authoritative volume includes contributions by many of the renowned neurobiologists and neurologists directly responsible for these advances. It is divided into four main sections, each of which is prefaced with an overview by a leading expert in the field. The sections cover cortical neurons and synapses, the cortical network, the developing cortical neuron, and the vulnerable cortical neuron. This final section focuses on the cortical neuron in relation to the mechanisms of epilepsy. Together, the chapters provide a balanced, up-to-date, multidisciplinary perspective on the normal and pathological function of the cells of the cerebral cortex, identifying the controversies and critical issues facing modern researchers in this exciting field.},
author = {Gutnick, M J and Mody, Istvan},
isbn = {019508330X},
publisher = {Oxford University Press US},
title = {{The cortical neuron}},
url = {http://books.google.com/books?id=z2xQ8QVxSpEC{\&}pgis=1},
year = {1995}
}
@article{Nilsson|2006|,
abstract = {We present a robust method for 3D reconstruction of closed surfaces
from sparsely sampled parallel contours. A solution to this problem
is especially important for medical segmen- tation, where manual
contouring of 2D imaging scans is still extensively used. Our proposed
method is based on a mor- phing process applied to neighboring contours
that sweeps out a 3D surface. Our method is guaranteed to produce
closed surfaces that exactly pass through the input contours, regardless
of the topology of the reconstruction. Our general approach consecutively
morphs between sets of input contours using an Eulerian formulation
(i.e. {\^{A}}¯xed grid) augmented with Lagrangian particles (i.e. interface
track- ing). This is numerically accomplished by propagating the
input contours as 2D level sets with carefully constructed continuous
speed functions. Speci{\^{A}}¯cally this involves parti- cle advection
to estimate distances between the contours, monotonicity constrained
spline interpolation to compute continuous speed functions without
overshooting, and state- of-the-art numerical techniques for solving
the level set equa- tions. We demonstrate the robustness of our method
on a variety of medical, topographic and synthetic data sets.},
annote = {The paper describes a method for reconstruction of 3D surfaces from{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}set of contrours using level-set-approach based extrapolation of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the latter.},
author = {Nilsson, O and Breen, D and Museth, K},
keywords = {3D reconstruction,computational,contours,image processing,level sets,unread},
title = {{Surface reconstruction via contour metamorphosis: an eulerian approach with lagrangian particle tracking}}
}
@article{Button2013,
author = {Button, Katherine S. and Ioannidis, John P. a. and Mokrysz, Claire and Nosek, Brian a. and Flint, Jonathan and Robinson, Emma S. J. and Munaf{\`{o}}, Marcus R.},
doi = {10.1038/nrn3475},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
month = {apr},
number = {April},
title = {{Power failure: why small sample size undermines the reliability of neuroscience}},
url = {http://www.nature.com/doifinder/10.1038/nrn3475},
year = {2013}
}
@article{PAN07,
author = {Paninski, L},
journal = {Journal of Computational Neuroscience},
title = {{Inferring synaptic inputs given a noisy voltage trace via sequential {\{}Monte Carlo{\}} methods}},
volume = {Under revi},
year = {2009}
}
@article{Kralj2012,
abstract = {Reliable optical detection of single action potentials in mammalian neurons has been one of the longest-standing challenges in neuroscience. Here we achieved this goal by using the endogenous fluorescence of a microbial rhodopsin protein, Archaerhodopsin 3 (Arch) from Halorubrum sodomense, expressed in cultured rat hippocampal neurons. This genetically encoded voltage indicator exhibited an approximately tenfold improvement in sensitivity and speed over existing protein-based voltage indicators, with a roughly linear twofold increase in brightness between -150 mV and +150 mV and a sub-millisecond response time. Arch detected single electrically triggered action potentials with an optical signal-to-noise ratio {\textgreater}10. Arch(D95N) lacked endogenous proton pumping and had 50{\%} greater sensitivity than wild type but had a slower response (41 ms). Nonetheless, Arch(D95N) also resolved individual action potentials. Microbial rhodopsin-based voltage indicators promise to enable optical interrogation of complex neural circuits and electrophysiology in systems for which electrode-based techniques are challenging.},
annote = {נראה שלטכניקה הזאת יש פוטנציאל גבוה...},
author = {Kralj, Joel M and Douglass, Adam D and Hochbaum, Daniel R and Maclaurin, Dougal and Cohen, Adam E},
doi = {10.1038/nmeth.1782},
issn = {1548-7105},
journal = {Nature methods},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cell Membrane,Cell Membrane: metabolism,Fluorescent Dyes,Fluorescent Dyes: metabolism,HEK293 Cells,Halorhodopsins,Halorhodopsins: genetics,Halorhodopsins: metabolism,Halorubrum,Halorubrum: chemistry,Hippocampus,Hippocampus: cytology,Humans,Neurons,Neurons: physiology,Optics and Photonics,Rats},
month = {jan},
number = {1},
pages = {90--5},
pmid = {22120467},
title = {{Optical recording of action potentials in mammalian neurons using a microbial rhodopsin.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3248630{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2012}
}
@book{Kampen1992,
author = {Kampen, NG Van},
isbn = {0444529659},
number = {April},
title = {{Stochastic processes in physics and chemistry}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=3e7XbMoJzmoC{\&}oi=fnd{\&}pg=PP2{\&}dq=Stochastic+Processes+in+Physics+and+Chemistry{\&}ots=Acu4s3pdmV{\&}sig=bE2Y4dfre96YMi47VtVvZpcwI5c},
year = {1992}
}
@article{Karniel2003,
abstract = {Does the observation of well-timed movements imply the existence of some internal representation of time, such as a hypothetical neural clock? Here we report the results of experiments designed to investigate whether subjects form a correct adaptive representation of mechanical environments that change in a very predictable manner. In these experiments, subjects were asked to execute arm movements over a two-dimensional workspace while experiencing time-dependent disturbing forces. We provide a formal definition for time representation and conclude that our subjects didn't use time representation for motor adaptation under the tested conditions. Subjects performed arm-reaching movements in the following experiments: (1) six experiments in a sinusoidal time-varying force field; (2) six experiments in a simple sequence of alternating viscous force fields, in which the number of targets allowed for the approximation of the force by a complex state-dependent force field; and (3) six experiments in the same simple sequence of alternating viscous force fields, in which no state-dependent force field approximation was possible. We found that the subjects did not adapt to the time-varying force field and were unable to form an adequate representation of the simple sequence of force fields. In the latter case, whenever possible, they adapted to a single state-dependent field that produced forces similar to the two alternating fields. This state-dependent field produced the same forces as the applied sequence of fields only over the trajectories that subjects executed during the training phase. However, the state-dependent field was inadequate to produce the correct forces generated by the field sequence over a new set of trajectories.These results are not consistent with the hypothesis that subjects would develop a correct representation of time-dependent forces, at least under the tested circumstances. We speculate that the system responsible for adaptation of movements to external forces may be unable to employ temporal representation. While it is possible that such a representation may emerge in a more prolonged and/or intense training, our findings indicate a preference by the adaptive system to generalize based on representing dependence of external forces upon state rather than upon time.},
author = {Karniel, Amir and Mussa-Ivaldi, Ferdinando a},
doi = {10.1007/s00422-003-0397-7},
isbn = {9724829480},
issn = {0340-1200},
journal = {Biological cybernetics},
keywords = {Adaptation, Physiological,Adaptation, Physiological: physiology,Arm,Arm: physiology,Environment,Humans,Models, Biological,Movement,Movement: physiology,Psychomotor Performance,Psychomotor Performance: physiology},
month = {jul},
number = {1},
pages = {10--21},
pmid = {12836029},
title = {{Sequence, time, or state representation: how does the motor control system adapt to variable environments?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12836029},
volume = {89},
year = {2003}
}
@article{Barrett2008,
abstract = {There is evidence that biological synapses have a limited number of discrete weight states. Memory storage with such synapses behaves quite differently from synapses with unbounded, continuous weights, as old memories are automatically overwritten by new memories. Consequently, there has been substantial discussion about how this affects learning and storage capacity. In this paper, we calculate the storage capacity of discrete, bounded synapses in terms of Shannon information. We use this to optimize the learning rules and investigate how the maximum information capacity depends on the number of synapses, the number of synaptic states, and the coding sparseness. Below a certain critical number of synapses per neuron (comparable to numbers found in biology), we find that storage is similar to unbounded, continuous synapses. Hence, discrete synapses do not necessarily have lower storage capacity.},
author = {Barrett, Adam B and van Rossum, M C W},
doi = {10.1371/journal.pcbi.1000230},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Algorithms,Learning,Learning: physiology,Memory,Memory: physiology,Models, Neurological,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neuronal Plasticity,Neurons,Neurons: physiology,Synapses,Synapses: physiology,Synaptic Transmission},
month = {nov},
number = {11},
pages = {e1000230},
pmid = {19043540},
title = {{Optimal learning rules for discrete synapses.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2580035{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2008}
}
@article{Simoen1999,
author = {Simoen, E and Claeys, C},
journal = {Solid-State Electronics},
title = {{On the flicker noise in submicron silicon MOSFETs}},
url = {http://www.sciencedirect.com/science/article/pii/S0038110198003220},
volume = {43},
year = {1999}
}
@article{NEAL03,
author = {Neal, R M},
journal = {Annals of Statistics},
pages = {705--767},
title = {{Slice sampling}},
volume = {31},
year = {2003}
}
@article{Dempster1977,
author = {Dempster, AP and Laird, NM and Rubin, DB},
isbn = {0000000779},
journal = {Journal of the Royal statistical Society},
keywords = {incomplete,likelihood,maximum},
number = {1},
pages = {1--38},
title = {{Maximum likelihood from incomplete data via the EM algorithm}},
url = {http://www.academia.edu/download/31110297/dempster{\_}EM{\_}1977.pdf},
volume = {39},
year = {1977}
}
@article{buonomano2009state,
annote = {2008num39},
author = {Buonomano, D V and Maass, W},
journal = {Nature Reviews Neuroscience},
number = {2},
pages = {113--125},
publisher = {Nature Publishing Group},
title = {{State-dependent computations: spatiotemporal processing in cortical networks}},
volume = {10},
year = {2009}
}
@inproceedings{Jim2003,
author = {Jim{\'{e}}nez, D A},
booktitle = {MICRO-36. Proceedings. 36th Annual IEEE/ACM International Symposium on. IEEE},
isbn = {076952043X},
pages = {243--252},
title = {{Fast path-based neural branch prediction}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1253199},
year = {2003}
}
@article{CressieJohannesson08,
author = {Cressie, Noel and Johannesson, Gardar},
journal = {Journal Of The Royal Statistical Society Series B},
pages = {209--226},
title = {{Fixed rank kriging for very large spatial data sets}},
volume = {70},
year = {2008}
}
@article{BerridgeRoderick03,
abstract = {Ca2+ is a highly versatile intracellular signal that operates over

a wide temporal range to regulate many different cellular processes.

An extensive Ca2+-signalling toolkit is used to assemble signalling

systems with very different spatial and temporal dynamics. Rapid

highly localized Ca2+ spikes regulate fast responses, whereas slower

responses are controlled by repetitive global Ca2+ transients or

intracellular Ca2+ waves. Ca2+ has a direct role in controlling the

expression patterns of its signalling systems that are constantly

being remodelled in both health and disease.},
author = {Berridge, Michael J and Bootman, Martin D and Roderick, H Llewelyn},
doi = {10.1038/nrm1155},
journal = {Nat Rev Mol Cell Biol},
keywords = {Animals; Calcium; Calcium Channels; Calcium Signal,Biological; Second Messenger Systems},
month = {jul},
number = {7},
pages = {517--529},
pmid = {12838335},
title = {{Calcium signalling: dynamics, homeostasis and remodelling.}},
url = {http://dx.doi.org/10.1038/nrm1155},
volume = {4},
year = {2003}
}
@article{Field87,
author = {Field, D},
journal = {Journal of the Optical Society of America A},
pages = {2379--2394},
title = {{Relations Between the Statistics of Natural Images and the Response Profiles of Cortical Cells}},
volume = {4},
year = {1987}
}
@article{PeelMcLachlan00,
author = {Peel, D and McLachlan, G J},
journal = {Statistics and Computing},
number = {4},
pages = {339--348},
title = {{Robust mixture modelling using the t distribution}},
volume = {10},
year = {2000}
}
@article{Berndt2009,
abstract = {Here we describe bi-stable channelrhodopsins that convert a brief pulse of light into a stable step in membrane potential. These molecularly engineered probes nevertheless retain millisecond-scale temporal precision. Photocurrents can be precisely initiated and terminated with different colors of light, but operate at vastly longer time scales than conventional channelrhodopsins as a result of modification at the C128 position that extends the lifetime of the open state. Because of their enhanced kinetic stability, these step-function tools are also effectively responsive to light at orders of magnitude lower intensity than wild-type channelrhodopsins. These molecules therefore offer important new capabilities for a broad range of in vivo applications.},
author = {Berndt, Andr{\'{e}} and Yizhar, Ofer and Gunaydin, Lisa A and Hegemann, Peter and Deisseroth, Karl},
doi = {10.1038/nn.2247},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Cell Line,Cells,Cultured,Genetic Engineering,Genetic Engineering: methods,Hippocampus,Hippocampus: cytology,Humans,Kidney,Kidney: cytology,Light Signal Transduction,Light Signal Transduction: physiology,Mutagenesis,Neurons,Neurons: cytology,Neurons: physiology,Ocular,Ocular: physiology,Oocytes,Oocytes: physiology,Rats,Rhodopsin,Rhodopsin: genetics,Rhodopsin: physiology,Site-Directed,Sprague-Dawley,Transfection,Vision,Xenopus laevis},
month = {feb},
number = {2},
pages = {229--234},
pmid = {19079251},
publisher = {Nature Publishing Group},
shorttitle = {Nat Neurosci},
title = {{Bi-stable neural state switches.}},
url = {http://dx.doi.org/10.1038/nn.2247},
volume = {12},
year = {2009}
}
@article{Kuramoto1987,
annote = {2010IInum8.5},
author = {Kuramoto, Y. and Nishikawa, I.},
journal = {Journal of Statistical Physics},
number = {3},
pages = {569--605},
publisher = {Springer},
title = {{Statistical macrodynamics of large dynamical systems. Case of a phase transition in oscillator communities}},
url = {http://www.springerlink.com/index/VW6062608372Q4J2.pdf},
volume = {49},
year = {1987}
}
@article{CV95,
author = {Chaloner, K and Verdinelli, I},
journal = {Statistical Science},
number = {3},
pages = {273--304},
publisher = {JSTOR},
title = {{Bayesian experimental design: a review}},
volume = {10},
year = {1995}
}
@article{Quirk99,
author = {Quirk, Michael C and Wilson, Matthew A},
journal = {Journal of Neuroscience Methods},
pages = {41--52},
title = {{Interaction between spike waveform classification and temporal sequence detection}},
volume = {94},
year = {1999}
}
@article{Bonifazi2009,
abstract = {Brain function operates through the coordinated activation of neuronal assemblies. Graph theory predicts that scale-free topologies, which include "hubs" (superconnected nodes), are an effective design to orchestrate synchronization. Whether hubs are present in neuronal assemblies and coordinate network activity remains unknown. Using network dynamics imaging, online reconstruction of functional connectivity, and targeted whole-cell recordings in rats and mice, we found that developing hippocampal networks follow a scale-free topology, and we demonstrated the existence of functional hubs. Perturbation of a single hub influenced the entire network dynamics. Morphophysiological analysis revealed that hub cells are a subpopulation of gamma-aminobutyric acid-releasing (GABAergic) interneurons possessing widespread axonal arborizations. These findings establish a central role for GABAergic interneurons in shaping developing networks and help provide a conceptual framework for studying neuronal synchrony.},
annote = {2010IInum10.1},
author = {Bonifazi, Paolo and Goldin, M and Picardo, M A and Jorquera, I and Cattani, A and Bianconi, G and Represa, a and Ben-Ari, Y and Cossart, R},
doi = {10.1126/science.1175509},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Action Potentials,Animals,Axons,Axons: ultrastructure,CA3 Region,Calcium,Calcium: metabolism,Dendrites,Dendrites: ultrastructure,Excitatory Postsynaptic Potentials,Hippocampal,Hippocampal: cytology,Hippocampal: physiology,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Interneurons,Interneurons: physiology,Interneurons: ultrastructure,Mice,Nerve Net,Nerve Net: physiology,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Synapses,Synapses: physiology,Wistar,gamma-Aminobutyric Acid,gamma-Aminobutyric Acid: physiology,networks},
mendeley-tags = {networks},
month = {dec},
number = {5958},
pages = {1419--24},
pmid = {19965761},
title = {{GABAergic hub neurons orchestrate synchrony in developing hippocampal networks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19965761},
volume = {326},
year = {2009}
}
@article{Larremore2011,
annote = {

you may be interested in the attached paper - seems quite convincing at first reading, and the generality
is impressive. 

Ronny},
author = {Larremore, Daniel and Shew, Woodrow and Restrepo, Juan},
doi = {10.1103/PhysRevLett.106.058101},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {jan},
number = {5},
pages = {1--4},
title = {{Predicting Criticality and Dynamic Range in Complex Networks: Effects of Topology}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.106.058101},
volume = {106},
year = {2011}
}
@article{McKinneyMoore06,
author = {McKinney, B A and Crowe, J E Jr and Voss, H U and Crooke, P S and Barney, N and Moore, J H},
journal = {Phys Rev E Stat Nonlin Soft Matter Phys},
month = {feb},
number = {2 Pt 1},
pages = {21912},
title = {{Hybrid grammar-based approach to nonlinear dynamical system identification from biological time series}},
volume = {73},
year = {2006}
}
@incollection{Moerland1997,
address = {New York},
author = {Moerland, P and Fiesler, E},
booktitle = {Handbook of neural computation},
publisher = {Oxford University Press},
title = {{Neural Network Adaptations to Hardware Implementations}},
url = {http://ftp.idiap.ch/pub/reports/1997/rr97-17.pdf},
year = {1997}
}
@article{Ferrari-Trecate,
author = {Ferrari-Trecate, G. and Cuzzola, F.a. and Mignone, D. and Morari, M.},
doi = {10.1109/ACC.2001.945542},
isbn = {0-7803-6495-3},
journal = {Proceedings of the 2001 American Control Conference. (Cat. No.01CH37148)},
keywords = {h,hybrid systems,piecewise affine systems,robust control},
number = {Mld},
pages = {200--205},
publisher = {Ieee},
title = {{Analysis and control with performance of piecewise affine and hybrid systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=945542}
}
@article{Hsu04,
author = {Hsu, Anne and Borst, Alexander and Theunissen, Frederic E},
journal = {Network},
month = {may},
number = {2},
pages = {91--109},
title = {{Quantifying variability in neural responses and its application for the validation of model predictions}},
volume = {15},
year = {2004}
}
@article{WHT06,
author = {Woolley, S and Hauber, M and Theunissen, F},
journal = {Society for Neuroscience Abstracts},
title = {{Spike rates in the songbird forebrain but not the midbrain are higher to conspecific than to heterospecific songs and are altered by cross-fostering}},
year = {2006}
}
@article{Bruce2009,
abstract = {Fox and Lu derived an algorithm based on stochastic differential equations for approximating the kinetics of ion channel gating that is simpler and faster than "exact" algorithms for simulating Markov process models of channel gating. However, the approximation may not be sufficiently accurate to predict statistics of action potential generation in some cases. The objective of this study was to develop a framework for analyzing the inaccuracies and determining their origin. Simulations of a patch of membrane with voltage-gated sodium and potassium channels were performed using an exact algorithm for the kinetics of channel gating and the approximate algorithm of Fox {\&} Lu. The Fox {\&} Lu algorithm assumes that channel gating particle dynamics have a stochastic term that is uncorrelated, zero-mean Gaussian noise, whereas the results of this study demonstrate that in many cases the stochastic term in the Fox {\&} Lu algorithm should be correlated and non-Gaussian noise with a non-zero mean. The results indicate that: (i) the source of the inaccuracy is that the Fox {\&} Lu algorithm does not adequately describe the combined behavior of the multiple activation particles in each sodium and potassium channel, and (ii) the accuracy does not improve with increasing numbers of channels.},
author = {Bruce, I C},
doi = {10.1007/s10439-009-9635-z},
issn = {1521-6047},
journal = {Annals of biomedical engineering},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Computer Simulation,Ion Channel Gating,Ion Channel Gating: physiology,Ion Channels,Ion Channels: physiology,Kinetics,Markov Chains,Membrane Potentials,Membrane Potentials: physiology,Models, Biological,Potassium Channels,Potassium Channels: physiology,Sodium Channels,Sodium Channels: physiology,Stochastic Processes},
month = {apr},
number = {4},
pages = {824--38},
pmid = {19152030},
title = {{Evaluation of stochastic differential equation approximation of ion channel gating models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19152030},
volume = {37},
year = {2009}
}
@article{MUS88,
author = {Mussa-Ivaldi, F},
journal = {Neuroscience Letters},
pages = {106--111},
title = {{Do neurons in the motor cortex encode movement direction? {\{}A{\}}n alternative hypothesis}},
volume = {91},
year = {1988}
}
@article{Petreska2011,
author = {Petreska, Biljana and Yu, BM and Cunningham, J.P. and Santhanam, G. and Ryu, S.I. and Shenoy, K.V. and Sahani, M.},
journal = {NIPS},
keywords = {Network modeling},
mendeley-tags = {Network modeling},
pages = {1--9},
publisher = {Curran Associates, Inc.},
title = {{Dynamical segmentation of single trials from population neural data}},
url = {http://www.gatsby.ucl.ac.uk/{~}maneesh/papers/petreska-etal-2011-nips-preprint.pdf},
year = {2011}
}
@article{VS02,
author = {Venkataramanan, L and Sigworth, F},
journal = {Biophysical Journal},
pages = {1930--1942},
title = {{Applying Hidden Markov Models to the Analysis of Single Ion Channel Activity}},
volume = {82},
year = {2002}
}
@book{SO01,
editor = {Saad, D and Opper, M},
publisher = {MIT Press},
title = {{Advanced Mean Field Methods: Theory and Practice}},
year = {2001}
}
@article{Wicks|1996|,
author = {Wicks, S R and Roehrig, C J and Rankin, C H},
journal = {J. Neurosci.},
pages = {4017},
title = {{A dynamic network simulation of the nematode tap withdrawal circuit: predictions concerning synaptic function using behavioral criteria.}},
volume = {16}
}
@article{Sidiropoulou2006,
abstract = {For many decades, neurons were considered to be the elementary computational units of the brain and were assumed to summate incoming signals and elicit action potentials only in response to suprathreshold stimuli. Although modelling studies predicted that single neurons constitute a much more powerful computational entity, able to perform an array of nonlinear calculations, this possibility was not explored experimentally until the discovery of active mechanisms in the dendrites of most neuron types. Here, we review several modelling studies that have addressed information processing in single neurons, starting with those characterizing the arithmetic of different dendritic components, to those tackling neuronal integration at the cell body and, finally, those analysing the computational abilities of the axon. We present modelling predictions along with supporting experimental data in an effort to highlight the significant contribution of modelling work to enhancing our understanding of single-neuron arithmetic.},
annote = {2010IInum12.32},
author = {Sidiropoulou, Kyriaki and Pissadaki, Eleftheria Kyriaki and Poirazi, P},
doi = {10.1038/sj.embor.7400789},
issn = {1469-221X},
journal = {EMBO reports},
keywords = {Animals,Axons,Axons: chemistry,Computer Simulation,Dendrites,Dendrites: chemistry,Dendrites: physiology,Drosophila,Forecasting,Mice,Models,Neurological,Neuron Model,Neurons,Neurons: chemistry,Neurons: metabolism,Neurons: physiology,Nonlinear Dynamics,Regeneration,Synapses,Synapses: physiology},
mendeley-tags = {Neuron Model},
month = {sep},
number = {9},
pages = {886--92},
pmid = {16953202},
title = {{Inside the brain of a neuron.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16953202},
volume = {7},
year = {2006}
}
@article{ZhengVoigt06a,
author = {Zheng, Xiaohan and Voigt, Herbert F},
journal = {Annals of Biomedical Engineering},
month = {apr},
number = {4},
pages = {697--708},
title = {{A modeling study of notch noise responses of type III units in the gerbil dorsal cochlear nucleus}},
volume = {34},
year = {2006}
}
@article{JelenkoviA2003,
author = {Jelenkovic, P R and Petar, Momcilovic and Momcilovic, P},
journal = {Annals of Applied Probability},
pages = {576--603},
publisher = {Institute of Mathematical Statistics},
title = {{Asymptotic loss probability in a finite buffer fluid queue with heterogeneous heavy-tailed on-off processes}},
url = {http://projecteuclid.org/euclid.aoap/1050689595 http://www.jstor.org/stable/1193160},
year = {2003}
}
@article{Savin2014,
author = {Savin, Cristina and Dayan, Peter and Lengyel, M{\'{a}}t{\'{e}}},
doi = {10.1371/journal.pcbi.1003489},
editor = {Sporns, Olaf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {feb},
number = {2},
pages = {e1003489},
title = {{Optimal Recall from Bounded Metaplastic Synapses: Predicting Functional Adaptations in Hippocampal Area CA3}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1003489},
volume = {10},
year = {2014}
}
@article{Sarid2007a,
abstract = {We report a step in constructing an in silico model of a neocortical column, focusing on the synaptic connection between layer 4 (L4) spiny neurons and L2/3 pyramidal cells in rat barrel cortex. It is based first on a detailed morphological and functional characterization of synaptically connected pairs of L4-L2/3 neurons from in vitro recordings and second, on in vivo recordings of voltage responses of L2/3 pyramidal cells to current pulses and to whisker deflection. In vitro data and a detailed compartmental model of L2/3 pyramidal cells enabled us to extract their specific membrane resistivity ( approximately 16,000 ohms x cm(2)) and capacitance ( approximately 0.8 microF/cm(2)) and the spatial distribution of L4-L2/3 synaptic contacts. The average peak conductance per L4 synaptic contact is 0.26 nS for the alpha-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid and 0.2 nS for NMDA receptors. The in vivo voltage response for current steps was then used to calibrate the model for in vivo conditions in the Down state. Consequently, the effect of a single whisker deflection was modeled by converging, on average, 350 +/- 20 L4 axons onto the modeled L2/3 pyramidal cell. Based on values of synaptic conductance, the spatial distribution of L4 synapses on L2/3 dendrites, and the average in vivo spiking probability of L4 spiny neurons, the model predicts that the feed-forward L4-L2/3 connection on its own does not fire the L2/3 neuron. With a broader distribution in the number of L4 neurons or with slight synchrony among them, the L2/3 model does spike with low probability.},
annote = {2010IIInum2},
author = {Sarid, Leora and Bruno, Randy and Sakmann, B and Segev, I and Feldmeyer, Dirk},
doi = {10.1073/pnas.0707853104},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {AMPA,AMPA: physiology,Animals,Electrophysiology,Evoked Potentials,Jackie,Models,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: physiology,Neocortex,Neocortex: anatomy {\&} histology,Neocortex: cytology,Neocortex: physiology,Neurological,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Rats,Receptors,Somatosensory,Synapses,Synapses: physiology,Vibrissae,Vibrissae: innervation},
mendeley-tags = {Jackie},
month = {oct},
number = {41},
pages = {16353--8},
pmid = {17913876},
title = {{Modeling a layer 4-to-layer 2/3 module of a single column in rat neocortex: interweaving in vitro and in vivo experimental observations.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2000451{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {104},
year = {2007}
}
@article{Hirsch07,
author = {Wang, X and Wei, Y and Vaingankar, V and Wang, Q and Koepsell, K and Sommer, F and Hirsch, J},
journal = {Neuron},
pages = {465--478},
title = {{Feedforward Excitation and Inhibition Evoke Dual Modes of Firing in the Cat's Visual Thalamus during Naturalistic Viewing}},
volume = {55},
year = {2007}
}
@article{KennedyPendleton91,
author = {Kennedy, A D and Pendleton, Brian},
doi = {DOI: 10.1016/0920-5632(91)90893-J},
issn = {0920-5632},
journal = {Nuclear Physics B - Proceedings Supplements},
pages = {118--121},
title = {{Acceptances and autocorrelations in hybrid {\{}Monte Carlo{\}}}},
url = {http://www.sciencedirect.com/science/article/B6TVD-48HRGRD-W/2/406ce19e252614d87c87f89ba3794f57},
volume = {20},
year = {1991}
}
@article{Rudy1978a,
author = {Rudy, B Y B},
pages = {1--21},
title = {{Marine Biological A8sociation}},
year = {1978}
}
@article{YoungReiss05,
author = {Young, Eric D and Yu, Jane J and Reiss, Lina A J},
journal = {International Review of Neurobiology},
pages = {135--168},
title = {{Non-linearities and the representation of auditory spectra}},
volume = {70},
year = {2005}
}
@article{Keijzer2002a,
author = {Keijzer, Fred},
keywords = {1,a criticism of the,as important factors of,cognition,cognition is now,dynamical and embodied cognition,new themes are acknowledged,representation,the last few years,use of representations},
pages = {275--288},
title = {{R epresentation in dynamical and embodied cognition}},
volume = {3},
year = {2002}
}
@inproceedings{Schneider1991,
address = {Seattle, WA},
author = {Schneider, C. and Card, H},
booktitle = {IJCNN-91-Seattle International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.1991.155217},
isbn = {0-7803-0164-1},
month = {jul},
pages = {437--442},
publisher = {IEEE},
title = {{CMOS implementation of analog Hebbian synaptic learning circuits}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=155217},
volume = {i},
year = {1991}
}
@article{Shapiro|1982|,
abstract = {This review is an account of some theoretical methods in photodissociation
dynamicsw ith whicht he authors are familiar, and a brief comparison
of experiments with theory. For reasons of space, numerousto pics
have been omitted, such as a survey of experimental results (1-3),
infrared multiphoton dissociation (e.g. see 4), van tier Waals complex
dissociation (e.g. see 4), and complementaarysp ects of photodissociation
of polyatomics, reviewed by Gelbart (5). Thef ascinating aspect of
photodissociationd ynamicsp, articularly of a triatomic ABC{\~{}} A+BCi,s
the possibility of solution of the quantum equations of motion, on
the ground and excited state potential surfaces, and eventual comparison
with the experimental cross sections. This is muchm ored ifficult
for a three body exchanger eaction A + BC- {\~{}} AB+ C, mainly because
of the different boundary conditions and because a wide range of
impact parameters must be considered. The observables in photodissociation
and reaction dynamicsa re very similar--the disposal of the available
energy into translation, vibration, and rotation, and the angular
distribution of the products. The available energy is "tuned" in
reactive scattering by changing the reactant velocities or sometimes
their internal states. In photodissociation the dissociating wavelength
is changed.},
author = {Shapiro, M and Bersohn, R},
journal = {Annual Review of Nuclear and Particle Science},
keywords = {photodissociation,physics,quantum,solid state,unread},
pages = {409},
title = {{Theories of the dynamics of photodissociation}},
volume = {33}
}
@article{Plenz,
annote = {Isn{\&}{\#}039;t the stationarity contradicted by the P(t){\~{}}1/(t-t{\_}0) distribution of the ISIs? {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}What does he mean by stationarity anyway?},
author = {Plenz, D and Chialvo, Dante R and Neuroscience, Porter},
journal = {Neuroscience Research},
number = {2},
pages = {1--21},
title = {{Scaling properties of neuronal avalanches are consistent with critical dynamics}}
}
@article{HK86,
author = {Hunter, I and Korenberg, M},
journal = {Biological Cybernetics},
pages = {135--144},
title = {{The identification of nonlinear biological systems: Wiener and Hammerstein cascade models}},
volume = {55},
year = {1986}
}
@techreport{JOHN00,
author = {Johnstone, I},
institution = {Stanford},
number = {2000-27},
title = {{On the distribution of the largest principal component}},
year = {2000}
}
@article{Fang1996,
author = {Fang, S C and Venkatesh, S S},
journal = {Journal of Computer and System Sciences},
pages = {374--389},
title = {{Learning binary Perceptrons perfectly efficiently}},
url = {http://www.sciencedirect.com/science/article/pii/S0022000096900288},
volume = {52},
year = {1996}
}
@article{Destexhe07,
author = {Pospischil, M and Piwkowska, Z and Rudolph, M and Bal, T and Destexhe, A},
journal = {Journal of Neurophysiology},
pages = {2544--2552},
title = {{Calculating event-triggered average synaptic conductances from the membrane potential}},
volume = {97},
year = {2007}
}
@article{IshikawaTakahashi05,
abstract = {At the nerve terminal, both N- and P/Q-type Ca2+ channels mediate

synaptic transmission, with their relative contribution varying between

synapses and with postnatal age. To clarify functional significance

of different presynaptic Ca2+ channel subtypes, we recorded N-type

and P/Q-type Ca2+ currents directly from calyces of Held nerve terminals

in alpha1A-subunit-deficient mice and wild-type (WT) mice, respectively.

The most prominent feature of P/Q-type Ca2+ currents was activity-dependent

facilitation, which was absent for N-type Ca2+ currents. EPSCs mediated

by P/Q-type Ca2+ currents showed less depression during high-frequency

stimulation compared with those mediated by N-type Ca2+ currents.

In addition, the maximal inhibition by the GABAB receptor agonist

baclofen was greater for EPSCs mediated by N-type channels than for

those mediated by P/Q-type channels. These results suggest that the

developmental switch of presynaptic Ca2+ channels from N- to P/Q-type

may serve to increase synaptic efficacy at high frequencies of activity,

securing high-fidelity synaptic transmission.},
author = {Ishikawa, Taro and Kaneko, Masahiro and Shin, Hee-Sup and Takahashi, Tomoyuki},
doi = {10.1113/jphysiol.2005.089912},
journal = {J Physiol},
keywords = {Animals; Animals,Inbred C57BL; Mice,Knockout; Neuronal Plasticity; Presynaptic Termin,N-Type; Calcium Channels,Newborn; Baclofen; Brain Stem; Calcium; Calcium C,P-Type; Calcium Channels,Q-Type; Excitatory Postsynaptic Potentials; GABA},
month = {oct},
number = {Pt 1},
pages = {199--209},
pmid = {16037093},
title = {{Presynaptic N-type and P/Q-type [Ca{\^{}}{\{}2+{\}}] channels mediating synaptic transmission at the calyx of Held of mice.}},
url = {http://dx.doi.org/10.1113/jphysiol.2005.089912},
volume = {568},
year = {2005}
}
@article{Baldassi2009,
author = {Baldassi, C},
doi = {10.1007/s10955-009-9822-1},
issn = {0022-4715},
journal = {Journal of Statistical Physics},
keywords = {binary synapses,generalization,learning,online,perceptron,sbpi},
month = {sep},
number = {5},
pages = {902--916},
title = {{Generalization Learning in a Perceptron with Binary Synapses}},
url = {http://www.springerlink.com/index/10.1007/s10955-009-9822-1},
volume = {136},
year = {2009}
}
@article{Cartwright|2005|,
abstract = {A network is a countable, connected graph X viewed as a one-complex,
where each edge [x, y] = [y, x] (x, y $\backslash$E X{\^{}}0, the vertex set) is
a copy of the unit interval within the graph{\"{i}}¾'s one-skeleton X1
and is assigned a positive conductance c(xy). A reference {\"{i}}¾“Lebesgue{\"{i}}¾”
measure on X1 is built up by using Lebesgue measure with total mass
c(xy) on each edge [x, y]. There are three natural operators on X:
the transition operator P acting on functions on X{\^{}}0 (the reversible
Markov chain associated with c), the averaging operator A over spheres
of radius 1 on X{\^{}}1, and the Laplace operator $\backslash$Laplace on X1 (with
Kirchhoff conditions weighted by c at the vertices). The relation
between the {\^{a}}„“2-spectrum of P and the H2-spectrum of Laplace was
described by Cattaneo [4]. In this paper we describe the relation
between the {\^{a}}„“2-spectrum of P and the L2-spectrum of A.},
author = {Cartwright, D I and Woess, W},
journal = {arXiv},
keywords = {averaging,mathematics,metric,networks,operator,spectrum},
pages = {509595},
title = {{The spectrum of the averaging operator on a network (metric graph)}},
volume = {math}
}
@article{Cohen1984,
abstract = {The mutual exclusion problem in a distributed system, in which each process has a memory of its own, into which it has exclusive write privileges but from which others may read, is reconsidered. Symmetric solutions are looked for. It is shown that, though no such solution may be deterministic, there are probabilistic solutions. Different solutions are provided for two processes, and then a solution is proposed for any number of processes. The solutions offered are amenable to a formal proof of their correctness with a small effort. The solutions are correct even against a very well informed scheduler, unlike Rabin's probabilistic solution to the mutual exclusion problem in a centralized system. Some of the solutions are correct even against an evil scheduler the knows in advance the results of the future random draws, in sharp contrast with the algorithms of Lehmann and Rabin (1981). The solutions are economical: mutual exclusion between two processes may be achieved with variables capable of holding four different values (to be compared with Peterson and Fischer's three), mutual exclusion between n processes may be achieved with variables capable of holding ten different values (to be compared with Peterson and Fischer's fourteen). All solutions have been attained by careful reasoning and not by an exhaustive computer search: they exhibit general principles of design that may be useful in solving other similar problems.},
annote = {2011num1{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Cohen, S},
doi = {10.1016/0304-3975(84)90118-X},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {1-2},
pages = {215--225},
title = {{Symmetric and economical solutions to the mutual exclusion problem in a distributed system}},
url = {http://dx.doi.org/10.1016/0304-3975(84)90118-X http://linkinghub.elsevier.com/retrieve/pii/030439758490118X},
volume = {34},
year = {1984}
}
@article{Veksler2008,
abstract = {N/A},
author = {Veksler, Olga},
doi = {10.1007/978-3-540-88690-7-34},
isbn = {3540886893},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 3},
pages = {454--467},
title = {{Star shape prior for graph-cut image segmentation}},
volume = {5304 LNCS},
year = {2008}
}
@article{Pavan1997,
author = {Pavan, Paolo and Bez, Roberto and Olivo, Piero and Zanoni, Enrico},
journal = {Proceedings of the IEEE},
keywords = {charge carrier processes,read-only memory,semi-},
number = {8},
title = {{Flash memory cells-an overview}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=622505},
volume = {85},
year = {1997}
}
@article{Hayter2011,
author = {Hayter, A J and Lin, Y},
doi = {10.1007/s00180-011-0267-z},
issn = {0943-4062},
journal = {Computational Statistics},
keywords = {computational intensity,multivariate normal distribution,numerical integration,orthant probability,quadrivariate normal distribution},
month = {jun},
number = {3},
pages = {459--471},
title = {{The evaluation of two-sided orthant probabilities for a quadrivariate normal distribution}},
url = {http://link.springer.com/10.1007/s00180-011-0267-z},
volume = {27},
year = {2011}
}
@article{MAY99,
author = {Maynard, E and Hatsopoulos, N and Ojakangas, C and Acuna, B and Sanes, J and Normann, R and Donoghue, J},
journal = {Journal of Neuroscience},
pages = {8083--8093},
title = {{Neuronal Interactions Improve Cortical Population Coding of Movement Direction}},
volume = {19},
year = {1999}
}
@article{Bouchaud1987,
author = {Bouchaud, J P and Comtet, A},
doi = {10.1051/jphys:019870048090144500},
issn = {0302-0738},
journal = {J. Physique},
pages = {1445--1450},
title = {{Anomalous diffusion in random media of any dimensionality}},
url = {http://jphys.journaldephysique.org/articles/jphys/abs/1987/09/jphys{\_}1987{\_}{\_}48{\_}9{\_}1445{\_}0/jphys{\_}1987{\_}{\_}48{\_}9{\_}1445{\_}0.html},
volume = {48},
year = {1987}
}
@book{anderson1979optimal,
address = {Englewood Cliffs, NJ},
author = {Anderson, B D O and Moore, J B},
publisher = {Prentice hall},
title = {{Optimal Filtering}},
url = {http://www.innoventek.com/AndersonAndMooreOptimalFiltering.pdf},
volume = {11},
year = {1979}
}
@article{Crammer2013,
author = {Crammer, K and Kulesza, A and Dredze, M},
doi = {10.1007/s10994-013-5327-x},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {adaptive,online learning,supervised learning,text classification},
month = {mar},
number = {2},
pages = {155--187},
title = {{Adaptive regularization of weight vectors}},
url = {http://link.springer.com/10.1007/s10994-013-5327-x},
volume = {91},
year = {2013}
}
@article{miller2002neural,
annote = {2009num61},
author = {Miller, K D and Troyer, T W},
journal = {Journal of Neurophysiology},
number = {2},
pages = {653},
publisher = {Am Physiological Soc},
title = {{Neural noise can explain expansive, power-law nonlinearities in neural response functions}},
volume = {87},
year = {2002}
}
@article{LuLichtman09,
abstract = {{\textless}p{\textgreater}We introduce a method for large scale reconstruction of complex
bundles of neural processes from fluorescent image stacks. We imaged
yellow fluorescent protein labeled axons that innervated a whole
muscle, as well as dendrites in cerebral cortex, in transgenic mice,
at the diffraction limit with a confocal microscope. Each image stack
was digitally re-sampled along an orientation such that the majority
of axons appeared in cross-section. A region growing algorithm was
implemented in the open-source {\textless}italic{\textgreater}Reconstruct{\textless}/italic{\textgreater} software
and applied to the semi-automatic tracing of individual axons in
three dimensions. The progression of region growing is constrained
by user-specified criteria based on pixel values and object sizes,
and the user has full control over the segmentation process. A full
montage of reconstructed axons was assembled from the ‚{\`{a}}{\textordmasculine}200 individually
reconstructed stacks. Average reconstruction speed is ‚{\`{a}}{\textordmasculine}0.5 mm per
hour. We found an error rate in the automatic tracing mode of ‚{\`{a}}{\textordmasculine}1
error per 250 um of axonal length. We demonstrated the capacity of
the program by reconstructing the connectome of motor axons in a
small mouse muscle.{\textless}/p{\textgreater}},
author = {Lu, Ju and Fiala, John C and Lichtman, Jeff W},
doi = {10.1371/journal.pone.0005655},
journal = {PLoS ONE},
number = {5},
pages = {e5655},
publisher = {Public Library of Science},
title = {{Semi-Automated Reconstruction of Neural Processes from Large Numbers of Fluorescence Images}},
url = {http://dx.doi.org/10.1371/journal.pone.0005655},
volume = {4},
year = {2009}
}
@article{StuartSakmann94,
author = {Stuart, G and Sakmann, B},
journal = {Nature},
pages = {69--72},
title = {{Active propagation of somatic action potential into neocortical pyramidal cell dendrites}},
volume = {367},
year = {1994}
}
@inproceedings{Mignone,
author = {Mignone, Domenico and Ferrari-Trecate, G. and Morari, Manfred},
booktitle = {Decision and Control, 2000. Proceedings of the 39th IEEE Conference on},
isbn = {0780366387},
pages = {504--509},
publisher = {IEEE},
title = {{Stability and stabilization of piecewise affine and hybrid systems: An LMI approach}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=912814},
volume = {1},
year = {2002}
}
@article{ParhamKim95,
author = {Parham, K and Kim, D O},
journal = {Journal of Neurophysiology},
month = {feb},
number = {2},
pages = {550--561},
title = {{Spontaneous and sound-evoked discharge characteristics of complex-spiking neurons in the dorsal cochlear nucleus of the unanesthetized decerebrate cat}},
volume = {73},
year = {1995}
}
@article{Krissian|1999|,
abstract = {Detection of tubular structures in 3D images is an important issue
for vascular medical imaging. We present in this report an extension
of a previous work done by same authors [KMA98]. The following improvements
have been done: a better state of the art; a modification of the
response function by introducing a coefficient theta whose value
is deduced from the model; an experimental study on synthetic images
with junctions, tangent structures, structures with varying diameters,
and tubular structures with Gaussian-like cross-sections or convolved
bar-like cross-sections; an experimental study on a phantom image
and on real X-ray and MRA images.},
author = {Krissian, K and Malandain, G and Ayache, N and Vaillant, R and Trousset, Y},
journal = {Rapport de recherche},
keywords = {3d images,computational,detection,filtering,image processing,multiscale analysis,segmentation,tubular structrues,vessel detection},
title = {{Model Based Detection of Tubular Structures in 3D Images}},
volume = {3736}
}
@article{haider2009rapid,
annote = {2009num50},
author = {Haider, B and McCormick, D A},
journal = {Neuron},
number = {2},
pages = {171--189},
publisher = {Elsevier},
title = {{Rapid Neocortical Dynamics: Cellular and Network Mechanisms}},
volume = {62},
year = {2009}
}
@article{Faisal2008,
abstract = {Noise--random disturbances of signals--poses a fundamental problem for information processing and affects all aspects of nervous-system function. However, the nature, amount and impact of noise in the nervous system have only recently been addressed in a quantitative manner. Experimental and computational methods have shown that multiple noise sources contribute to cellular and behavioural trial-to-trial variability. We review the sources of noise in the nervous system, from the molecular to the behavioural level, and show how noise contributes to trial-to-trial variability. We highlight how noise affects neuronal networks and the principles the nervous system applies to counter detrimental effects of noise, and briefly discuss noise's potential benefits.},
annote = {2009num52},
author = {Faisal, A A and Selen, L P J and Wolpert, D M},
doi = {10.1038/nrn2258},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Humans,Information Theory,Models,Nerve Net,Nerve Net: physiology,Nervous System,Nervous System Physiological Phenomena,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurological,Noise},
number = {4},
pages = {292--303},
pmid = {18319728},
title = {{Noise in the nervous system.}},
volume = {9},
year = {2008}
}
@book{Rojas1996,
address = {Verlag Berlin Heidelberg},
author = {Rojas, R},
publisher = {Springer},
title = {{Neural networks: a systematic introduction}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=txsjjYzFJS4C{\&}oi=fnd{\&}pg=PA3{\&}dq=Neural+Networks+-+A+Systematic+Introduction{\&}ots=fl5-JKIvvT{\&}sig=G6ngHSQQqxkRA{\_}lWDRliLoSXOBw},
year = {1996}
}
@article{SV86,
author = {Shapley, R and Victor, J},
journal = {Science},
pages = {999--1002},
title = {{Hyperacuity in Cat Retinal Ganglion Cells}},
volume = {231},
year = {1986}
}
@article{Woolley|1996|,
author = {Woolley, C S and Wenzel, H J and Schwartzkroin, P A},
journal = {J Comp Neurol},
number = {1},
pages = {108--117},
title = {{Estradiol increases the frequency of multiple synapse boutons in the hippocampal CA1 region of the adult female rat.}},
volume = {373}
}
@article{GM64,
author = {Gerstein, G and Mandelbrot, B},
journal = {Biophysical Journal},
pages = {41--68},
title = {{Random walk models for the spike activity of a single neuron}},
volume = {4},
year = {1964}
}
@article{Yedidia2004,
author = {Yedidia, Jonathan S and Freeman, William T and Weiss, Y},
title = {{Constructing Free Energy Approximations and Generalized Belief Propagation Algorithms}},
year = {2004}
}
@book{Vapnik82,
author = {Vapnik, V N},
publisher = {Springer, Berlin},
title = {{Estimation of Dependences Baed on Empirical Data}},
year = {1982}
}
@article{Cressie2010,
author = {Cressie, Noel and Shi, Tao and Kang, Emily L},
journal = {Journal of Computational and Graphical Statistics},
pages = {724--745},
title = {{Fixed Rank Filtering for Spatio-Temporal Data}},
volume = {19},
year = {2010}
}
@inproceedings{Querlioz2011,
address = {San Jose, CA},
author = {Querlioz, D and Bichler, Olivier},
booktitle = {Neural Networks (IJCNN), The 2011 International Joint Conference on. IEEE},
isbn = {9781424496372},
month = {aug},
pages = {1775--1781},
title = {{Simulation of a memristor-based spiking neural network immune to device variations}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6033439},
year = {2011}
}
@article{Karhunen|2006|,
abstract = {Independent Component Analysis (ICA) is a recently developed technique
that in many cases characterizes the data in a natural way. The main
application area of the linear ICA model is blind source separation.
Here, unknown source signals are estimated from their unknown linear
mixtures using the strong assumption that the sources are mutually
independent. In practice, separation can be achieved by using suitable
higher-order statistics or nonlinearities. Various neural approaches
have recently been proposed for blind source separation and ICA.
In this paper, these approaches and the respective learning algorithms
are briefly reviewed, and some extensions of the basic ICA model
are discussed.},
author = {Karhunen, J},
keywords = {independent component analysis,mathematics,neural networks,neurobiology,source separation},
title = {{Neural Approaches to Independent Component Analysis and Source Separation}}
}
@article{JOS03,
author = {Joshi, J and O'Leary, J and Hatsopoulos, N},
journal = {Society for Neuroscience Abstracts},
pages = {661.11},
title = {{Decoding arm kinematics from multiple simultaneously recorded single units in dorsal premotor and primary motor cortices}},
year = {2003}
}
@book{Daubechies92,
author = {Daubechies, I},
publisher = {SIAM},
title = {{Ten Lectures on Wavelets}},
year = {1992}
}
@article{Destexhe:2007,
author = {Destexhe, A},
journal = {Scholarpedia},
number = {11},
pages = {1341},
title = {{High-conductance state}},
url = {http://www.scholarpedia.org/article/High-conductance{\_}state},
volume = {2},
year = {2007}
}
@article{Pnevmatikakis2016,
abstract = {{\textcopyright} 2016 Elsevier Inc.We present a modular approach for analyzing calcium imaging recordings of large neuronal ensembles. Our goal is to simultaneously identify the locations of the neurons, demix spatially overlapping components, and denoise and deconvolve the spiking activity from the slow dynamics of the calcium indicator. Our approach relies on a constrained nonnegative matrix factorization that expresses the spatiotemporal fluorescence activity as the product of a spatial matrix that encodes the spatial footprint of each neuron in the optical field and a temporal matrix that characterizes the calcium concentration of each neuron over time. This framework is combined with a novel constrained deconvolution approach that extracts estimates of neural activity from fluorescence traces, to create a spatiotemporal processing algorithm that requires minimal parameter tuning. We demonstrate the general applicability of our method by applying it to in vitro and in vivo multi-neuronal imaging data, whole-brain light-sheet imaging data, and dendritic imaging data. Advances in calcium imaging pose significant statistical analysis challenges. Pnevmatikakis et al. present a method for identifying and spatially demixing imaged neural components and deconvolving their activity from the indicator dynamics. The method is applied to a variety of datasets.},
author = {Pnevmatikakis, E.A. A and Soudry, D. and Gao, Y. and Machado, T.A. A and Merel, J. and Pfau, D. and Reardon, T. and Mu, Y. and Lacefield, C. and Yang, W. and Ahrens, M. and Bruno, R. and Jessell, T.M. M and Peterka, D.S. S and Yuste, R. and Paninski, L.},
doi = {10.1016/j.neuron.2015.11.037},
issn = {08966273},
journal = {Neuron},
number = {2},
pages = {1--15},
title = {{Simultaneous Denoising, Deconvolution, and Demixing of Calcium Imaging Data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315010843},
volume = {89},
year = {2016}
}
@article{Appleton|2005|,
abstract = {An approach to optimal object segmentation in the geodesic active
contour framework is presented with application to automated image
segmentation. The new segmentation scheme seeks the geodesic active
contour of globally minimal energy under the sole restriction that
it contains a specified internal point pint. This internal point
selects the object of interest and may be used as the only input
parameter to yield a highly automated segmentation scheme. The image
to be segmented is represented as a Riemannian space S with an associated
metric induced by the image. The metric is an isotropic and decreasing
function of the local image gradient at each point in the image,
encoding the local homogeneity of image features. Optimal segmentations
are then the closed geodesics which partition the object from the
background with minimal similarity across the partitioning. An efficient
algorithm is presented for the computation of globally optimal segmentations
and applied to cell microscopy, x-ray, magnetic resonance and cDNA
microarray images.},
annote = {The paper introduces a method for 2D segmentation based on extraction{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of geodesic closed contour from a given point on the boundary of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the object.},
author = {Appleton, B and Talbot, H},
journal = {Journal of Mathematical Imaging and Vision},
keywords = {circular shortest path,computational,geodesic active contour,image processing,optimal segmentation,segmentation},
pages = {67},
title = {{Globally optimal geodesic active contours}},
volume = {23}
}
@article{Dong1992,
author = {Dong, Dawei and Hopfield, John},
doi = {10.1088/0954-898X/3/3/002},
issn = {0954-898X},
journal = {Network: Computation in Neural Systems},
number = {3},
pages = {267--283},
title = {{Dynamic properties of neural networks with adapting synapses}},
url = {http://www.informaworld.com/openurl?genre=article{\&}doi=10.1088/0954-898X/3/3/002{\&}magic=crossref{\%}7C{\%}7CD404A21C5BB053405B1A640AFFD44AE3},
volume = {3},
year = {1992}
}
@article{VandenBroeck1994,
author = {{Van den Broeck}, C and Parrondo, J M R and Toral, R},
journal = {Physical review letters},
number = {25},
pages = {3395--3398},
publisher = {APS},
title = {{Noise-induced nonequilibrium phase transition}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.73.3395},
volume = {73},
year = {1994}
}
@article{Padmanabhan2010,
annote = {2010IIInum42},
author = {Padmanabhan, K and Urban, N N},
doi = {10.1038/nn.2630},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {aug},
number = {10},
pages = {1276--1282},
publisher = {Nature Publishing Group},
title = {{Intrinsic biophysical diversity decorrelates neuronal firing while increasing information content}},
url = {http://www.nature.com/doifinder/10.1038/nn.2630},
volume = {13},
year = {2010}
}
@article{Elenes2002,
abstract = {Nicotinic ACh receptor channels (AChRs) exposed to high concentrations of ACh adopt  desensitized' conformations that have a high affinity for the transmitter and no measurable ion conductance. Single-channel currents elicited by 0.1 or 1 mMACh were recorded from human embryonic kidney (HEK) cells that had been transiently transfected with mouse {\{}alpha{\}}, {\{}beta{\}}, {\{}delta{\}}, and {\{}varepsilon{\}} subunits. On the time scale of [{\~{}}]0.1 ms to [{\~{}}]1 h, apparent open intervals are described by a single exponential component, and shut intervals associated with desensitization are described by the sum of four or five exponential components. The kinetic behaviour appeared to be stationary and homogeneous. Desensitization rate constants were estimated by kinetic modelling of currents from cell-attached and outside-out patches (where the number of channels in the patch was measured). A single AChR recovered from the longest-lived desensitized state only after [{\~{}}]5 min. The occupancy of an AChR for each of the desensitized states was calculated as a function of time after the continuous application of a pulse of saturating ACh. The longest-lived desensitized state accounted for 90 {\%} of the total only after several seconds. The fractional recovery from desensitization (during a 200 ms wash period) decreased as the duration of the desensitizing pulse increased, suggesting that recovery is slower from the longer-lived desensitized states. The free energy landscape for the AChR desensitization reaction in cell-attached patches exhibited an initial destabilization, followed by a plateau region of gradually increasing stability, followed by a deep well.},
author = {Elenes, S and Auerbach, A.},
doi = {10.1113/jphysiol.2001.016022},
issn = {0022-3751},
journal = {The Journal of Physiology},
month = {apr},
number = {2},
pages = {367--383},
title = {{Desensitization of diliganded mouse muscle nicotinic acetylcholine receptor channels}},
url = {http://jp.physoc.org/cgi/content/abstract/541/2/367},
volume = {541},
year = {2002}
}
@article{Cecchi2000,
abstract = {Neuronal responses are conspicuously variable. We focus on one particular aspect of that variability: the precision of action potential timing. We show that for common models of noisy spike generation, elementary considerations imply that such variability is a function of the input, and can be made arbitrarily large or small by a suitable choice of inputs. Our considerations are expected to extend to virtually any mechanism of spike generation, and we illustrate them with data from the visual pathway. Thus, a simplification usually made in the application of information theory to neural processing is violated: noise is not independent of the message. However, we also show the existence of error-correcting topologies, which can achieve better timing reliability than their components.},
annote = {2008num33},
author = {Cecchi, G a and Sigman, M and Alonso, J M and Mart{\'{i}}nez, L and Chialvo, D R and Magnasco, M O},
doi = {10.1073/pnas.100113597},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Brain,Brain: physiology,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Noise,Time Factors},
month = {may},
number = {10},
pages = {5557--61},
pmid = {10792057},
title = {{Noise in neurons is message dependent}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=25867{\&}tool=pmcentrez{\&}rendertype=abstract http://www.ncbi.nlm.nih.gov/pubmed/10792057},
volume = {97},
year = {2000}
}
@article{Helfer|2003|,
abstract = {The prediction that black holes radiate due to quantum effects is
often considered one of the most secure in quantum field theory in
curved space{\^{A}}–time. Yet this prediction rests on two dubious assumptions:
that ordinary physics may be applied to vacuum fluctuations at energy
scales increasing exponentially without bound; and that quantum{\^{A}}–gravitational
effects may be neglected. Various suggestions have been put forward
to address these issues: that they might be explained away by lessons
from sonic black hole models; that the prediction is indeed successfully
reproduced by quantum gravity; that the success of the link provided
by the prediction between black holes and thermodynamics justifies
the prediction. This paper explains the nature of the difficulties,
and reviews the proposals that have been put forward to deal with
them. None of the proposals put forward can so far be considered
to be really successful, and simple dimensional arguments show that
quantum{\^{A}}–gravitational effects might well alter the evaporation process
outlined by Hawking. Thus a definitive theoretical treatment will
require an understanding of quantum gravity in at least some regimes.
Until then, no compelling theoretical case for or against radiation
by black holes is likely to be made. The possibility that non{\^{A}}–radiating
{\"{i}}¾“mini{\"{i}}¾” black holes exist should be taken seriously; such holes
could be part of the dark matter in the Universe. Attempts to place
observational limits on the number of {\"{i}}¾“mini{\"{i}}¾” black holes (independent
of the assumption that they radiate) would be most welcome.},
annote = {This paper provides an overview to black hole Hocking{\&}{\#}039;s radiation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and also discusses few other alternatives.},
author = {Helfer, A D},
journal = {arXiv},
keywords = {Hocking radiation,astrophysics,black holes,physics},
number = {0304042},
title = {{Do black holes radiate?}},
volume = {gr-gc}
}
@phdthesis{Verlaan98,
author = {Verlaan, M},
school = {TU Delft},
title = {{Efficient {\{}K{\}}alman filtering algorithms for hydrodynamic models}},
year = {1998}
}
@article{Severi2009,
author = {Severi, S and Corsi, C and Rocchetti, M and Zaza, A},
journal = {Biophysical Journal},
title = {{Mechanisms of $\beta$-Adrenergic Modulation of IKs in the Guinea-Pig Ventricle: Insights {\ldots}}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349509005700},
year = {2009}
}
@article{Andersen|1994|,
author = {Andersen, P and Trommald, M and Jensen, V},
journal = {Adv Second Messenger Phosphoprotein Res},
keywords = {Afferent Pathways/physiology Animals Axons/*metabo,Wistar Synapses/*metabolism},
pages = {340--351},
title = {{Low synaptic convergence of CA3 collaterals on CA1 pyramidal cells suggests few release sites}},
volume = {29}
}
@article{Arenas2006,
annote = {2010IInum8.8},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0511730v2},
author = {Arenas, Alex and D{\'{i}}az-Guilera, A and P{\'{e}}rez-Vicente, CJ and Diaz-Guilera, A and Perez-Vicente, CJ},
eprint = {0511730v2},
journal = {Physical Review Letters},
pages = {1--4},
primaryClass = {arXiv:cond-mat},
title = {{Synchronization reveals topological scales in complex networks}},
url = {http://prl.aps.org/abstract/PRL/v96/i11/e114102 http://link.aps.org/doi/10.1103/PhysRevLett.96.114102},
year = {2006}
}
@article{malenka2004ltp,
annote = {2008num18},
author = {Malenka, R C and Bear, M F},
journal = {Neuron},
number = {1},
pages = {5--21},
publisher = {Elsevier},
title = {{LTP and LTD an embarrassment of riches}},
volume = {44},
year = {2004}
}
@inproceedings{Claus|2004|,
annote = {This is good powerpoing presentation about nearest neighbor search{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and methods to reduce amount of stored information by condensing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the data without substantial loss of representation.},
author = {Claus, D},
booktitle = {Computer Vision Reading Group},
keywords = {computational,condensing,image processing,nearest neighbor},
title = {{Nearest neighbour condensing and editing}}
}
@article{Mino2002,
author = {Ino, H Iroyuki M and Ubinstein, J A Y T R and Hite, J O H N A W and Mino, Hiroyuki and Rubinstein, Jay T. and White, J A},
doi = {10.1114/1.1475343},
issn = {0090-6964},
journal = {Annals of Biomedical Engineering},
keywords = {action potentials,computer simulations,hodgkin,huxley equations,markov jumping process,neural excit-},
month = {apr},
number = {4},
pages = {578--587},
title = {{Comparison of Algorithms for the Simulation of Action Potentials with Stochastic Sodium Channels}},
url = {http://www.springerlink.com/openurl.asp?id=doi:10.1114/1.1475343},
volume = {30},
year = {2002}
}
@article{Lutcke2013,
abstract = {Two-photon calcium imaging enables functional analysis of neuronal circuits by inferring action potential (AP) occurrence ("spike trains") from cellular fluorescence signals. It remains unclear how experimental parameters such as signal-to-noise ratio (SNR) and acquisition rate affect spike inference and whether additional information about network structure can be extracted. Here we present a simulation framework for quantitatively assessing how well spike dynamics and network topology can be inferred from noisy calcium imaging data. For simulated AP-evoked calcium transients in neocortical pyramidal cells, we analyzed the quality of spike inference as a function of SNR and data acquisition rate using a recently introduced peeling algorithm. Given experimentally attainable values of SNR and acquisition rate, neural spike trains could be reconstructed accurately and with up to millisecond precision. We then applied statistical neuronal network models to explore how remaining uncertainties in spike inference affect estimates of network connectivity and topological features of network organization. We define the experimental conditions suitable for inferring whether the network has a scale-free structure and determine how well hub neurons can be identified. Our findings provide a benchmark for future calcium imaging studies that aim to reliably infer neuronal network properties.},
author = {L{\"{u}}tcke, H and Gerhard, F and Zenke, F and Gerstner, W and Helmchen, F},
doi = {10.3389/fncir.2013.00201},
issn = {1662-5110},
journal = {Frontiers in neural circuits},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Calcium,Calcium: metabolism,Computer Simulation,Fluorescence,Microscopy,Models,Multiphoton,Nerve Net,Nerve Net: metabolism,Nerve Net: physiology,Neurological,Neurons,Neurons: metabolism,Neurons: physiology,Signal-To-Noise Ratio},
number = {Dec},
pages = {201},
pmid = {24399936},
title = {{Inference of neuronal network spike dynamics and topology from calcium imaging data.}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3871709/ http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3871709{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@book{PL93,
address = {Oxford},
author = {Porter, R and Lemon, R},
publisher = {Clarendon Press},
title = {{Corticospinal function and voluntary movement}},
year = {1993}
}
@article{Hauser|1994|,
abstract = {Using the cluster expansions for n-point Green functions we derive
a closed set of dynamical equations of motion for connected equal-time
Green functions by neglecting all connected functions higher than
4th order for the lambda Phi{\^{}}4-theory in 1 + 1 dimensions. We apply
the equations to the investigation of spontaneous ground state symmetry
breaking, i.e. to the evaluation of the effective potential at temperature
T = 0. Within our momentum space discretization we obtain a second
order phase transition (in agreement with the Simon-Griffith theorem)
and a critical coupling of lambda{\_}crit/4m2 = 2.446 as compared to
a first order phase transition and lambda{\_}crit/4m2 = 2.568 from the
Gaussian effective potential approach.},
author = {Hauser, J M and Cassing, W and Peter, A and Thoma, M H},
journal = {arXiv},
keywords = {effective potential,green's function,ground state,phi{\^{}}4,physics,quantum field theory,symmetry breaking},
pages = {9408355},
title = {{Connected Green function approach to ground state symmetry breaking in Phi{\^{}}4{\_}1+1 theory}},
volume = {hep-ph}
}
@article{DGA00,
author = {Doucet, A and Godsill, S and Andrieu, C},
journal = {Statistics and Computing},
number = {3},
pages = {197--208},
publisher = {Springer},
title = {{On sequential Monte Carlo sampling methods for Bayesian filtering}},
volume = {10},
year = {2000}
}
@article{CaicedoHerbert93,
author = {Caicedo, A and Herbert, H},
journal = {Journal of Comparative Neurology},
month = {feb},
number = {3},
pages = {377--392},
title = {{Topography of descending projections from the inferior colliculus to auditory brainstem nuclei in the rat}},
volume = {328},
year = {1993}
}
@article{Fox2011,
annote = {2012num4},
author = {Fox, Douglas},
journal = {Scientic American},
pages = {36--43},
title = {{The limits of Intelligence}},
year = {2011}
}
@article{Douglas2004b,
abstract = {We explore the extent to which neocortical circuits generalize, i.e., to what extent can neocortical neurons and the circuits they form be considered as canonical? We find that, as has long been suspected by cortical neuroanatomists, the same basic laminar and tangential organization of the excitatory neurons of the neocortex is evident wherever it has been sought. Similarly, the inhibitory neurons show characteristic morphology and patterns of connections throughout the neocortex. We offer a simple model of cortical processing that is consistent with the major features of cortical circuits: The superficial layer neurons within local patches of cortex, and within areas, cooperate to explore all possible interpretations of different cortical input and cooperatively select an interpretation consistent with their various cortical and subcortical inputs.},
annote = {2010IInum12.45},
author = {Douglas, Rodney J and Martin, Kevan A C},
doi = {10.1146/annurev.neuro.27.070203.144152},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {Animals,Cell Size,Cell Size: physiology,Humans,Models,Neocortex,Neocortex: cytology,Neocortex: physiology,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neural Inhibition,Neural Inhibition: physiology,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurological,Neuron Model,Neurons,Neurons: physiology,Synaptic Transmission,Synaptic Transmission: physiology,as canon-,as has long been,computation,e,excitation,i,i abstract we explore,ical,inhibition,model,neocortical circuits generalize,network,neurons and the circuits,suspected by cortical neuroanatomists,the extent to which,the same,they form be considered,to,we find that,what extent can neocortical},
mendeley-tags = {Neuron Model},
month = {jan},
pages = {419--51},
pmid = {15217339},
title = {{Ircuits of the}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15217339},
volume = {27},
year = {2004}
}
@article{Linares-Barranco1993,
abstract = {The transconductance-mode (T-mode) approach is extended to implement analog continuous-time neural network hardware systems to include on-chip Hebbian learning and on-chip analog weight storage capability. The demonstration vehicle used is a 5+5-neuron bidirectional associative memory (BAM) prototype fabricated in a standard 2-mum double-metal double-polysilicon CMOS process. Mismatches and nonidealities in learning neural hardware are not supposed to be critical if on-chip learning is available, because they will be implicitly compensated. However, mismatches in the learning circuits themselves cannot always be compensated. This mismatch is specially important if the learning circuits use transistors operating in weak inversion. The authors estimate the expected mismatch between learning circuits in the BAM network prototype and evaluate its effect on the learning performance, using theoretical computations and Monte Carlo HSPICE simulations. These theoretical predictions are verified using experimentally measured results on the test vehicle prototype.},
author = {Linares-Barranco, B and Sanchez-Sinencio, E and Rodriguez-Vazquez, a and Huertas, J L},
doi = {10.1109/72.217187},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
month = {jan},
number = {3},
pages = {445--55},
pmid = {18267748},
title = {{A CMOS analog adaptive BAM with on-chip learning and weight refreshing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18267748},
volume = {4},
year = {1993}
}
@article{Featherstone1996,
abstract = {Rat skeletal muscle (Skm1) sodium channel alpha and beta 1 subunits were coexpressed in Xenopus oocytes, and resulting sodium currents were recorded from on-cell macropatches. First, the kinetics and steady-state probability of both fast and slow inactivation in Skm1 wild type (WT) sodium channels were characterized. Next, we confirmed that mutation of IFM to QQQ (IFM1303QQQ) in the DIII-IV 'inactivation loop' completely removed fast inactivation at all voltages. This mutation was then used to characterize Skm1 slow inactivation without the presence of fast inactivation. The major findings of this paper are as follows: 1) Even with complete removal of fast inactivation by the IFM1303QQQ mutation, slow inactivation remains intact. 2) In WT channels, approximately 20{\%} of channels fail to slow-inactivate after fast-inactivating, even at very positive potentials. 3) Selective removal of fast inactivation by IFM1303QQQ allows slow inactivation to occur more quickly and completely than in WT. We conclude that fast inactivation reduces the probability of subsequent slow inactivation.},
author = {Featherstone, D E and Richmond, J E and Ruben, P C},
doi = {10.1016/S0006-3495(96)79504-8},
isbn = {8017971575},
issn = {0006-3495},
journal = {Biophysical journal},
keywords = {Amino Acid Sequence,Animals,Female,Ion Channel Gating,Kinetics,Macromolecular Substances,Membrane Potentials,Muscle, Skeletal,Muscle, Skeletal: physiology,Mutagenesis, Site-Directed,Oocytes,Oocytes: physiology,Patch-Clamp Techniques,Rats,Recombinant Proteins,Recombinant Proteins: metabolism,Sodium Channels,Sodium Channels: physiology,Time Factors,Xenopus laevis},
month = {dec},
number = {6},
pages = {3098--109},
pmid = {8968581},
title = {{Interaction between fast and slow inactivation in Skm1 sodium channels.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1233799{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {71},
year = {1996}
}
@article{Mishchenko2011c,
author = {Mishchenko, Y and Vogelstein, J T and Paninski, L},
journal = {The Annals of Applied Statistics},
number = {2B},
pages = {1229--1261},
title = {{A Bayesian approach for inferring neuronal connectivity from calcium fluorescent imaging data}},
url = {http://projecteuclid.org/euclid.aoas/1310562720},
volume = {5},
year = {2011}
}
@article{HATS98,
author = {Hatsopoulos, N and Ojakangas, C and Paninski, L and Donoghue, J},
journal = {PNAS},
pages = {15706--15711},
title = {{Information about movement direction obtained by synchronous activity of motor cortical neurons}},
volume = {95},
year = {1998}
}
@article{Wainrib2011b,
author = {Wainrib, G},
doi = {10.1103/PhysRevE.84.051113},
issn = {1539-3755},
journal = {Physical Review E},
month = {nov},
number = {5},
pages = {1--8},
title = {{Noise-controlled dynamics through the averaging principle for stochastic slow-fast systems}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.84.051113},
volume = {84},
year = {2011}
}
@article{Cuntz2010,
author = {Cuntz, Hermann and Forstner, Friedrich and Borst, Alexander and H{\"{a}}usser, M},
doi = {10.1371/journal.pcbi.1000877},
editor = {Morrison, Abigail},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {aug},
number = {8},
pages = {e1000877},
title = {{One Rule to Grow Them All: A General Theory of Neuronal Branching and Its Practical Application}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1000877},
volume = {6},
year = {2010}
}
@article{Douglas1996,
abstract = {The synapse, first introduced as physiological hypothesis by C.S. Sherrington at the close of the nineteenth century, has, 100 years on, become the nexus for anatomical and functional investigations of interneuronal communication. A number of hypotheses have been proposed that give local synaptic interactions specific roles in generating an algebra or logic for computations in the neocortex. Experimental work, however, has provided little support for such schemes. Instead, both structural and functional studies indicate that characteristically cortical functions, e.g., the identification of the motion or orientation of objects, involve computations that must be achieved with high accuracy through the collective action of hundreds or thousands of neurons connected in recurrent microcircuits. Some important principles that emerge from this collective action can effectively be captured by simple electronic models. More detailed models explain the nature of the complex computations performed by the cortical circuits and how the computations remain so remarkably robust in the face of a number of sources of noise, including variability in the anatomical connections, large variance in the synaptic responses and in the trial-to-trial output of single neurons, and weak or degraded input signals.},
author = {Douglas, R J and Mahowald, M and Martin, K a and Stratford, K J},
issn = {0300-4864},
journal = {Journal of neurocytology},
keywords = {Animals,Cats,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Ion Channels,Ion Channels: physiology,Models, Neurological,Neurons,Neurons: physiology,Neurons: ultrastructure,Synapses,Synapses: physiology,Synapses: ultrastructure,Visual Cortex,Visual Cortex: physiology,Visual Cortex: ultrastructure},
month = {dec},
number = {12},
pages = {893--911},
pmid = {9023732},
title = {{The role of synapses in cortical computation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9023732},
volume = {25},
year = {1996}
}
@inproceedings{Memarsadeghi08,
author = {Memarsadeghi, N and Raykar, V C and Duraiswami, R and Mount, D M},
booktitle = {Aerospace Conference, 2008 IEEE},
pages = {1--7},
title = {{Efficient Kriging via Fast Matrix-Vector Products}},
year = {2008}
}
@article{Henning|1995|,
abstract = {The study of quantum effects in hot, dense matter requires to account
for the full spectral function of its constituents. Traditional quantum
statistical methods have to be modified accordingly: Propagators
and diagram rules for generalized free fields are discussed in this
work, using the formalism of therm0 field dynamics (ml. This formalism
is briefly reviewed at the elementary level of a single oscillator.
Commuting representations of the canonical commutation relations
are constructed in Liouville space, and a continuous symmetry of
the time evolution generator is discussed. TFJI is then applied to
interacting relativistic quantum fields: The symplectic symmetry
of the liouvillean is transcribed into the concept of diagonalization
of the full single-particle propagator. While it leads to global
equilibrium conditions for space-time homogeneous states, the diagonalization
condition is equivalent to a transport equation for non-equilibrium
states. To illustrate some consequences of a non-trivial spectral
function on the properties of hot, dense matter, the formalism is
then applied to nuclear physics: The equilibration problem in the
g-w model is discussed, and pion propagator and transport coefficients
are calculated within the A-hole model.},
author = {Henning, P A},
journal = {Physics Reports},
keywords = {physics,quantum field theory,thermo field,thermodynamics},
pages = {235},
title = {{Thermo field dynamics for quantum fields with continuous mass spectrum}},
volume = {253}
}
@article{CasellaLavineRobert01,
author = {Casella, G and Lavine, M and Robert, C},
journal = {The American Statistician},
pages = {299--305},
title = {{Explaining the Perfect Sampler}},
volume = {55},
year = {2001}
}
@article{Westover|2001|,
abstract = {The population vector is a linear decoder for an ensemble of neurons,
whose response properties are nonlinear functions of the input vector.
However, previous analyses of this decoder seem to have missed the
obsevation that the population vector can also be used to estimate
functions of the input vector. We explore how to use singular value
decomposition to delineate the class of functions which are linearly
decodable from a given population of noisy neural encoders.},
annote = {The paper introduces linear coding-decoding operations for representation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of the input functional stimili in a population firing rates code},
author = {Westover, M B and Eliasmith, C and Anderson, C H},
keywords = {attractor,networks,neural networks,neurobiology,population codes,unread},
title = {{Linearly decodable functions from neural population codes}}
}
@article{GAO02,
author = {Gao, Y and Black, M J and Bienenstock, E and Shoham, S and Donoghue, J P},
journal = {NIPS},
pages = {221--228},
title = {{Probabilistic inference of arm motion from neural activity in motor cortex}},
volume = {14},
year = {2002}
}
@article{Fee1996,
author = {Fee, M and Mitra, P and Kleinfeld, D},
journal = {J. Neurosci. Meth.},
pages = {175--188},
title = {{Automatic sorting of multiple unit neuronal signals in the presence of anisotropic and non-Gaussian variability}},
volume = {69},
year = {1996}
}
@article{Hodgkin1952,
author = {Hodgkin, A L and Huxley, A F},
journal = {The Journal of physiology},
number = {4},
pages = {500},
publisher = {Physiological Soc},
title = {{A quantitative description of membrane current and its application to conduction and excitation in nerve}},
url = {http://jp.physoc.org/content/117/4/500.full.pdf},
volume = {117},
year = {1952}
}
@article{Carelli2005,
abstract = {Irregular intrinsic behavior of neurons seems ubiquitous in the nervous system. Even in circuits specialized to provide periodic and reliable patterns to control the repetitive activity of muscles, such as the pyloric central pattern generator (CPG) of the crustacean stomatogastric ganglion (STG), many bursting motor neurons present irregular activity when deprived from synaptic inputs. Moreover, many authors attribute to these irregularities the role of providing flexibility and adaptation capabilities to oscillatory neural networks such as CPGs. These irregular behaviors, related to nonlinear and chaotic properties of the cells, pose serious challenges to developing deterministic Hodgkin-Huxley-type (HH-type) conductance models. Only a few deterministic HH-type models based on experimental conductance values were able to show such nonlinear properties, but most of these models are based on slow oscillatory dynamics of the cytosolic calcium concentration that were never found experimentally in STG neurons. Based on an up-to-date single-compartment deterministic HH-type model of a STG neuron, we developed a stochastic HH-type model based on the microscopic Markovian states that an ion channel can achieve. We used tools from nonlinear analysis to show that the stochastic model is able to express the same kind of irregularities, sensitivity to initial conditions, and low dimensional dynamics found in the neurons isolated from the STG. Without including any nonrealistic dynamics in our whole cell stochastic model, we show that the nontrivial dynamics of the membrane potential naturally emerge from the interplay between the microscopic probabilistic character of the ion channels and the nonlinear interactions among these elements. Moreover, the experimental irregular behavior is reproduced by the stochastic model for the same parameters for which the membrane potential of the original deterministic model exhibits periodic oscillations.},
author = {Carelli, Pedro V PV V and Reyes, MB B Marcelo B and Sartorelli, Jos{\'{e}} C and Pinto, Reynaldo D},
doi = {10.1152/jn.00070.2005},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Electric Stimulation,Electric Stimulation: methods,Ganglia,Invertebrate,Invertebrate: cytology,Ion Channels,Ion Channels: classification,Ion Channels: physiology,Membrane Potentials,Membrane Potentials: physiology,Models,Neural Conduction,Neural Conduction: physiology,Neurological,Neurons,Neurons: classification,Neurons: physiology,Nonlinear Dynamics,Palinuridae,Reaction Time,Stochastic Processes,Time Factors},
month = {aug},
number = {2},
pages = {1169--79},
pmid = {15800078},
title = {{Whole cell stochastic model reproduces the irregularities found in the membrane potential of bursting neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15800078 http://jn.physiology.org/content/94/2/1169.short},
volume = {94},
year = {2005}
}
@book{kandel1991principles,
author = {Kandel, E R and Schwartz, J H and Jessell, T M},
booktitle = {kermit-project.org},
edition = {4th},
publisher = {McGraw Hill},
title = {{Principles of neural science}},
volume = {3},
year = {2000}
}
@book{FellerBook71,
address = {New York},
author = {Feller, William},
edition = {2},
howpublished = {Paperback},
isbn = {0471257095},
publisher = {Wiley},
title = {{An Introduction to Probability Theory and Its Applications, Vol. 2 (Volume 2)}},
url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20{\&}path=ASIN/0471257095},
year = {1971}
}
@article{Fellous|2004|,
abstract = {When a cortical neuron is repeatedly injected with the same fluctuating
current stimulus (frozen noise) the timing of the spikes is highly
precise from trial to trial and the spike pattern appears to be unique.
We show here that the same repeated stimulus can produce more than
one reliable temporal pattern of spikes. A new method is introduced
to find these patterns in raw multitrial data and is tested on surrogate
data sets. Using it, multiple coexisting spike patterns were discovered
in pyramidal cells recorded from rat prefrontal cortex in vitro,
in data obtained in vivo from the middle temporal area of the monkey
(Buracas et al., 1998) and from the cat lateral geniculate nucleus
(Reinagel and Reid, 2002). The spike patterns lasted from a few tens
of milliseconds in vitro to several seconds in vivo. We conclude
that the prestimulus history of a neuron may influence the precise
timing of the spikes in response to a stimulus over a wide range
of time scales.},
author = {Fellous, J.-M. and Tlesinga, P H E and Thomas, P J and Sejnowski, T J},
journal = {The journal of neuroscience},
keywords = {MT,cluster,electroencyphalogram,lateral geniculate,network,neurobiology,primary components analysis,synapse,vision},
number = {12},
pages = {2989},
title = {{Discovering Spike Patterns in Neuronal Responses}},
volume = {24}
}
@article{WallaceHasan08,
abstract = {Measurement of population activity with single-action-potential, single-neuron resolution is pivotal for understanding information representation and processing in the brain and how the brain's responses are altered by experience. Genetically encoded indicators of neuronal activity allow long-term, cell type-specific expression. Fluorescent Ca2+ indicator proteins (FCIPs), a main class of reporters of neural activity, initially suffered, in particular, from an inability to report single action potentials in vivo. Although suboptimal Ca2+-binding dynamics and Ca2+-induced fluorescence changes in FCIPs are important factors, low levels of expression also seem to play a role. Here we report that delivering D3cpv, an improved fluorescent resonance energy transfer-based FCIP, using a recombinant adeno-associated virus results in expression sufficient to detect the Ca2+ transients that accompany single action potentials. In upper-layer cortical neurons, we were able to detect transients associated with single action potentials firing at rates of {\textless}1 Hz, with high reliability, from in vivo recordings in living mice.},
author = {Wallace, Damian J and {Meyer zum Alten Borgloh}, Stephan and Astori, Simone and Yang, Ying and Bausen, Melanie and K{\"{u}}gler, Sebastian and Palmer, Amy E and Tsien, Roger Y and Sprengel, Rolf and Kerr, Jason N D and Denk, W and Hasan, Mazahir T and {zum Alten Borgloh}, S M and Kugler, S},
doi = {10.1038/nmeth.1242},
isbn = {1548-7091 (Print)$\backslash$r1548-7091 (Linking)},
issn = {1548-7091},
journal = {Nature methods},
number = {9},
pages = {797--804},
pmid = {19160514},
publisher = {Nature Publishing Group},
title = {{Single-spike detection in vitro and in vivo with a genetic Ca2+ sensor}},
url = {http://www.nature.com/nmeth/journal/v5/n9/abs/nmeth.1242.html},
volume = {5},
year = {2008}
}
@article{Cheng1969,
author = {Cheng, MC},
journal = {The Annals of Mathematical Statistics},
number = {1},
pages = {152--161},
title = {{The orthant probabilities of four Gaussian variates}},
url = {http://www.jstor.org/stable/10.2307/2239206},
volume = {40},
year = {1969}
}
@article{Elliott2009,
abstract = {A stochastic model of spike-timing-dependent plasticity proposes that single synapses express fixed-amplitude jumps in strength, the amplitudes being independent of the spike time difference. However, the probability that a jump in strength occurs does depend on spike timing. Although the model has a number of desirable features, the stochasticity of response of a synapse introduces potentially large fluctuations into changes in synaptic strength. These can destabilize the segregated patterns of afferent connectivity characteristic of neuronal development. Previously we have taken these jumps to be small relative to overall synaptic strengths to control fluctuations, but doing so increases developmental timescales unacceptably. Here, we explore three alternative ways of taming fluctuations. First, a calculation of the variance for the change in synaptic strength shows that the mean change eventually dominates fluctuations, but on timescales that are too long. Second, it is possible that fluctuations in strength may cancel between synapses, but we show that correlations between synapses emasculate the law of large numbers. Finally, by separating plasticity induction and expression, we introduce a temporal window during which induction signals are low-pass-filtered before expression. In this way, fluctuations in strength are tamed, stabilizing segregated states of afferent connectivity.},
author = {Elliott, Terry and Lagogiannis, Konstantinos},
doi = {10.1162/neco.2009.12-08-916},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Models,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Stochastic Processes,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
month = {dec},
number = {12},
pages = {3363--3407},
pmid = {19635017},
title = {{Taming fluctuations in a stochastic model of spike-timing-dependent plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19635017},
volume = {21},
year = {2009}
}
@article{Fleidervish1996,
abstract = {1. Spike adaptation of neocortical pyramidal neurones was studied with sharp electrode recordings in slices of guinea-pig parietal cortex and whole-cell patch recordings of mouse somatosensory cortex. Repetitive intracellular stimulation with 1 s depolarizing pulses delivered at intervals of {\textless} 5 s caused slow, cumulative adaptation of spike firing, which was not associated with a change in resting conductance, and which persisted when Co2+ replaced Ca2+ in the bathing medium. 2. Development of slow cumulative adaptation was associated with a gradual decrease in maximal rates of rise of action potentials, a slowing in the post-spike depolarization towards threshold, and a positive shift in the threshold voltage for the next spike in the train; maximal spike repolarization rates and after-hyperpolarizations were unchanged. 3. The data suggested that slow adaptation reflects use-dependent removal of Na+ channels from the available pool by an inactivation process which is much slower than fast, Hodgkin-Huxley-type inactivation. 4. We therefore studied the properties of Na+ channels in layer II-III mouse neocortical cells using the cell-attached configuration of the patch-in-slice technique. These had a slope conductance of 18 +/- 1 pS and an extrapolated reversal potential of 127 +/- 6 mV above resting potential (Vr) (mean +/- S.E.M.; n = 5). Vr was estimated at -72 +/- 3 mV (n = 8), based on the voltage dependence of the steady-state inactivation (h infinity) curve. 5. Slow inactivation (SI) of Na+ channels had a mono-exponential onset with tau on between 0.86 and 2.33 s (n = 3). Steady-state SI was half-maximal at -43.8 mV and had a slope of 14.4 mV (e-fold)-1. Recovery from a 2 s conditioning pulse was bi-exponential and voltage dependent; the slow time constant ranged between 0.45 and 2.5 s at voltages between-128 and -68 mV. 6. The experimentally determined parameters of SI were adequate to simulate slow cumulative adaptation of spike firing in a single-compartment computer model. 7. Persistent Na+ current, which was recorded in whole-cell configuration during slow voltage ramps (35 mV s-1), also underwent pronounced SI, which was apparent when the ramp was preceded by a prolonged depolarizing pulse.},
annote = {2009num9},
author = {Fleidervish, I A and Friedman, A and Gutnick, M J},
journal = {Journal of Physiology},
number = {Pt 1},
pages = {83--97},
title = {{Slow inactivation of Na+ current and slow cumulative spike adaptation in mouse and guinea-pig neocortical neurones in slices}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8735696},
volume = {493},
year = {1996}
}
@incollection{Sollaa,
address = {Cambridge},
author = {Solla, S A and Winther, O},
booktitle = {On-Line Learning in Neural Networks},
publisher = {Cambridge University Press},
title = {{Optimal perceptron learning: an online Bayesian approach}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.4856{\&}rep=rep1{\&}type=pdf},
year = {1998}
}
@article{DavisYoung00,
author = {Davis, K A and Young, E D},
journal = {Journal of Neurophysiology},
month = {feb},
number = {2},
pages = {926--940},
title = {{Pharmacological evidence of inhibitory and disinhibitory neuronal circuits in dorsal cochlear nucleus}},
volume = {83},
year = {2000}
}
@article{Wang2013,
abstract = {With the rapid increase in the number of technologies aimed at observing electric activity inside the brain, scientists have felt the urge to create proper links between intracellular- and extracellular-based experimental approaches. Biophysical models at both physical scales have been formalized under assumptions that impede the creation of such links. In this work, we address this issue by proposing a multicompartment model that allows the introduction of complex extracellular and intracellular resistivity profiles. This model accounts for the geometrical and electrotonic properties of any type of neuron through the combination of four devices: the integrator, the propagator, the 3D connector, and the collector. In particular, we applied this framework to model the tufted pyramidal cells of layer 5 (PCL5) in the neocortex. Our model was able to reproduce the decay and delay curves of backpropagating action potentials (APs) in this type of cell with better agreement with experimental data. We used the voltage drops of the extracellular resistances at each compartment to approximate the local field potentials generated by a PCL5 located in close proximity to linear microelectrode arrays. Based on the voltage drops produced by backpropagating APs, we were able to estimate the current multipolar moments generated by a PCL5. By adding external current sources in parallel to the extracellular resistances, we were able to create a sensitivity profile of PCL5 to electric current injections from nearby microelectrodes. In our model for PCL5, the kinetics and spatial profile of each ionic current were determined based on a literature survey, and the geometrical properties of these cells were evaluated experimentally. We concluded that the inclusion of the extracellular space in the compartmental models of neurons as an extra electrotonic medium is crucial for the accurate simulation of both the propagation of the electric potentials along the neuronal dendrites and the neuronal reactivity to an electrical stimulation using external microelectrodes.},
author = {Wang, Kai and Riera, Jorge and Enjieu-Kadji, Herve and Kawashima, Ryuta},
doi = {10.1162/NECO_a_00458},
issn = {1530-888X},
journal = {Neural computation},
month = {apr},
pages = {1807--1852},
pmid = {23607554},
title = {{The Role of Extracellular Conductivity Profiles in Compartmental Models for Neurons: Particulars for Layer 5 Pyramidal Cells.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23607554},
volume = {5},
year = {2013}
}
@article{McAlpine2003,
author = {McAlpine, David and Grothe, Benedikt},
doi = {10.1016/S0166-2236(03)00140-1},
issn = {01662236},
journal = {Trends in Neurosciences},
month = {jul},
number = {7},
pages = {347--350},
title = {{Sound localization and delay lines do mammals fit the model?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166223603001401},
volume = {26},
year = {2003}
}
@article{Statistics2013,
author = {Harris, TE},
journal = {The Annals of Probability},
number = {6},
pages = {969--988},
title = {{Contact interactions on a lattice}},
url = {http://www.jstor.org/stable/10.2307/2959099},
volume = {2},
year = {1974}
}
@article{Schreiber2002,
abstract = {We investigate the energy efficiency of signaling mechanisms that transfer information by means of discrete stochastic events, such as the opening or closing of an ion channel. Using a simple model for the generation of graded electrical signals by sodium and potassium channels, we find optimum numbers of channels that maximize energy efficiency. The optima depend on several factors: the relative magnitudes of the signaling cost (current flow through channels), the fixed cost of maintaining the system, the reliability of the input, additional sources of noise, and the relative costs of upstream and downstream mechanisms. We also analyze how the statistics of input signals influence energy efficiency. We find that energy-efficient signal ensembles favor a bimodal distribution of channel activations and contain only a very small fraction of large inputs when energy is scarce. We conclude that when energy use is a significant constraint, trade-offs between information transfer and energy can strongly influence the number of signaling molecules and synapses used by neurons and the manner in which these mechanisms represent information.},
annote = {2010IIInum33},
author = {Schreiber, S and Machens, C.K. and Herz, Andreas V M and Laughlin, S B},
doi = {10.1162/089976602753712963},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Animals,Artifacts,Energy Metabolism,Humans,Models, Neurological,Neurons,Neurons: physiology,Potassium Channels,Potassium Channels: physiology,Signal Transduction,Signal Transduction: physiology,Sodium Channels,Sodium Channels: physiology,Stochastic Processes},
month = {jun},
number = {6},
pages = {1323--46},
pmid = {12020449},
title = {{Energy-efficient coding with discrete stochastic events.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12020449},
volume = {14},
year = {2002}
}
@article{Rabinovich2008,
author = {Rabinovich, Misha and Huerta, Ramon and Laurent, Gilles},
doi = {10.1126/science.1155564},
issn = {1095-9203},
journal = {Science},
keywords = {Animals,Cognition,Grasshoppers,Grasshoppers: physiology,Mathematics,Models,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Odors,Perception,Zebrafish,Zebrafish: physiology,networks},
mendeley-tags = {networks},
month = {jul},
number = {5885},
pages = {48},
pmid = {18599763},
publisher = {American Association for the Advancement of Science},
title = {{Transient dynamics for neural processing}},
url = {http://www.sciencemag.org/content/321/5885/48.short http://www.ncbi.nlm.nih.gov/pubmed/18599763},
volume = {321},
year = {2008}
}
@article{Seide2014,
abstract = {We show empirically that in SGD training of deep neural networks, one can, at no or nearly no loss of accuracy, quantize the gradients aggressively-to but one bit per value-if the quantization error is carried forward across minibatches (error feedback). This size reduction makes it feasible to parallelize SGD through data-parallelism with fast processors like recent GPUs. We implement data-parallel deterministically distributed SGD by combining this finding with AdaGrad, automatic minibatch-size selection, double buffering, and model parallelism. Unexpectedly, quantization benefits AdaGrad, giving a small accuracy gain. For a typical Switchboard DNN with 46M parameters, we reach computation speeds of 27k frames per second (kfps) when using 2880 samples per minibatch, and 51kfps with 16k, on a server with 8 K20X GPUs. This corresponds to speed-ups over a single GPU of 3.6 and 6.3, respectively. 7 training passes over 309h of data complete in under 7h. A 160M-parameter model training processes 3300h of data in under 16h on 20 dual-GPU servers-a 10 times speed-up-albeit at a small accuracy loss.},
author = {Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {[Electronic Manuscript]},
number = {September},
pages = {1058--1062},
title = {{1-bit stochastic gradient descent and its application to data-parallel distributed training of speech DNNs}},
year = {2014}
}
@article{Vit67,
author = {Viterbi, A},
journal = {IEEE Trans. Informat. Theory},
pages = {260--269},
title = {{Error bounds for convolutional codes and an asymptotically optimal decoding algorithm}},
volume = {IT-13},
year = {1967}
}
@article{Fink2009,
abstract = {Markov models (MMs) represent a generalization of Hodgkin-Huxley models. They provide a versatile structure for modelling single channel data, gating currents, state-dependent drug interaction data, exchanger and pump dynamics, etc. This paper uses examples from cardiac electrophysiology to discuss aspects related to parameter estimation. (i) Parameter unidentifiability (found in 9 out of 13 of the considered models) results in an inability to determine the correct layout of a model, contradicting the idea that model structure and parameters provide insights into underlying molecular processes. (ii) The information content of experimental voltage step clamp data is discussed, and a short but sufficient protocol for parameter estimation is presented. (iii) MMs have been associated with high computational cost (owing to their large number of state variables), presenting an obstacle for multicellular whole organ simulations as well as parameter estimation. It is shown that the stiffness of models increases computation time more than the number of states. (iv) Algorithms and software programs are provided for steady-state analysis, analytical solutions for voltage steps and numerical derivation of parameter identifiability. The results provide a new standard for ion channel modelling to further the automation of model development, the validation process and the predictive power of these models.},
annote = {2010num3.7},
author = {Fink, Martin and Noble, Denis},
doi = {10.1098/rsta.2008.0301},
issn = {1364-503X},
journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
keywords = {Algorithms,Biological,Ion Channels,Ion Channels: physiology,Markov Chains,Models},
month = {jun},
number = {1896},
pages = {2161--79},
pmid = {19414451},
title = {{Markov models for ion channels: versatility versus identifiability and speed.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19414451},
volume = {367},
year = {2009}
}
@article{SmithLewicki05,
author = {Smith, Evan and Lewicki, Michael S},
journal = {Neural Computation},
month = {jan},
number = {1},
pages = {19--45},
title = {{Efficient coding of time-relative structure using spikes}},
volume = {17},
year = {2005}
}
@article{Lund88,
author = {Lund, J},
journal = {Ann Rev Neurosci},
pages = {253--288},
title = {{Anatomical organization of macaque monkey striate visual cortex}},
volume = {11},
year = {2988}
}
@article{Soudry2012b,
abstract = {In recent experiments, synaptically isolated neurons from rat cortical culture, were stimulated with periodic extracellular fixed-amplitude current pulses for extended durations of days. The neuron's response depended on its own history, as well as on the history of the input, and was classified into several modes. Interestingly, in one of the modes the neuron behaved intermittently, exhibiting irregular firing patterns changing in a complex and variable manner over the entire range of experimental timescales, from seconds to days. With the aim of developing a minimal biophysical explanation for these results, we propose a general scheme, that, given a few assumptions (mainly, a timescale separation in kinetics) closely describes the response of deterministic conductance-based neuron models under pulse stimulation, using a discrete time piecewise linear mapping, which is amenable to detailed mathematical analysis. Using this method we reproduce the basic modes exhibited by the neuron experimentally, as well as the mean response in each mode. Specifically, we derive precise closed-form input-output expressions for the transient timescale and firing rates, which are expressed in terms of experimentally measurable variables, and conform with the experimental results. However, the mathematical analysis shows that the resulting firing patterns in these deterministic models are always regular and repeatable (i.e., no chaos), in contrast to the irregular and variable behavior displayed by the neuron in certain regimes. This fact, and the sensitive near-threshold dynamics of the model, indicate that intrinsic ion channel noise has a significant impact on the neuronal response, and may help reproduce the experimentally observed variability, as we also demonstrate numerically. In a companion paper, we extend our analysis to stochastic conductance-based models, and show how these can be used to reproduce the details of the observed irregular and variable neuronal response.},
author = {Soudry, D. and Meir, R.},
doi = {10.3389/fncom.2012.00004},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {adaptation,chaos,discrete maps,ion channels,neuron,nois,noise,pulse stimulation,slow inactivation},
number = {4},
pmid = {22355288},
title = {{Conductance-based neuron models and the slow dynamics of excitability}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3280430{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2012}
}
@article{Alamino2007,
author = {de Oliveira, EA and Alamino, RC},
journal = {Neural Networks, IEEE {\ldots}},
number = {3},
pages = {902--905},
title = {{Performance of the Bayesian online algorithm for the perceptron}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4182376},
volume = {18},
year = {2007}
}
@article{Stroud2001,
author = {Stroud, Jonathan R and Muller, Peter and Sanso, Bruno},
journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
pages = {pp. 673--689},
title = {{Dynamic Models for Spatiotemporal Data}},
volume = {63},
year = {2001}
}
@book{BELL57,
author = {Bellman, R},
publisher = {Princeton University Press},
title = {{Dynamic Programming}},
year = {1957}
}
@article{Knott|2006|,
author = {Knott, G W and Holtmaat, A and Wilbrecht, L and Welker, E and Svoboda, K},
journal = {Nat Neurosci},
keywords = {Age Factors Animals Dendritic Spines/*physiology/u,Anatomic Models,Electron Models,Neurological Neocortex/*physiology Synapses/*phys},
number = {9},
pages = {1117--1124},
title = {{Spine growth precedes synapse formation in the adult neocortex in vivo}},
volume = {9}
}
@article{Chen,
author = {Chen, M and Weinberger, KQ and Xu, ZE and Sha‏, F},
file = {::},
journal = {cse.wustl.edu‏},
title = {{Marginalizing Stacked Linear Denoising Autoencoders‏}},
url = {http://www.cse.wustl.edu/{~}kilian/papers/msdaJMLR.pdf}
}
@article{Santhanam06,
author = {Santhanam, Gopal and Ryu, Stephen I and Yu, Byron M and Afshar, Afsheen and Shenoy, Krishna V},
journal = {Nature},
pages = {195--198},
title = {{A high-performance brain-computer interface}},
volume = {442},
year = {2006}
}
@article{DAN02,
author = {Touryan, J and Lau, B and Dan, Y},
journal = {Journal of Neuroscience},
pages = {10811--10818},
title = {{Isolation of Relevant Visual Features from Random Stimuli for Cortical Complex Cells}},
volume = {22},
year = {2002}
}
@article{Tao2006,
abstract = {This papers contains two results concerning random {\$}n \backslashtimes n{\$} Bernoulli matrices. First, we show that with probability tending to one the determinant has absolute value {\$}\backslashsqrt {\{}n!{\}} \backslashexp(O(\backslashsqrt(n log n))){\$}. Next, we prove a new upper bound {\$}.939{\^{}}n{\$} on the probability that the matrix is singular. We also give some generalizations to other random matrix models.},
archivePrefix = {arXiv},
arxivId = {math/0411095},
author = {Tao, Terence and Vu, Van},
doi = {10.1002/rsa.20109},
eprint = {0411095},
isbn = {1581139608},
issn = {10429832},
journal = {Random Structures and Algorithms},
number = {1},
pages = {1--23},
primaryClass = {math},
title = {{On random ± 1 matrices: Singularity and determinant}},
volume = {28},
year = {2006}
}
@article{Singh2014,
author = {Singh, Komal and Sahu, C and Singh, J},
isbn = {9781479939466},
journal = {Quality Electronic Design (ISQED), {\ldots}},
title = {{Linearly separable pattern classification using memristive crossbar circuits}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6783343},
year = {2014}
}
@article{ALOPEX79,
author = {Tzanakou, E and Michalak, R and Harth, E},
journal = {Biological Cybernetics},
pages = {161--174},
title = {{The Alopex Process: Visual Receptive Fields by Response Feedback}},
volume = {35},
year = {1979}
}
@article{London2010,
abstract = {It is well known that neural activity exhibits variability, in the sense that identical sensory stimuli produce different responses, but it has been difficult to determine what this variability means. Is it noise, or does it carry important information-about, for example, the internal state of the organism? Here we address this issue from the bottom up, by asking whether small perturbations to activity in cortical networks are amplified. Based on in vivo whole-cell patch-clamp recordings in rat barrel cortex, we find that a perturbation consisting of a single extra spike in one neuron produces approximately 28 additional spikes in its postsynaptic targets. We also show, using simultaneous intra- and extracellular recordings, that a single spike in a neuron produces a detectable increase in firing rate in the local network. Theoretical analysis indicates that this amplification leads to intrinsic, stimulus-independent variations in membrane potential of the order of +/-2.2-4.5 mV-variations that are pure noise, and so carry no information at all. Therefore, for the brain to perform reliable computations, it must either use a rate code, or generate very large, fast depolarizing events, such as those proposed by the theory of synfire chains. However, in our in vivo recordings, we found that such events were very rare. Our findings are thus consistent with the idea that cortex is likely to use primarily a rate code.},
annote = {

2010IInum12.47

See also supplementary information},
author = {London, Michael and Roth, Arnd and Beeren, Lisa and H{\"{a}}usser, Michael and Latham, Peter E and Ha, Michael},
doi = {10.1038/nature09086},
issn = {0028-0836},
journal = {Nature},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Artifacts,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Models,Neurological,Neuron Model,Neurons,Neurons: metabolism,Patch-Clamp Techniques,Probability,Rats,Sprague-Dawley,Stochastic Processes},
mendeley-tags = {Neuron Model},
month = {jul},
number = {7302},
pages = {123--127},
pmid = {20596024},
title = {{Sensitivity to perturbations in vivo implies high noise and suggests rate coding in cortex}},
url = {http://www.nature.com/doifinder/10.1038/nature09086 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2898896{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {466},
year = {2010}
}
@article{AG00,
author = {Amirikian, B and Georgopoulos, A},
journal = {Neuroscience Research},
pages = {73--79},
title = {{Directional tuning profiles of motor cortical cells}},
volume = {36},
year = {2000}
}
@article{BUR98,
author = {Buracas, G and Zador, A and DeWeese, M and Albright, T},
journal = {Neuron},
pages = {959--969},
title = {{Efficient discrimination of temporal patterns by motion-sensitive neurons in primate visual cortex}},
volume = {5},
year = {1998}
}
@article{HancockDavisVoigt97,
author = {Hancock, K E and Davis, K A and Voigt, H F},
journal = {Biological Cybernetics},
month = {jun},
number = {6},
pages = {419--428},
title = {{Modeling inhibition of type II units in the dorsal cochlear nucleus}},
volume = {76},
year = {1997}
}
@article{Djurisic04,
abstract = {To obtain a more complete description of individual neurons, it is
necessary to complement the electrical patch pipette measurements
with technologies that permit a massive parallel recording from many
sites on neuronal processes. This can be achieved by using voltage
imaging with intracellular dyes. With this approach, we investigated
the functional structure of a mitral cell, the principal output neuron
in the rat olfactory bulb. The most significant finding concerns
the characteristics of EPSPs at the synaptic sites and surprisingly
small attenuation along the trunk of the primary dendrite. Also,
the experiments were performed to determine the number, location,
and stability of spike trigger zones, the excitability of terminal
dendritic branches, and the pattern and nature of spike initiation
and propagation in the primary and secondary dendrites. The results
show that optical data can be used to deduce the amplitude and shape
of the EPSPs evoked by olfactory nerve stimulation at the site of
origin (glomerular tuft) and to determine its attenuation along the
entire length of the primary dendrite. This attenuation corresponds
to an unusually large mean apparent "length constant" of the primary
dendrite. Furthermore, the images of spike trigger zones showed that
an action potential can be initiated in three different compartments
of the mitral cell: the soma-axon region, the primary dendrite trunk,
and the terminal dendritic tuft, which appears to be fully excitable.
Finally, secondary dendrites clearly support the active propagation
of action potentials.},
author = {Djurisic, Maja and Antic, Srdjan and Chen, Wei R and Zecevic, Dejan},
doi = {10.1523/JNEUROSCI.0307-04.2004},
journal = {J. Neurosci.},
number = {30},
pages = {6703--6714},
title = {{Voltage Imaging from Dendrites of Mitral Cells: {\{}EPSP{\}} Attenuation and Spike Trigger Zones}},
url = {http://www.jneurosci.org/cgi/content/abstract/24/30/6703},
volume = {24},
year = {2004}
}
@article{Wang2003a,
author = {Wang, D and Chaudhari, NS},
journal = {International Journal of Neural Systems},
keywords = {binary neural networks,bnn,boolean functions,etl,expand and truncate learning,linear sequential learning,linearly separable functions,mlp,multi-layer perception},
number = {5},
pages = {333--351},
title = {{Binary neural network training algorithms based on linear sequential learning}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0129065703001613},
volume = {13},
year = {2003}
}
@article{Parikh2013,
author = {Parikh, Neal and Boyd, Stephen},
journal = {Foundations and Trends in Optimization},
number = {3},
pages = {123--231},
title = {{Proximal algorithms}},
url = {http://www.stanford.edu/{~}boyd/papers/pdf/prox{\_}algs.pdf},
volume = {1},
year = {2013}
}
@article{Zhang2012,
author = {Zhang, Bai and Miller, David J and Wang, Yue},
journal = {IEEE Transactions on Neural Networks},
keywords = {Reservoir Computing},
mendeley-tags = {Reservoir Computing},
number = {1},
pages = {175--182},
title = {{Nonlinear System Modeling with Random Matrices :}},
volume = {23},
year = {2012}
}
@article{PAN05,
author = {Paninski, L},
journal = {Advances in Neural Information Processing Systems},
title = {{Log-concavity results on {\{}G{\}}aussian process methods for supervised and unsupervised learning}},
volume = {17},
year = {2005}
}
@article{Gerhard2011a,
abstract = {Statistical models of neural activity are integral to modern neuroscience. Recently interest has grown in modeling the spiking activity of populations of simultaneously recorded neurons to study the effects of correlations and functional connectivity on neural information processing. However, any statistical model must be validated by an appropriate goodness-of-fit test. Kolmogorov-Smirnov tests based on the time-rescaling theorem have proven to be useful for evaluating point-process-based statistical models of single-neuron spike trains. Here we discuss the extension of the time-rescaling theorem to the multivariate (neural population) case. We show that even in the presence of strong correlations between spike trains, models that neglect couplings between neurons can be erroneously passed by the univariate time-rescaling test. We present the multivariate version of the time-rescaling theorem and provide a practical step-by-step procedure for applying it to testing the sufficiency of neural population models. Using several simple analytically tractable models and more complex simulated and real data sets, we demonstrate that important features of the population activity can be detected only using the multivariate extension of the test.},
author = {Gerhard, F and Haslinger, Robert and Pipa, Gordon},
doi = {10.1162/NECO_a_00126},
issn = {1530-888X},
journal = {Neural Computation},
keywords = {networks},
mendeley-tags = {networks},
month = {jun},
number = {6},
pages = {1452--83},
pmid = {21395436},
title = {{Applying the multivariate time-rescaling theorem to neural population models.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3090500{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {23},
year = {2011}
}
@book{DA01,
author = {Dayan, P and Abbott, L F},
publisher = {MIT Press},
title = {{Theoretical Neuroscience}},
year = {2001}
}
@article{Feizi2013,
abstract = {Recognizing direct relationships between variables connected in a network is a pervasive problem in biological, social and information sciences as correlation-based networks contain numerous indirect relationships. Here we present a general method for inferring direct effects from an observed correlation matrix containing both direct and indirect effects. We formulate the problem as the inverse of network convolution, and introduce an algorithm that removes the combined effect of all indirect paths of arbitrary length in a closed-form solution by exploiting eigen-decomposition and infinite-series sums. We demonstrate the effectiveness of our approach in several network applications: distinguishing direct targets in gene expression regulatory networks; recognizing directly interacting amino-acid residues for protein structure prediction from sequence alignments; and distinguishing strong collaborations in co-authorship social networks using connectivity information alone. In addition to its theoretical impact as a foundational graph theoretic tool, our results suggest network deconvolution is widely applicable for computing direct dependencies in network science across diverse disciplines.},
author = {Feizi, Soheil and Marbach, Daniel and M{\'{e}}dard, Muriel and Kellis, Manolis},
doi = {10.1038/nbt.2635},
issn = {1546-1696},
journal = {Nature biotechnology},
month = {jul},
number = {8},
pmid = {23851448},
title = {{Network deconvolution as a general method to distinguish direct dependencies in networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23851448},
volume = {31},
year = {2013}
}
@incollection{multisvm03,
author = {Sha, Fei and Saul, Lawrence and Lee, Daniel},
booktitle = {Advances in Neural Information Processing Systems 15},
pages = {1041--1048},
publisher = {MIT Press},
title = {{Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines}},
year = {2003}
}
@book{Antoulas05,
author = {Antoulas, A},
publisher = {Cambridge University Press},
title = {{Approximation of large-scale dynamical systems}},
year = {2005}
}
@article{BKW05,
author = {Behseta, S and Kass, R and Wallstrom, G},
journal = {Biometrika},
pages = {419--434},
title = {{Hierarchical models for assessing variability among functions}},
volume = {92},
year = {2005}
}
@book{Izhikevich2007,
address = {MA, Cambridge},
author = {Izhikevich, EM M},
booktitle = {Dynamical Systems},
isbn = {9780262090438},
publisher = {MIT Press},
title = {{Dynamical Systems in Neuroscience}},
url = {http://mitpress.mit.edu/9780262090438 http://books.google.com/books?hl=en{\&}lr={\&}id=kVjM6DFk-twC{\&}oi=fnd{\&}pg=PR15{\&}dq=Dynamical+Systems+in+Neuroscience{\&}ots=KTyujXi9vh{\&}sig=4Kj-VchMjxUtRu7QC7oYQKSXvcE},
year = {2007}
}
@article{Harris|2007|,
author = {Harris, K M and Bourne, J and Mendenhall, J and Spacek, J},
journal = {Soc Neurosci Abstracts},
title = {{Hippocampal CA1 dendrites of greater caliber have more spines and contain more microtubules as a subcellular supply route.}}
}
@inproceedings{Kavehei2011,
address = {Adelaide},
author = {Kavehei, Omid and Al-Sarawi, Said and Cho, Kyoung-Rok and Iannella, Nicolangelo and Kim, Sung-Jin and Eshraghian, Kamran and Abbott, Derek},
booktitle = {2011 Seventh International Conference on Intelligent Sensors, Sensor Networks and Information Processing},
doi = {10.1109/ISSNIP.2011.6146610},
isbn = {978-1-4577-0674-5},
month = {dec},
pages = {137--142},
publisher = {Ieee},
title = {{Memristor-based synaptic networks and logical operations using in-situ computing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6146610},
year = {2011}
}
@article{shahaf2008order,
annote = {2008num8},
author = {Shahaf, G and Eytan, D and Gal, A and Kermany, E and Lyakhov, V and Zrenner, C and Marom, S},
journal = {PLoS Computational Biology},
number = {11},
publisher = {Public Library of Science},
title = {{Order-based representation in random networks of cortical neurons}},
volume = {4},
year = {2008}
}
@article{Olshausen,
author = {Olshausen, B A},
journal = {redwood.berkeley.edu},
title = {{20 years of learning about vision: Questions answered, questions unanswered, and questions not yet asked}},
url = {http://redwood.berkeley.edu/bruno/papers/CNS2010-chapter.pdf}
}
@article{Campero2011,
abstract = {It has been previously shown that unmyelinated afferent fibres in human skin are differentiated not only by their receptor characteristics, but also by their profiles of activity-dependent slowing. One type of profile, described originally as 'type 3', is different from that of nociceptors (type 1), cold afferents (type 2) and sympathetic efferents (type 4), in that these fibres display a minimal activity-dependent slowing (∼1{\%} at 2 Hz). However, their function remains to be determined. Here we describe one unit with a typical 'type 3' activity-dependent slowing profile recorded from an undamaged fascicle of the superficial peroneal nerve of a patient. Its conduction velocity was 1.8 m s(-1) and it slowed by 1.3{\%} during the 2 Hz tetanus. This unit had a mechanical receptive field in the hairy skin and responded readily to weak mechanical stimuli, and not to cold. This suggests that the low threshold unmyelinated mechanoreceptors recently described in human hairy skin are probably endowed with a 'type 3' activity-dependent profile.},
author = {Campero, Mario and Bostock, Hugh and Baumann, Thomas K and Ochoa, Jos{\'{e}} L},
doi = {10.1016/j.neulet.2011.02.012},
issn = {1872-7972},
journal = {Neuroscience letters},
keywords = {Action Potentials,Action Potentials: physiology,Female,Hair Follicle,Hair Follicle: physiology,Humans,Mechanoreceptors,Mechanoreceptors: physiology,Middle Aged,Mononeuropathies,Mononeuropathies: physiopathology,Nerve Fibers,Neural Conduction,Neural Conduction: physiology,Peroneal Nerve,Peroneal Nerve: physiology,Unmyelinated,Unmyelinated: physiology},
month = {apr},
number = {3},
pages = {92--96},
pmid = {21335061},
publisher = {Elsevier Ireland Ltd},
title = {{Activity-dependent slowing properties of an unmyelinated low threshold mechanoreceptor in human hairy skin.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21335061},
volume = {493},
year = {2011}
}
@article{Gustafsson|2005|,
author = {Gustafsson, M G L},
journal = {PNAS},
number = {102},
pages = {13081},
title = {{Nonlinear structured-illumination microscopy: wide-field fluorescence imaging with theoretically unlimited resolution.}}
}
@article{Rybicki91,
author = {Rybicki, G and Hummer, D},
journal = {Astronomy and Astrophysics},
pages = {171},
title = {{An Accelerated Lambda Iteration Method for Multilevel Radiative Transfer, appendix B: Fast Solution for the Diagonal Elements of the Inverse of a Tridiagonal Matrix}},
volume = {245},
year = {1991}
}
@article{Gazzaniga2010,
annote = {2010IIInum28},
author = {Gazzaniga, Michael S},
doi = {10.1016/j.tics.2010.04.005},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
month = {may},
pages = {291--292},
pmid = {20547092},
title = {{Neuroscience and the correct level of explanation for understanding mind An extraterrestrial roams through some neuroscience laboratories and concludes earthlings are not grasping how best to understand the mind-brain interface.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20547092},
volume = {14},
year = {2010}
}
@article{Olshausen2004,
abstract = {Several theoretical, computational, and experimental studies suggest that neurons encode sensory information using a small number of active neurons at any given point in time. This strategy, referred to as 'sparse coding', could possibly confer several advantages. First, it allows for increased storage capacity in associative memories; second, it makes the structure in natural signals explicit; third, it represents complex data in a way that is easier to read out at subsequent levels of processing; and fourth, it saves energy. Recent physiological recordings from sensory neurons have indicated that sparse coding could be a ubiquitous strategy employed in several different modalities across different organisms.},
author = {Olshausen, Bruno a and Field, David J},
doi = {10.1016/j.conb.2004.07.007},
issn = {0959-4388},
journal = {Current Opinion in Neurobiology},
keywords = {Action Potentials,Action Potentials: physiology,Afferent,Afferent Pathways,Afferent Pathways: physiology,Afferent: physiology,Animals,Brain,Brain: cytology,Brain: physiology,Humans,Models,Neurological,Neurons,Sensation,Sensation: physiology,Signal Transduction,Signal Transduction: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
month = {aug},
number = {4},
pages = {481--7},
pmid = {15321069},
title = {{Sparse coding of sensory inputs.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15321069},
volume = {14},
year = {2004}
}
@article{Fu2008,
author = {Fu, Z and Culurciello, E and Lichtsteiner, P and Delbruck, T},
isbn = {9781424416844},
journal = {IEEE Circuits and Systems},
keywords = {AER,Address-event,CMOS image sensor,assisted living,elderly home care,fall detection,motion detection,temporal-difference,vision sensor.},
pages = {424--427},
title = {{Fall Detection using an Address-Event Temporal Contrast Vision Sensor}},
year = {2008}
}
@article{Genz1992,
author = {Genz, Alan},
journal = {Journal of computational and graphical statistics},
keywords = {adaptive integration,monte-carlo,multivariate normal distribution},
pages = {1--7},
title = {{Numerical computation of multivariate normal probabilities}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.1992.10477010},
volume = {1},
year = {1992}
}
@article{Macke2011,
author = {Macke, J.H. and Cunningham, J.P. and Byron, M.Y. and Shenoy, K.V. and Sahani, M.},
journal = {NIPS},
keywords = {Network modeling},
mendeley-tags = {Network modeling},
pages = {1--9},
publisher = {Curran Associates, Inc.},
title = {{Empirical models of spiking in neural populations}},
url = {http://www.gatsby.ucl.ac.uk/{~}maneesh/papers/macke-etal-2011-nips-preprint.pdf},
year = {2011}
}
@article{SH96,
author = {Simoncelli, E P and Heeger, D J},
journal = {Vision Research},
month = {mar},
number = {5},
pages = {743--761},
title = {{A Model of neuronal responses in visual area {\{}MT{\}}}},
volume = {38},
year = {1998}
}
@article{Peterlin00,
author = {Peterlin, Z A and Kozloski, J and Mao, B and Tsiola, A and Yuste, R},
journal = {Proc. Natl. Acad. Sci. USA},
number = {7},
pages = {3619--3624},
title = {{Optical probing of neuronal circuits with calcium indicators.}},
volume = {97},
year = {2000}
}
@article{KAK99,
author = {Kakei, S and Hoffman, D and Strick, P},
journal = {Science},
pages = {2136--2139},
title = {{Muscle and movement representations in the primary motor cortex}},
volume = {285},
year = {1999}
}
@article{Zucker2002a,
abstract = {Synaptic transmission is a dynamic process. Postsynaptic responses wax and wane as presynaptic activity evolves. This prominent characteristic of chemical synaptic transmission is a crucial determinant of the response properties of synapses and, in turn, of the stimulus properties selected by neural networks and of the patterns of activity generated by those networks. This review focuses on synaptic changes that result from prior activity in the synapse under study, and is restricted to short-term effects that last for at most a few minutes. Forms of synaptic enhancement, such as facilitation, augmentation, and post-tetanic potentiation, are usually attributed to effects of a residual elevation in presynaptic [Ca(2+)]i, acting on one or more molecular targets that appear to be distinct from the secretory trigger responsible for fast exocytosis and phasic release of transmitter to single action potentials. We discuss the evidence for this hypothesis, and the origins of the different kinetic phases of synaptic enhancement, as well as the interpretation of statistical changes in transmitter release and roles played by other factors such as alterations in presynaptic Ca(2+) influx or postsynaptic levels of [Ca(2+)]i. Synaptic depression dominates enhancement at many synapses. Depression is usually attributed to depletion of some pool of readily releasable vesicles, and various forms of the depletion model are discussed. Depression can also arise from feedback activation of presynaptic receptors and from postsynaptic processes such as receptor desensitization. In addition, glial-neuronal interactions can contribute to short-term synaptic plasticity. Finally, we summarize the recent literature on putative molecular players in synaptic plasticity and the effects of genetic manipulations and other modulatory influences.},
annote = {2010num5.5},
author = {Zucker, RS S and Regehr, WG G},
doi = {10.1146/annurev.physiol.64.092501.114547},
issn = {0066-4278},
journal = {Annual Review of Physiology},
keywords = {Animals,Calcium: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Synapses,Synapses: physiology,augmentation,calcium,chemi-,depression,facilitation,is a dynamic process,post-tetanic potentiation,postsynaptic responses,presynaptic activity evolves,s abstract synaptic transmission,synapse,this prominent characteristic of,wax and wane as},
mendeley-tags = {synapse},
pages = {355--405},
pmid = {11826273},
title = {{Short-term synaptic plasticity}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.physiol.64.092501.114547 http://www.ncbi.nlm.nih.gov/pubmed/11826273},
volume = {64},
year = {2002}
}
@article{Pnevmatikakis2012a,
author = {Pnevmatikakis, E A and Rad, Kamiar Rahnama and Huggins, Jonathan and Paninski, L},
keywords = {Estimation,covariance approximation,fast algorithm,low rank methods,numerical analysis},
mendeley-tags = {Estimation},
title = {{Fast Kalman filtering and forward-backward smoothing via a low-rank perturbative approach}},
year = {2012}
}
@article{Wood06,
author = {Wood, Simon N},
journal = {Biometrics},
pages = {1025--1036},
title = {{Low-rank scale-invariant tensor product smooths for generalized additive mixed models.}},
volume = {62},
year = {2006}
}
@article{GrinvaldFarber81,
author = {Grinvald, Amiram and Farber, Ira C},
journal = {Science},
pages = {1164--1167},
title = {{Optical recording of calcium action potentials from growth cones of cultured neurons with a laser microbeam}},
volume = {212},
year = {1981}
}
@article{DR72,
author = {Darroch, J and Ratcliff, D},
journal = {Annals of Mathematical Statistics},
pages = {1470--1480},
title = {{Generalized iterative scaling for log-linear models}},
volume = {43},
year = {1972}
}
@article{Kuhn2008,
author = {K{\"{u}}hn, R.},
journal = {Journal of Physics A: Mathematical and Theoretical},
keywords = {Reservoir Computing},
mendeley-tags = {Reservoir Computing},
pages = {295002},
publisher = {IOP Publishing},
title = {{Spectra of sparse random matrices}},
url = {http://iopscience.iop.org/1751-8121/41/29/295002},
volume = {41},
year = {2008}
}
@book{Stirzaker2001,
author = {Stirzaker, D and Grimmett, D},
edition = {3rd},
publisher = {Oxford},
title = {{Probability and random processes}},
year = {2001}
}
@article{Elston|2003|,
author = {Elston, G N},
journal = {Cereb Cortex},
keywords = {Animals Cognition/*physiology Humans Nerve Net/cyt},
number = {11},
pages = {1124--1138},
title = {{Cortex, cognition and the cell: new insights into the pyramidal neuron and prefrontal function}},
volume = {13}
}
@phdthesis{CSAPHD,
author = {Csato, L},
school = {Aston U.},
title = {{Gaussian Processes - Iterative sparse approximations}},
year = {2002}
}
@article{Lu2009,
annote = {2010num1.11},
author = {Lu, W and Vaswani, N},
journal = {Arxiv preprint arXiv:0904.0602},
title = {{The Wiener-Khinchin Theorem for Non-wide Sense stationary Random  {\ldots}}},
url = {http://arxiv.org/pdf/0904.0602},
year = {2009}
}
@article{Mouttet2012a,
author = {Mouttet, Blaise},
keywords = {- scientific method,memristor,rram},
title = {{The memristor and the scientific method}},
url = {http://vixra.org/abs/1205.0004},
year = {2012}
}
@article{Lewi07,
author = {Lewi, J and Butera, R and Paninski, L},
journal = {AISTATS07},
title = {{Efficient active learning with generalized linear models}},
year = {2007}
}
@article{GRA88,
author = {Grassberger, P},
journal = {Physics Letters A},
pages = {369--373},
title = {{Finite sample corrections to entropy and dimension estimates}},
volume = {128},
year = {1988}
}
@article{Friedrich2016,
abstract = {Progress in modern neuroscience critically depends on our ability to observe the activity of large neuronal populations with cellular spatial and high temporal resolution. However, two bottlenecks constrain efforts towards fast imaging of large populations. First, the resulting large video data is challenging to analyze. Second, there is an explicit tradeoff between imaging speed, signal-to-noise, and field of view: with current recording technology we cannot image very large neuronal populations with simultaneously high spatial and temporal resolution. Here we describe multi-scale approaches for alleviating both of these bottlenecks. First, we show that spatial and temporal decimation techniques provide order-of-magnitude speedups in spatiotemporally demixing calcium video data into estimates of single-cell neural activity. Second, once the shapes of individual neurons have been identified (e.g., after an initial phase of conventional imaging with standard temporal and spatial resolution), we find that the spatial/temporal resolution tradeoff shifts dramatically: after demixing we can accurately recover neural activity from data that has been spatially decimated by an order of magnitude. This offers a cheap method for compressing this large video data, and also implies that it is possible to either speed up imaging significantly, or to "zoom out" by a corresponding factor to image order-of-magnitude larger neuronal populations with minimal loss in accuracy or temporal resolution.{\%}U http://biorxiv.org/content/biorxiv/early/2016/12/02/091132.full.pdf},
author = {Friedrich, Johannes and Yang, Weijian and Soudry, Daniel and Mu, Yu and Ahrens, Misha B and Yuste, Rafael and Peterka, Darcy S. and Paninski, Liam},
doi = {10.1101/091132},
journal = {Accepted to PLOS Comp. Biol.},
pages = {1--21},
title = {{Multi-scale approaches for high-speed imaging and analysis of large neural populations}},
year = {2016}
}
@article{Juan2010,
annote = {2011num54},
author = {Juan, M and Yu-Ye, L and Chun-Ling, W and Ming-Hao, Y and Hua-Guang, G and Shi-Xian, Q and Wei, R},
journal = {Chinese Physics B},
keywords = {border-collision bifurcation,discontinuous maps,neural,period-adding bifurcation},
pages = {080513},
publisher = {IOP Publishing},
title = {{Interpreting a period-adding bifurcation scenario in neural bursting patterns using border-collision bifurcation in a discontinuous map of a slow control variable}},
url = {http://iopscience.iop.org/1674-1056/19/8/080513},
volume = {19},
year = {2010}
}
@article{Larkum08,
abstract = {The six-layered mammalian neocortex evolved from the three-layered paleocortex, which is retained in present-day reptiles such as the turtle. Thus the turtle offers an opportunity to examine which cellular and circuit properties are fundamental to cortical function. We characterized the dendritic properties of pyramidal neurons in different cortical regions of mature turtles, Pseudemys scripta elegans, using whole cell recordings and calcium imaging from the axon, soma, and dendrites in a slice preparation. The firing properties, in response to intrasomatic depolarization, resembled those previously recorded with sharp electrodes in this preparation. Somatic spikes led to active backpropagating high-amplitude dendritic action potentials and intracellular calcium ion concentration ([Ca2+]i) changes at all dendritic locations, suggesting that both backpropagation and dendritic voltage-gated Ca2+ channels are primitive traits. We found no indication that Ca2+ spikes could be evoked in the dendrites, but fast Na+ spikes could be initiated there following intradendritic stimulation. Several lines of evidence indicate that fast, smaller-amplitude somatic spikes ("prepotentials") that are easily recorded in this preparation are generated in the axon. Most synaptically activated [Ca2+]i changes resulted from Ca2+ entry through voltage-gated channels. In some cells synaptic stimulation evoked a delayed Ca2+ wave due to release from internal stores following activation of metabotropic glutamate receptors. With some small differences these properties resemble those of pyramidal neurons in mammalian species. We conclude that spike backpropagation, dendritic Ca2+ channels, and synaptically activated Ca2+ release are primitive and conserved features of cortical pyramidal cells, and therefore likely fundamental to cortical function.
},
author = {Larkum, Matthew E and Watanabe, Shigeo and Lasser-Ross, Nechama and Rhodes, Paul and Ross, William N},
journal = {J Neurophysiol},
number = {2},
pages = {683--694},
title = {{Dendritic Properties of Turtle Pyramidal Neurons}},
volume = {99},
year = {2008}
}
@incollection{Bottou1998,
author = {Bottou, L},
booktitle = {On-line learning in neural networks},
isbn = {978-0521117913},
pages = {9--42},
title = {{Online learning and stochastic approximations}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=iu2v6C5nx4oC{\&}oi=fnd{\&}pg=PA9{\&}dq=Online+Learning+and+Stochastic+Approximations{\&}ots=oyFbNGmOOc{\&}sig=dMFIVHPeRai645DxGXT{\_}WIyydoA},
year = {1998}
}
@article{Chandler1970,
author = {Chandler, W K and Meves, H},
issn = {0022-3751},
journal = {The Journal of Physiology},
number = {3},
pages = {707--728},
publisher = {Physiological Soc},
title = {{Slow changes in membrane permeability and long-lasting action potentials in axons perfused with fluoride solutions}},
url = {http://jp.physoc.org/content/211/3/707.abstract},
volume = {211},
year = {1970}
}
@article{Cunningham2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1406.0873v1},
author = {Cunningham, JP and Ghahramani, Zoubin},
eprint = {arXiv:1406.0873v1},
journal = {arXiv preprint arXiv:1406.0873},
pages = {1--28},
title = {{Unifying linear dimensionality reduction}},
url = {http://arxiv.org/abs/1406.0873},
year = {2014}
}
@article{Brader2007,
abstract = {We present a model of spike-driven synaptic plasticity inspired by experimental observations and motivated by the desire to build an electronic hardware device that can learn to classify complex stimuli in a semisupervised fashion. During training, patterns of activity are sequentially imposed on the input neurons, and an additional instructor signal drives the output neurons toward the desired activity. The network is made of integrate-and-fire neurons with constant leak and a floor. The synapses are bistable, and they are modified by the arrival of presynaptic spikes. The sign of the change is determined by both the depolarization and the state of a variable that integrates the postsynaptic action potentials. Following the training phase, the instructor signal is removed, and the output neurons are driven purely by the activity of the input neurons weighted by the plastic synapses. In the absence of stimulation, the synapses preserve their internal state indefinitely. Memories are also very robust to the disruptive action of spontaneous activity. A network of 2000 input neurons is shown to be able to classify correctly a large number (thousands) of highly overlapping patterns (300 classes of preprocessed Latex characters, 30 patterns per class, and a subset of the NIST characters data set) and to generalize with performances that are better than or comparable to those of artificial neural networks. Finally we show that the synaptic dynamics is compatible with many of the experimental observations on the induction of long-term modifications (spike-timing-dependent plasticity and its dependence on both the postsynaptic depolarization and the frequency of pre- and postsynaptic neurons).},
author = {Brader, Joseph M and Senn, Walter and Fusi, Stefano},
doi = {10.1162/neco.2007.19.11.2881},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Calcium,Calcium: metabolism,Computer Simulation,Learning,Learning: physiology,Models, Neurological,Neural Networks (Computer),Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Nonlinear Dynamics,Probability,Synapses,Synaptic Transmission,Time Factors},
month = {nov},
number = {11},
pages = {2881--912},
pmid = {17883345},
title = {{Learning real-world stimuli in a neural network with spike-driven synaptic dynamics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17883345},
volume = {19},
year = {2007}
}
@misc{Barbour2007,
author = {Barbour, Boris and Brunel, Nicolas and Hakim, Vincent and Nadal, Jean-Pierre},
booktitle = {Trends in neurosciences},
isbn = {0166-2236},
month = {dec},
number = {12},
pages = {622--629},
publisher = {Elsevier Applied Science Publishing},
title = {{What can we learn from synaptic weight distributions?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166223607002615},
volume = {30},
year = {2007}
}
@techreport{Minka99,
author = {Minka, Thomas P},
institution = {Tech. Rep. 531, Vision and Modeling Group of Media Lab, MIT},
title = {{From hidden {\{}M{\}}arkov models to linear dynamical systems}},
year = {1999}
}
@article{Toderici2016,
abstract = {Although image compression has been actively studied for decades, there has been relatively little research on learning to compress images with modern neural networks. Standard approaches, such as those employing patch-based autoencoders, have shown a great deal of promise but cannot compete with popular image codecs because they fail to address three questions: 1) how to effectively binarize activations: in the absence of binarization, a bottleneck layer alone tends not to lead to efficient compression; 2) how to achieve variable-rate encoding: a standard autoencoder generates a fixed-length code for each fixed-resolution input patch, resulting in the same cost for low- and high-entropy patches, and requiring the network to be completely retrained to achieve different compression rates; and 3) how to avoid block artifacts: patch-based approaches are prone to block discontinuities. We propose a general framework for variable-rate image compression and a novel architecture based on convolutional and deconvolutional recurrent networks, including LSTMs, that address these issues and report promising results compared to existing baseline codecs. We evaluate the proposed methods on a large-scale benchmark consisting of tiny images (32{\$}\backslashtimes{\$}32), which proves to be very challenging for all the methods.},
archivePrefix = {arXiv},
arxivId = {1511.06085},
author = {Toderici, George and O'Malley, Sean M. and Hwang, Sung Jin and Vincent, Damien and Minnen, David and Baluja, Shumeet and Covell, Michele and Sukthankar, Rahul},
eprint = {1511.06085},
journal = {ICLR},
pages = {1--9},
title = {{Variable Rate Image Compression with Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1511.06085},
year = {2015}
}
@article{MullerConnor91,
abstract = {The possibility that postsynaptic spines on neuronal dendrites are

discrete biochemical compartments for {\{}Ca{\}}{\^{}}{\{}2+{\}}-activated processes

involved in synaptic plasticity is a widely proposed concept that

has eluded experimental demonstration. Using microfluorometry on

CA3 neurons in hippocampal slices, we show here that with weak presynaptic

stimulation of associative/commissural fibres, {\{}Ca{\}}{\^{}}{\{}2+{\}} accumulates

in single postsynaptic spines but not in the parent dendrite. Stronger

stimulation also promotes changes in dendrites. The NMDA-receptor

antagonist AP-5 blocks changes in {\{}Ca{\}}{\^{}}{\{}2+{\}} in spines. Sustained

steep {\{}Ca{\}}{\^{}}{\{}2+{\}} gradients between single spines and the parent

dendrite, often lasting several minutes, develop with repeated stimulation.

The observed compartmentalization allows for the specificity, cooperativity

and associativity displayed by memory models such as long-term potentiation.},
author = {M{\"{u}}ller, W and Connor, J A},
doi = {10.1038/354073a0},
journal = {Nature},
keywords = {2-Amino-5-phosphonovalerate; Animals; Calcium; Cyt},
month = {nov},
number = {6348},
pages = {73--76},
pmid = {1682815},
title = {{Dendritic spines as individual neuronal compartments for synaptic {\{}Ca{\}}{\^{}}{\{}2+{\}} responses.}},
url = {http://dx.doi.org/10.1038/354073a0},
volume = {354},
year = {1991}
}
@article{Karoui08,
author = {{El Karoui}, N},
journal = {Annals of Statistics},
pages = {2717--2756},
title = {{Operator norm consistent estimation of large-dimensional sparse covariance matrices}},
volume = {36},
year = {2008}
}
@article{Mathematics2010,
author = {Mathematics, Applied and Journal, Siam},
keywords = {60g60,62m15,ams,f noise,isotropic,kriging,l,mos,spectrum,subject classifications},
number = {1},
pages = {270--291},
title = {{No Title}},
volume = {52},
year = {2010}
}
@article{Pakman2012,
abstract = {We present fast methods for filtering voltage measurements and performing optimal inference of the location and strength of synaptic connections in large dendritic trees. Given noisy, subsampled voltage observations we develop fast l 1-penalized regression methods for Kalman state-space models of the neuron voltage dynamics. The value of the l 1-penalty parameter is chosen using cross-validation or, for low signal-to-noise ratio, a Mallows' C p -like criterion. Using low-rank approximations, we reduce the inference runtime from cubic to linear in the number of dendritic compartments. We also present an alternative, fully Bayesian approach to the inference problem using a spike-and-slab prior. We illustrate our results with simulations on toy and real neuronal geometries. We consider observation schemes that either scan the dendritic geometry uniformly or measure linear combinations of voltages across several locations with random coefficients. For the latter, we show how to choose the coefficients to offset the correlation between successive measurements imposed by the neuron dynamics. This results in a "compressed sensing" observation scheme, with an important reduction in the number of measurements required to infer the synaptic weights.},
author = {Pakman, A and Huggins, Jonathan and Smith, Carl and Paninski, L},
doi = {10.1007/s10827-013-0478-0},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Estimation},
mendeley-tags = {Estimation},
month = {sep},
number = {3},
pages = {415--443},
pmid = {24077932},
title = {{Fast penalized state-space methods for inferring dendritic synaptic connectivity}},
url = {http://stat.columbia.edu/{~}liam/research/pubs/pakman-huggins-synaptic.pdf http://www.ncbi.nlm.nih.gov/pubmed/24077932},
volume = {36},
year = {2014}
}
@article{Brownstone07,
author = {Wilson, Jennifer M and Dombeck, Daniel A and Diaz-Rios, Manuel and Harris-Warrick, Ronald M and Brownstone, Robert M},
journal = {J Neurophysiol},
number = {4},
pages = {3118--3125},
title = {{Two-Photon Calcium Imaging of Network Activity in XFP-Expressing Neurons in the Mouse}},
volume = {97},
year = {2007}
}
@article{MWZ03,
author = {Machens, C and Wehr, M and Zador, A},
journal = {NIPS},
title = {{Spectro-temporal receptive fields of subthreshold responses in auditory cortex}},
year = {2003}
}
@article{Erlich2011,
abstract = {Anatomical, stimulation, and lesion data have suggested a homology between the rat frontal orienting fields (FOF) (centered at +2 AP, ±1.3 ML mm from Bregma) and primate frontal cortices such as the frontal or supplementary eye fields. We investigated the functional role of the FOF using rats trained to perform a memory-guided orienting task, in which there was a delay period between the end of a sensory stimulus instructing orienting direction and the time of the allowed motor response. Unilateral inactivation of the FOF resulted in impaired contralateral responses. Extracellular recordings of single units revealed that 37{\%} of FOF neurons had delay period firing rates that predicted the direction of the rats' later orienting motion. Our data provide the first electrophysiological and pharmacological evidence supporting the existence in the rat, as in the primate, of a frontal cortical area involved in the preparation and/or planning of orienting responses.},
author = {Erlich, Jeffrey C and Bialek, Max and Brody, Carlos D},
doi = {10.1016/j.neuron.2011.07.010},
issn = {1097-4199},
journal = {Neuron},
keywords = {Animals,Behavior, Animal,Behavior, Animal: physiology,Choice Behavior,Choice Behavior: physiology,Frontal Lobe,Frontal Lobe: physiology,Male,Memory,Memory: physiology,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Rats,Rats, Long-Evans,Space Perception,Space Perception: physiology,Visual Pathways,Visual Pathways: physiology},
month = {oct},
number = {2},
pages = {330--43},
pmid = {22017991},
publisher = {Elsevier Inc.},
title = {{A cortical substrate for memory-guided orienting in the rat.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3212026{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {72},
year = {2011}
}
@article{krogh1992generalization,
author = {Krogh, A. and Hertz, J},
journal = {Journal of Physics A: Mathematical and General},
pages = {1135},
publisher = {IOP Publishing},
title = {{Generalization in a linear perceptron in the presence of noise}},
url = {http://iopscience.iop.org/0305-4470/25/5/020},
volume = {25},
year = {1992}
}
@article{Jian2012,
author = {Jian, Bao and LiangJie, Z and Yi, Yan},
journal = {Appl. Math},
keywords = {approximation,artificial neural networks,complexity,integer weights},
number = {2},
pages = {317--323},
title = {{Analysis on complexity of neural networks using integer weights}},
url = {http://qpl.naturalspublishing.com/files/published/b924uf879pd533.pdf},
volume = {323},
year = {2012}
}
@article{Levy1996a,
abstract = {Extracellular potassium modulates recovery from C-type inactivation of Kv1.3 in human T lymphocytes. The results of whole-cell patch clamp recordings show that there is a linear increase in recovery rate with increasing [K+]o. An increase from 5 to 150 mM K+o causes a sixfold acceleration of recovery rate at a holding potential of -90 mV. Our results suggest that 1) a low-affinity K+ binding site is involved in recovery, 2) the rate of recovery increases with hyperpolarization, 3) potassium must bind to the channel before inactivation to speed its recovery, and 4) recovery rate depends on external [K+] but not on the magnitude of the driving force through open channels. We present a model in which a bound K+ ion destabilizes the inactivated state to increase the rate of recovery of C-type inactivation, thereby providing a mechanism for autoregulation of K+ channel activity. The ability of K+ to regulate its own conductance may play a role in modulating voltage-dependent immune function.},
author = {Levy, D I and Deutsch, C},
doi = {10.1016/S0006-3495(96)79619-4},
issn = {0006-3495},
journal = {Biophysical journal},
keywords = {Binding Sites,Biophysical Phenomena,Biophysics,Cells,Cultured,Extracellular Space,Extracellular Space: metabolism,Humans,Kinetics,Kv1.3 Potassium Channel,Membrane Potentials,Potassium,Potassium Channel Blockers,Potassium Channels,Potassium Channels: drug effects,Potassium Channels: metabolism,Potassium: metabolism,Potassium: pharmacology,T-Lymphocytes,T-Lymphocytes: drug effects,T-Lymphocytes: immunology,T-Lymphocytes: metabolism,Voltage-Gated},
month = {feb},
number = {2},
pages = {798--805},
pmid = {8789096},
publisher = {Elsevier},
title = {{Recovery from C-type inactivation is modulated by extracellular potassium.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1224979{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {70},
year = {1996}
}
@article{Lefort2009,
author = {Lefort, S and Tomm, C and {Floyd Sarria}, J.-C. and Petersen, C C H},
journal = {Neuron},
pages = {301--316},
title = {{The excitatory neuronal network of the C2 barrel column in mouse primary somatosensory cortex}},
volume = {61},
year = {2009}
}
@article{Hovin2002,
author = {Hovin, M and Wisland, Dag},
isbn = {0780374487},
journal = {Circuits and Systems {\ldots}},
pages = {617--620},
title = {{Delta-sigma modulation in single neurons}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1010779},
year = {2002}
}
@article{Moehlis06,
author = {Moehlis, J and Shea-Brown, E and Rabitz, H},
journal = {ASME Journal of Computational and Nonlinear Dynamics},
pages = {358--367},
title = {{Optimal inputs for phase models of spiking neurons}},
volume = {1},
year = {2006}
}
@article{Granit1933,
abstract = {ERG; retina; dark-adapted; cat; in vivo; a-wave; b-wave; c-wave; d-wave; OFF-response; decerebrated;},
author = {Granit, Ragnar},
doi = {10.1113/jphysiol.1933.sp002964},
isbn = {0022-3751 (Print)$\backslash$n0022-3751 (Linking)},
issn = {00223751},
journal = {The Journal of Physiology},
number = {3},
pages = {207--239},
pmid = {16994385},
title = {{The components of the retinal action potential in mammals and their relation to the discharge in the optic nerve.}},
url = {http://doi.wiley.com/10.1113/jphysiol.1933.sp002964},
volume = {77},
year = {1933}
}
@article{Boyd2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1104.5557v3},
author = {Mahoney, M.l W.},
eprint = {arXiv:1104.5557v3},
title = {{Randomized Algorithms for Matrices and Data}},
url = {http://dx.doi.org/10.1561/2200000035},
year = {2010}
}
@article{Arieli96,
abstract = {Evoked activity in the mammalian cortex and the resulting behavioral responses exhibit a large variability to repeated presentations of the same stimulus. This study examined whether the variability can be attributed to ongoing activity. Ongoing and evoked spatiotemporal activity patterns in the cat visual cortex were measured with real-time optical imaging; local field potentials and discharges of single neurons were recorded simultaneously, by electrophysiological techniques. The evoked activity appeared deterministic, and the variability resulted from the dynamics of ongoing activity, presumably reflecting the instantaneous state of cortical networks. In spite of the large variability, evoked responses in single trials could be predicted by linear summation of the deterministic response and the preceding ongoing activity. Ongoing activity must play an important role in cortical function and cannot be ignored in exploration of cognitive processes.},
author = {Arieli, a and Sterkin, A and Grinvald, A and Aertsen, A},
issn = {0036-8075},
journal = {Science},
keywords = {Animals,Cats,Computer-Assisted,Evoked Potentials,Membrane Potentials,Neurons,Neurons: physiology,Photic Stimulation,Signal Processing,Visual,Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology},
month = {sep},
number = {5283},
pages = {1868--1871},
pmid = {8791593},
title = {{Explanation of the Large Variability in Evoked Cortical Responses}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8791593 http://www.sciencemag.org/content/273/5283/1868.short},
volume = {273},
year = {1996}
}
@book{Koch2004,
address = {New York},
author = {Koch, C},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
publisher = {Oxford University Press},
title = {{Biophysics of Computation: Information Processing in Single Neurons}},
url = {http://www.lavoisier.fr/notice/fr330820.html http://books.google.com/books?hl=en{\&}lr={\&}id=fqHQtY-j2dYC{\&}oi=fnd{\&}pg=PA2{\&}dq=Biophysics+of+computation:+Information+processing+in+single+neurons{\&}ots=XWoqlWufrE{\&}sig=zGVX1JLz5UjhgN1qqA10{\_}BmAPXk},
year = {2005}
}
@article{FeldmeyerSakmann00,
author = {Feldmeyer, D and Sakmann, B},
journal = {J Physiol},
pages = {31--39},
title = {{Synaptic efficacy and reliability of excitatory connections between the principal neurones of the input (layer 4) and output layer (layer 5) of the neocortex}},
volume = {525},
year = {2000}
}
@book{Tao2012,
abstract = {Terry Tao's Book},
author = {Tao, Terence},
isbn = {ISBN-10: 0-8218-7430-6},
pages = {47},
publisher = {American Mathematical Soc},
title = {{Topics in random matrix theory}},
url = {https://terrytao.files.wordpress.com/2011/02/matrix-book.pdf},
year = {2012}
}
@article{Zador1996,
annote = {2010IIInum39},
author = {Zador, A M and Pearlmutter, BA},
journal = {of the ninth annual conference on},
title = {{VC dimension of an integrate-and-fire neuron model}},
url = {http://portal.acm.org/citation.cfm?id=238064},
year = {1996}
}
@techreport{NEAL97,
author = {Neal, R M},
institution = {University of Toronto},
number = {9702},
title = {{Monte {\{}C{\}}arlo implementation of {\{}G{\}}aussian process models for {\{}B{\}}ayesian regression and classification}},
year = {1997}
}
@article{Hagmann2007,
author = {Hagmann, P and Kurant, M and Gigandet, X and Thiran, P and Wedeen, V and Meuli, R and Thiran, J.-P.},
journal = {PLoS ONE},
number = {7},
pages = {e597},
title = {{Mapping Human Whole-Brain Structural Networks with Diffusion MRI}},
volume = {2},
year = {2007}
}
@article{RialVerde08,
author = {{Rial Verde}, E and Zayat, L and Etchenique, R and Yuste, R},
journal = {Frontiers in Neural Circuits},
pages = {2},
title = {{Photorelease of {\{}GABA{\}} with visible light using an inorganic caging group}},
volume = {2},
year = {2008}
}
@article{Hardt2015a,
abstract = {We show that any model trained by a stochastic gradient method with few iterations has vanishing generalization error. We prove this by showing the method is algorithmically stable in the sense of Bousquet and Elisseeff. Our analysis only employs elementary tools from convex and continuous optimization. Our results apply to both convex and non-convex optimization under standard Lipschitz and smoothness assumptions. Applying our results to the convex case, we provide new explanations for why multiple epochs of stochastic gradient descent generalize well in practice. In the nonconvex case, we provide a new interpretation of common practices in neural networks, and provide a formal rationale for stability-promoting mechanisms in training large, deep models. Conceptually, our findings underscore the importance of reducing training time beyond its obvious benefit.},
archivePrefix = {arXiv},
arxivId = {1509.01240},
author = {Hardt, Moritz and Recht, Benjamin and Singer, Y},
eprint = {1509.01240},
journal = {ICML},
pages = {1--24},
title = {{Train faster, generalize better: Stability of stochastic gradient descent}},
url = {http://arxiv.org/abs/1509.01240},
year = {2016}
}
@incollection{TsaiKleinfeld02,
author = {Tsai, P S and Nishimura, N and Yoder, E J and Dolnick, E M and White, G A and Kleinfeld, D},
chapter = {Principles},
editor = {Frostig, Ron D},
pages = {113--171},
publisher = {CRC Press},
title = {{In Vivo Optical Imaging of Brain Function}},
year = {2002}
}
@article{HP06,
author = {Huys, Q and Paninski, L},
journal = {PLOS Computational Biology},
pages = {e1000379},
title = {{Model-based smoothing of, and parameter estimation from, noisy biophysical recordings}},
volume = {5},
year = {2009}
}
@article{Sporea2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1112.0213v1},
author = {Sporea, Ioana and Kingdom, United},
eprint = {arXiv:1112.0213v1},
keywords = {logical operation,spike trains,spiking neural networks,supervised learning},
pages = {1--15},
title = {{Supervised Learning of Logical Operations in Layered Spiking Neural Networks with Spike Train Encoding}},
year = {2011}
}
@article{WSA02,
author = {Weiss, Y and Simoncelli, E and Adelson, E},
journal = {Nature Neuroscience},
pages = {598--604},
title = {{Motion illusions as optimal percepts}},
volume = {5},
year = {2002}
}
@article{MarkhamConchello99,
abstract = {Blind-deconvolution microscopy, the simultaneous estimation of the

specimen function and the point-spread function (PSF) of the microscope,

is an underdetermined problem with nonunique solutions that are usually

avoided by enforcing constraints on the specimen function and the

PSF. We derived a maximum-likelihood-based method for blind deconvolution

in which we assume a mathematical model for the PSF that depends

on a small number of parameters (e.g., less than 20). The algorithm

then estimates the unknown parameters together with the specimen

function. The mathematical model ensures that all the constraints

of the PSF are satisfied, and the maximum-likelihood approach ensures

that the specimen is nonnegative. The method successfully estimates

the PSF and removes out-of-focus blur. The PSF estimation is robust

to aberrations in the PSF and to noise in the image.},
author = {Markham, J and Conchello, J A},
journal = {Journal of The Optical Society Of America A. Optics, Image Science, and Vision},
keywords = {Algorithms; Artifacts; Likelihood Functions; Micro,Theoretical},
month = {oct},
number = {10},
pages = {2377--2391},
pmid = {10517022},
title = {{Parametric blind deconvolution: a robust method for the simultaneous estimation of image and blur.}},
volume = {16},
year = {1999}
}
@article{YuSahani06,
author = {Yu, B and Afshar, A and Santhanam, G and Ryu, S and Shenoy, K and Sahani, M},
journal = {NIPS},
title = {{Extracting Dynamical Structure Embedded in Neural Activity}},
year = {2006}
}
@article{wallach2008selective,
annote = {2008num10},
author = {Wallach, A and Eytan, D and Marom, S and Meir, R},
journal = {PLoS Computational Biology},
title = {{Selective adaptation in networks of heterogeneous populations: Model, simulation, and experiment}},
year = {2008}
}
@incollection{KaltenbachZacharek01,
author = {Kaltenbach, J A and Heffner, H E and Zhang, J and Mathog, T A and Zacharek, M A},
booktitle = {Noise Induced Hearing Loss, Basic Mechanisms, Prevention and Control},
editor = {Henderson, D and Prasher, D and Kopke, R and Salvi, R and Hamernik, R},
pages = {153--168},
publisher = {Noise Research Network Publications},
title = {{Neuro-physiological mechanisms of noise-induced tinnitus}},
year = {2001}
}
@article{Gomez-cabrero2011,
author = {Gomez-Cabrero, D. and Compte, Albert and Tegner, Jesper},
doi = {10.1098/rsfs.2011.0015},
journal = {Interface Focus},
keywords = {bioinformatics,computational biology,systems biology},
number = {3},
pages = {438},
publisher = {The Royal Society},
title = {{Workflow for generating competing hypothesis from models with parameter uncertainty}},
url = {http://rsfs.royalsocietypublishing.org/content/1/3/438.short},
volume = {1},
year = {2011}
}
@article{GM00,
author = {Gibbs, M and MacKay, D J C},
journal = {IEEE Transactions on Neural Networks},
pages = {1458--1464},
title = {{Variational Gaussian Process Classifiers}},
volume = {11},
year = {2000}
}
@article{Tang1993,
author = {Tang, PYH},
isbn = {0780309995},
title = {{Sigma-delta modulation neural networks}},
url = {http://repository.ust.hk/dspace/handle/1783.1/4375},
year = {1993}
}
@article{Douglas2007,
abstract = {While we know that the neocortex occupies 85{\%} of our brains and that its circuits allow an enormous flexibility and repertoire of behavior (not to mention unexplained phenomena like consciousness), a century after Cajal we have very little knowledge of the details of the cortical circuits or their mode of function. One simplifying hypothesis that has existed since Cajal is that the neocortex consists of repeated copies of the same fundamental circuit. However, finding that fundamental circuit has proved elusive, although partial drafts of a "canonical circuit" appear in many different guises of structure and function. Here, we review some critical stages in the history of this quest. In doing so, we consider the style of cortical computation in relation to the neuronal machinery that supports it. We conclude that the structure and function of cortex honors two major computational principles: "just-enough" and "just-in-time."},
author = {Douglas, Rodney J and Martin, Kevan a C},
doi = {10.1016/j.neuron.2007.10.017},
issn = {0896-6273},
journal = {Neuron},
keywords = {Animals,Axons,Axons: physiology,Brain Mapping,Dendrites,Dendrites: physiology,Humans,Models, Neurological,Neocortex,Neocortex: cytology,Neocortex: physiology,Pyramidal Cells,Pyramidal Cells: physiology},
month = {oct},
number = {2},
pages = {226--38},
pmid = {17964242},
title = {{Mapping the matrix: the ways of neocortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17964242},
volume = {56},
year = {2007}
}
@article{Kawaguchi2017,
abstract = {With a goal of understanding what drives generalization in deep networks, we consider several recently suggested explanations, including norm-based control, sharpness and robustness. We study how these measures can ensure generalization, highlighting the importance of scale normalization, and making a connection between sharpness and PAC-Bayes theory. We then investigate how well the measures explain different observed phenomena.},
archivePrefix = {arXiv},
arxivId = {1706.08947},
author = {Kawaguchi, Kenji and Kaelbling, Leslie Pack and Bengio, Yoshua},
eprint = {1706.08947},
file = {:C$\backslash$:/Users/Daniel/Downloads/1710.05468.pdf:pdf},
journal = {Arxiv},
title = {{Generalization in Deep Learning}},
url = {http://arxiv.org/abs/1706.08947},
year = {2017}
}
@article{Fodor|2003|,
abstract = {One problem in similarity-based object retrieval (SBOR) is how to
define and estimate the similar- ity between two objects. In this
paper we present a shape similarity measure based on thin-plate splines,
and compare its performance with several other mea- sures used in
SBOR. We evaluate the methods on both artificial and real images.},
annote = {The paper introduces method for assesing similarity of two shapes{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}via bending energy of 2D transformation morphing one shape into the{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}other, both represented by spline curves.},
author = {Fodor, I K},
keywords = {computational,image processing,similarity based object retrieval,thin-plate splines},
title = {{Statistical techniques to find similar objects in images}}
}
@article{MKWG98,
author = {Metzner, W and Koch, C and Wessel, R and Gabbiani, F},
journal = {Journal of Neuroscience},
pages = {2283--2300},
title = {{Feature Extraction by Burst-Like Spike Patterns in Multiple Sensory Maps}},
volume = {18},
year = {1998}
}
@article{CASTI02,
author = {Casti, A and Omurtag, A and Sornborger, A and Kaplan, E and Knight, B and Sirovich, L and Victor, J},
journal = {Neural Computation},
pages = {957--986},
title = {{A population study of integrate-and-fire-or-burst neurons}},
volume = {14},
year = {2002}
}
@article{ParsonsVoigt01,
author = {Parsons, J E and Lim, E and Voigt, H F},
journal = {Annals of Biomedical Engineering},
month = {oct},
number = {10},
pages = {887--896},
title = {{Type III units in the gerbil dorsal cochlear nucleus may be spectral notch detectors}},
volume = {29},
year = {2001}
}
@article{Schneidman2006,
abstract = {Biological networks have so many possible states that exhaustive sampling is impossible. Successful analysis thus depends on simplifying hypotheses, but experiments on many systems hint that complicated, higher-order interactions among large groups of elements have an important role. Here we show, in the vertebrate retina, that weak correlations between pairs of neurons coexist with strongly collective behaviour in the responses of ten or more neurons. We find that this collective behaviour is described quantitatively by models that capture the observed pairwise correlations but assume no higher-order interactions. These maximum entropy models are equivalent to Ising models, and predict that larger networks are completely dominated by correlation effects. This suggests that the neural code has associative or error-correcting properties, and we provide preliminary evidence for such behaviour. As a first test for the generality of these ideas, we show that similar results are obtained from networks of cultured cortical neurons.},
author = {Schneidman, E and Berry, Michael J and Segev, Ronen and Bialek, William},
doi = {10.1038/nature04701},
journal = {Nature},
keywords = {Action Potentials,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Entropy,Guinea Pigs,Models,Neurological,Neurons,Neurons: cytology,Neurons: physiology,Poisson Distribution,Retina,Retina: cytology,Retina: physiology,Urodela},
month = {apr},
number = {7087},
pages = {1007--1012},
pmid = {16625187},
title = {{Weak pairwise correlations imply strongly correlated network states in a neural population.}},
url = {http://www.nature.com/nature/journal/v440/n7087/abs/nature04701.html http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1785327{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {440},
year = {2006}
}
@article{Sterman|1977|,
abstract = {The properties of hadronic jets in e{\^{}}+e{\^{}}- annihilation are examined
in quantum chromodynamics, without using the assumptions of the parton
model. We find that two-jet events dominate the cross section at
high energy, and have the experimentally observed angular distribution.
Estimates are given for the jet angular radius and its energy dependence.
We argue that the detailed results of perturbation theory for production
of arbitrary numbers of quarks and gluons can be reinterpreted in
quantum chromodynamics as predictions for the production of jets.},
annote = {This paper is seen as important contribution to the treatment and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}interpretation of infrared divergences in QFT.},
author = {Sterman, G and Weinberg, S},
journal = {Physical Review Letters},
keywords = {infrared corrections in quantum field theory,jets,perturbation theory,physics,quantum chromodynamics},
number = {22},
pages = {1436},
title = {{Jets from Quantum Chromodynamics}},
volume = {39}
}
@article{Tewksbury1978,
author = {Tewksbury, S and Hallock, RW},
journal = {Circuits and Systems, IEEE {\ldots}},
pages = {436--447},
title = {{Oversampled, linear predictive and noise-shaping coders of order N{\textgreater} 1}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1084499},
year = {1978}
}
@article{Valle1996,
author = {Valle, M and Caviglia, D D and Bisio, G M},
journal = {Analog Integrated Circuits and Signal Processing},
number = {3},
pages = {231--245},
title = {{An experimental analog VLSI neural network with on-chip back-propagation learning}},
url = {http://link.springer.com/article/10.1007/BF00194907},
volume = {9},
year = {1996}
}
@book{KOCH99,
author = {Koch, C},
publisher = {Oxford University Press},
title = {{Biophysics of Computation}},
year = {1999}
}
@article{Brown2002,
abstract = {Measuring agreement between a statistical model and a spike train data series, that is, evaluating goodness of fit, is crucial for establishing the model's validity prior to using it to make inferences about a particular neural system. Assessing goodness-of-fit is a challenging problem for point process neural spike train models, especially for histogram-based models such as perstimulus time histograms (PSTH) and rate functions estimated by spike train smoothing. The time-rescaling theorem is a well-known result in probability theory, which states that any point process with an integrable conditional intensity function may be transformed into a Poisson process with unit rate. We describe how the theorem may be used to develop goodness-of-fit tests for both parametric and histogram-based point process models of neural spike trains. We apply these tests in two examples: a comparison of PSTH, inhomogeneous Poisson, and inhomogeneous Markov interval models of neural spike trains from the supplementary eye field of a macque monkey and a comparison of temporal and spatial smoothers, inhomogeneous Poisson, inhomogeneous gamma, and inhomogeneous inverse gaussian models of rat hippocampal place cell spiking activity. To help make the logic behind the time-rescaling theorem more accessible to researchers in neuroscience, we present a proof using only elementary probability theory arguments. We also show how the theorem may be used to simulate a general point process model of a spike train. Our paradigm makes it possible to compare parametric and histogram-based neural spike train models directly. These results suggest that the time-rescaling theorem can be a valuable tool for neural spike train data analysis.},
author = {Brown, E N and Barbieri, R and Ventura, V and Kass, R E and Frank, L M},
doi = {10.1162/08997660252741149},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Animals,Macaca,Models,Neurological,Neurons,Neurons: physiology,Probability Theory,Visual Pathways,Visual Pathways: physiology,networks},
mendeley-tags = {networks},
month = {feb},
number = {2},
pages = {325--46},
pmid = {11802915},
title = {{The time-rescaling theorem and its application to neural spike train data analysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11802915},
volume = {14},
year = {2002}
}
@article{Schlander|1986|,
abstract = {Morphological characteristics of non-pyramidal neurons in the guinea
pig hippocampus (regions CA1 and CA3) were analyzed by a correlated
light and electron microscopic approach. Following Golgi impregnation,
the cells were first studied under the light microscope and classified
according to the location of their cell bodies and the distribution
of their dendrites in the different hippocampal layers. Next, the
Golgi impregnated non-pyramidal neurons were gold-toned and deimpregnated,
allowing an electron microscopic analysis of the identified structures.
With regard to cell body location and dendritic pattern, non-pyramidal
cells are a rather heterogeneous group of neurons. Their perikarya
were found in all hippocampal layers and their dendrites had a less
regular orientation when compared to pyramidal neurons and granule
cells. Two basic types, i.e., "vertical" and "horizontal" non-pyramidal
neurons are described. Many cells were of an intermediate type with
dendrites extending in all directions. Non-pyramidal cell dendrites
were mostly devoid of spines but exhibited numerous varicosities.
Non-pyramidal cell axons could sometimes be seen extending towards
the pyramidal cell layer. A surprising uniformity was observed when
the impregnated, identified non-pyramidal neurons were studied in
the electron microscope. Their perikarya exhibited a well-developed
endoplasmic reticulum and indented nuclei. Both the cell bodies and
the varicose dendrites were densely covered with synaptic boutons
which mainly formed asymmetric synaptic contacts. Only occasionally
were symmetric synaptic contacts observed. Non-pyramidal cell dendrites
extending into the stratum lucidum of CA3 were found to be contacted
by the giant boutons of mossy fiber axons. In addition to synaptic
contacts, the dendrites of gold-toned non-pyramidal neurons formed
gap junctions with neighboring dendrites. The results are discussed
in relation to recent immunocytochemical studies which have shown
non-pyramidal neurons in the hippocampus to contain gamma-aminobutyric
acid and/or various neuropeptides.},
annote = {Journal Article Research Support, Non-U.S. Gov{\&}{\#}039;t Germany, west},
author = {Schlander, M and Frotscher, M},
journal = {Anat Embryol (Berl)},
keywords = {Animals Dendrites/ultrastructure Gold Guinea Pigs,Electron Microtomy/methods Neurons/*classificatio},
number = {1},
pages = {35--47},
title = {{Non-pyramidal neurons in the guinea pig hippocampus. A combined Golgi-electron microscope study}},
volume = {174}
}
@article{Bennequin2009,
abstract = {Human movements show several prominent features; movement duration is nearly independent of movement size (the isochrony principle), instantaneous speed depends on movement curvature (captured by the 2/3 power law), and complex movements are composed of simpler elements (movement compositionality). No existing theory can successfully account for all of these features, and the nature of the underlying motion primitives is still unknown. Also unknown is how the brain selects movement duration. Here we present a new theory of movement timing based on geometrical invariance. We propose that movement duration and compositionality arise from cooperation among Euclidian, equi-affine and full affine geometries. Each geometry posses a canonical measure of distance along curves, an invariant arc-length parameter. We suggest that for continuous movements, the actual movement duration reflects a particular tensorial mixture of these canonical parameters. Near geometrical singularities, specific combinations are selected to compensate for time expansion or compression in individual parameters. The theory was mathematically formulated using Cartan's moving frame method. Its predictions were tested on three data sets: drawings of elliptical curves, locomotion and drawing trajectories of complex figural forms (cloverleaves, lemniscates and lima{\c{c}}ons, with varying ratios between the sizes of the large versus the small loops). Our theory accounted well for the kinematic and temporal features of these movements, in most cases better than the constrained Minimum Jerk model, even when taking into account the number of estimated free parameters. During both drawing and locomotion equi-affine geometry was the most dominant geometry, with affine geometry second most important during drawing; Euclidian geometry was second most important during locomotion. We further discuss the implications of this theory: the origin of the dominance of equi-affine geometry, the possibility that the brain uses different mixtures of these geometries to encode movement duration and speed, and the ontogeny of such representations.},
annote = {2011num20},
author = {Bennequin, Daniel and Fuchs, Ronit and Berthoz, Alain and Flash, Tamar},
doi = {10.1371/journal.pcbi.1000426},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Algorithms,Data Interpretation, Statistical,Hand,Handwriting,Humans,Models, Biological,Movement,Movement: physiology,Perception,Regression Analysis,Time Factors,Walking},
month = {jul},
number = {7},
pages = {e1000426},
pmid = {19593380},
title = {{Movement timing and invariance arise from several geometries.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2702097{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@article{Goldwyn2011b,
abstract = {Conductance-based equations for electrically active cells form one of the most widely studied mathematical frameworks in computational biology. This framework, as expressed through a set of differential equations by Hodgkin and Huxley, synthesizes the impact of ionic currents on a cell's voltage--and the highly nonlinear impact of that voltage back on the currents themselves--into the rapid push and pull of the action potential. Later studies confirmed that these cellular dynamics are orchestrated by individual ion channels, whose conformational changes regulate the conductance of each ionic current. Thus, kinetic equations familiar from physical chemistry are the natural setting for describing conductances; for small-to-moderate numbers of channels, these will predict fluctuations in conductances and stochasticity in the resulting action potentials. At first glance, the kinetic equations provide a far more complex (and higher-dimensional) description than the original Hodgkin-Huxley equations or their counterparts. This has prompted more than a decade of efforts to capture channel fluctuations with noise terms added to the equations of Hodgkin-Huxley type. Many of these approaches, while intuitively appealing, produce quantitative errors when compared to kinetic equations; others, as only very recently demonstrated, are both accurate and relatively simple. We review what works, what doesn't, and why, seeking to build a bridge to well-established results for the deterministic equations of Hodgkin-Huxley type as well as to more modern models of ion channel dynamics. As such, we hope that this review will speed emerging studies of how channel noise modulates electrophysiological dynamics and function. We supply user-friendly MATLAB simulation code of these stochastic versions of the Hodgkin-Huxley equations on the ModelDB website (accession number 138950) and http://www.amath.washington.edu/{\~{}}etsb/tutorials.html.},
archivePrefix = {arXiv},
arxivId = {arXiv:submit/0237013},
author = {Goldwyn, J H and Shea-brown, Eric},
doi = {10.1371/journal.pcbi.1002247},
eprint = {0237013},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Axons,Axons: physiology,Decapodiformes,Electric Conductivity,Markov Chains,Models,Neurological,Potassium Channels,Potassium Channels: physiology,Sodium Channels,Sodium Channels: physiology,Stochastic Processes},
month = {nov},
number = {11},
pages = {e1002247},
pmid = {22125479},
primaryClass = {arXiv:submit},
title = {{The what and where of adding channel noise to the Hodgkin-Huxley equations.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3219615{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2011}
}
@article{FanEllisman99,
author = {Fan, G Y and Fujisaki, H and Miyawaki, A and Tsay, R K and Tsien, R Y and Ellisman, M H},
journal = {Biophysical Journal},
month = {may},
number = {5},
pages = {2412--2420},
title = {{Video-rate scanning two-photon excitation fluorescence microscopy and ratio imaging with cameleons}},
volume = {76},
year = {1999}
}
@article{Duan|2003|,
author = {Duan, H and Wearne, S L and Rocher, A B and Macedo, A and Morrison, J H and Hof, P R},
journal = {Cereb Cortex},
keywords = {*Aging/pathology Animals Cerebral Cortex/*anatomy},
number = {9},
pages = {950--961},
title = {{Age-related dendritic and spine changes in corticocortically projecting neurons in macaque monkeys}},
volume = {13}
}
@article{GriesbeckTsien01,
abstract = {Yellow mutants of the green fluorescent protein (YFP) are crucial

constituents of genetically encoded indicators of signal transduction

and fusions to monitor protein-protein interactions. However, previous

YFPs show excessive pH sensitivity, chloride interference, poor photostability,

or poor expression at 37 degrees C. Protein evolution in Escherichia

coli has produced a new YFP named Citrine, in which the mutation

Q69M confers a much lower pK(a) (5.7) than for previous YFPs, indifference

to chloride, twice the photostability of previous YFPs, and much

better expression at 37 degrees C and in organelles. The halide resistance

is explained by a 2.2-A x-ray crystal structure of Citrine, showing

that the methionine side chain fills what was once a large halide-binding

cavity adjacent to the chromophore. Insertion of calmodulin within

Citrine or fusion of cyan fluorescent protein, calmodulin, a calmodulin-binding

peptide and Citrine has generated improved calcium indicators. These

chimeras can be targeted to multiple cellular locations and have

permitted the first single-cell imaging of free [{\{}Ca{\}}{\^{}}{\{}2+{\}}] in

the Golgi. Citrine is superior to all previous YFPs except when pH

or halide sensitivity is desired and is particularly advantageous

within genetically encoded fluorescent indicators of physiological

signals.},
author = {Griesbeck, O and Baird, G S and Campbell, R E and Zacharias, D A and Tsien, R Y},
doi = {10.1074/jbc.M102815200},
journal = {J Biol Chem},
keywords = {Amino Acid Substitution; Bacterial Proteins; Bindi,Molecular; Crystallography,Molecular; Mutagenesis,Site-Directed; Photolysis; Polymerase Chain React,X-Ray; Escherichia coli; Fluorescent Dyes; Golgi},
month = {aug},
number = {31},
pages = {29188--29194},
pmid = {11387331},
title = {{Reducing the environmental sensitivity of yellow fluorescent protein. Mechanism and applications.}},
url = {http://dx.doi.org/10.1074/jbc.M102815200},
volume = {276},
year = {2001}
}
@article{Rubinstein1995,
author = {Rubinstein, J},
doi = {10.1016/S0006-3495(95)80252-3},
issn = {00063495},
journal = {Biophysical Journal},
keywords = {neuron},
mendeley-tags = {neuron},
month = {mar},
number = {3},
pages = {779--785},
publisher = {Elsevier},
title = {{Threshold fluctuations in an N sodium channel model of the node of Ranvier}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349595802523},
volume = {68},
year = {1995}
}
@article{Bruna,
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6203v3},
author = {Bruna, J and Zaremba, W and Szlam, A and LeCun, Y},
eprint = {arXiv:1312.6203v3},
pages = {1--14},
title = {{Spectral Networks and Deep Locally Connected Networks on Graphs}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Spectral+Networks+and+Deep+Locally+Connected+Networks+on+Graphs{\#}0},
year = {2014}
}
@article{Rossignol2006,
author = {Rossignol, Serge and Dubuc, R. and Gossard, J.P. P},
doi = {10.1152/physrev.00028.2005.},
issn = {0031-9333},
journal = {Physiological Reviews},
keywords = {motor control},
mendeley-tags = {motor control},
number = {1},
pages = {89},
publisher = {Am Physiological Soc},
title = {{Dynamic sensorimotor interactions in locomotion}},
url = {http://physrev.physiology.org/cgi/content/abstract/86/1/89},
volume = {86},
year = {2006}
}
@article{bobrowski2009bayesian,
annote = {2010num4.2},
author = {Bobrowski, O and Meir, R and Eldar, Y C},
journal = {Neural Computation},
number = {5},
pages = {1277--1320},
publisher = {MIT Press},
title = {{Bayesian filtering in spiking neural networks: Noise, adaptation, and multisensory integration}},
volume = {21},
year = {2009}
}
@article{HasanDenk04,
abstract = {Genetically encoded fluorescent calcium indicator proteins (FCIPs)

are promising tools to study calcium dynamics in many activity-dependent

molecular and cellular processes. Great hopes-for the measurement

of population activity, in particular-have therefore been placed

on calcium indicators derived from the green fluorescent protein

and their expression in (selected) neuronal populations. Calcium

transients can rise within milliseconds, making them suitable as

reporters of fast neuronal activity. We here report the production

of stable transgenic mouse lines with two different functional calcium

indicators, inverse pericam and camgaroo-2, under the control of

the tetracycline-inducible promoter. Using a variety of in vitro

and in vivo assays, we find that stimuli known to increase intracellular

calcium concentration (somatically triggered action potentials (APs)

and synaptic and sensory stimulation) can cause substantial and rapid

changes in FCIP fluorescence of inverse pericam and camgaroo-2.},
author = {Hasan, Mazahir T and Friedrich, Rainer W and Euler, Thomas and Larkum, Matthew E and Giese, G{\"{u}}nter and Both, Matthias and Duebel, Jens and Waters, Jack and Bujard, Hermann and Griesbeck, Oliver and Tsien, Roger Y and Nagai, Takeharu and Miyawaki, Atsushi and Denk, W},
doi = {10.1371/journal.pbio.0020163},
journal = {PLoS Biol},
keywords = {Animals; Brain; Brain Mapping; Calcium; Calcium Ch,Fluorescence; Olfactory Bulb; Photic Stimulation;,Transgenic; Microscopy},
month = {jun},
number = {6},
pages = {e163},
pmid = {15208716},
title = {{Functional fluorescent {\{}Ca{\}}{\^{}}{\{}2+{\}} indicator proteins in transgenic mice under TET control.}},
url = {http://dx.doi.org/10.1371/journal.pbio.0020163},
volume = {2},
year = {2004}
}
@article{PAN04b,
author = {Paninski, L and Pillow, J W and Simoncelli, E},
journal = {Neurocomputing},
pages = {379--385},
title = {{Comparing integrate-and-fire-like models estimated using intracellular and extracellular data}},
volume = {65},
year = {2004}
}
@article{VoigtYoung90,
author = {Voigt, H F and Young, E D},
journal = {Journal of Neurophysiology},
month = {nov},
number = {5},
pages = {1590--1610},
title = {{Cross-correlation analysis of inhibitory interactions in dorsal cochlear nucleus}},
volume = {64},
year = {1990}
}
@article{Lindner2004,
annote = {2009num46},
author = {Lindner, B},
doi = {10.1016/j.physrep.2003.10.015},
issn = {03701573},
journal = {Physics Reports},
keywords = {active,brownian motion,coe cient of variation,excitable dynamics,firing rate,fitzhugh,in periodic potentials,ion-channel clusters,laser dynamics,leaky integrate-and-{\"{y}}re model,nagumo system,noise induced phase transition,noisy pattern formation,phase rotators,phase synchronization,spike count di usion,stochastic cellular automata,stochastic dynamics},
month = {mar},
number = {6},
pages = {321--424},
title = {{Effects of noise in excitable systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0370157303004228},
volume = {392},
year = {2004}
}
@article{Montague2012,
abstract = {Computational ideas pervade many areas of science and have an integrative explanatory role in neuroscience and cognitive science. However, computational depictions of cognitive function have had surprisingly little impact on the way we assess mental illness because diseases of the mind have not been systematically conceptualized in computational terms. Here, we outline goals and nascent efforts in the new field of computational psychiatry, which seeks to characterize mental dysfunction in terms of aberrant computations over multiple scales. We highlight early efforts in this area that employ reinforcement learning and game theoretic frameworks to elucidate decision-making in health and disease. Looking forwards, we emphasize a need for theory development and large-scale computational phenotyping in human subjects.},
author = {Montague, P Read and Dolan, Raymond J and Friston, Karl J and Dayan, Peter},
doi = {10.1016/j.tics.2011.11.018},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
month = {jan},
number = {1},
pages = {72--80},
pmid = {22177032},
title = {{Computational psychiatry}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22177032},
volume = {16},
year = {2012}
}
@article{Fitzhugh1961,
abstract = {Van der Pol's equation for a relaxation oscillator is generalized by the addition of terms to produce a pair of non-linear differential equations with either a stable singular point or a limit cycle. The resulting "BVP model" has two variables of state, representing excitability and refractoriness, and qualitatively resembles Bonhoeffer's theoretical model for the iron wire model of nerve. This BVP model serves as a simple representative of a class of excitable-oscillatory systems including the Hodgkin-Huxley (HH) model of the squid giant axon. The BVP phase plane can be divided into regions corresponding to the physiological states of nerve fiber (resting, active, refractory, enhanced, depressed, etc.) to form a "physiological state diagram," with the help of which many physiological phenomena can be summarized. A properly chosen projection from the 4-dimensional HH phase space onto a plane produces a similar diagram which shows the underlying relationship between the two models. Impulse trains occur in the BVP and HH models for a range of constant applied currents which make the singular point representing the resting state unstable.},
author = {Fitzhugh, R},
issn = {0006-3495},
journal = {Biophysical Journal},
month = {jul},
number = {6},
pages = {445--66},
pmid = {19431309},
title = {{Impulses and Physiological States in Theoretical Models of Nerve Membrane.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1366333{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {1},
year = {1961}
}
@article{LIN56,
author = {Lindley, D},
journal = {Annals of Mathematical Statistics},
pages = {986--1005},
title = {{On a measure of information provided by an experiment}},
volume = {29},
year = {1956}
}
@article{Guo,
archivePrefix = {arXiv},
arxivId = {arXiv:cs/0412108v1},
author = {Guo, Dongning and Shamai, S},
eprint = {0412108v1},
journal = {Information Theory, IEEE},
primaryClass = {arXiv:cs},
title = {{Mutual information and minimum mean-square error in Gaussian channels}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1412024},
year = {2005}
}
@article{Catsigeras2012,
abstract = {We study the global dynamics of integrate and fire neural networks composed of an arbitrary number of identical neurons interacting by inhibition and excitation. We prove that if the interactions are strong enough, then the support of the stable asymptotic dynamics consists of limit cycles. We also find sufficient conditions for the synchronization of networks containing excitatory neurons. The proofs are based on the analysis of the equivalent dynamics of a piecewise continuous Poincar{\'{e}} map associated to the system. We show that for efficient interactions the Poincar{\'{e}} map is piecewise contractive. Using this contraction property, we prove that there exist a countable number of limit cycles attracting all the orbits dropping into the stable subset of the phase space. This result applies not only to the Poincar{\'{e}} map under study, but also to a wide class of general n-dimensional piecewise contractive maps.},
author = {Catsigeras, Eleonora and Guiraud, Pierre},
doi = {10.1007/s00285-012-0560-7},
issn = {1432-1416},
journal = {Journal of mathematical biology},
keywords = {integrate and fire neural,limit cycles,networks,piecewise contractive maps},
month = {jul},
pmid = {22821206},
title = {{Integrate and fire neural networks, piecewise contractive maps and limit cycles.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22821206},
year = {2012}
}
@article{Ghani2011,
author = {Ghani, A and McDaid, LJ and Campus, Magee and Ireland, N and Hill, Brownlow and Liverpool, L},
isbn = {9781424496372},
journal = {{\ldots} (IJCNN), The 2011 {\ldots}},
pages = {1162--1168},
title = {{Evaluating the training dynamics of a CMOS based synapse}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6033355},
year = {2011}
}
@article{Mickus1999a,
author = {Mickus, Timothy and Jung, Hae-yoon and Spruston, Nelson},
doi = {10.1016/S0006-3495(99)77248-6},
issn = {0006-3495},
journal = {Biophysical Journal},
number = {2},
pages = {846--860},
publisher = {Elsevier},
title = {{Hippocampal CA1 Pyramidal Neurons}},
url = {http://dx.doi.org/10.1016/S0006-3495(99)77248-6},
volume = {76},
year = {1999}
}
@article{renart2010asynchronous,
annote = {2010IInum10.2},
author = {Renart, A and de la Rocha, J and Bartho, P and Hollender, L and Parga, N and Reyes, A and Harris, K D},
journal = {science},
number = {5965},
pages = {587},
publisher = {AAAS},
title = {{The Asynchronous State in Cortical Circuits}},
volume = {327},
year = {2010}
}
@book{Seung2012,
author = {Seung, S},
publisher = {Houghton Mifflin Harcourt},
title = {{Connectome: How the brain's wiring makes us who we are}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=uNDW{\_}dQ{\_}dlAC{\&}oi=fnd{\&}pg=PP2{\&}dq=sebastian+seung{\&}ots=G6Zyxkhc2O{\&}sig=7Ae39wKxU1jLI7e1-QSUeAJSD1E},
year = {2012}
}
@article{TanCarney03,
author = {Tan, Qing and Carney, Laurel H},
journal = {Journal of The Acoustical Society Of America},
month = {oct},
number = {4 Pt 1},
pages = {2007--2020},
title = {{A phenomenological model for the responses of auditory-nerve fibers II Nonlinear tuning with a frequency glide}},
volume = {114},
year = {2003}
}
@article{Morrison2008,
abstract = {Synaptic plasticity is considered to be the biological substrate of learning and memory. In this document we review phenomenological models of short-term and long-term synaptic plasticity, in particular spike-timing dependent plasticity (STDP). The aim of the document is to provide a framework for classifying and evaluating different models of plasticity. We focus on phenomenological synaptic models that are compatible with integrate-and-fire type neuron models where each neuron is described by a small number of variables. This implies that synaptic update rules for short-term or long-term plasticity can only depend on spike timing and, potentially, on membrane potential, as well as on the value of the synaptic weight, or on low-pass filtered (temporally averaged) versions of the above variables. We examine the ability of the models to account for experimental data and to fulfill expectations derived from theoretical considerations. We further discuss their relations to teacher-based rules (supervised learning) and reward-based rules (reinforcement learning). All models discussed in this paper are suitable for large-scale network simulations.},
author = {Morrison, Abigail and Diesmann, Markus and Gerstner, W},
doi = {10.1007/s00422-008-0233-1},
issn = {0340-1200},
journal = {Biological Cybernetics},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Synapses,Synapses: physiology,Time Factors,synapse},
mendeley-tags = {synapse},
month = {jun},
number = {6},
pages = {459--78},
pmid = {18491160},
title = {{Phenomenological models of synaptic plasticity based on spike timing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18491160},
volume = {98},
year = {2008}
}
@article{Hund2004,
abstract = {BACKGROUND: Computational biology is a powerful tool for elucidating arrhythmogenic mechanisms at the cellular level, where complex interactions between ionic processes determine behavior. A novel theoretical model of the canine ventricular epicardial action potential and calcium cycling was developed and used to investigate ionic mechanisms underlying Ca2+ transient (CaT) and action potential duration (APD) rate dependence. METHODS AND RESULTS: The Ca2+/calmodulin-dependent protein kinase (CaMKII) regulatory pathway was integrated into the model, which included a novel Ca2+-release formulation, Ca2+ subspace, dynamic chloride handling, and formulations for major ion currents based on canine ventricular data. Decreasing pacing cycle length from 8000 to 300 ms shortened APD primarily because of I(Ca(L)) reduction, with additional contributions from I(to1), I(NaK), and late I(Na). CaT amplitude increased as cycle length decreased from 8000 to 500 ms. This positive rate-dependent property depended on CaMKII activity. CONCLUSIONS: CaMKII is an important determinant of the rate dependence of CaT but not of APD, which depends on ion-channel kinetics. The model of CaMKII regulation may serve as a paradigm for modeling effects of other regulatory pathways on cell function.},
author = {Hund, Thomas J TJ J and Rudy, Y},
doi = {10.1161/01.CIR.0000147231.69595.D3},
issn = {1524-4539},
journal = {Circulation},
keywords = {4-Aminopyridine,4-Aminopyridine: pharmacology,Action Potentials,Animals,Artificial,Calcium,Calcium Channels,Calcium Signaling,Calcium Signaling: physiology,Calcium-Calmodulin-Dependent Protein Kinase Type 2,Calcium-Calmodulin-Dependent Protein Kinases,Calcium-Calmodulin-Dependent Protein Kinases: phys,Calcium: metabolism,Cardiac,Cardiac Pacing,Cardiac: enzymology,Cardiac: physiology,Cardiovascular,Chlorides,Chlorides: metabolism,Computational Biology,Computer Simulation,Delayed Rectifier Potassium Channels,Dogs,Heart Conduction System,Heart Conduction System: physiology,Heart Rate,Heart Rate: physiology,Heart Ventricles,Heart Ventricles: cytology,Ion Transport,Isoenzymes,Isoenzymes: physiology,L-Type,L-Type: metabolism,Models,Myocytes,Pericardium,Pericardium: physiology,Potassium,Potassium Channels,Potassium: metabolism,Ryanodine Receptor Calcium Release Channel,Ryanodine Receptor Calcium Release Channel: metabo,Sarcoplasmic Reticulum,Sarcoplasmic Reticulum: metabolism,Sodium,Sodium Channels,Sodium Channels: metabolism,Sodium Chloride Symporters,Sodium-Calcium Exchanger,Sodium-Calcium Exchanger: metabolism,Sodium: metabolism,Symporters,Symporters: metabolism,Voltage-Gated,Voltage-Gated: metabolism},
month = {nov},
number = {20},
pages = {3168--3174},
pmid = {15505083},
title = {{Rate dependence and regulation of action potential and calcium transient in a canine cardiac ventricular cell model.}},
url = {http://circ.ahajournals.org/cgi/reprint/01.CIR.0000147231.69595.D3v1.pdf http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1851913{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {110},
year = {2004}
}
@article{Nagayama2007,
author = {Nagayama, S and Zheng, S and Xiong, W and Fletcher, L V and Masurkar, A V and Davis, D J and Pieribone, V A and Chen, W R},
journal = {Neuron},
pages = {789--803},
title = {{In vivo simultaneous tracing and Ca{\^{}}{\{}2+{\}} imaging of local neuronal circuits.}},
volume = {53},
year = {2007}
}
@article{Djurisic08,
abstract = {The inputoutput transform performed by mitral cells, the principal projection neurons of the olfactory bulb, is one of the key factors in understanding olfaction. We used combined calcium and voltage imaging from the same neuron and computer modeling to investigate signal processing in the mitral cells, focusing on the glomerular dendritic tuft. The main finding was that the dendritic tuft functions as a single electrical compartment for subthreshold signals within the range of amplitudes detectable by voltage-sensitive dye recording. These evoked EPSPs had uniform characteristics throughout the glomerular tuft. The Ca2+ transients associated with spatially uniform subthreshold synaptic potentials were comparable but not equal in amplitude in all regions. The average range of normalized amplitudes of the EPSP-driven Ca2+ signals from different locations on dendritic branches in the glomerular tuft was relatively narrow and appeared to be independent of the dendritic surface-to-volume ratio. The computer simulations constrained by the imaging data indicated that a synchronized activation of [{\~{}}]100 synapses randomly distributed on tuft branches was sufficient to generate spatially homogenous EPSPs. This number of activated synapses is consistent with the data from anatomical studies. Furthermore, voltage attenuation of the EPSP along the primary dendrite at physiological temperature was weak compared with other cell types. In the model, weak attenuation of the EPSP along the primary dendrite could be accounted for by passive electrical properties of the mitral cell.
},
author = {Djurisic, Maja and Popovic, Marko and Carnevale, Nicholas and Zecevic, Dejan},
doi = {10.1523/JNEUROSCI.5296-07.2008},
journal = {J. Neurosci.},
number = {15},
pages = {4057--4068},
title = {{Functional Structure of the Mitral Cell Dendritic Tuft in the Rat Olfactory Bulb}},
url = {http://www.jneurosci.org/cgi/content/abstract/28/15/4057},
volume = {28},
year = {2008}
}
@article{MITDeepLearning,
author = {Hof, R D},
journal = {MIT Technology Review},
month = {apr},
title = {{Deep Learning}},
url = {http://www.technologyreview.com/featuredstory/513696/deep-learning/},
year = {2013}
}
@article{Derrida1982,
author = {Derrida, B. and Pomeau, Y.},
journal = {Physical Review Letters},
number = {9},
pages = {627--630},
publisher = {APS},
title = {{Classical diffusion on a random chain}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.48.627},
volume = {48},
year = {1982}
}
@article{Timme2004,
annote = {

2010IInum8.4},
author = {Timme, M and Wolf, F and Geisel, T},
journal = {Physical Review Letters},
title = {{Topological speed limits to network synchronization}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.92.074101},
year = {2004}
}
@article{Brodsky|2001|,
abstract = {A natural calculus for describing the bound-state structure of relativistic
composite systems in quantum field theory is the light-front Fock
expansion which encodes the properties of a hadrons in terms of a
set of frame-independent n-particle wavefunctions. Light-front quantization
in the doubly-transverse light-cone gauge has a number of remarkable
advantages, including explicit unitarity, a physical Fock expansion,
the absence of ghost degrees of freedom, and the decoupling properties
needed to prove factorization theorems in high momentum transfer
inclusive and exclusive reactions. A number of applications are discussed
in these lectures, including semileptonic B decays, two-photon exclusive
reactions, diffractive dissociation into jets, and deeply virtual
Compton scattering. The relation of the intrinsic sea to the light-front
wavefunctions is discussed. Light-front quantization can also be
used in the Hamiltonian form to construct an event generator for
high energy physics reactions at the amplitude level. The light-cone
partition function, summed over exponentiallyweighted light-cone
energies, has simple boost properties which may be useful for studies
in heavy ion collisions. I also review recent work which shows that
the structure functions measured in deep inelastic lepton scattering
are affected by final-state rescattering, thus modifying their connection
to light-front probability distributions. In particular, the shadowing
of nuclear structure functions is due to destructive interference
effects from leading-twist diffraction of the virtual photon, physics
not included in the nuclear light-cone wavefunctions.},
annote = {The paper discusses light front perturation theory and its applications{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to calculations of QCD processes and GPD},
author = {Brodsky, S J},
journal = {arXiv},
keywords = {generalized parton distribution,perturbation theory,physics,quantum chromodynamics},
pages = {111340},
title = {{QCD phenomenology and light-front wavefunctions}},
volume = {hep-ph}
}
@article{Borkowski2009,
author = {Borkowski, L.},
doi = {10.1103/PhysRevE.80.051914},
issn = {1539-3755},
journal = {Physical Review E},
number = {5},
pages = {1--6},
title = {{Response of a Hodgkin-Huxley neuron to a high-frequency input}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.80.051914},
volume = {80},
year = {2009}
}
@article{Antomonov1983,
author = {Antomonov, Yu. G.},
doi = {10.1007/BF01068748},
journal = {Cybernetics},
number = {5},
pages = {670--679},
title = {{Biological cybernetics: Results and prospects}},
volume = {18},
year = {1983}
}
@article{SHPI03,
author = {Shpigelman, L and Singer, Y and Paz, R and Vaadia, E},
journal = {NIPS},
title = {{Spikernels: embedding spike neurons in inner product spaces.}},
volume = {15},
year = {2003}
}
@inproceedings{Martens2011,
author = {Martens, James and Sutskever, I},
booktitle = {ICML '11},
pages = {1033--1040},
title = {{Learning recurrent neural networks with Hessian-free optimization}},
url = {http://www.cs.toronto.edu/{~}jmartens/docs/RNN{\_}HF.pdf},
year = {2011}
}
@article{LiuChen98,
author = {Liu, J S and Chen, R},
journal = {Journal of the American Statistical Association},
number = {443},
pages = {1032--1044},
publisher = {JSTOR},
title = {{Sequential Monte Carlo Methods for Dynamic Systems}},
volume = {93},
year = {1998}
}
@article{RS02,
author = {Reid, R and Shapley, R},
journal = {Journal of Neuroscience},
pages = {6158--6175},
title = {{Space and time maps of cone photoreceptor signals in macaque lateral geniculate nucleus}},
volume = {22},
year = {2002}
}
@article{Ching2012,
annote = {No units for parameters (e.g. F, Km)! Maybe check ref. 1-3 to get these. Its not clear whether they use fast kinetics to get slow dynamics (as Ronny suggested). Maybe I can use this specific model in the neuron paper?},
author = {Ching, S and Purdon, P L and Vijayan, S and Kopell, N J and Brown, E N},
doi = {10.1073/pnas.1121461109},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Circadian Rhytems},
mendeley-tags = {Circadian Rhytems},
month = {feb},
title = {{A neurophysiological-metabolic model for burst suppression}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1121461109},
year = {2012}
}
@article{Stein04,
author = {Stein, R B and Weber, D J and Aoyagi, Y and Prochazka, A and Wagenaar, J B M and Shoham, S and Normann, R A},
doi = {10.1113/jphysiol.2004.068668},
journal = {J Physiol (Lond)},
number = {3},
pages = {883--896},
title = {{Coding of position by simultaneously recorded sensory neurones in the cat dorsal root ganglion}},
url = {http://jp.physoc.org/cgi/content/abstract/560/3/883},
volume = {560},
year = {2004}
}
@article{SM03,
author = {Schnitzer, M and Meister, M},
journal = {Neuron},
pages = {499--511},
title = {{Multineuronal firing patterns in the signal from eye to brain}},
volume = {37},
year = {2003}
}
@article{Goychuk2008,
archivePrefix = {arXiv},
arxivId = {arXiv:physics/0407105v2},
author = {Goychuk, Igor},
eprint = {0407105v2},
pages = {1--11},
primaryClass = {arXiv:physics},
title = {{Fractional diffusion modeling of ion channel gating}},
year = {2008}
}
@article{Richardson2003,
abstract = {Many types of neurons exhibit subthreshold resonance. However, little is known about whether this frequency preference influences spike emission. Here, the link between subthreshold resonance and firing rate is examined in the framework of conductance-based models. A classification of the subthreshold properties of a general class of neurons is first provided. In particular, a class of neurons is identified in which the input impedance exhibits a suppression at a nonzero low frequency as well as a peak at higher frequency. The analysis is then extended to the effect of subthreshold resonance on the dynamics of the firing rate. The considered input current comprises a background noise term, mimicking the massive synaptic bombardment in vivo. Of interest is the modulatory effect an additional weak oscillating current has on the instantaneous firing rate. When the noise is weak and firing regular, the frequency most preferentially modulated is the firing rate itself. Conversely, when the noise is strong and firing irregular, the modulation is strongest at the subthreshold resonance frequency. These results are demonstrated for two specific conductance-based models and for a generalization of the integrate-and-fire model that captures subthreshold resonance. They suggest that resonant neurons are able to communicate their frequency preference to postsynaptic targets when the level of noise is comparable to that prevailing in vivo.},
author = {Richardson, M J E and Brunel, N and Hakim, Vincent},
doi = {10.1152/jn.00955.2002},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Algorithms,Electrophysiology,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Interneurons,Interneurons: physiology,Membrane Potentials,Membrane Potentials: physiology,Models,Neural Conduction,Neural Conduction: physiology,Neurological,Neurons,Neurons: physiology,Stochastic Processes,Synapses,Synapses: physiology},
month = {may},
number = {5},
pages = {2538--54},
pmid = {12611957},
title = {{From subthreshold to firing-rate resonance.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12611957},
volume = {89},
year = {2003}
}
@article{Fox1994,
author = {Fox, R F and Lu, Y N},
doi = {10.1103/PhysRevE.49.3421},
issn = {1063-651X},
journal = {Physical Review E},
month = {apr},
number = {4},
pages = {3421--3431},
title = {{Emergent collective behavior in large numbers of globally coupled independently stochastic ion channels}},
url = {http://pre.aps.org/abstract/PRE/v49/i4/p3421{\_}1},
volume = {49},
year = {1994}
}
@article{Weston2008,
address = {New York, New York, USA},
author = {Weston, Jason and Ratle, Fr{\'{e}}d{\'{e}}ric and Collobert, Ronan},
doi = {10.1145/1390156.1390303},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
pages = {1168--1175},
publisher = {ACM Press},
title = {{Deep learning via semi-supervised embedding}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390303},
year = {2008}
}
@article{BrenowitzRegehr07,
abstract = {Activity-dependent elevation of calcium within presynaptic boutons

regulates many aspects of synaptic transmission. Here, we examine

presynaptic residual calcium (Ca(res)) transients in individual presynaptic

boutons of cerebellar granule cells at near-physiological temperatures

using two-photon microscopy. Properties of Ca(res) under conditions

of zero-added buffer were determined by measuring Ca(res) transients

while loading boutons to a steady-state indicator concentration.

These experiments revealed that, in the absence of exogenous calcium

buffers, a single action potential evokes transients of Ca(res) that

vary widely in different boutons both in amplitude (400-900 nM) and

time course (25-55 ms). Variation in calcium influx density, endogenous

buffer capacity, and calcium extrusion density contribute to differences

in Ca(res) among boutons. Heterogeneity in Ca(res) within different

boutons suggests that plasticity can be regulated independently at

different synapses arising from an individual granule cell. In a

given bouton, Ca(res) signals were highly reproducible from trial

to trial and failures of calcium influx were not observed. We find

that a factor contributing to this reliability is that an action

potential opens a large number of calcium channels (20-125) in a

bouton. Presynaptic calcium signals were also used to assess the

ability of granule cell axons to convey somatically generated action

potentials to distant synapses. In response to pairs of action potentials

or trains, granule cell boutons showed a remarkable ability to respond

reliably at frequencies up to 500 Hz. Thus, individual boutons appear

specialized for reliable calcium signaling during bursts of high-frequency

activation such as those that are observed in vivo.},
author = {Brenowitz, Stephan D and Regehr, Wade G},
doi = {10.1523/JNEUROSCI.1064-07.2007},
journal = {J Neurosci},
keywords = {Action Potentials; Animals; Calcium Signaling; Cer,Sprague-Dawley},
month = {jul},
number = {30},
pages = {7888--7898},
pmid = {17652580},
title = {{Reliability and heterogeneity of calcium signaling at single presynaptic boutons of cerebellar granule cells.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.1064-07.2007},
volume = {27},
year = {2007}
}
@article{Cooney|2002|,
author = {Cooney, J and Hurlburt, J and Selig, D and Harris, K M and Fiala, J C},
journal = {J Neurosci},
number = {6},
pages = {2215--2224},
title = {{Endosomal compartments serve multiple hippocampal dendritic spines from a widespread rather than a local store of recycling membrane.}},
volume = {22}
}
@article{Manis90,
abstract = {Intracellular recordings were made from neurons of the guinea pig

dorsal cochlear nucleus in an in vitro brain slice preparation. The

membrane properties of the cells were studied, and the membrane potentials

were manipulated by current injection to determine how intrinsic

conductances might alter the cell discharge patterns. Eleven cells

were marked with Lucifer yellow. Ten of these cells were identified

as the large pyramidal cells of layer 2 of this nucleus, and 1 cell

was identified as a "vertical" cell in layer 3. Two kinds of action

potentials were observed: simple spikes and complex spikes. This

report discusses only cells with simple spikes. Simple spiking cells

(60/72 recorded cells; all stained cells were simple spiking cells)

discharged in a regular fashion with depolarization, and had linear

frequency-current relationships up to 2 nA with a mean slope of 116

Hz/nA. The discharge rate was approximately constant throughout the

current pulse. Responses of simple spiking cells to depolarizing

current steps superimposed on a steady-state membrane hyperpolarization

were studied. When the membrane has been held hyperpolarized, small

current pulses produce a long-latency regular train of action potentials.

Larger current pulses superimposed on membrane hyperpolarization

can produce a short-latency action potential followed by a long silent

interval (i.e., a long first interspike interval), and finally a

regular train of spikes. It is concluded that the membrane conductances

of DCN pyramidal cells are capable of generating at least 3 discharge

patterns (regular firing, long first spike latency, and long first

interspike interval) depending on the state of the membrane potential

prior to a depolarizing current step. These responses are similar

to the "chopper," "buildup," and "pauser" discharge patterns reported

for these cells in vivo in response to tone bursts. The modulation

of the intrinsic membrane conductances by membrane polarization and

the possible contribution of these conductances to the generation

of DCN discharge patterns provide new insights into the mechanisms

underlying the responses of DCN cells to acoustic stimuli.},
author = {Manis, P B},
journal = {J Neurosci},
keywords = {Animals; Brain Stem; Cell Membrane; Electric Condu},
month = {jul},
number = {7},
pages = {2338--2351},
pmid = {2376777},
title = {{Membrane properties and discharge characteristics of guinea pig dorsal cochlear nucleus neurons studied in vitro.}},
volume = {10},
year = {1990}
}
@article{Dorogovtsev|2002|,
abstract = {We propose a consistent approach to the statistics of the shortest
paths in random graphs with a given degree distribution. This approach
goes further than a usual tree ansatz and rigorously accounts for
loops in a network. We calculate the distribution of shortest-path
lengths (intervertex distances) in these networks and a number of
related characteristics for the networks with various degree distributions.
We show that in the large network limit this extremely narrow intervertex
distance distribution has a finite width while the mean intervertex
distance grows with the size of a network. The size dependence of
the mean intervertex distance is discussed in various situations.},
annote = {The paper is foudation-laying research/review of methods to describe{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}[random] networks},
author = {Dorogovtsev, S N and Mendes, J F F and Samukhin, A N},
journal = {arXiv},
keywords = {connected components,continuous networks,distance,internet,intervertex distance,metric,network metrics,networks,random geometry,random graphs,unread},
number = {0210085},
title = {{Metric structure of random networks}},
volume = {cond-mat}
}
@techreport{Widrow1960,
address = {Stanford, CA},
author = {Widrow, B and Hoff, ME},
institution = {STANFORD ELECTRONICS LABS},
title = {{Adaptive switching circuits}},
url = {http://www-isl.stanford.edu/people/widrow/papers/c1960adaptiveswitching.pdf},
year = {1960}
}
@article{Buschges2005,
author = {Bu, Ansgar and Buschges, A.},
doi = {10.1152/jn.00615.2004.},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {motor control},
mendeley-tags = {motor control},
number = {3},
pages = {1127},
publisher = {Am Physiological Soc},
title = {{Sensory control and organization of neural networks mediating coordination of multisegmental organs for locomotion}},
url = {http://jn.physiology.org/cgi/content/abstract/93/3/1127},
volume = {93},
year = {2005}
}
@article{Lelievre2012,
abstract = {We consider non-reversible perturbations of reversible diffusions that do not alter the invariant distribution and we ask whether there exists an optimal perturbation such that the rate of convergence to equilibrium is maximized. We solve this problem for the case of linear drift by proving the existence of such optimal perturbations and by providing an easily implementable algorithm for constructing them. We discuss in particular the role of the prefactor in the exponential convergence estimate. Our rigorous results are illustrated by numerical experiments.},
archivePrefix = {arXiv},
arxivId = {1212.0876},
author = {Leli{\`{e}}vre, Tony and Nier, Francis and Pavliotis, Grigorios a.},
eprint = {1212.0876},
keywords = {convergence to equilibrium,non-reversible diffusion,wick},
month = {dec},
pages = {6--8},
title = {{Optimal non-reversible linear drift for the convergence to equilibrium of a diffusion}},
url = {http://arxiv.org/abs/1212.0876},
year = {2012}
}
@article{Kvatinsky2013,
author = {Kvatinsky, S and Nacson, Y H and Etsion, Y and Friedman, E G and Kolodny, A and Weiser, U C},
journal = {Computer Architecture Letters},
number = {1},
pages = {41--44},
title = {{Memristor-based Multithreading}},
volume = {13},
year = {2013}
}
@article{ALD05,
author = {Aldworth, Z and Miller, J and Gedeon, T and Cummins, G and Dimitrov, A},
journal = {Journal of Neuroscience},
pages = {5323--5332},
title = {{Dejittered spike-conditioned stimulus waveforms yield improved estimates of neuronal feature selectivity and spike-timing precision of sensory interneurons}},
volume = {25},
year = {2005}
}
@article{Taghvaei2017,
abstract = {This paper is concerned with the problem of representing and learning a linear transformation using a linear neural network. In recent years, there has been a growing interest in the study of such networks in part due to the successes of deep learning. The main question of this body of research and also of this paper pertains to the existence and optimality properties of the critical points of the mean-squared loss function. The primary concern here is the robustness of the critical points with regularization of the loss function. An optimal control model is introduced for this purpose and a learning algorithm (regularized form of backprop) derived for the same using the Hamilton's formulation of optimal control. The formulation is used to provide a complete characterization of the critical points in terms of the solutions of a nonlinear matrix-valued equation, referred to as the characteristic equation. Analytical and numerical tools from bifurcation theory are used to compute the critical points via the solutions of the characteristic equation. The main conclusion is that the critical point diagram can be fundamentally different even with arbitrary small amounts of regularization.},
archivePrefix = {arXiv},
arxivId = {1709.09625},
author = {Taghvaei, Amirhossein and Kim, Jin W. and Mehta, Prashant G.},
eprint = {1709.09625},
file = {::},
journal = {arXiv},
month = {sep},
title = {{How regularization affects the critical points in linear networks}},
url = {http://arxiv.org/abs/1709.09625},
year = {2017}
}
@article{Schuman2017,
abstract = {Neuromorphic computing has come to refer to a variety of brain-inspired computers, devices, and models that contrast the pervasive von Neumann computer architecture. This biologically inspired approach has created highly connected synthetic neurons and synapses that can be used to model neuroscience theories as well as solve challenging machine learning problems. The promise of the technology is to create a brain-like ability to learn and adapt, but the technical challenges are significant, starting with an accurate neuroscience model of how the brain works, to finding materials and engineering breakthroughs to build devices to support these models, to creating a programming framework so the systems can learn, to creating applications with brain-like capabilities. In this work, we provide a comprehensive survey of the research and motivations for neuromorphic computing over its history. We begin with a 35-year review of the motivations and drivers of neuromorphic computing, then look at the major research areas of the field, which we define as neuro-inspired models, algorithms and learning approaches, hardware and devices, supporting systems, and finally applications. We conclude with a broad discussion on the major research topics that need to be addressed in the coming years to see the promise of neuromorphic computing fulfilled. The goals of this work are to provide an exhaustive review of the research conducted in neuromorphic computing since the inception of the term, and to motivate further work by illuminating gaps in the field where new research is needed.},
archivePrefix = {arXiv},
arxivId = {1705.06963},
author = {Schuman, Catherine D. and Potok, Thomas E. and Patton, Robert M. and Birdwell, J. Douglas and Dean, Mark E. and Rose, Garrett S. and Plank, James S.},
eprint = {1705.06963},
file = {:C$\backslash$:/Users/Daniel/Downloads/1705.06963.pdf:pdf},
isbn = {9781510829008},
pages = {1--88},
title = {{A Survey of Neuromorphic Computing and Neural Networks in Hardware}},
url = {http://arxiv.org/abs/1705.06963},
year = {2017}
}
@article{Hurvich1993,
abstract = {We consider the asymptotic distribution of the normalized periodogram ordinates I(03C9j)/f(03C9j) (j= 1,2,2026) of a general long-memory time series. Here, I(03C9;) is the periodogram based on a sample size n, f(03C9) is the spectral density and 03C9j= 203C0j/n. We assume that n2192221D with j held fixed, and so our focus is on low frequencies; these are the most important frequencies for the periodogram-based estimation of the memory parameter d. Contrary to popular belief, the normalized periodogram ordinates obtained from a Gaussian process are asymptotically neither independent identically distributed nor exponentially distributed. In fact, limn E{\{}I(03C9j)/f(03C9j){\}} depends on both j and d and is typically greater than unity, implying a positive asymptotic relative bias in I(03C9j) as an estimator of f(03C9j). Tapering is found to reduce this bias dramatically, except at frequency 03C91. The asymptotic distribution of I(03C9j)/f(03C9j) for a Gaussian process is, in general, that of an unequally weighted linear combination of two independent X21 random variables. The asymptotic mean of the log normalized periodogram depends on j and d and is not in general equal to the negative of Euler's constant, as is commonly assumed. Consequently, the regression estimator of d proposed by Geweke and Porter-Hudak will be asymptotically biased if the number of frequencies used in the regression is held fixed as n2192221D.},
author = {Hurvich, C M and Beltrao, K I},
doi = {10.1111/j.1467-9892.1993.tb00157.x},
issn = {0143-9782},
journal = {Journal of Time Series Analysis},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {sep},
number = {5},
pages = {455--472},
title = {{Asymptotics for the low-frequency ordinates of the periodogram of a long-memory time series}},
url = {http://www3.interscience.wiley.com/journal/119838632/abstract},
volume = {14},
year = {1993}
}
@article{Øuoo,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0306512v1},
author = {{\O}{\^{u}}{\'{o}}{\"{o}}, {\"{A}} {\~{N}} {\O} {\O} {\'{O}} {\AE} and {\"{O}}{\'{o}}{\`{o}}, {\"{E}} {\'{Y}} {\`{O}} and {\O}{\o}, {\`{O}} and {\O}{\^{u}}{\'{o}}{\"{o}}, {\`{O}} {\"{I}} and {\O}{\"{o}}, {\~{N}} {\'{O}} {\`{O}} and {\O}{\"{o}}, {\O} {\O} {\O} {\"{O}} {\`{O}} {\'{O}} {\~{N}} {\~{N}} and {\`{U}}{\"{o}}, {\`{U}} {\O} {\'{O}} and {\^{O}}{\"{o}}, {\O} Ð {\'{Y}} and {\"{O}}{\'{o}}{\`{o}}, {\'{O}} {\'{Y}} {\`{O}} and {\O}{\^{u}}{\'{o}}{\"{o}}, Þ {\O} {\'{O}} {\`{O}} {\`{O}} {\`{U}} {\`{O}} and {\'{O}}{\`{o}}, {\^{O}} {\`{O}} {\`{O}} {\O} and {\^{O}}, {\`{U}} {\"{O}} {\O} {\"{O}}{\~{n}}{\'{o}}{\"{o}} {\^{U}} {\'{O}} {\^{U}} {\O} {\O} {\O} and {\O}, {\'{O}} {\'{Y}} {\`{O}} {\"{O}} {\'{O}} {\`{O}} Þ {\O} {\'{O}} {\`{O}} Ð {\~{N}} and {\'{A}}{\`{o}}, {\'{O}} {\~{N}} {\`{O}} {\`{O}} {\O} and {\O}, {\O} {\'{O}} {\`{O}} {\'{O}} {\`{U}} {\"{O}} {\"{O}} {\`{U}} Ð {\O} {\`{O}} {\O} {\O} and {\"{O}}{\'{o}}{\`{o}}{\'{y}}, {\'{Y}} {\`{O}} and {\`{U}}{\`{o}}, {\"{O}} {\'{O}} {\`{U}} {\O} and {\O}{\`{u}}{\"{o}}, {\"{O}} {\O} {\"{O}} {\`{U}} and {\'{O}}{\`{o}}, Ð {\^{O}} {\"{O}}{\o}{\`{u}}{\"{o}} {\O} and {\'{Y}}{\`{o}}, {\'{O}} {\O} {\`{O}} {\O}{\^{u}}{\'{o}}{\"{o}} and {\`{O}}{\`{u}}{\~{n}}, {\`{E}} {\"{E}} {\"{O}} and {\O}{\^{u}}{\'{o}}{\"{o}}, {\'{O}}{\~{n}}{\^{o}}ð {\"{U}} {\`{O}} and {\`{O}}{\o}, {\"{O}} {\O} {\`{O}} {\O} and {\`{O}}{\'{o}}{\"{o}}{\~{n}}{\'{o}}{\`{u}}, {\"{O}} and {\O}{\`{u}}{\"{o}}, {\O} {\"{O}} {\`{U}} and {\`{O}}{\o}, {\"{O}} {\^{O}} {\O} and {\O}{\`{u}}, {\AA} {\'{O}} {\O} and {\O}{\^{u}}{\'{o}}{\"{o}}, Ð {\`{O}} and {\O}, {\"{O}} {\^{U}} {\`{O}} {\"{O}} {\'{O}} {\~{N}} and {\^{O}}{\o}, {\'{Y}} {\`{O}} and {\O}{\'{o}}{\"{o}}, {\'{O}} Ð Ð and {\'{O}}{\`{o}}, {\~{O}} {\`{U}} {\O} and {\^{A}}{\'{o}}, {\^{O}} and Ðð, {\'{O}} and {\'{A}}{\o}, {\^{U}} and {\^{O}}, {\`{O}} {\O} {\`{O}} {\O} {\`{O}} {\'{O}} {\`{U}}},
eprint = {0306512v1},
primaryClass = {arXiv:cond-mat},
title = {{{\`{I}}{\'{o}}{\^{o}}{\'{o}}ð{\'{o}} ð {\"{e}}{\^{o}}}}
}
@article{Yasumatsu2008,
abstract = {Long-term potentiation of synapse strength requires enlargement of dendritic spines on cerebral pyramidal neurons. Long-term depression is linked to spine shrinkage. Indeed, spines are dynamic structures: they form, change their shapes and volumes, or can disappear in the space of hours. Do all such changes result from synaptic activity, or do some changes result from intrinsic processes? How do enlargement and shrinkage of spines relate to elimination and generation of spines, and how do these processes contribute to the stationary distribution of spine volumes? To answer these questions, we recorded the volumes of many individual spines daily for several days using two-photon imaging of CA1 pyramidal neurons in cultured slices of rat hippocampus between postnatal days 17 and 23. With normal synaptic transmission, spines often changed volume or were created or eliminated, thereby showing activity-dependent plasticity. However, we found that spines changed volume even after we blocked synaptic activity, reflecting a native instability of these small structures over the long term. Such "intrinsic fluctuations" showed unique dependence on spine volume. A mathematical model constructed from these data and the theory of random fluctuations explains population behaviors of spines, such as rates of elimination and generation, stationary distribution of volumes, and the long-term persistence of large spines. Our study finds that generation and elimination of spines are more prevalent than previously believed, and spine volume shows significant correlation with its age and life expectancy. The population dynamics of spines also predict key psychological features of memory.},
annote = {2008num29},
author = {Yasumatsu, N and Matsuzaki, M and Miyazaki, T and Noguchi, J and Kasai, H},
doi = {10.1523/JNEUROSCI.0603-08.2008},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Dendritic Spines,Dendritic Spines: physiology,Hippocampus,Hippocampus: physiology,Long-Term Potentiation,Long-Term Potentiation: physiology,Models,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: metabolism,Neurological,Organ Culture Techniques,Rats,Receptors,Sprague-Dawley,Theoretical},
number = {50},
pages = {13592--13608},
pmid = {19074033},
title = {{Principles of long-term dynamics of dendritic spines.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19074033},
volume = {28},
year = {2008}
}
@article{BIA91,
author = {Bialek, W and Rieke, F and {de Ruyter van Steveninck}, R and Warland, D},
journal = {Science},
pages = {1854--1857},
title = {{Reading a neural code}},
volume = {252},
year = {1991}
}
@article{RhodeSmith83,
author = {Rhode, W S and Smith, P H and Oertel, D},
journal = {The Journal of Comparative Neurology},
month = {feb},
number = {4},
pages = {448--463},
title = {{Physiological response properties of cells labeled intracellularly with horseradish peroxidase in cat ventral cochlear nucleus}},
volume = {213},
year = {1983}
}
@article{Xu2015,
abstract = {In this paper we investigate the performance of different types of rectified activation functions in convolutional neural network: standard rectified linear unit (ReLU), leaky rectified linear unit (Leaky ReLU), parametric rectified linear unit (PReLU) and a new ran- domized leaky rectified linear units (RReLU). We evaluate these activation function on standard image classification task. Our experiments suggest that incorporating a non-zero slope for negative part in rectified activation units could consistently improve the results. Thus our findings are negative on the common belief that sparsity is the key of good performance in ReLU. Moreover, on small scale dataset, using deterministic negative slope or learning it are both prone to overfitting. They are not as effective as using their randomized counterpart.},
archivePrefix = {arXiv},
arxivId = {1505.00853},
author = {Xu, Bing and Wang, Naiyan and Chen, Tianqi and Li, Mu},
eprint = {1505.00853},
journal = {ICML Deep Learning Workshop},
title = {{Empirical Evaluation of Rectified Activations in Convolution Network}},
year = {2015}
}
@article{Peters2006,
author = {Peters, O and Neelin, JD},
journal = {Nature Physics},
title = {{Critical phenomena in atmospheric precipitation}},
url = {http://www.nature.com/nphys/journal/v2/n6/abs/nphys314.html},
year = {2006}
}
@article{Kaufman08,
author = {Kaufman, Cari G and Schervish, Mark J and Nychka, Douglas W},
journal = {Journal of the American Statistical Association},
number = {484},
pages = {1545--1555},
title = {{Covariance Tapering for Likelihood-Based Estimation in Large Spatial Data Sets}},
volume = {103},
year = {2008}
}
@book{Strogatz1994,
address = {New York},
author = {Strogatz, S H},
isbn = {0-201-54344-3},
publisher = {Perseus Books},
title = {{Nonlinear dynamics and chaos}},
year = {1994}
}
@article{Anshelevich1982,
author = {Anshelevich, VV V and Khanin, KM M and Sinai, Y.G. G},
journal = {Communications in Mathematical Physics},
number = {3},
pages = {449--470},
publisher = {Springer},
title = {{Symmetric random walks in random environments}},
url = {http://www.springerlink.com/index/kn40t6p67674678v.pdf},
volume = {85},
year = {1982}
}
@article{Xu2012,
abstract = {We derive generalization bounds for learning algorithms based on their robustness: the property that if a testing sample is "similar" to a training sample, then the testing error is close to the training error. This provides a novel approach, different from the complexity or stability arguments, to study generalization of learning algorithms. We further show that a weak notion of robustness is both sufficient and necessary for generalizability, which implies that robustness is a fundamental property for learning algorithms to work.},
archivePrefix = {arXiv},
arxivId = {1005.2243},
author = {Xu, Huan and Mannor, Shie},
doi = {10.1007/s10994-011-5268-1},
eprint = {1005.2243},
isbn = {9780982252925},
issn = {08856125},
journal = {Machine Learning},
keywords = {Generalization,Non-IID sample,Quantile loss,Robust},
number = {3},
pages = {391--423},
pmid = {19626713},
title = {{Robustness and generalization}},
volume = {86},
year = {2012}
}
@article{Genz2004,
author = {Genz, A},
journal = {Statistics and Computing},
number = {3},
pages = {251--260},
title = {{Numerical computation of rectangular bivariate and trivariate normal and t probabilities}},
url = {http://medcontent.metapress.com/index/A65RM03P4874243N.pdf http://link.springer.com/article/10.1023/B:STCO.0000035304.20635.31},
volume = {14},
year = {2004}
}
@article{Gray2005,
author = {Gray, J M and Hill, J J and Bargmann, C I},
journal = {PNAS},
pages = {3184},
title = {{A circuit for navigation in Caenorhabditis elegans.}},
volume = {102},
year = {2005}
}
@article{Batenburg|2005|,
abstract = {In this paper we propose a new algorithm for reconstructing 3D binary
images on a lattice from a small number of their projections. The
algorithm is iterative; a new 3D image is computed in each iteration,
using network flow methods. It is based on an algorithm for computing
3D reconstructions, which performs very well for a large class of
images. We demonstrate the performance of our algorithm on a set
of characteristic test images.},
annote = {This paper describes a fast method for computing binary 3D tomography,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}based on linear summation of binary {\&}{\#}039;atoms{\&}{\#}039; along the line of sight,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}utilizing linear programming algorithms (network flow) to resolve{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}this problem as a linear-constrained optimization with tweaks.},
author = {Batenburg, K J},
keywords = {binary images,discrete tomography,mathematics,network flow},
title = {{A new algorithm for 3D binary tomography}}
}
@article{Chomsky|1957|,
annote = {This is fundamental paper of mathematical linguistic},
author = {Chomsky, N},
keywords = {codes,language,linguistics,markov,mathematics,phonetics,syntactic structures},
pages = {11},
title = {{Syntactic Structures}}
}
@article{Hromadka2009,
abstract = {How does auditory cortex represent auditory stimuli, and how do these representations contribute to behavior? Recent experimental evidence suggests that activity in auditory cortex consists of sparse and highly synchronized volleys of activity, observed both in anesthetized and awake animals. Many neurons are capable of remarkably precise activity with very low jitter or spike count variability. Most importantly, animals are capable of exploiting such precise neuronal activity in making sensory decisions. Whether the ability of auditory cortex to exploit fine temporal differences in cortical activity is unique to auditory modality, or represents a general strategy used by cortical circuits remains an open question.},
author = {Hrom{\'{a}}dka, Tom{\'{a}}s and Zador, A M},
doi = {10.1016/j.conb.2009.07.009},
issn = {1873-6882},
journal = {Current opinion in neurobiology},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Auditory,Auditory Cortex,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Auditory: physiology,Evoked Potentials,Neurons,Neurons: physiology},
month = {aug},
number = {4},
pages = {430--3},
pmid = {19674890},
title = {{Representations in auditory cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2757052{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {19},
year = {2009}
}
@article{Hwang1972,
abstract = {New necessary and sufficient conditions are presented for the observability of systems described by nonlinear ordinary differential equations with nonlinear observations. The conditions are based on extension of the necessary and sufficient conditions for observability of time-varying linear systems to the linearized trajectory of the nonlinear system. The result is that the local observability of any initial condition can be readily determined, and the observability of the entire initial domain can be computed. The observability of constant parameters appearing in the differential equations is also considered. Examples are presented to illustrate the theory.},
author = {Hwang, M. and Seinfeld, J. H.},
doi = {10.1007/BF00934972},
issn = {0022-3239},
journal = {Journal of Optimization Theory and Applications},
keywords = {Mathematics and Statistics},
month = {aug},
number = {2},
pages = {67--77},
publisher = {Springer Netherlands},
title = {{Observability of nonlinear systems}},
url = {http://www.springerlink.com/content/kr35867706745170/},
volume = {10},
year = {1972}
}
@misc{Hlavac|2006|,
annote = {This lecture presentation provides great discussion on bayessian{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}decision making},
author = {Hlavac, V},
keywords = {bayessian,decision making,mathematics,neurobiology,unread},
title = {{Non-bayesian decision making}}
}
@article{Nykamp2009,
abstract = {We present an analysis of interactions among neurons in stimulus-driven networks that is designed to control for effects from unmeasured neurons. This work builds on previous connectivity analyses that assumed connectivity strength to be constant with respect to the stimulus. Since unmeasured neuron activity can modulate with the stimulus, the effective strength of common input connections from such hidden neurons can also modulate with the stimulus. By explicitly accounting for the resulting stimulus-dependence of effective interactions among measured neurons, we are able to remove ambiguity in the classification of causal interactions that resulted from classification errors in the previous analyses. In this way, we can more reliably distinguish causal connections among measured neurons from common input connections that arise from hidden network nodes. The approach is derived in a general mathematical framework that can be applied to other types of networks. We illustrate the effects of stimulus-dependent connectivity estimates with simulations of neurons responding to a visual stimulus.},
author = {Nykamp, D Q},
doi = {10.1007/s00285-008-0224-9},
issn = {1432-1416},
journal = {Journal of mathematical biology},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Computer Simulation,Humans,Likelihood Functions,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Photic Stimulation,ROC Curve},
month = {aug},
number = {2},
pages = {147--73},
pmid = {18830595},
title = {{A stimulus-dependent connectivity analysis of neuronal networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18830595},
volume = {59},
year = {2009}
}
@article{PAN02,
author = {Paninski, L and Fellows, M and Shoham, S and Donoghue, J},
journal = {Society for Neuroscience Abstracts},
title = {{Nonlinear encoding and decoding in primary motor cortex}},
volume = {28},
year = {2002}
}
@article{FB02,
author = {Fourcaud, N and Brunel, N},
journal = {Neural Computation},
pages = {2057--2110},
title = {{Dynamics of the firing probability of noisy integrate-and-fire neurons}},
volume = {14},
year = {2002}
}
@article{Liebovitch1990,
author = {Liebovitch, L S and T{\'{o}}th, T.I.},
journal = {Annals of Biomedical Engineering},
number = {2},
pages = {177--194},
publisher = {Springer},
title = {{Using fractals to understand the opening and closing of ion channels}},
url = {http://www.springerlink.com/index/L6M728N3V2HP2247.pdf},
volume = {18},
year = {1990}
}
@article{NRS85,
author = {Nobile, A and Ricciardi, L and Sacerdote, L},
journal = {Journal of Applied Probability},
pages = {346--359},
title = {{A Note on First-Passage Time and Some Related Problems}},
volume = {22},
year = {1985}
}
@article{Brown1966,
annote = {2009num62},
author = {Brown, MC and Stein, RB},
journal = {Biological Cybernetics},
number = {4},
pages = {175--185},
publisher = {Springer},
title = {{Quantitative studies on the slowly adapting stretch receptor of the crayfish}},
url = {http://www.springerlink.com/index/Q726R17226747H34.pdf},
volume = {3},
year = {1966}
}
@article{Stevenson08,
author = {Stevenson, I H and Rebesco, J and Hatsopoulos, N and Haga, Z and Miller, L and Koerding, K},
journal = {Statistical Analysis of Neural Data meeting},
title = {{Inferring network structure from spikes}},
year = {2008}
}
@article{TP95,
author = {Treves, A and Panzeri, S},
journal = {Neural Computation},
pages = {399--407},
title = {{The upward bias in measures of information derived from limited data samples}},
volume = {7},
year = {1995}
}
@article{Jylanki2013,
archivePrefix = {arXiv},
arxivId = {1303.6938},
author = {Jyl{\"{a}}nki, Pasi and Nummenmaa, Aapo and Vehtari, Aki},
eprint = {1303.6938},
keywords = {expectation propagation,linear model,multilayer perceptron,neural network,sparse},
month = {mar},
pages = {1--39},
title = {{Expectation Propagation for Neural Networks with Sparsity-promoting Priors}},
url = {http://arxiv.org/abs/1303.6938v1},
year = {2013}
}
@article{Rudy1978,
author = {Rudy, B Y B},
doi = {10.1017/S0025315400056939},
issn = {0022-3751},
journal = {The Journal of Physiology},
month = {nov},
number = {1},
pages = {1003},
title = {{Slow inactivation of the sodium conductance in squid giant axons. Pronase resistance.}},
volume = {283},
year = {1978}
}
@article{Greenstein1969a,
abstract = {Previous experimental comparisons of 1/f and Nyquist noise in carbon resistorsreveal that both are normally distributed in any time intervalbut that 1/f noise appears to have a nonstationary variance.The present paper examines the possibility that this fluctuation iscaused by insufficient sampling of the 1/f noise signal. Itis hypothesized that the 1/f noise is wide-sense stationary andthe number of independent samples per measurement is found andshown to be far less than that for Nyquist noise.An experiment is then described in which the number ofsamples is sufficiently large to eliminate this source of variancefluctuation. The results exhibit the same spread in measured 1/f noise variance reported earlier, suggesting that an intrinsic nonstationarity doesexist in this noise process when produced in carbon resistors. {\textcopyright}1969 The American Institute of Physics},
author = {Greenstein, L J and Brophy, J J},
journal = {Journal of Applied Physics},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {feb},
number = {2},
pages = {682--685},
publisher = {AIP},
shorttitle = {J. Appl. Phys.},
title = {{Influence of Lower Cutoff Frequency on the Measured Variance of 1/f Noise}},
url = {http://link.aip.org/link/?JAP/40/682/1 http://link.aip.org/link/?JAPIAU/40/682/1},
volume = {40},
year = {1969}
}
@book{Hebb2002,
address = {Mahwah, NJ, USA},
author = {Hebb, D O},
publisher = {Lawerence Erlbaum Associates, Inc.},
title = {{The organization of behavior: A neuropsychological theory}},
url = {http://scholar.google.com/scholar?q=The+Organization+of+Behavior{\#}4},
year = {2002}
}
@article{Drew2006a,
annote = {2009num53},
author = {Drew, PJ and Abbott, L F},
doi = {10.1152/jn.00134.2006},
journal = {Journal of neurophysiology},
pages = {826--833},
title = {{Models and properties of power-law adaptation in neural systems}},
url = {http://jn.physiology.org/content/96/2/826.short},
year = {2006}
}
@article{chsuperfluidity,
abstract = {In a classical liquid the elementary excitations are composed of sound
waves and turbulent eddies. As the temperature is decreased any liquid
approaches a limit where the quantum-properties of the elementary
excitations become important. The liquid is then called a quantum
liquid. Landau did much of the pioneering work in the theory of quantum
liquids. His earlier work separated quantum liquids into Fermi-type
and Bose-type. He3 and He4, respectively, are the relevant examples
of liquids of these two types. Super uidity, at least as understood
in this context, is associated with Bose-type liquids.},
annote = {This is chapter in a book on superfluidity. It provides good description
including Landau's theory of superfluidity and role of nonmomnotonic
dispersion relation.},
keywords = {bogoliubov transformation,physics,quantum mechanics,superfluidity},
title = {{Superfluidity}}
}
@article{Xu-Friedman|2001|,
author = {Xu-Friedman, M A and Harris, K M and Regehr, W G},
journal = {J Neurosci},
number = {17},
pages = {6666--6672},
title = {{Three-Dimensional Comparison of Ultrastructural Characteristics at Depressing and Facilitating Synapses onto Cerebellar Purkinje Cells.}},
volume = {21}
}
@article{GuerreroIsacoff05,
abstract = {At the Drosophila melanogaster larval neuromuscular junction (NMJ),

a motor neuron releases glutamate from 30-100 boutons onto the muscle

it innervates. How transmission strength is distributed among the

boutons of the NMJ is unknown. To address this, we created synapcam,

a version of the Ca2+ reporter Cameleon. Synapcam localizes to the

postsynaptic terminal and selectively reports Ca2+ influx through

glutamate receptors (GluRs) with single-impulse and single-bouton

resolution. GluR-based Ca2+ signals were uniform within a given connection

(that is, a given bouton/postsynaptic terminal pair) but differed

considerably among connections of an NMJ. A steep gradient of transmission

strength was observed along axonal branches, from weak proximal connections

to strong distal ones. Presynaptic imaging showed a matching axonal

gradient, with higher Ca2+ influx and exocytosis at distal boutons.

The results suggest that transmission strength is mainly determined

presynaptically at the level of individual boutons, possibly by one

or more factors existing in a gradient.},
author = {Guerrero, Giovanna and Reiff, Dierk F and Rieff, Dierk F and Agarwal, Gautam and Ball, Robin W and Borst, Alexander and Goodman, Corey S and Isacoff, Ehud Y},
doi = {10.1038/nn1526},
journal = {Nat Neurosci},
keywords = {Animals; Animals,Developmental; Immunohistochemistry; Larva; Lumin,Genetically Modified; Axons; Calcium Signaling; D,Insertional; Neuromuscular Junction; Patch-Clamp},
month = {sep},
number = {9},
pages = {1188--1196},
pmid = {16116446},
title = {{Heterogeneity in synaptic transmission along a Drosophila larval motor axon.}},
url = {http://dx.doi.org/10.1038/nn1526},
volume = {8},
year = {2005}
}
@article{GILL06,
author = {Gill, P and Zhang, J and Woolley, S and Fremouw, T and Theunissen, F},
journal = {Journal of Computational Neuroscience},
pages = {5--20},
title = {{Sound representation methods for spectro-temporal receptive field estimation}},
volume = {21},
year = {2006}
}
@article{Cai2013,
abstract = {This paper studies the asymptotic behaviors of the pairwise angles among n randomly and uniformly distributed unit vectors in R{\^{}}p as the number of points n -{\textgreater} infinity, while the dimension p is either fixed or growing with n. For both settings, we derive the limiting empirical distribution of the random angles and the limiting distributions of the extreme angles. The results reveal interesting differences in the two settings and provide a precise characterization of the folklore that "all high-dimensional random vectors are almost always nearly orthogonal to each other". Applications to statistics and machine learning and connections with some open problems in physics and mathematics are also discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1306.0256v1},
author = {Cai, Tony and Fan, Jianqing and Jiang, Tiefeng},
eprint = {arXiv:1306.0256v1},
isbn = {1532-4435 (Print)$\backslash$r1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {empirical law,extreme-value distribution,maximum of,minimum of random variables,packing on,random angle,random variables,uniform distribution on sphere},
pages = {1837--1864},
pmid = {25324693},
title = {{Distributions of Angles in Random Packing on Spheres}},
url = {http://arxiv.org/abs/1306.0256},
volume = {14},
year = {2013}
}
@article{Reyes98,
author = {Reyes, A and Lujan, R and Rozov, A and Burnashev, N and Somogyi, P and Sakmann, B},
journal = {Nat Neurosci},
pages = {279--285},
title = {{Target-cell-specific facilitation and depression in neocortical circuits}},
volume = {1},
year = {1998}
}
@article{Robbins1951,
abstract = {Let M(x) denote the expected value at level x of the response to a certain experiment. M(x) is assumed to be a monotone function of x but is unknown to the experimenter, and it is desired to find the solution x = $\theta$ of the equation M(x) = $\alpha$, where $\alpha$ is a given constant. We give a method for making successive experiments at levels x1,x2,⋯ in such a way that xn will tend to $\theta$ in probability.},
author = {Robbins, Herbert and Monro, Sutton},
doi = {10.1214/aoms/1177729586},
journal = {The Annals of Mathematical Statistics},
number = {3},
pages = {400--407},
title = {{A stochastic approximation method}},
volume = {22},
year = {1951}
}
@article{Brower1978,
author = {Brower, RC and Furman, MA and Moshe, M},
journal = {Physics Letters B},
title = {{Critical exponents for the Reggeon quantum spin model}},
url = {http://www.sciencedirect.com/science/article/pii/0370269378902794},
year = {1978}
}
@article{Wiggins|2003|,
abstract = {Motivated by recent experimental developments in functional genomics,
we construct and test a numerical technique for inferring process
pathways, in which one process calls another process, from time series
data. We validate using a case in which data are readily available
and we formulate an extension, appropriate for genetic regulatory
networks, which exploits Bayesian inference and in which the present-day
undersampling is compensated for by prior understanding of genetic
regulation.},
annote = {This interesting paper introduces an attempt to infer interecting{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}network structure via time series of measurments from its nodes},
author = {Wiggins, C H and Nemenman, I},
journal = {Experimental Mechanics},
keywords = {activity imaging,computational,networks},
number = {3},
pages = {361},
title = {{Process pathway inference via time series analysis}},
volume = {43}
}
@article{Kirov|1999|,
author = {Kirov, S A and Sorra, K E and Harris, K M},
journal = {J. Neurosci.},
pages = {2876--2886},
title = {{Slices Have More Synapses than Perfusion-Fixed Hippocampus from both Young and Mature Rats}},
volume = {19}
}
@article{BALSER1990,
author = {BALSER, J},
doi = {10.1016/S0006-3495(90)82560-1},
issn = {00063495},
journal = {Biophysical Journal},
number = {3},
pages = {433--444},
title = {{Global parameter optimization for cardiac potassium channel gating models}},
url = {http://dx.doi.org/10.1016/S0006-3495(90)82560-1},
volume = {57},
year = {1990}
}
@article{Pennington2017,
abstract = {Understanding the geometry of neural network loss surfaces is important for the development of improved optimization algorithms and for building a theoretical understanding of why deep learning works. In this paper, we study the geometry in terms of the distribution of eigenvalues of the Hessian matrix at critical points of varying energy. We introduce an analytical framework and a set of tools from random matrix theory that allow us to compute an approximation of this distribution under a set of simplifying assumptions. The shape of the spectrum depends strongly on the energy and another key parameter, {\$}\phi{\$}, which measures the ratio of parameters to data points. Our analysis predicts and numerical simulations support that for critical points of small index, the number of negative eigenvalues scales like the 3/2 power of the energy. We leave as an open problem an explanation for our observation that, in the context of a certain memorization task, the energy of minimizers is well-approximated by the function {\$}1/2(1-\phi){\^{}}2{\$}.},
author = {Pennington, Jeffrey and Bahri, Yasaman},
issn = {1938-7228},
journal = {Proceedings of the 34th International Conference on Machine Learning},
pages = {2798--2806},
title = {{Geometry of Neural Network Loss Surfaces via Random Matrix Theory}},
url = {http://proceedings.mlr.press/v70/pennington17a.html},
volume = {70},
year = {2017}
}
@article{Molgedey1992,
author = {Molgedey, L and Schuchhardt, J and Schuster, HG G},
issn = {1079-7114},
journal = {Physical Review Letters},
number = {26},
pages = {3717--3719},
publisher = {APS},
title = {{Suppressing chaos in neural networks by noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.69.3717},
volume = {69},
year = {1992}
}
@article{Zhitnitsky|2003|,
abstract = {We discuss a novel cold dark matter candidate which is formed from
the ordinary quarks during the QCD phase transition when the axion
domain wall undergoes an unchecked collapse due to the tension in
the wall. If a large number of quarks is trapped inside the bulk
of a closed axion domain wall, the collapse stops due to the internal
Fermi pressure. In this case the system in the bulk, may reach the
critical density when it undergoes a phase transition to a color
superconducting phase with the ground state being the quark condensate,
similar to the Cooper pairs in BCS theory. If this happens, the new
state of matter representing the diquark condensate with a large
baryon number B approx10{\^{}}32 becomes a stable soliton-like configuration.
Consequently, it may serve as a novel cold dark matter candidate.},
author = {Zhitnitsky, A R},
journal = {arXiv},
keywords = {astrophysics,baryonic,candidate,dark matter,interaction,physics,strongly interacting dark matter,superconductor},
pages = {202161},
title = {{Nonbaryonic Dark Matter as Baryonic Color Superconductor}},
volume = {hep-ph}
}
@article{Cox1954,
annote = {2010num1.4},
author = {Cox, D R and Smith, WL},
journal = {Biometrika},
title = {{On the superposition of renewal processes}},
url = {http://biomet.oxfordjournals.org/cgi/reprint/41/1-2/91.pdf},
year = {1954}
}
@article{SzobotaIsacoff07,
author = {Szobota, S and Gorostiza, P and {Del Bene}, F and Wyart, C and Fortin, D L and Kolstad, K D and Tulyathan, O and Volgraf, M and Numano, R and Aaron, H L and Scott, E K and Kramer, R H and Flannery, J and Baier, H and Trauner, D and Isacoff, E Y},
journal = {Neuron},
pages = {535--545},
title = {{Remote control of neuronal activity with a light-gated glutamate receptor.}},
volume = {54},
year = {2007}
}
@article{Hinrichsen2000,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0001070v2},
author = {Hinrichsen, Haye},
eprint = {0001070v2},
journal = {Advances in physics},
keywords = {absor-,bing state transitions,contact process,damage spreading,depinning transitions,directed percolation,interface growth,nonequilibrium phase transitions,nonequilibrium wetting,parity-conserving class,roughening transitions,stochastic lattice models},
pages = {1--153},
primaryClass = {arXiv:cond-mat},
title = {{Nonequilibrium Critical Phenomena and Phase Transitions into Absorbing States}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00018730050198152},
year = {2000}
}
@article{weiss01correctness,
author = {Weiss, Yair and Freeman, William T},
journal = {Neural Computation},
number = {10},
pages = {2173--2200},
title = {{Correctness of Belief Propagation in {\{}G{\}}aussian Graphical Models of Arbitrary Topology}},
volume = {13},
year = {2001}
}
@article{Candes2008,
author = {Candes, E J and Wakin, M},
journal = {IEEE Signal Processing Magazine},
number = {2},
pages = {21--30},
title = {{An introduction to compressive sampling}},
volume = {25},
year = {2008}
}
@article{BS03,
author = {Butts, D and Stanley, G},
journal = {Society for Neuroscience Abstracts},
title = {{Quick and accurate information calculations based on linear characterizations of sensory neurons}},
year = {2003}
}
@article{Bianchini1994,
abstract = {Many researchers have recently focused their efforts on devising efficient algorithms, mainly based on optimization schemes, for learning the weights of recurrent neural networks. As in the case of feedforward networks, however, these learning algorithms may get stuck in local minima during gradient descent, thus discovering sub-optimal solutions. This paper analyses the problem of optimal learning in recurrent networks by proposing conditions that guarantee local minima free error surfaces. An example is given that also shows the constructive role of the proposed theory in designing networks suitable for solving a given task. Moreover, a formal relationship between recurrent and static feedforward networks is established such that the examples of local minima for feedforward networks already known in the literature can be associated with analogous ones in recurrent networks.},
author = {Bianchini, M and Gori, M and Maggini, M},
doi = {10.1109/72.279182},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
number = {2},
pages = {167--77},
pmid = {18267788},
title = {{On the problem of local minima in recurrent neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18267788},
volume = {5},
year = {1994}
}
@article{Araya06b,
author = {Araya, Roberto and Eisenthal, Kenneth B and Yuste, R},
doi = {10.1073/pnas.0609225103},
journal = {PNAS},
number = {49},
pages = {18799--18804},
title = {{Dendritic spines linearize the summation of excitatory potentials}},
volume = {103},
year = {2006}
}
@misc{Pnevmatikakis2014,
abstract = {We present a structured matrix factorization approach to analyzing calcium imaging recordings of large neuronal ensembles. Our goal is to simultaneously identify the locations of the neurons, demix spatially overlapping components, and denoise and deconvolve the spiking activity of each neuron from the slow dynamics of the calcium indicator. The matrix factorization approach relies on the observation that the spatiotemporal fluorescence activity can be expressed as a product of two matrices: a spatial matrix that encodes the location of each neuron in the optical field and a temporal matrix that characterizes the calcium concentration of each neuron over time. We present a simple approach for estimating the dynamics of the calcium indicator as well as the observation noise statistics from the observed data. These parameters are then used to set up the matrix factorization problem in a constrained form that requires no further parameter tuning. We discuss initialization and post-processing techniques that enhance the performance of our method, along with efficient and largely parallelizable algorithms. We apply our method to {\{}$\backslash$it in vivo{\}} large scale multi-neuronal imaging data and also demonstrate how similar methods can be used for the analysis of {\{}$\backslash$it in vivo{\}} dendritic imaging data.},
archivePrefix = {arXiv},
arxivId = {1409.2903},
author = {Pnevmatikakis, E A and Gao, Yuanjun and Soudry, D. and Pfau, David and Lacefield, Clay and Poskanzer, Kira and Bruno, Randy and Yuste, Rafael and Paninski, Liam},
booktitle = {In prep.},
eprint = {1409.2903},
howpublished = {http://arxiv.org/abs/1409.2903},
pages = {1--16},
title = {{A structured matrix factorization framework for large scale calcium imaging data analysis}},
url = {http://arxiv.org/abs/1409.2903},
urldate = {2015-03-19},
year = {2014}
}
@article{Sharpee06,
author = {Sharpee, T and Sugihara, H and Kurgansky, A and Rebrik, S and Stryker, M and Miller, K},
journal = {Nature},
pages = {936--942},
title = {{Adaptive filtering enhances information transmission in visual cortex}},
volume = {439},
year = {2006}
}
@article{kolodziejski2009asymptotic,
annote = {2008num12},
author = {Kolodziejski, C and Porr, B and W$\backslash$$\backslash$"org$\backslash$$\backslash$"otter, F},
journal = {Neural Computation},
number = {4},
pages = {1173--1202},
publisher = {MIT Press},
title = {{On the Asymptotic Equivalence Between Differential Hebbian and Temporal Difference Learning}},
volume = {21},
year = {2009}
}
@article{Gerstner2009,
author = {Gerstner, W and Naud, R},
doi = {10.1126/science.1181936},
issn = {1095-9203},
journal = {Science},
number = {5951},
pages = {379--80},
pmid = {19833951},
title = {{How good are neuron models?}},
url = {http://www.sciencemag.org/cgi/content/summary/326/5951/379},
volume = {326},
year = {2009}
}
@article{Ibarz2011,
author = {Ibarz, B and Casado, J M and Sanju{\'{a}}n, M A F},
doi = {10.1016/j.physrep.2010.12.003},
issn = {0370-1573},
journal = {Physics Reports},
number = {1-2},
pages = {1--74},
publisher = {Elsevier B.V.},
title = {{Map-based models in neuronal dynamics}},
url = {http://dx.doi.org/10.1016/j.physrep.2010.12.003},
volume = {501},
year = {2011}
}
@article{Huffaker|2005|,
abstract = {We consider and compare four Internet distance metrics and analyze
the predictive power of these metrics in selecting, from a given
source, the lowest latency destination from among a candidate set.
The four metrics are: IP path length; autonomous system (AS) path
length; great circle geographic distance; and previously measured
round trip time (RTT). We describe general properties of these four
metrics and, using an unprecedented volume of real Internet macroscopic
topology and RTT data, compare their correlation with actual RTT
to the destination. The new methodology we propose for testing different
metrics is suitable for evaluating new distance estimation techniques
as they become available.},
annote = {Paper presents result of experimental measurement of distance between{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}nodes in Internet 2001 in RTT (relative time delay), geographical,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}IP and AS distances and their value as predictors for access time.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}RTT was found to the best predictor as well as geographical distance{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}can be used as predictor while IP {\&} AS show lower correlation with{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}access time.},
author = {Huffaker, B and Fomenkov, M and Plummer, D J and Moore, D and Claffy, K},
keywords = {continuous networks,distance,internet,metric,network metrics,networks},
title = {{Distance Metrics in the Internet}}
}
@article{evans95methods,
author = {Evans, M and Swartz, T},
journal = {Statistical Science},
pages = {254--272},
title = {{Methods for approximating integrals in statistics with special emphasis on {\{}Bayesian{\}} integration problems}},
url = {citeseer.ist.psu.edu/99394.html},
volume = {10},
year = {1995}
}
@article{Serrano-Gotarredona2013,
abstract = {In this paper we review several ways of realizing asynchronous Spike-Timing-Dependent-Plasticity (STDP) using memristors as synapses. Our focus is on how to use individual memristors to implement synaptic weight multiplications, in a way such that it is not necessary to (a) introduce global synchronization and (b) to separate memristor learning phases from memristor performing phases. In the approaches described, neurons fire spikes asynchronously when they wish and memristive synapses perform computation and learn at their own pace, as it happens in biological neural systems. We distinguish between two different memristor physics, depending on whether they respond to the original "moving wall" or to the "filament creation and annihilation" models. Independent of the memristor physics, we discuss two different types of STDP rules that can be implemented with memristors: either the pure timing-based rule that takes into account the arrival time of the spikes from the pre- and the post-synaptic neurons, or a hybrid rule that takes into account only the timing of pre-synaptic spikes and the membrane potential and other state variables of the post-synaptic neuron. We show how to implement these rules in cross-bar architectures that comprise massive arrays of memristors, and we discuss applications for artificial vision.},
author = {Serrano-Gotarredona, T and Masquelier, T and Prodromakis, T and Indiveri, G and Linares-Barranco, B},
doi = {10.3389/fnins.2013.00002},
issn = {1662-4548},
journal = {Frontiers in neuroscience},
keywords = {artificial-learning-synapses,cmos,memristor,memristor/cmos, artificial-learning-synapses, spik},
month = {jan},
number = {February},
pages = {2},
pmid = {23423540},
title = {{STDP and STDP variations with memristors for spiking neuromorphic learning systems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23423540},
volume = {7},
year = {2013}
}
@article{Takase2009,
author = {Haruhiko, Takas E and Masaru, Fujita and Hiroharu, Kawanaka and Takase, H and Fujita, M},
isbn = {9781424435531},
journal = {Neural Networks},
pages = {3062--3066},
title = {{Obstacle to training SpikeProp networks - Cause of surges in training process}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5178756},
year = {2009}
}
@article{NSB01,
author = {Nemenman, I and Shafee, F and Bialek, W},
journal = {NIPS},
title = {{Entropy and inference, revisited}},
volume = {14},
year = {2002}
}
@article{Approximation,
author = {Approximation, Diffusion and Figure, See and Information, Supporting and Chain, Markov},
number = {1},
title = {{SUPPORTING INFORMATION S2 The uncoupled DA and its Markov Chain equivalent}},
volume = {3}
}
@article{KT99,
author = {Kontsevich, L and Tyler, C},
journal = {Vision Research},
pages = {2729--2737},
title = {{Bayesian adaptive estimation of psychometric slope and threshold}},
volume = {39},
year = {1999}
}
@article{Wang2013a,
abstract = {Preventing feature co-adaptation by encouraging independent contributions from different features often improves classification and regression performance. Dropout training (Hinton et al., 2012) does this by randomly dropping out (zeroing) hidden units and input features during training of neural networks. However, repeatedly sampling a random subset of input features makes training much slower. Based on an examination of the implied objective function of dropout training, we show how to do fast dropout training by sampling from or integrating a Gaussian approximation, instead of doing Monte Carlo optimization of this objective. This approximation, justified by the central limit theorem and empirical evidence, gives an order of magnitude speedup and more stability. We show how to do fast dropout training for classification, regression, and multilayer neural networks. Beyond dropout, our technique is extended to integrate out other types of noise and small image transformations.},
author = {Wang, Sida I and Manning, Christopher D},
journal = {International Conference on Machine Learning},
keywords = {I,boring formatting information,machine learning},
pages = {118--126},
title = {{Fast dropout training}},
volume = {28},
year = {2013}
}
@inproceedings{He2015a,
abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra com-putational cost and little overfitting risk. Second, we de-rive a robust initialization method that particularly consid-ers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our PReLU networks (PReLU-nets), we achieve 4.94{\%} top-5 test error on the ImageNet 2012 classifica-tion dataset. This is a 26{\%} relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66{\%} [29]). To our knowledge, our result is the first to surpass human-level per-formance (5.1{\%}, [22]) on this visual recognition challenge.},
archivePrefix = {arXiv},
arxivId = {1502.01852},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2015.123},
eprint = {1502.01852},
isbn = {978-1-4673-8391-2},
pages = {1026--1034},
title = {{Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}},
year = {2015}
}
@article{Stein1965,
author = {Stein, Richard B.},
doi = {10.1016/S0006-3495(65)86709-1},
issn = {00063495},
journal = {Biophysical Journal},
month = {mar},
number = {2},
pages = {173--194},
publisher = {Elsevier},
title = {{A Theoretical Analysis of Neuronal Variability}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349565867091},
volume = {5},
year = {1965}
}
@article{Babaev|1999|,
abstract = {We briefly review the nonlinear sigma model approach for the subject
of increasing interest: {\"{i}}¾“two-step{\"{i}}¾” phase transitions in the Gross-Neveu
and the modified Nambu{\^{A}}–Jona-Lasinio models at low N and condensation
from pseudogap phase in strong-coupling superconductors. Recent success
in describing {\"{i}}¾“Bose-type{\"{i}}¾” superconductors that possess two characterstic
temperatures and a pseudogap above Tc is the development approximately
comparable with the BCS theory. One can expect that it should have
influence on high-energy physics, similar to impact of the BCS theory
on this subject. Although first generalizations of this concept to
particle physics were made recently, these results were not systematized.
In this review we summarize this development and discuss similarities
and differences of the appearence of the pseudogap phase in superconductors
and the Gross-Neveu and Nambu{\^{A}}–Jona-Lasinio - like models. We discuss
its possible relevance for chiral phase transition in QCD and color
superconductors. This paper is organized in three parts: in the first
section we briefly review the separation of temperatures of pair
formation and pair condensation in strong - coupling and low carrier
density superconductors (i.e. the formation of the pseudogap phase
). Second part is a review of nonlinear sigma model approach to an
analogous phenomenon in the Chiral Gross-Neveu model at small N.
In the third section we discuss the modified Nambu{\^{A}}–Jona- Lasinio
model where the chiral phase transition is accompanied by a formation
of a phase analogous to the pseudogap phase.},
author = {Babaev, E},
journal = {arXiv},
keywords = {Gross-Neveu model,Nambu-Jona-Lasinio model,phase disorder transition,physics,pseudogap,quantum field theory,sigma-model,superconductors},
pages = {9909052},
title = {{Nonlinear sigma model approach for phase disorder transitions and the pseudogap phase in chiral Gross-Neveu, Nambu-Jona-Lasinio models and strong-coupling superconductors}},
volume = {hep-th}
}
@article{MUS99,
author = {Mussa-Ivaldi, F},
journal = {Current Opinion in Neurobiology},
pages = {713--717},
title = {{Modular features of motor control and learning}},
volume = {9},
year = {1999}
}
@article{OrioSoudry2011,
abstract = {Background: The phenomena that emerge from the interaction of the stochastic opening and closing of ion channels (channel noise) with the non-linear neural dynamics are essential to our understanding of the operation of the nervous system. The effects that channel noise can have on neural dynamics are generally studied using numerical simulations of stochastic models. Algorithms based on discrete Markov Chains (MC) seem to be the most reliable and trustworthy, but even optimized algorithms come with a non-negligible computational cost. Diffusion Approximation (DA) methods use Stochastic Differential Equations (SDE) to approximate the behavior of a number of MCs, considerably speeding up simulation times. However, model comparisons have suggested that DA methods did not lead to the same results as in MC modeling in terms of channel noise statistics and effects on excitability. Recently, it was shown that the difference arose because MCs were modeled with coupled activation subunits, while the DA was modeled using uncoupled activation subunits. Implementations of DA with coupled subunits, in the context of a specific kinetic scheme, yielded similar results to MC. However, it remained unclear how to generalize these implementations to different kinetic schemes, or whether they were faster than MC algorithms. Additionally, a steady state approximation was used for the stochastic terms, which, as we show here, can introduce significant inaccuracies. Main Contributions: We derived the SDE explicitly for any given ion channel kinetic scheme. The resulting generic equations were surprisingly simple and interpretable – allowing an easy, transparent and efficient DA implementation, avoiding unnecessary approximations. The algorithm was tested in a voltage clamp simulation and in two different current clamp simulations, yielding the same results as MC modeling. Also, the simulation efficiency of this DA method demonstrated considerable superiority over MC methods, except when short time steps or low channel numbers were used.},
author = {Orio, P. and Soudry, D.},
doi = {10.1371/journal.pone.0036670},
issn = {19326203},
journal = {PLoS ONE},
number = {5},
pages = {e36670},
title = {{Simple, fast and accurate implementation of the diffusion approximation algorithm for stochastic ion channels with multiple states}},
volume = {7},
year = {2012}
}
@article{Kamiar08,
author = {{Rahnama Rad}, K and Paninski, L},
journal = {Network},
pages = {142--168},
title = {{Efficient estimation of two-dimensional firing rate surfaces via {\{}G{\}}aussian process methods}},
volume = {21},
year = {2008}
}
@article{SumnerMeddis03,
author = {Sumner, Christian J and O'Mard, Lowel P and Lopez-Poveda, Enrique A and Meddis, Ray},
journal = {Journal of The Acoustical Society Of America},
month = {jun},
number = {6},
pages = {3264--3274},
title = {{A nonlinear filter-bank model of the guinea-pig cochlear nerve: rate responses}},
volume = {113},
year = {2003}
}
@article{Galan2010,
author = {Gal{\'{a}}n, Roberto F and Ermentrout, G Bard and Urban, Nathaniel N and Neurophysiol, J and Gala, Roberto F},
doi = {10.1152/jn.00563.2007},
pages = {277--283},
title = {{and Experiments}},
year = {2010}
}
@article{He2002,
abstract = {Paired-pulse depression (PPD) of synaptic transmission is important for neuronal information processing. Historically, depletion of the readily releasable pool of synaptic vesicles has been proposed as the major component of PPD. Recent results suggest, however, that other mechanisms may be involved in PPD, including inactivation of presynaptic voltage-dependent sodium channels (NaChs), which may influence coupling of action potentials to transmitter release. In hippocampal cultures, we have examined the potential role and relative contribution of presynaptic NaCh inactivation in excitatory postsynaptic current (EPSC) PPD. Based on current- and voltage-clamp recordings from somas, our data suggest that NaCh inactivation could potentially participate in PPD. Paired stimulation of somatic action potentials (20- to 100-ms interval) results in subtle changes in action potential shape that are mimicked by low concentrations of tetrodotoxin (TTX) and that appear to be generated by a combination of fast and slow recovery from NaCh inactivation. Dilute concentrations of TTX dramatically depress glutamate release. However, we find evidence for only minimal contribution of NaCh inactivation to EPSC PPD under basal conditions. Hyperpolarization of presynaptic elements to speed recovery from inactivation or increasing the driving force on Na(+) ions through active NaChs had minimal effects on PPD while more robustly reversing the effects of pharmacological NaCh blockade. On the other hand, slight depolarization of the presynaptic membrane potential, by elevating extracellular [K(+)](o), significantly increased PPD and frequency-dependent depression of EPSCs during short trains of action potentials. The results suggest that NaCh inactivation is poised to modulate EPSC amplitude with small tonic depolarizations that likely occur with physiological or pathophysiological activity.},
author = {He, Yejun and Zorumski, Charles F and Mennerick, S},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Action Potentials: drug effects,Action Potentials: physiology,Anesthetics,Animals,Cells,Cnidarian Venoms,Cnidarian Venoms: pharmacology,Cultured,Excitatory Amino Acid Antagonists,Excitatory Amino Acid Antagonists: pharmacology,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: drug effects,Excitatory Postsynaptic Potentials: physiology,Glutamic Acid,Glutamic Acid: metabolism,Hippocampus,Hippocampus: cytology,Ion Channel Gating,Ion Channel Gating: drug effects,Ion Channel Gating: physiology,Local,Local: pharmacology,Neural Inhibition,Neural Inhibition: physiology,Neurons,Neurons: physiology,Neurotoxins,Neurotoxins: pharmacology,Potassium,Potassium: pharmacology,Presynaptic,Presynaptic: physiology,Rats,Receptors,Riluzole,Riluzole: pharmacology,Sodium,Sodium Channels,Sodium Channels: physiology,Sodium: pharmacokinetics,Synaptic Transmission,Synaptic Transmission: drug effects,Synaptic Transmission: physiology,Tetrodotoxin,Tetrodotoxin: pharmacology},
month = {feb},
number = {2},
pages = {925--36},
pmid = {11826057},
title = {{Contribution of presynaptic Na(+) channel inactivation to paired-pulse synaptic depression in cultured hippocampal neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11826057},
volume = {87},
year = {2002}
}
@article{Ghandour|1987|,
abstract = {An effective generating function F(q,Q) is introduced for any given
pair of quantum-mechanical systems whose classical Hamiltonians are
canonically equivalent. Using e{\^{}}{\{}iF{\}} as a kernel, an integral transform
relates the wave functions of the corresponding quantum systems.
The function F reduces in the classical limit hbar-{\textgreater}0 to the generating
function of the classical transformation. Conversely, starting with
the classical form, F can be calculated in a recurrent fashion, order
by order in powers of hbar. For the canonical transformation that
relates a particle moving in an exponential (Liouville) potential
to a free particle, the effective quantum generating function is
identical to its counterpart. The generalization to quantum field
theory is possible using the Schrodinger wave-function formalism.},
annote = {This paper introduces quantum canonical transformations as specific{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}integral transform for the differential equations, generalizaing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}idea of Dirac. Expansion for generating function participating in{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the transform in powers of hbar is obtained. Some applications are{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}demonstrated. Very interesting and useful paper.},
author = {Ghandour, G I},
journal = {Physical Review D},
keywords = {canonical transformations,generating functions,infinitesimal canonical transformation,physics,quantum mechanics},
number = {4},
pages = {1289},
title = {{Effective generating functions for quantum canonical transformations}},
volume = {35}
}
@article{Khoini-Poorfard1995,
author = {Khoini-Poorfard, R and Johns, DA},
journal = {Circuits and Systems II: Analog {\ldots}},
number = {3},
pages = {164--175},
title = {{Analysis of Delta Sigma modulators with zero mean stochastic inputs}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=372866},
volume = {42},
year = {1995}
}
@article{turing1952chemical,
author = {Turing, A M},
journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences},
number = {641},
pages = {37},
publisher = {The Royal Society},
title = {{The chemical basis of morphogenesis}},
url = {http://rstb.royalsocietypublishing.org/content/237/641/37.short},
volume = {237},
year = {1952}
}
@article{Chicurel|1992|,
author = {Chicurel, M and Harris, K M},
journal = {J Comp Neurol},
pages = {169--182},
title = {{Three-dimensional analysis of the structure and composition of CA3 branched dendritic spines and their synaptic relationships with mossy fiber boutons in the rat hippocampus.}},
volume = {325}
}
@article{BellCraciun05,
author = {Bell, Jonathan and Craciun, Gheorghe},
journal = {Mathematical Biosciences},
number = {1},
pages = {1--19},
title = {{A distributed parameter identification problem in neuronal cable theory models}},
volume = {194},
year = {2005}
}
@article{Minerbi2009,
abstract = {Synaptic plasticity is widely believed to constitute a key mechanism for modifying functional properties of neuronal networks. This belief implicitly implies, however, that synapses, when not driven to change their characteristics by physiologically relevant stimuli, will maintain these characteristics over time. How tenacious are synapses over behaviorally relevant time scales? To begin to address this question, we developed a system for continuously imaging the structural dynamics of individual synapses over many days, while recording network activity in the same preparations. We found that in spontaneously active networks, distributions of synaptic sizes were generally stable over days. Following individual synapses revealed, however, that the apparently static distributions were actually steady states of synapses exhibiting continual and extensive remodeling. In active networks, large synapses tended to grow smaller, whereas small synapses tended to grow larger, mainly during periods of particularly synchronous activity. Suppression of network activity only mildly affected the magnitude of synaptic remodeling, but dependence on synaptic size was lost, leading to the broadening of synaptic size distributions and increases in mean synaptic size. From the perspective of individual neurons, activity drove changes in the relative sizes of their excitatory inputs, but such changes continued, albeit at lower rates, even when network activity was blocked. Our findings show that activity strongly drives synaptic remodeling, but they also show that significant remodeling occurs spontaneously. Whereas such spontaneous remodeling provides an explanation for "synaptic homeostasis" like processes, it also raises significant questions concerning the reliability of individual synapses as sites for persistently modifying network function.},
author = {Minerbi, Amir and Kahana, Roni and Goldfeld, Larissa and Kaufman, Maya and Marom, S and Ziv, Noam E},
doi = {10.1371/journal.pbio.1000136},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Calcium,Calcium: metabolism,Cells,Cerebral Cortex,Cerebral Cortex: cytology,Confocal,Cultured,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Green Fluorescent Proteins,Green Fluorescent Proteins: genetics,Green Fluorescent Proteins: metabolism,Intracellular Signaling Peptides and Proteins,Intracellular Signaling Peptides and Proteins: gen,Intracellular Signaling Peptides and Proteins: met,Membrane Proteins,Membrane Proteins: genetics,Membrane Proteins: metabolism,Microscopy,Models,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: cytology,Neurons: metabolism,Neurons: physiology,Newborn,Rats,Recombinant Fusion Proteins,Recombinant Fusion Proteins: genetics,Recombinant Fusion Proteins: metabolism,Sprague-Dawley,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors,Transfection},
number = {6},
pages = {e1000136},
pmid = {19554080},
title = {{Long-term relationships between synaptic tenacity, synaptic remodeling, and network activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19554080},
volume = {7},
year = {2009}
}
@article{Rowat2007,
abstract = {When the classical Hodgkin-Huxley equations are simulated with Na- and K-channel noise and constant applied current, the distribution of interspike intervals is bimodal: one part is an exponential tail, as often assumed, while the other is a narrow gaussian peak centered at a short interspike interval value. The gaussian arises from bursts of spikes in the gamma-frequency range, the tail from the interburst intervals, giving overall an extraordinarily high coefficient of variation--up to 2.5 for 180,000 Na channels when I approximately 7 microA/cm(2). Since neurons with a bimodal ISI distribution are common, it may be a useful model for any neuron with class 2 firing. The underlying mechanism is due to a subcritical Hopf bifurcation, together with a switching region in phase-space where a fixed point is very close to a system limit cycle. This mechanism may be present in many different classes of neurons and may contribute to widely observed highly irregular neural spiking.},
author = {Rowat, P},
doi = {10.1162/neco.2007.19.5.1215},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Action Potentials: radiation effects,Animals,Electric Stimulation,Electric Stimulation: methods,Models,Neurological,Neurons,Neurons: physiology,Neurons: radiation effects,Nonlinear Dynamics,Normal Distribution,Periodicity,Probability,Sodium Channels,Sodium Channels: physiology,Stochastic Processes,Time Factors},
month = {may},
number = {5},
pages = {1215--1250},
pmid = {17381265},
title = {{Interspike interval statistics in the stochastic Hodgkin-Huxley model: coexistence of gamma frequency bursts and highly irregular firing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17381265},
volume = {19},
year = {2007}
}
@book{Torquato|2002|,
address = {New York},
author = {Torquato, S},
publisher = {Springer},
title = {{Random heterogeneous materials: microstructure and macroscopic properties}}
}
@article{Brette07,
author = {Brette, R and Piwkowska, Z and Rudolph, M and Bal, T and Destexhe, A},
journal = {Neurocomputing},
pages = {1597--1601},
title = {{A nonparametric electrode model for intracellular recording}},
volume = {70},
year = {2007}
}
@article{Karakiewicz2012,
author = {Karakiewicz, R and Genov, R and Cauwenberghs, G},
journal = {IEEE Sensors Journal},
number = {4},
pages = {785--792},
title = {{1.1 TMACS/mW Fine-Grained Stochastic Resonant Charge-Recycling Array Processor}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5711631},
volume = {12},
year = {2012}
}
@article{Rosenblueth1943,
author = {Rosenblueth, Arturo and Wiener, N and Bigelow, Julian},
doi = {10.1086/286788},
issn = {0031-8248},
journal = {Philosophy of Science},
month = {jan},
number = {1},
pages = {18},
title = {{Behavior, Purpose and Teleology}},
url = {http://www.journals.uchicago.edu/doi/abs/10.1086/286788},
volume = {10},
year = {1943}
}
@article{Shevtsova2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1111.6554v1},
author = {Shevtsova, Irina},
eprint = {arXiv:1111.6554v1},
journal = {arXiv preprint arXiv:1111.6554},
keywords = {absolute constant,berry,central limit theorem,characteristic function,esseen inequality,inequality,smoothing},
number = {1},
pages = {1--7},
title = {{On the absolute constants in the Berry-Esseen type inequalities for identically distributed summands}},
url = {http://arxiv.org/abs/1111.6554},
year = {2011}
}
@article{Lee|2001|,
author = {Lee, T and Luo, L},
journal = {Trends Neuroscience},
number = {5},
pages = {251--254},
title = {{Mosaic analysis with a repressible cell marker (MARCM) for Drosophila neural development.}},
volume = {24}
}
@article{TankDelaney95,
abstract = {Augmentation and posttetanic potentiation--two forms of short-term
synaptic enhancement produced by repetitive presynaptic action potentials--are
dependent on the buildup and decay of nerve terminal residual calcium
that occurs on the seconds to minutes time scale. With the goal of
providing a quantitative understanding of these kinetics, we measured
the buildup and decay of calcium ions in nerve terminals at the crayfish
neuromuscular junction under a variety of intracellular buffer conditions
and stimulation paradigms. The calcium extrusion process in the terminals
was characterized by analysis of calcium levels reached during long
stimulus trains as a function of action potential frequency. The
extrusion was linearly dependent on the free calcium ion concentration.
Using this result, we developed a mathematical model and computer
simulation of the residual calcium kinetics. The model demonstrates
the experimentally observed dependence of decay rate on exogenous
calcium buffer concentration, and can be explicitly solved to provide
an expression for the limiting exponential time course of calcium
decay following trains in terms of calcium buffer and extrusion characteristics.
Methods to determine the calcium influx per action potential, characteristics
of endogenous buffer, and the rate of calcium extrusion are suggested
by our analysis and demonstrated experimentally.},
author = {Tank, D W and Regehr, W G and Delaney, K R},
journal = {J Neurosci},
month = {dec},
number = {12},
pages = {7940--7952},
title = {{A quantitative analysis of presynaptic calcium dynamics that contribute to short-term enhancement.}},
volume = {15},
year = {1995}
}
@article{YangShamma91,
author = {Yang, X and Shamma, S A},
journal = {Biological Cybernetics},
number = {3},
pages = {171--179},
title = {{Minimum mean square error estimation of connectivity in biological neural networks}},
volume = {65},
year = {1991}
}
@article{PEL87,
author = {Pelli, D},
journal = {Investigative Ophthalmology and Visual Science (Supplement)},
pages = {366},
title = {{The ideal psychometric procedure}},
volume = {28},
year = {1987}
}
@article{CH52,
author = {Chernoff, H},
journal = {Annals of Mathematical Statistics},
pages = {493--509},
title = {{A measure of asymptotic efficiency for tests of hypothesis based on the sum of observations}},
volume = {23},
year = {1952}
}
@article{Hochbaum2014,
abstract = {All-optical electrophysiology-spatially resolved simultaneous optical perturbation and measurement of membrane voltage-would open new vistas in neuroscience research. We evolved two archaerhodopsin-based voltage indicators, QuasAr1 and QuasAr2, which show improved brightness and voltage sensitivity, have microsecond response times and produce no photocurrent. We engineered a channelrhodopsin actuator, CheRiff, which shows high light sensitivity and rapid kinetics and is spectrally orthogonal to the QuasArs. A coexpression vector, Optopatch, enabled cross-talk-free genetically targeted all-optical electrophysiology. In cultured rat neurons, we combined Optopatch with patterned optical excitation to probe back-propagating action potentials (APs) in dendritic spines, synaptic transmission, subcellular microsecond-timescale details of AP propagation, and simultaneous firing of many neurons in a network. Optopatch measurements revealed homeostatic tuning of intrinsic excitability in human stem cell-derived neurons. In rat brain slices, Optopatch induced and reported APs and subthreshold events with high signal-to-noise ratios. The Optopatch platform enables high-throughput, spatially resolved electrophysiology without the use of conventional electrodes.},
author = {Hochbaum, Daniel R and Zhao, Yongxin and Farhi, Samouil L and Klapoetke, Nathan and Werley, Christopher a and Kapoor, Vikrant and Zou, Peng and Kralj, Joel M and Maclaurin, Dougal and Smedemark-Margulies, Niklas and Saulnier, Jessica L and Boulting, Gabriella L and Straub, Christoph and Cho, Yong Ku and Melkonian, Michael and Wong, Gane Ka-Shu and Harrison, D Jed and Murthy, Venkatesh N and Sabatini, Bernardo L and Boyden, Edward S and Campbell, Robert E and Cohen, Adam E},
doi = {10.1038/nmeth.3000},
issn = {1548-7105},
journal = {Nature methods},
month = {jun},
number = {8},
pages = {825--833},
pmid = {24952910},
title = {{All-optical electrophysiology in mammalian neurons using engineered microbial rhodopsins.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24952910},
volume = {11},
year = {2014}
}
@book{SES93,
address = {Oxford},
author = {Seshadri, V},
publisher = {Clarendon},
title = {{The inverse {\{}G{\}}aussian distribution}},
year = {1993}
}
@article{Hines1984,
author = {Hines, M},
journal = {International journal of bio-medical computing},
title = {{Efficient computation of branched nerve equations}},
url = {http://www.sciencedirect.com/science/article/pii/0020710184900084},
year = {1984}
}
@article{Assaf2008,
author = {Assaf, Michael and Meerson, Baruch},
doi = {10.1103/PhysRevLett.100.058105},
issn = {0031-9007},
journal = {Physical Review Letters},
number = {5},
pages = {1--4},
title = {{Noise Enhanced Persistence in a Biochemical Regulatory Network with Feedback Control}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.100.058105},
volume = {100},
year = {2008}
}
@article{Mirollo1990,
annote = {2010num7.2},
author = {Mirollo, Renato E and Strogatz, S H},
doi = {10.1137/0150098},
issn = {00361399},
journal = {SIAM Journal on Applied Mathematics},
number = {6},
pages = {1645},
title = {{Synchronization of Pulse-Coupled Biological Oscillators}},
url = {http://epubs.siam.org/doi/abs/10.1137/0150098 http://link.aip.org/link/SMJMAP/v50/i6/p1645/s1{\&}Agg=doi http://www.jstor.org/stable/2101911},
volume = {50},
year = {1990}
}
@article{PAN06b,
author = {Paninski, L},
journal = {IEEE Transactions on Information Theory},
pages = {4750--4755},
title = {{A coincidence-based test for uniformity given very sparsely-sampled discrete data}},
volume = {54},
year = {2008}
}
@inproceedings{NH99,
author = {Neal, R M and Hinton, G E},
booktitle = {Learning in Graphical Models},
editor = {Jordan, M},
pages = {355--368},
publisher = {MIT Press},
title = {{A view of the {\{}EM{\}} algorithm that justifies incremental, sparse, and other variants}},
year = {1999}
}
@incollection{Weiss2011,
author = {Weiss, Y and Yanoverr, C and Meltzer, T},
booktitle = {Markov random fields for vision and image processing},
editor = {Blake, A and Kohli, P and Rother, C},
keywords = {Message passing},
pages = {1--20},
title = {{Linear programming and variants of Belief Propagation}},
year = {2011}
}
@article{Serr02,
author = {Serruya, M and Hatsopoulos, N and Paninski, L and Fellows, M and Donoghue, J},
journal = {Nature},
pages = {141--142},
title = {{Instant neural control of a movement signal}},
volume = {416},
year = {2002}
}
@article{Ienne1996,
author = {Ienne, Paolo and Cornu, Thierry and Kuhn, Gary},
doi = {10.1007/BF00930664},
issn = {0922-5773},
journal = {Journal of VLSI Signal Processing},
month = {aug},
number = {1},
pages = {5--25},
title = {{Special-purpose digital hardware for neural networks: An architectural survey}},
url = {http://link.springer.com/10.1007/BF00930664},
volume = {13},
year = {1996}
}
@article{Schwindt1989,
abstract = {1. The function and ionic mechanism of a slow outward current were studied in large layer V neurons of cat sensorimotor cortex using an in vitro slice preparation and single microelectrode voltage clamp. 2. With Ca2+ influx blocked, a slow relaxation ("tail") of outward current followed either (1) repetitive firing evoked for 1 s or (2) a small 1-s depolarizing voltage clamp step that activated the persistent Na+ current of neocortical neurons, INaP. When a depolarization that activated INaP was maintained, an outward current gradually developed and increased in amplitude over a period of tens of seconds to several minutes. An outward tail current of similar duration followed repolarization. The slow outward current was abolished by TTX, indicating it depended on Na+ influx. 3. With Ca2+ influx blocked, the onset of the slow Na+-dependent outward current caused spike frequency adaptation during current-evoked repetitive firing. Following the firing, the decay of the Na+-dependent current caused a slow afterhyperpolarization (sAHP) and a long-lasting reduction of excitability. It also was responsible for habituation of the response to repeated identical current pulses. 4. The Na+-dependent tail current had properties expected of a K+ current. Membrane chord conductance increased during the tail, and tail amplitude was reduced or reversed by membrane potential hyperpolarization and raised extracellular K+ concentration [( K+]0). 5. The current tail was reduced reversibly by the K+ channel blockers TEA (5-10 mM), muscarine (5-20 microM), and norepinephrine (100 microM). These agents also resulted in a larger, more sustained inward current during the preceding step depolarization. Comparison of current time course before and after the application of blocking agents suggested that, in spite of its capability for slow buildup and decay, the onset of the Na+-dependent outward current occurs within 100 ms of an adequate step depolarization. 6. With Ca2+ influx blocked, extracellular application of dantrolene sodium (30 microM) had no clear effect on the current tail or the corresponding sAHP.(ABSTRACT TRUNCATED AT 400 WORDS)},
author = {Schwindt, P C and Spain, W.J. J and Crill, W E},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Animals,Calcium,Calcium: pharmacology,Cats,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Cerebrospinal Fluid,Electrophysiology,Neurons,Neurons: physiology,Norepinephrine,Norepinephrine: pharmacology,Perfusion,Potassium,Potassium: antagonists {\&} inhibitors,Potassium: physiology,Sodium,Sodium: physiology,Tetraethylammonium,Tetraethylammonium Compounds,Tetraethylammonium Compounds: pharmacology,Tetrodotoxin,Tetrodotoxin: pharmacology,Time Factors},
month = {feb},
number = {2},
pages = {233--44},
pmid = {2918352},
title = {{Long-lasting reduction of excitability by a sodium-dependent potassium current in cat neocortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2918352},
volume = {61},
year = {1989}
}
@article{EftychiosNIPS11,
author = {Pnevmatikakis, E A and Paninski, L},
journal = {Submitted},
title = {{Fast interior-point inference in high-dimensional sparse, penalized state-space models}},
year = {2011}
}
@article{CZANNER05,
author = {Czanner, G and Eden, U and Wirth, S and Yanike, M and Suzuki, W and Brown, E},
journal = {Journal of Neurophysiology},
pages = {2672--2693},
title = {{Analysis of between-trial and within-trial neural spiking dynamics}},
volume = {99},
year = {2008}
}
@article{Faisal2005,
abstract = {The action potential (AP) is transmitted by the concerted action of voltage-gated ion channels. Thermodynamic fluctuations in channel proteins produce probabilistic gating behavior, causing channel noise. Miniaturizing signaling systems increases susceptibility to noise, and with many cortical, cerebellar, and peripheral axons {\textless}0.5 mum diameter [1, 2 and 3], channel noise could be significant [4 and 5]. Using biophysical theory and stochastic simulations, we investigated channel-noise limits in unmyelinated axons. Axons of diameter below 0.1 microm become inoperable because single, spontaneously opening Na channels generate spontaneous AP at rates that disrupt communication. This limiting diameter is relatively insensitive to variations in biophysical parameters (e.g., channel properties and density, membrane conductance and leak) and will apply to most spiking axons. We demonstrate that the essential molecular machinery can, in theory, fit into 0.06 microm diameter axons. However, a comprehensive survey of anatomical data shows a lower limit for AP-conducting axons of 0.08-0.1 microm diameter. Thus, molecular fluctuations constrain the wiring density of brains. Fluctuations have implications for epilepsy and neuropathic pain because changes in channel kinetics or axonal properties can change the rate at which channel noise generates spontaneous activity.},
annote = {I'm not sure if I believe their conclusions. It is suspicious that the spontanious firing rate rises so sharply below 0.1microAmp for coritcal neurons at 37C (Fig. 1A) - which is exactly the limit on axon miniturization (Fig. 1C). What makes this suspicious is that I don't understand where they got their parameters from. In table S1, they cite 

1) http://tonto.stanford.edu/{\~{}}sanger/pan.pdf
( which cites 
http://pamina.phys.uniroma1.it/Teaching/RetiNeurali/DocPoirazi/hoffman{\_}nature{\_}1997{\_}869.pdf
) 
2)http://www.jneurosci.org/content/16/21/6676.full.pdf
3)http://papers.cnl.salk.edu/PDFs/Reliability{\%}20of{\%}20Spike{\%}20Timing{\%}20in{\%}20Neocortical{\%}20Neurons{\%}201995-3393.pdf

as the source for their cortical neuron parameters, but I couldn't find their Q10 values for example. Not even in their squid axon refrences (HH+Koch book). What is also strange is that the Na conductance and R{\_}a also have Q10 (and I haven't seen this anywhere).




From Duplicate 3 ( Ion-channel noise places limits on the miniaturization of the brain's wiring. - Faisal, A A; White, J A; Laughlin, Simon B )

I'm not sure if I believe their conclusions. It is suspicious that the spontanious firing rate rises so sharply below 0.1microAmp for coritcal neurons at 37C (Fig. 1A) - which is exactly the limit on axon miniturization (Fig. 1C). What makes this suspicious is that I don't understand where they got their parameters from. In table S1, they cite 

1) http://tonto.stanford.edu/{\~{}}sanger/pan.pdf
( which cites 
http://pamina.phys.uniroma1.it/Teaching/RetiNeurali/DocPoirazi/hoffman{\_}nature{\_}1997{\_}869.pdf
) 
2)http://www.jneurosci.org/content/16/21/6676.full.pdf
3)http://papers.cnl.salk.edu/PDFs/Reliability{\%}20of{\%}20Spike{\%}20Timing{\%}20in{\%}20Neocortical{\%}20Neurons{\%}201995-3393.pdf

as the source for their cortical neuron parameters, but I couldn't find their Q10 values for example. Not even in their squid axon refrences (HH+Koch book). What is also strange is that the Na conductance and R{\_}a also have Q10 (and I haven't seen this anywhere).},
author = {Faisal, A Aldo and White, John A and Laughlin, Simon B},
doi = {10.1016/j.cub.2005.05.056},
issn = {0960-9822},
journal = {Current Biology : CB},
keywords = {Animals,Axons,Axons: physiology,Biophysical Phenomena,Biophysics,Brain,Brain: physiology,Cerebral Cortex,Cerebral Cortex: anatomy {\&} histology,Cerebral Cortex: physiology,Ion Channels,Ion Channels: metabolism,Mammals,Models,Neurological,Stochastic Processes,Synaptic Transmission,Synaptic Transmission: physiology,Temperature},
month = {jun},
number = {12},
pages = {1143--1149},
pmid = {15964281},
title = {{Ion-channel noise places limits on the miniaturization of the brain's wiring.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15964281},
volume = {15},
year = {2005}
}
@article{Snider2011,
abstract = {In a synchronous digital platform for building large cognitive models, memristive nanodevices form dense, resistive memories that can be placed close to conventional processing circuitry. Through adaptive transformations, the devices can interact with the world in real time.},
author = {Snider, G S and Amerson, R and Carter, D and Abdalla, H and Qureshi, M S and Leveille, J and Versace, M and Ames, H and Patrick, S and Chandler, B. and Gorchetchnikov, A and Mingolla, E},
doi = {10.1109/MC.2011.48},
issn = {0018-9162},
journal = {Computer},
month = {feb},
number = {2},
pages = {21--28},
title = {{From Synapses to Circuitry: Using Memristive Memory to Explore the Electronic Brain}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=5713299},
volume = {44},
year = {2011}
}
@inproceedings{Balle2016,
abstract = {We describe an image compression system, consisting of a nonlinear encoding transformation, a uniform quantizer, and a nonlinear decoding transformation. Like many deep neural network architectures, the transforms consist of layers of convolutional linear filters and nonlinear activation functions, but we use a joint nonlinearity that implements a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the system for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. The relaxed optimization problem resembles that of variational autoencoders, except that it must operate at any point along the rate-distortion curve, whereas the optimization of generative models aims only to minimize entropy of the data under the model. Across an independent database of test images, we find that the optimized coder exhibits significantly better rate-distortion performance than the standard JPEG and JPEG 2000 compression systems, as well as a dramatic improvement in visual quality of compressed images.},
archivePrefix = {arXiv},
arxivId = {1611.01704},
author = {Ball{\'{e}}, Johannes and Laparra, Valero and Simoncelli, Eero P},
booktitle = {ICLR},
eprint = {1611.01704},
title = {{End-to-end Optimized Image Compression}},
url = {http://arxiv.org/abs/1611.01704},
year = {2016}
}
@article{Matheron1973a,
author = {Matheron, G.},
doi = {10.2307/1425829},
issn = {00018678},
journal = {Advances in Applied Probability},
month = {dec},
number = {3},
pages = {439},
title = {{The Intrinsic Random Functions and Their Applications}},
url = {http://www.jstor.org/stable/1425829?origin=crossref},
volume = {5},
year = {1973}
}
@incollection{BickelBengtsson08,
author = {Bickel, Peter and Li, Bo and Bengtsson, Thomas},
booktitle = {Pushing the Limits of Contemporary Statistics: Contributions in Honor of Jayanta K. Ghosh},
editor = {Clarke, Bertrand and Ghosal, Subhashis},
pages = {318--329},
publisher = {IMS},
title = {{Sharp failure rates for the bootstrap particle filter in high dimensions}},
year = {2008}
}
@article{Burkhalter89,
author = {Burkhalter, A},
journal = {J Comp Neurol},
pages = {171--186},
title = {{Intrinsic Connections of Rat Primary Visual Cortex: Laminar Organization of Axonal Projections}},
volume = {279},
year = {1989}
}
@article{Touboul2011,
author = {Touboul, J and Faugeras, Olivier D},
doi = {10.1007/s10827-011-0327-y},
journal = {Journal of computational neuroscience},
keywords = {event-based model,event-based simulation,linear integrate-and-fire neurons,stochastic network},
pages = {485--507},
title = {{A Markovian event-based framework for stochastic spiking neural networks}},
url = {http://www.springerlink.com/index/81736mn03j2221m7.pdf},
year = {2011}
}
@article{ReddySaggau05,
author = {Reddy, Gaddum Duemani and Saggau, Peter},
journal = {J Biomed Opt},
month = {nov},
number = {6},
pages = {64038},
title = {{Fast three-dimensional laser scanning scheme using acousto-optic deflectors}},
volume = {10},
year = {2005}
}
@article{MugnainiOsen80,
author = {Mugnaini, E and Warr, W B and Osen, K K},
journal = {Journal of Comparative Neurology},
month = {jun},
number = {4},
pages = {581--606},
title = {{Distribution and light microscopic features of granule cells in the cochlear nuclei of cat, rat, and mouse}},
volume = {191},
year = {1980}
}
@article{KhanMoura08,
author = {Khan, Usman A and Moura, Jos{\'{e}} M F},
journal = {IEEE Transactions on Signal Processing},
pages = {4919--4935},
title = {{Distributing the {\{}K{\}}alman Filter for Large-Scale Systems}},
volume = {56},
year = {2008}
}
@article{Helmstaedter2013,
abstract = {Neuronal networks are high-dimensional graphs that are packed into three-dimensional nervous tissue at extremely high density. Comprehensively mapping these networks is therefore a major challenge. Although recent developments in volume electron microscopy imaging have made data acquisition feasible for circuits comprising a few hundreds to a few thousands of neurons, data analysis is massively lagging behind. The aim of this perspective is to summarize and quantify the challenges for data analysis in cellular-resolution connectomics and describe current solutions involving online crowd-sourcing and machine-learning approaches.},
author = {Helmstaedter, Moritz},
doi = {10.1038/nmeth.2476},
journal = {Nature methods},
keywords = {Animals,Connectome,Humans,Microscopy, Electron,Neurons,Neurons: physiology,Statistics as Topic},
month = {jun},
number = {6},
pages = {501--507},
pmid = {23722209},
title = {{Cellular-resolution connectomics: challenges of dense neural circuit reconstruction.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23722209},
volume = {10},
year = {2013}
}
@book{Stirzaker2005,
author = {Stirzaker, D},
booktitle = {Europhys. Lett},
publisher = {Oxford University Press, USA},
title = {{Stochastic processes and models}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=0avUelS7e7cC{\&}oi=fnd{\&}pg=PP11{\&}dq=stochastic+processes+and+Models{\&}ots=74INClOAL7{\&}sig=Tk0jz4Z79rn24bKuKWE1xAZzDIw http://ideas.repec.org/b/oxp/obooks/9780198568148.html},
year = {2005}
}
@article{Bartlett1999,
author = {Bartlett, PL and Baxter, J},
journal = {The Austrialian National University, Canberra, Australia},
title = {{Hebbian synaptic modifications in spiking neurons that learn}},
url = {http://neuro.bstu.by/ai/To-dom/My{\_}research/Papers-2.0/RNN-spiking-neurons/2/Ref/Hebbian Synaptic Modi.pdf},
year = {1999}
}
@article{ScheussSvoboda06,
abstract = {Spine {\{}Ca{\}}{\^{}}{\{}2+{\}} triggers the induction of synaptic plasticity and

other adaptive neuronal responses. The amplitude and time course

of {\{}Ca{\}}{\^{}}{\{}2+{\}} signals specify the activation of the signaling pathways

that trigger different forms of plasticity such as long-term potentiation

and depression. The shapes of {\{}Ca{\}}{\^{}}{\{}2+{\}} signals are determined

by the dynamics of {\{}Ca{\}}{\^{}}{\{}2+{\}} sources, {\{}Ca{\}}{\^{}}{\{}2+{\}} buffers, and

{\{}Ca{\}}{\^{}}{\{}2+{\}} extrusion mechanisms. Here we show in rat CA1 pyramidal

neurons that plasma membrane {\{}Ca{\}}{\^{}}{\{}2+{\}} pumps (PMCAs) and Na+/{\{}Ca{\}}{\^{}}{\{}2+{\}}

exchangers are the major {\{}Ca{\}}{\^{}}{\{}2+{\}} extrusion pathways in spines

and small dendrites. Surprisingly, we found that {\{}Ca{\}}{\^{}}{\{}2+{\}} extrusion

via PMCA and Na+/{\{}Ca{\}}{\^{}}{\{}2+{\}} exchangers slows in an activity-dependent

manner, mediated by intracellular Na+ and {\{}Ca{\}}{\^{}}{\{}2+{\}} accumulations.

This activity-dependent depression of {\{}Ca{\}}{\^{}}{\{}2+{\}} extrusion is, in

part, attributable to {\{}Ca{\}}{\^{}}{\{}2+{\}}-dependent inactivation of PMCAs.

{\{}Ca{\}}{\^{}}{\{}2+{\}} extrusion recovers from depression with a time constant

of 0.5 s. Depression of {\{}Ca{\}}{\^{}}{\{}2+{\}} extrusion provides a positive

feedback loop, converting small differences in stimuli into large

differences in {\{}Ca{\}}{\^{}}{\{}2+{\}} concentration. Depression of {\{}Ca{\}}{\^{}}{\{}2+{\}}

extrusion produces {\{}Ca{\}}{\^{}}{\{}2+{\}} concentration dynamics that depend

on the history of neuronal activity and therefore likely modulates

the induction of synaptic plasticity.},
author = {Scheuss, Volker and Yasuda, Ryohei and Sobczyk, Aleksander and Svoboda, Karel},
doi = {10.1523/JNEUROSCI.1962-06.2006},
journal = {J Neurosci},
keywords = {Active; Calcium; Calcium Signaling; Cells,Animals; Biological Transport,Cultured; Computer Simulation; Dendrites; Hippoca,Neurological; Nonlinear Dynamics; Pyramidal Cells,Sprague-Dawley; Sodium-Calcium Exchanger},
month = {aug},
number = {31},
pages = {8183--8194},
pmid = {16885232},
title = {{Nonlinear [{\{}Ca{\}}{\^{}}{\{}2+{\}}] signaling in dendrites and spines caused by activity-dependent depression of {\{}Ca{\}}{\^{}}{\{}2+{\}} extrusion.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.1962-06.2006},
volume = {26},
year = {2006}
}
@article{Beck2011,
author = {Beck, Amir and Tetruashvili, Luba},
journal = {Submitted for publication in Mathematical {\ldots}},
pages = {1--26},
title = {{On the Convergence of Block Coordinate Descent Type Methods}},
url = {http://ie.technion.ac.il/Home/Users/becka/CD14.pdf},
year = {2011}
}
@book{KERN02,
author = {Scholkopf, B and Smola, A},
publisher = {MIT Press},
title = {{Learning with Kernels: Support Vector Machines, Regularization, Optimization and Beyond}},
year = {2002}
}
@article{Steingrube2010,
author = {Steingrube, Silke and Timme, Marc and W{\"{o}}rg{\"{o}}tter, Florentin and Manoonpong, Poramate},
doi = {10.1038/nphys1508},
issn = {1745-2473},
journal = {Nature Physics},
month = {jan},
number = {3},
pages = {224--230},
publisher = {Nature Publishing Group},
title = {{Self-organized adaptation of a simple neural circuit enables complex robot behaviour}},
url = {http://www.nature.com/doifinder/10.1038/nphys1508},
volume = {6},
year = {2010}
}
@book{kunita1997stochastic,
author = {Kunita, H},
publisher = {Cambridge Univ Pr},
title = {{Stochastic flows and stochastic differential equations}},
year = {1997}
}
@article{Custers2010a,
author = {Custers, Ruud},
doi = {10.1126/science.1188595},
title = {{The Unconscious Will : How the}},
volume = {47},
year = {2010}
}
@article{Ly2010,
author = {Ly, Cheng and Ermentrout, B},
doi = {10.1103/PhysRevE.81.011911},
issn = {1539-3755},
journal = {Physical Review E},
month = {jan},
number = {1},
title = {{Coupling regularizes individual units in noisy populations}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.81.011911},
volume = {81},
year = {2010}
}
@article{Spacek|2004|,
abstract = {Locations of a distinctive mode of trans-endocytosis involving dendrites,
axons, and glia were quantified through serial section electron microscopy.
Short vesicular or long vermiform evaginations emerged from dendrites
and axons and were engulfed by presynaptic or neighboring axons,
astrocytes, and, surprisingly, a growth cone to form double-membrane
structures called spinules. In total, 254 spinules were evaluated
in 326 micron{\^{}}3 of stratum radiatum in area CA1 of mature rat hippocampus.
Spinules emerged from spine heads (62{\%}), necks (24{\%}), axons (13{\%}),
dendritic shafts (1{\%}), or nonsynaptic protrusions ({\textless}1{\%}) and invaginated
into axons ({\textless}90{\%}), astrocytic processes ({\textless}8{\%}), or a growth cone ({\textless}1{\%}).
Coated pits occurred on the engulfing membrane at the tips of most
spinules ( 69{\%}), and double-membrane structures occurred freely in
axonal and astrocytic cytoplasm, suggesting trans-endocytosis. Spinule
locations differed among mushroom and thin spines. For mushroom spines,
most (84{\%}) of the spinules were engulfed by presynaptic axons, 16{\%}
by neighboring axons, and none by astrocytic processes. At thin spines,
only 17{\%} of the spinules were engulfed by presynaptic axons, whereas
67{\%} were engulfed by neighboring axons and 14{\%} by astrocytic processes.
Spinules engulfed by astrocytic processes support the growing evidence
that perisynaptic glia interact directly with synapses at least on
thin spines. Spinules with neighboring axons may provide a mechanism
for synaptic competition in the mature brain. Trans-endocytosis of
spinules by presynaptic axons suggest retrograde signaling or coordinated
remodeling of presynaptic and postsynaptic membranes to remove transient
perforations and assemble the postsynaptic density of large synapses
on mushroom spines.},
annote = {Paper discussing spinules and their role for, perhaps, exocytosis{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}from serial thin section reconstructions},
author = {Spacek, J and Harris, K M},
journal = {The journal of neuroscience},
keywords = {3D reconstruction,coated vesicles,dendritic spines,endocytosis,exocytosis,neurobiology,serial section electron micrograph,serial thin sectioning,spinules,synapse,three-dimensional reconstruction},
number = {17},
pages = {4233},
title = {{Trans-endocytosis via spinules in adult rat hippocampus}},
volume = {24}
}
@article{Ergun07,
author = {Ergun, A and Barbieri, R and Eden, U and Wilson, M and Brown, E},
journal = {IEEE Transactions on Biomedical Engineering},
pages = {419--428},
title = {{Construction of point process adaptive filter algorithms for neural systems using sequential {\{}Monte Carlo{\}} methods}},
volume = {54},
year = {2007}
}
@article{Cannon2010,
abstract = {Neuronal activity is mediated through changes in the probability of stochastic transitions between open and closed states of ion channels. While differences in morphology define neuronal cell types and may underlie neurological disorders, very little is known about influences of stochastic ion channel gating in neurons with complex morphology. We introduce and validate new computational tools that enable efficient generation and simulation of models containing stochastic ion channels distributed across dendritic and axonal membranes. Comparison of five morphologically distinct neuronal cell types reveals that when all simulated neurons contain identical densities of stochastic ion channels, the amplitude of stochastic membrane potential fluctuations differs between cell types and depends on sub-cellular location. For typical neurons, the amplitude of membrane potential fluctuations depends on channel kinetics as well as open probability. Using a detailed model of a hippocampal CA1 pyramidal neuron, we show that when intrinsic ion channels gate stochastically, the probability of initiation of dendritic or somatic spikes by dendritic synaptic input varies continuously between zero and one, whereas when ion channels gate deterministically, the probability is either zero or one. At physiological firing rates, stochastic gating of dendritic ion channels almost completely accounts for probabilistic somatic and dendritic spikes generated by the fully stochastic model. These results suggest that the consequences of stochastic ion channel gating differ globally between neuronal cell-types and locally between neuronal compartments. Whereas dendritic neurons are often assumed to behave deterministically, our simulations suggest that a direct consequence of stochastic gating of intrinsic ion channels is that spike output may instead be a probabilistic function of patterns of synaptic input to dendrites.},
annote = {2010IIInum26},
author = {Cannon, R C and O'Donnell, C and Nolan, M F},
doi = {10.1371/journal.pcbi.1000886},
editor = {Graham, Lyle J.},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Biophysics/Theory and Simulation,Computational Biology/Computational Neuroscience,Neuroscience/Neuronal Signaling Mechanisms,Neuroscience/Theoretical Neuroscience,Research Article},
month = {jan},
number = {8},
pages = {18},
pmid = {20711353},
publisher = {Public Library of Science},
title = {{Stochastic ion channel gating in dendritic neurons: morphology dependence and probabilistic synaptic activation of dendritic spikes.}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1000886},
volume = {6},
year = {2010}
}
@article{Hietarinta|1982|,
abstract = {We discuss how the Hamiltonian changes in quantum canonical transformations.
To the operator H(p,q) one can associate (in a given ordering rule)
a c-number function H(p,q). It is this function that appears in the
action of the phase-space integral. A quantum canonical transformation
H-{\textgreater}H' can now be expressed as an integral transformation H(p',q')=integral
dp dq F(p',q';p,q)H(p,q). The kernel F is constructed explicitly
for point transformations and for the p=-q', q=p' reflection by studying
changes of variables in the path integral. The ordering dependence
of F is displayed. The invariance of commutation rules is also discussed.},
author = {Hietarinta, J},
journal = {Physical Review D},
keywords = {canonical transformations,generating functions,infinitesimal canonical transformation,integral transformation,physics,quantum mechanics},
number = {8},
pages = {2103},
title = {{Quantum canonical transformations as integral transformations}},
volume = {25}
}
@article{Broglie1976,
author = {Broglie, Maurice De and Heisenberg, Werner and Schrodinger, Erwin},
number = {December},
pages = {23--27},
title = {{Heisenberg and the early days of quantum mechanics}},
year = {1976}
}
@article{Stanley99,
author = {Stanley, Garrett B and Li, Fei F and Dan, Yang},
journal = {J. Neurosci.},
number = {18},
pages = {8036--8042},
title = {{Reconstruction of Natural Scenes from Ensemble Responses in the {\{}Lateral Geniculate Nucleus{\}}}},
volume = {19},
year = {1999}
}
@article{LM96,
author = {Levin, J and Miller, J},
journal = {Nature},
pages = {165--168},
title = {{Broadband neural encoding in the cricket cercal sensory system enhanced by stochastic resonance}},
volume = {380},
year = {1996}
}
@article{Griffiths2006,
author = {Griffiths, R E and Pernarowski, M},
issn = {0036-1399},
journal = {SIAM Journal on Applied Mathematics},
keywords = {050635201,1,10,1137,34a,34c15,34c29,34d15,34e15,ams subject classifications,bea,bursting,bursting electrical activity,doi,introduction,is a phenomenon in,return map,singular perturbation solutions,which},
number = {6},
pages = {1917--1948},
publisher = {Citeseer},
title = {{Return map characterizations for a model of bursting with two slow variables}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.6967{\&}rep=rep1{\&}type=pdf},
volume = {66},
year = {2006}
}
@inproceedings{He2015,
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, K and Zhang, X and Ren, S and Sun, J.},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
eprint = {1512.03385},
keywords = {deep learning,denoising auto-encoder,image denoising},
pages = {770--778},
title = {{Deep Residual Learning for Image Recognition}},
year = {2016}
}
@article{Models1998,
annote = {2010IIInum4},
author = {Destexhe, A and Mainen, ZF F and Sejnowski, T J and TJ},
journal = {Methods in neuronal},
keywords = {synapse},
mendeley-tags = {synapse},
pages = {1--25},
title = {{Kinetic models of synaptic transmission}},
url = {http://papers.cnl.salk.edu/PDFs/Kinetic Models of Synaptic Transmission 1998-3229.pdf http://papers.cnl.salk.edu/PDFs/Kinetic Models of Synaptic Transmission 1998-3229.pdf http://www.csc.kth.se/utbildning/kth/kurser/DD2435/biomod12/kursbunt/f9/KochCh1Destexhe.pdf},
year = {1998}
}
@article{Yu2011,
author = {Yu, Shan and Yang, Hongdian and Nakahara, Hiroyuki and Plenz, Dietmar and Santos, Gustavo S and Nikolic, Danko},
doi = {10.1523/JNEUROSCI.3127-11.},
journal = {Computational Intelligence},
number = {48},
pages = {17514 --17526},
title = {{Higher-Order Interactions Characterized in Cortical Activity}},
volume = {31},
year = {2011}
}
@article{Bourne|2007|c,
author = {Bourne, J and Harris, K M},
journal = {Curr Opin Neurobiol},
keywords = {Animals Calcium/metabolism Computer Simulation Den,Molecular Neuronal Plasticity/*physiology Neurons},
number = {3},
pages = {381--386},
title = {{Do thin spines learn to be mushroom spines that remember?}},
volume = {17}
}
@article{Hoshi1991,
author = {Hoshi, T and Zagotta, W.N. and Aldrich, R.W.},
journal = {Neuron},
number = {4},
pages = {547--556},
publisher = {Elsevier},
title = {{Two types of inactivation in Shaker K+ channels: effects of alterations in the carboxy-terminal region}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0896627391903679 http://www.sciencedirect.com/science/article/pii/0896627391903679},
volume = {7},
year = {1991}
}
@article{MAST02,
author = {Mastroianni, G},
journal = {Electronic Transactions on Numerical Analysis},
pages = {142--151},
title = {{Polynomial inequalities, functional spaces, and best approximation on the real semiaxis with laguerre weights}},
volume = {14},
year = {2002}
}
@article{Fudenberg07,
author = {Fudenberg, G and Paninski, L},
journal = {IEEE Transactions on Image Processing},
title = {{Bayesian image recovery for low-{\{}SNR{\}} dendritic structures}},
volume = {In press},
year = {2008}
}
@article{Kumar2010,
abstract = {The brain is a highly modular structure. To exploit modularity, it is necessary that spiking activity can propagate from one module to another while preserving the information it carries. Therefore, reliable propagation is one of the key properties of a candidate neural code. Surprisingly, the conditions under which spiking activity can be propagated have received comparatively little attention in the experimental literature. By contrast, several computational studies in the last decade have addressed this issue. Using feedforward networks (FFNs) as a generic network model, they have identified two dynamical activity modes that support the propagation of either asynchronous (rate code) or synchronous (temporal code) spiking. Here, we review the dichotomy of asynchronous and synchronous propagation in FFNs, propose their integration into a single extended conceptual framework and suggest experimental strategies to test our hypothesis.},
author = {Kumar, Arvind and Rotter, Stefan and Aertsen, A},
doi = {10.1038/nrn2886},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
keywords = {Action Potentials,Animals,Humans,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology},
month = {sep},
number = {9},
pages = {615--27},
pmid = {20725095},
title = {{Spiking activity propagation in neuronal networks: reconciling different perspectives on neural coding.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20725095},
volume = {11},
year = {2010}
}
@article{SRG03,
author = {Salakhutdinov, Ruslan and Roweis, Sam T and Ghahramani, Zoubin},
journal = {International Conference on Machine Learning},
pages = {672--679},
title = {{Optimization with {\{}E{\}}{\{}M{\}} and Expectation-Conjugate-Gradient}},
volume = {20},
year = {2003}
}
@book{ChT97,
address = {New York},
author = {Chow, Y and Teicher, H},
publisher = {Springer},
title = {{Probability theory}},
year = {1997}
}
@article{Grigolini2009,
abstract = {The brain is probably the most interesting example of a complex network having 1/f variability as determined through the analysis of EEG time series and magnetoencephalogram recordings. Herein we develop a theory of 1/f noise of human cognition to explain the recent experimental observations that increasing the difficultly of cognitive tasks accelerates the transition from observed 1/f noise to white noise in decision-making time series.},
author = {Grigolini, Paolo and Aquino, Gerardo and Bologna, Mauro and Lukovi{\'{c}}, Mirko and West, Bruce J.},
doi = {10.1016/j.physa.2009.06.024},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {02.50.Ey,05.40.Fb,05.45.Tp,1/f noise,87.85.dm,Decision making,Task difficulty},
month = {oct},
number = {19},
pages = {4192--4204},
publisher = {Elsevier B.V.},
title = {{A theory of noise in human cognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378437109004476 http://www.sciencedirect.com/science/article/pii/S0378437109004476},
volume = {388},
year = {2009}
}
@article{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team} and Documents, Sharing},
journal = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
number = {October},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Ahmadian-Cosyne09,
author = {Ahmadian, Y and Pillow, J W and Shlens, J and Chichilnisky, E J and Simoncelli, E and Paninski, L},
journal = {COSYNE09},
title = {{A decoder-based spike train metric for analyzing the neural code in the retina}},
year = {2009}
}
@article{Liu2013,
author = {Liu, Y.-Y. and Slotine, J.-J. and Barabasi, A.-L.},
doi = {10.1073/pnas.1215508110},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Complex Networks},
mendeley-tags = {Complex Networks},
month = {jan},
pages = {1--6},
title = {{Observability of complex systems}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1215508110},
year = {2013}
}
@article{george1993variable,
author = {George, Edward I and McCulloch, Robert E},
journal = {Journal of the American Statistical Association},
number = {423},
pages = {881--889},
publisher = {Taylor {\&} Francis Group},
title = {{Variable selection via Gibbs sampling}},
volume = {88},
year = {1993}
}
@article{LAP08,
author = {Lazar, Aurel A and Pnevmatikakis, E A},
journal = {Neural Computation},
month = {nov},
number = {11},
pages = {2715--2744},
publisher = {The MIT Press},
title = {{Faithful Representation of Stimuli with a Population of Integrate-and-Fire Neurons}},
volume = {20},
year = {2008}
}
@article{JK05,
author = {Jedynak, B and Khudanpur, S},
journal = {Neural Computation},
pages = {1508--1530},
title = {{Maximum Likelihood Setf or Estimating a Probability Mass Function}},
volume = {17},
year = {2005}
}
@article{Shazeer2017,
abstract = {The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.},
archivePrefix = {arXiv},
arxivId = {1701.06538},
author = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
doi = {10.1051/0004-6361/201527329},
eprint = {1701.06538},
file = {::},
isbn = {9781611970685},
issn = {0004-6361},
month = {jan},
title = {{Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}},
url = {http://arxiv.org/abs/1701.06538},
year = {2017}
}
@misc{Dr.KristenM.Harris,
author = {Harris, Kristen M},
keywords = {synapse},
mendeley-tags = {synapse},
title = {{SynapseWeb}},
url = {http://synapses.clm.utexas.edu/}
}
@article{Gobel07,
abstract = {Imaging technologies are well suited to study neuronal dendrites,
which are key elements for synaptic integration in the CNS. Dendrites
are, however, frequently oriented perpendicular to tissue surfaces,
impeding in vivo imaging approaches. Here we introduce novel laser-scanning
modes for two-photon microscopy that enable in vivo imaging of spatiotemporal
activity patterns in dendrites. First, we developed a method to image
planes arbitrarily oriented in 3D, which proved particularly beneficial
for calcium imaging of parallel fibers and Purkinje cell dendrites
in rat cerebellar cortex. Second, we applied free linescanseither
through multiple dendrites or along a single vertically oriented
dendriteto reveal fast dendritic calcium dynamics in neocortical
pyramidal neurons. Finally, we invented a ribbon-type 3D scanning
method for imaging user-defined convoluted planes enabling simultaneous
measurements of calcium signals along multiple apical dendrites.
These novel scanning modes will facilitate optical probing of dendritic
function in vivo.},
author = {Gobel, Werner and Helmchen, Fritjof},
doi = {10.1152/jn.00850.2007},
journal = {J Neurophysiol},
number = {6},
pages = {3770--3779},
title = {{New Angles on Neuronal Dendrites In Vivo}},
url = {http://jn.physiology.org/cgi/content/abstract/98/6/3770},
volume = {98},
year = {2007}
}
@article{Molnar2008,
abstract = {Synaptic interactions between neurons of the human cerebral cortex were not directly studied to date. We recorded the first dataset, to our knowledge, on the synaptic effect of identified human pyramidal cells on various types of postsynaptic neurons and reveal complex events triggered by individual action potentials in the human neocortical network. Brain slices were prepared from nonpathological samples of cortex that had to be removed for the surgical treatment of brain areas beneath association cortices of 58 patients aged 18 to 73 y. Simultaneous triple and quadruple whole-cell patch clamp recordings were performed testing mono- and polysynaptic potentials in target neurons following a single action potential fired by layer 2/3 pyramidal cells, and the temporal structure of events and underlying mechanisms were analyzed. In addition to monosynaptic postsynaptic potentials, individual action potentials in presynaptic pyramidal cells initiated long-lasting (37 +/- 17 ms) sequences of events in the network lasting an order of magnitude longer than detected previously in other species. These event series were composed of specifically alternating glutamatergic and GABAergic postsynaptic potentials and required selective spike-to-spike coupling from pyramidal cells to GABAergic interneurons producing concomitant inhibitory as well as excitatory feed-forward action of GABA. Single action potentials of human neurons are sufficient to recruit Hebbian-like neuronal assemblies that are proposed to participate in cognitive processes.},
author = {Moln{\'{a}}r, G{\'{a}}bor and Ol{\'{a}}h, Szabolcs and Koml{\'{o}}si, Gergely and F{\"{u}}le, Mikl{\'{o}}s and Szabadics, J{\'{a}}nos and Varga, Csaba and Barz{\'{o}}, P{\'{a}}l and Tam{\'{a}}s, G{\'{a}}bor},
doi = {10.1371/journal.pbio.0060222},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Action Potentials,Action Potentials: physiology,Adolescent,Adult,Aged,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Cerebral Cortex: surgery,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Glutamic Acid,Glutamic Acid: metabolism,Humans,Middle Aged,Nerve Net,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Synapses,Synapses: physiology,gamma-Aminobutyric Acid,gamma-Aminobutyric Acid: metabolism},
month = {sep},
number = {9},
pages = {e222},
pmid = {18767905},
title = {{Complex events initiated by individual spikes in the human cerebral cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2528052{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {6},
year = {2008}
}
@article{Likharev2011,
author = {Likharev, Konstantin K.},
doi = {10.1166/sam.2011.1177},
issn = {19472935},
journal = {Science of Advanced Materials},
keywords = {adaptation,cognitive tasks,crossbar,hybrid circuits,latching switches,memristive devices,nanoelectronics,neural networks,neuromorphic circuits,plasticity},
month = {jun},
number = {3},
pages = {322--331},
title = {{CrossNets: Neuromorphic Hybrid CMOS/Nanoelectronic Networks}},
url = {http://openurl.ingenta.com/content/xref?genre=article{\&}issn=1947-2935{\&}volume=3{\&}issue=3{\&}spage=322},
volume = {3},
year = {2011}
}
@article{Dunnett1955,
author = {Dunnett, CW and Sobel, M},
journal = {Biometrika},
number = {1},
pages = {258--260},
title = {{Approximations to the probability integral and certain percentage points of a multivariate analogue of Student's t-distribution}},
url = {http://www.jstor.org/stable/2333441},
volume = {42},
year = {1955}
}
@book{cinlar1975introduction,
address = {Englewood Cliffs, NJ},
author = {Cinlar, E},
booktitle = {Englewood Cliffs},
publisher = {Prentice hall},
title = {{Introduction to stochastic processes}},
year = {1975}
}
@article{DavisYoung96,
author = {Davis, K A and Miller, R L and Young, E D},
journal = {Journal of Neurophysiology},
month = {nov},
number = {5},
pages = {3012--3024},
title = {{Effects of somatosensory and parallel-fiber stimulation on neurons in dorsal cochlear nucleus}},
volume = {76},
year = {1996}
}
@phdthesis{RASPHD,
author = {Rasmussen, C},
school = {University of Toronto},
title = {{Evaluation of {\{}G{\}}aussian Processes and other Methods for Non-Linear Regression}},
year = {1996}
}
@article{nayak2007time,
annote = {2009num60},
author = {Nayak, T K and Sikdar, S K},
journal = {Journal of Membrane Biology},
keywords = {slow sodium inactivation},
mendeley-tags = {slow sodium inactivation},
number = {1},
pages = {19--36},
publisher = {Springer},
title = {{Time-dependent molecular memory in single voltage-gated sodium channel}},
volume = {219},
year = {2007}
}
@article{Zumsteg05,
author = {Zumsteg, Z and Kemere, C and O'Driscoll, S and Santhanam, G and Ahmed, R and Shenoy, K and Meng, T},
journal = {IEEE Transactions in Neural Systems and Rehabilitation Engineering},
pages = {272--279},
title = {{Power feasibility of implantable digital spike sorting circuits for neural prosthetic systems}},
volume = {13},
year = {2005}
}
@article{Eliasmith|2004|,
abstract = {Extending work in Eliasmith and Anderson (2003), I employ a general
framework to construct biologically plausible simulations of the
three classes of attractor networks relevant for biological systems:
static (point, line, ring, and plane) attractors; cyclic attractors;
and chaotic attractors. I discuss these attractors in the context
of the neural systems that they have been posited to help explain:
eye control, working memory, and head direction; locomotion (specifically
swimming); and olfaction, respectively. I then demonstrate how to
introduce control into these models. The addition of control shows
how attractor networks can be used as subsystems in larger neural
systems, demonstrates how a much larger class of networks can be
related to attractor networks, and makes it clear how attractor networks
can be exploited for various information processing tasks in neurobiological
systems.},
annote = {The paper is foundation laying work on development of artificial{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}neural networks realizing given attractor dynamics based on simple{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}notions of information representation-processing and expression by{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}a population of neurons.},
author = {Eliasmith, C},
keywords = {attractor,networks,neurobiology,neuronal networks,unread},
title = {{A unified approach to building and controlling spiking attractor networks}}
}
@article{LOI98,
author = {Loizou, P},
journal = {IEEE Signal Processing Magazine},
pages = {101--130},
title = {{Mimicking the human ear: an introduction to cochlear implants}},
volume = {15},
year = {1998}
}
@article{Das2016,
abstract = {We design and implement a distributed multinode synchronous SGD algorithm, without altering hyper parameters, or compressing data, or altering algorithmic behavior. We perform a detailed analysis of scaling, and identify optimal design points for different networks. We demonstrate scaling of CNNs on 100s of nodes, and present what we believe to be record training throughputs. A 512 minibatch VGG-A CNN training run is scaled 90X on 128 nodes. Also 256 minibatch VGG-A and OverFeat-FAST networks are scaled 53X and 42X respectively on a 64 node cluster. We also demonstrate the generality of our approach via best-in-class 6.5X scaling for a 7-layer DNN on 16 nodes. Thereafter we attempt to democratize deep-learning by training on an Ethernet based AWS cluster and show {\~{}}14X scaling on 16 nodes.},
archivePrefix = {arXiv},
arxivId = {1602.06709},
author = {Das, Dipankar and Avancha, Sasikanth and Mudigere, Dheevatsa and Vaidynathan, Karthikeyan and Sridharan, Srinivas and Kalamkar, Dhiraj and Kaul, Bharat and Dubey, Pradeep},
eprint = {1602.06709},
title = {{Distributed Deep Learning Using Synchronous Stochastic Gradient Descent}},
url = {http://arxiv.org/abs/1602.06709},
year = {2016}
}
@article{Beran1992,
author = {Beran, J},
journal = {Journal of the Royal Statistical Society. Series B (},
keywords = {fractional,fractional autoregressive moving average,gaussian noise,goodness of fit,long range dependence,periodogram,process},
number = {3},
pages = {749--760},
title = {{A goodness-of-fit test for time series with long range dependence}},
url = {http://www.jstor.org/stable/10.2307/2345855},
volume = {54},
year = {1992}
}
@article{Camera2012,
author = {Camera, Giancarlo La and Rauch, Alexander and Thurbon, David and L{\"{u}}scher, Hans-r and Lundstrom, Brian N and Fairhall, A L and Maravall, Miguel and Miller, Mark N and Okaty, Benjamin W and Nelson, Sacha B and K{\"{o}}ndgen, Harold and Geisler, Caroline and Fusi, Stefano and Wang, Xiao-jing and L{\"{u}}scher, Hans-rudolf and Lu, Hans-r and Senn, W and Camera, La},
doi = {10.1152/jn.00453.2006},
number = {June 2006},
pages = {3448--3464},
title = {{Multiple Time Scales of Temporal Response in Pyramidal and Fast Spiking Cortical Neurons}},
year = {2012}
}
@article{Brown1984,
author = {Brown, Timothy C.},
doi = {10.2307/2322105},
issn = {00029890},
journal = {The American Mathematical Monthly},
month = {feb},
number = {2},
pages = {116},
title = {{Poisson Approximations and the Definition of the Poisson Process}},
url = {http://www.jstor.org/stable/2322105?origin=crossref},
volume = {91},
year = {1984}
}
@article{ManisMolitorWu03,
author = {Manis, Paul B and Molitor, Scott C and Wu, Huijie},
journal = {Experimental Brain Research},
month = {dec},
number = {4},
pages = {443--451},
title = {{Subthreshold oscillations generated by TTX-sensitive sodium currents in dorsal cochlear nucleus pyramidal cells}},
volume = {153},
year = {2003}
}
@article{Nimchinsky|2002|,
abstract = {Spines are neuronal protrusions, each of which receives input typically
from one excitatory synapse. They contain neurotransmitter receptors,
organelles, and signaling systems essential for synaptic function
and plasticity. Numerous brain disorders are associated with abnormal
dendritic spines. Spine formation, plasticity, and maintenance depend
on synaptic activity and can be modulated by sensory experience.
Studies of compartmentalization have shown that spines serve primarily
as biochemical, rather than electrical, compartments. In particular,
recent work has highlighted that spines are highly specialized compartments
for rapid large-amplitude Ca2C signals underlying the induction of
synaptic plasticity.},
author = {Nimchinsky, E A and Sabatini, B L and Svoboda, K},
journal = {Annual Reviews in Physiology},
keywords = {NMDA receptor,calcium,fragile X,neurobiology,spines,synapse,voltage-sensitive calcium channel},
pages = {313},
title = {{Structure and Function of Dendritic Spines}},
volume = {64}
}
@article{Abry2002,
author = {Abraham, D B and Flandrin, P. and Taqqu, M.S. and Veitch, D.},
journal = {Long-range Dependence: Theory and Applications},
pages = {527--56},
title = {{Self-similarity and long-range dependence through the wavelet lens}},
url = {http://perso.ens-lyon.fr/patrick.flandrin/douk01.pdf},
year = {2002}
}
@article{MillerYoung97,
author = {Miller, R L and Schilling, J R and Franck, K R and Young, E D},
journal = {Journal of The Acoustical Society Of America},
month = {jun},
number = {6},
pages = {3602--3616},
title = {{Effects of acoustic trauma on the representation of the vowel "eh" in cat auditory nerve fibers}},
volume = {101},
year = {1997}
}
@article{Bickel08,
author = {Bickel, J and Levina, Elizaveta},
journal = {Annals of Statistics},
pages = {199--227},
title = {{Regularized estimation of large covariance matrices}},
volume = {36},
year = {2008}
}
@article{Strong|1998|,
abstract = {The nervous system represents time dependent signals in sequences
of discrete, identical action potentials or spikes; information is
carried only in the spike arrival times. We show how to quantify
this information, in bits, free from any assumptions about which
features of the spike train or input signal are most important, and
we apply this approach to the analysis of experiments on a motion
sensitive neuron in the fly visual system. This neuron transmits
information about the visual stimulus at rates of up to 90 bitsys,
within a factor of 2 of the physical limit set by the entropy of
the spike train itself.},
author = {{Strong S. Koberle}, R and {de Ruyter van Steveninck R.} and Bialek, W and Strong, S P and Koberle, R and {de Ruyter van Steveninck}, R R},
journal = {Physical Review Letters},
keywords = {entropy,information,neurobiology,neurons,spike trains},
number = {1},
pages = {197--202},
title = {{Entropy and infromation in neural spike trains}},
volume = {80},
year = {1998}
}
@article{Fourcaud-Trocme2003,
abstract = {This study examines the ability of neurons to track temporally varying inputs, namely by investigating how the instantaneous firing rate of a neuron is modulated by a noisy input with a small sinusoidal component with frequency (f). Using numerical simulations of conductance-based neurons and analytical calculations of one-variable nonlinear integrate-and-fire neurons, we characterized the dependence of this modulation on f. For sufficiently high noise, the neuron acts as a low-pass filter. The modulation amplitude is approximately constant for frequencies up to a cutoff frequency, fc, after which it decays. The cutoff frequency increases almost linearly with the firing rate. For higher frequencies, the modulation amplitude decays as C/falpha, where the power alpha depends on the spike initiation mechanism. For conductance-based models, alpha = 1, and the prefactor C depends solely on the average firing rate and a spike "slope factor," which determines the sharpness of the spike initiation. These results are attributable to the fact that near threshold, the sodium activation variable can be approximated by an exponential function. Using this feature, we propose a simplified one-variable model, the "exponential integrate-and-fire neuron," as an approximation of a conductance-based model. We show that this model reproduces the dynamics of a simple conductance-based model extremely well. Our study shows how an intrinsic neuronal property (the characteristics of fast sodium channels) determines the speed with which neurons can track changes in input.},
author = {Fourcaud-Trocm{\'{e}}, Nicolas and Hansel, David and van Vreeswijk, C and Brunel, N},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Electric Conductivity,Kinetics,Models, Neurological,Neurons,Neurons: physiology,Sodium Channels,Sodium Channels: metabolism},
month = {dec},
number = {37},
pages = {11628--40},
pmid = {14684865},
title = {{How spike generation mechanisms determine the neuronal response to fluctuating inputs.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14684865},
volume = {23},
year = {2003}
}
@article{Frank02,
author = {Frank, L and Eden, U and Solo, V and Wilson, M and Brown, E},
journal = {J. Neurosci.},
number = {9},
pages = {3817--3830},
title = {{Contrasting Patterns of Receptive Field Plasticity in the Hippocampus and the Entorhinal Cortex: An Adaptive Filtering Approach}},
volume = {22},
year = {2002}
}
@article{Panyi1995,
abstract = {The lymphocyte voltage-gated K+ channel, Kv1.3, inactivates by a C-type process. We have elucidated the molecular basis for this process using a kinetic analysis of wild-type and mutant (A413V) Kv1.3 homo- and heteromultimeric currents in a mammalian lymphoid expression system. The medians of the measured inactivation time constants for wild-type and A413V homotetrameric currents are 204 and 4 ms, respectively. Co-expression of these subunits produces heteromultimeric channels manifesting inactivation kinetics intermediate between those of wild-type and A413V homomultimers. We have considered several models in which each subunit acts either independently or cooperatively to produce the observed inactivation kinetics. The cooperative model gives excellent fits to the data for any heteromultimeric composition of subunits, clearly distinguishing it from the independent models. In the cooperative model, the difference in free energy between the open and inactivated states of the channel is invariant with subunit composition and equals approximately 1.5 kcal/mol. Each subunit contributes equally to the activation free energy for transitions between open and inactivated states, with an A413V subunit decreasing the free energy barrier for inactivation (and for recovery from inactivation) by approximately 0.6 kcal/mol. Our results are consistent with a physical model in which the outer mouth of the channel constricts during C-type inactivation (G. Yellen, D. Sodickson, T. Chen, and M.E. Jurman, 1994, Biophys. J. 66:1068-1075).},
author = {Panyi, G and Sheng, Zufang and Deutsch, Carol and Tu, Liwei},
doi = {10.1016/S0006-3495(95)79963-5},
issn = {0006-3495},
journal = {Biophysical journal},
keywords = {Animals,Cells,Cultured,Cytotoxic,Electrophysiology,Electrophysiology: methods,Humans,Kinetics,Kv1.3 Potassium Channel,Macromolecular Substances,Mathematics,Membrane Potentials,Mice,Models,Mutagenesis,Plasmids,Point Mutation,Potassium Channels,Potassium Channels: biosynthesis,Potassium Channels: physiology,Recombinant Proteins,Recombinant Proteins: biosynthesis,Recombinant Proteins: metabolism,Site-Directed,T-Lymphocytes,Theoretical,Transfection,Voltage-Gated},
month = {sep},
number = {3},
pages = {896--903},
pmid = {8519989},
publisher = {Elsevier},
title = {{C-type inactivation of a voltage-gated K+ channel occurs by a cooperative mechanism.}},
url = {http://dx.doi.org/10.1016/S0006-3495(95)79963-5 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1236318{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {69},
year = {1995}
}
@book{Feng04,
editor = {Feng, J},
publisher = {CRC Press},
title = {{Computational Neuroscience: a comprehensive approach}},
year = {2004}
}
@article{Somogyi82,
author = {Somogyi, P and Freund, T and Cowey, A},
journal = {Neuroscience},
pages = {2577--2607},
title = {{The axo-axonic interneuron in the cerebral cortex of the rat, cat and monkey}},
volume = {7},
year = {1982}
}
@article{Zenke2015,
abstract = {Deep learning has led to remarkable advances when applied to problems where the data distri-bution does not change over the course of learn-ing. In stark contrast, biological neural networks continually adapt to changing domains, and solve a diversity of tasks simultaneously. Furthermore, synapses in biological neurons are not simply real-valued scalars, but possess complex molec-ular machinery enabling non-trivial learning dy-namics. In this study, we take a first step to-ward bringing this biological complexity into ar-tificial neural networks. We introduce a model of intelligent synapses that accumulate task rel-evant information over time, and exploit this in-formation to efficiently consolidate memories of old tasks to protect them from being overwritten as new tasks are learned. We apply our frame-work to learning sequences of related classifica-tion problems, and show that it dramatically re-duces catastrophic forgetting while maintaining computational efficiency.},
archivePrefix = {arXiv},
arxivId = {1703.04200},
author = {Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
eprint = {1703.04200},
title = {{Improved multitask learning through synaptic intelligence}},
url = {https://arxiv.org/pdf/1703.04200.pdf},
year = {2015}
}
@book{zemanian1987distribution,
author = {Zemanian, A H},
publisher = {Dover Pubns},
title = {{Distribution theory and transform analysis: an introduction to generalized functions, with applications}},
year = {1987}
}
@article{Kvatinsky2013a,
author = {Kvatinsky, S and Wald, N and Satat, E and Friedman, E G and Kolodny, A and Weiser, U C},
journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
month = {oct},
number = {10},
pages = {2054--2066},
title = {{Memristor-based Material Implication (IMPLY) Logic: Design Principles and Methodologies}},
volume = {22},
year = {2013}
}
@article{Larkum2009,
abstract = {Tuft dendrites are the main target for feedback inputs innervating neocortical layer 5 pyramidal neurons, but their properties remain obscure. We report the existence of N-methyl-D-aspartate (NMDA) spikes in the fine distal tuft dendrites that otherwise did not support the initiation of calcium spikes. Both direct measurements and computer simulations showed that NMDA spikes are the dominant mechanism by which distal synaptic input leads to firing of the neuron and provide the substrate for complex parallel processing of top-down input arriving at the tuft. These data lead to a new unifying view of integration in pyramidal neurons in which all fine dendrites, basal and tuft, integrate inputs locally through the recruitment of NMDA receptor channels relative to the fixed apical calcium and axosomatic sodium integration points.},
annote = {2010IInum12.24},
author = {Larkum, Matthew E and Nevian, Thomas and Sandler, Maya and Polsky, Alon and Schiller, Jackie},
doi = {10.1126/science.1171958},
issn = {1095-9203},
journal = {Science},
keywords = {Action Potentials,Animals,Axons,Axons: physiology,Calcium Signaling,Computer Simulation,Dendrites,Dendrites: physiology,Excitatory Postsynaptic Potentials,Jackie,Models,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: metabolism,N-Methylaspartate,N-Methylaspartate: metabolism,Neocortex,Neocortex: cytology,Neocortex: physiology,Neurological,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Receptors,Sodium,Sodium: metabolism,Synapses,Synapses: physiology,Synaptic Potentials,Wistar},
mendeley-tags = {Jackie},
month = {aug},
number = {5941},
pages = {756--60},
pmid = {19661433},
title = {{Synaptic integration in tuft dendrites of layer 5 pyramidal neurons: a new unifying principle.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19661433},
volume = {325},
year = {2009}
}
@article{Banerjee08,
author = {Banerjee, Sudipto and Gelfand, Alan E and Finley, Andrew O and Sang, Huiyan},
journal = {Journal Of The Royal Statistical Society Series B},
pages = {825--848},
title = {{Gaussian predictive process models for large spatial data sets}},
volume = {70},
year = {2008}
}
@article{Nere2012,
abstract = {In this work we investigate the possibilities offered by a minimal framework of artificial spiking neurons to be deployed in silico. Here we introduce a hierarchical network architecture of spiking neurons which learns to recognize moving objects in a visual environment and determine the correct motor output for each object. These tasks are learned through both supervised and unsupervised spike timing dependent plasticity (STDP). STDP is responsible for the strengthening (or weakening) of synapses in relation to pre- and post-synaptic spike times and has been described as a Hebbian paradigm taking place both in vitro and in vivo. We utilize a variation of STDP learning, called burst-STDP, which is based on the notion that, since spikes are expensive in terms of energy consumption, then strong bursting activity carries more information than single (sparse) spikes. Furthermore, this learning algorithm takes advantage of homeostatic renormalization, which has been hypothesized to promote memory consolidation during NREM sleep. Using this learning rule, we design a spiking neural network architecture capable of object recognition, motion detection, attention towards important objects, and motor control outputs. We demonstrate the abilities of our design in a simple environment with distractor objects, multiple objects moving concurrently, and in the presence of noise. Most importantly, we show how this neural network is capable of performing these tasks using a simple leaky-integrate-and-fire (LIF) neuron model with binary synapses, making it fully compatible with state-of-the-art digital neuromorphic hardware designs. As such, the building blocks and learning rules presented in this paper appear promising for scalable fully neuromorphic systems to be implemented in hardware chips.},
author = {Nere, A and Olcese, U and Balduzzi, D and Tononi, G},
doi = {10.1371/journal.pone.0036958},
issn = {1932-6203},
journal = {PloS one},
month = {jan},
number = {5},
pages = {e36958},
pmid = {22615855},
title = {{A neuromorphic architecture for object recognition and motion anticipation using burst-STDP.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3352850{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2012}
}
@article{Karoui06,
author = {{El Karoui}, N},
journal = {arXiv:math/0609418v1},
title = {{Spectrum estimation for large dimensional covariance matrices using random matrix theory}},
year = {2007}
}
@article{Graves2011,
author = {Graves, A},
journal = {Advances in Neural Information Processing Systems},
pages = {1--9},
title = {{Practical variational inference for neural networks}},
url = {http://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks},
year = {2011}
}
@article{Rosenbaum2012,
author = {Rosenbaum, Robert and Rubin, Jonathan and Doiron, Brent},
doi = {10.1371/journal.pcbi.1002557},
editor = {Sporns, Olaf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {jun},
number = {6},
pages = {e1002557},
title = {{Short Term Synaptic Depression Imposes a Frequency Dependent Filter on Synaptic Information Transfer}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002557},
volume = {8},
year = {2012}
}
@article{Shankaran2007,
annote = {2010num4.3{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Shankaran, H and Wiley, H S and Resat, H},
journal = {BMC Systems Biology},
number = {1},
pages = {48},
publisher = {BioMed Central Ltd},
title = {{Receptor downregulation and desensitization enhance the information processing ability of signalling receptors}},
url = {http://www.biomedcentral.com/1752-0509/1/48},
volume = {1},
year = {2007}
}
@article{Richardson2005,
abstract = {The subthreshold membrane voltage of a neuron in active cortical tissue is a fluctuating quantity with a distribution that reflects the firing statistics of the presynaptic population. It was recently found that conductance-based synaptic drive can lead to distributions with a significant skew. Here it is demonstrated that the underlying shot noise caused by Poissonian spike arrival also skews the membrane distribution, but in the opposite sense. Using a perturbative method, we analyze the effects of shot noise on the distribution of synaptic conductances and calculate the consequent voltage distribution. To first order in the perturbation theory, the voltage distribution is a gaussian modulated by a prefactor that captures the skew. The gaussian component is identical to distributions derived using current-based models with an effective membrane time constant. The well-known effective-time-constant approximation can therefore be identified as the leading-order solution to the full conductance-based model. The higher-order modulatory prefactor containing the skew comprises terms due to both shot noise and conductance fluctuations. The diffusion approximation misses these shot-noise effects implying that analytical approaches such as the Fokker-Planck equation or simulation with filtered white noise cannot be used to improve on the gaussian approximation. It is further demonstrated that quantities used for fitting theory to experiment, such as the voltage mean and variance, are robust against these non-Gaussian effects. The effective-time-constant approximation is therefore relevant to experiment and provides a simple analytic base on which other pertinent biological details may be added.},
author = {Richardson, M J E and Gerstner, W},
doi = {10.1162/0899766053429444},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Artifacts,Cell Membrane,Cell Membrane: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Humans,Ion Channels,Ion Channels: physiology,Neural Conduction,Neural Conduction: physiology,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Normal Distribution,Poisson Distribution,Synaptic Transmission,Synaptic Transmission: physiology},
month = {apr},
number = {4},
pages = {923--47},
pmid = {15829095},
title = {{Synaptic shot noise and conductance fluctuations affect the membrane voltage with equal significance.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15829095},
volume = {17},
year = {2005}
}
@article{Deco2010,
abstract = {During decision making between sequential stimuli, the first stimulus must be held in memory and then compared with the second. Here, we show that in systems that encode the stimuli by their firing rate, neurons can use synaptic facilitation not only to remember the first stimulus during the delay but during the presentation of the second stimulus so that they respond to a combination of the first and second stimuli, as has been found for "partial differential" neurons recorded in the ventral premotor cortex during vibrotactile flutter frequency decision making. Moreover, we show that such partial differential neurons provide important input to a subsequent attractor decision-making network that can then compare this combination of the first and second stimuli with inputs from other neurons that respond only to the second stimulus. Thus, both synaptic facilitation and neuronal attractor dynamics can account for sequential decision making in such systems in the brain.},
author = {Deco, Gustavo and Rolls, Edmund T and Romo, Ranulfo},
doi = {10.1073/pnas.1002333107},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Brain,Brain: metabolism,Decision Making,Decision Making: physiology,Humans,Interneurons,Interneurons: cytology,Memory,Memory: physiology,Models, Biological,Models, Neurological,Models, Statistical,Motor Cortex,Neurons,Neurons: metabolism,Pyramidal Cells,Pyramidal Cells: cytology,Synapses,Synapses: physiology,Synaptic Transmission,Time Factors},
month = {apr},
number = {16},
pages = {7545--9},
pmid = {20360555},
title = {{Synaptic dynamics and decision making.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2867686{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {107},
year = {2010}
}
@article{Hestenes|1996|,
abstract = {A new gauge theory of gravitation on {\^{A}}°at spacetime has recently been
developed by Lasenby, Doran, and Gull in the language of Geometric
Calculus. This paper provides a systematic account of the mathematical
formalism to facilitate applications and extensions of the theory.
It includes formulations of di{\^{A}}{\textregistered}erential geometry, Lie derivatives
and integrability theorems which are coordinate-free and gauge-covariant.
Emphasis is on use of the language to express physical and geometrical
concepts.},
author = {Hestenes, D},
keywords = {gravity,physics,quantum field theory,quantum gravity,unread},
title = {{Space-time calculus for gravitation theory}}
}
@article{OertelDizack90,
author = {Oertel, D and Wu, S H and Garb, M W and Dizack, C},
journal = {Journal of Comparative Neurology},
month = {may},
number = {1},
pages = {136--154},
title = {{Morphology and physiology of cells in slice preparations of the posteroventral cochlear nucleus of mice}},
volume = {295},
year = {1990}
}
@misc{Hoffman|2006|,
annote = {This short presentation deals with varieties of gaussian filters{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and their applications},
author = {Hoffman, G},
keywords = {band-pass,computational,filter,gaussian,image processing},
title = {{Gaussian Filters}}
}
@article{Shalev-Shwartz2010,
author = {Shalev-Shwartz, S and Singer, Y and Srebro, Nathan and Cotter, A},
doi = {10.1007/s10107-010-0420-4},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {stochastic gradient descent,svm},
month = {oct},
number = {1},
pages = {3--30},
title = {{Pegasos: primal estimated sub-gradient solver for SVM}},
url = {http://www.springerlink.com/index/10.1007/s10107-010-0420-4},
volume = {127},
year = {2010}
}
@article{Xiong2011,
abstract = {MOTIVATION: Alternative splicing is a major contributor to cellular diversity in mammalian tissues and relates to many human diseases. An important goal in understanding this phenomenon is to infer a 'splicing code' that predicts how splicing is regulated in different cell types by features derived from RNA, DNA and epigenetic modifiers. METHODS: We formulate the assembly of a splicing code as a problem of statistical inference and introduce a Bayesian method that uses an adaptively selected number of hidden variables to combine subgroups of features into a network, allows different tissues to share feature subgroups and uses a Gibbs sampler to hedge predictions and ascertain the statistical significance of identified features. RESULTS: Using data for 3665 cassette exons, 1014 RNA features and 4 tissue types derived from 27 mouse tissues (http://genes.toronto.edu/wasp), we benchmarked several methods. Our method outperforms all others, and achieves relative improvements of 52{\%} in splicing code quality and up to 22{\%} in classification error, compared with the state of the art. Novel combinations of regulatory features and novel combinations of tissues that share feature subgroups were identified using our method. CONTACT: frey@psi.toronto.edu SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
author = {Xiong, H Y and Barash, Y and Frey, B J},
doi = {10.1093/bioinformatics/btr444},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Alternative Splicing,Alternative Splicing: genetics,Animals,Base Sequence,Bayes Theorem,Exons,Gene Expression,Gene Expression Regulation,Genetic,Humans,Mice,Models,RNA,RNA Isoforms,RNA Isoforms: genetics,RNA Splicing,RNA: genetics,Transcription},
month = {oct},
number = {18},
pages = {2554--62},
pmid = {21803804},
title = {{Bayesian prediction of tissue-regulated splicing using RNA sequence and cellular context.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21803804},
volume = {27},
year = {2011}
}
@article{Ienne1993,
author = {Ienne, Paolo},
title = {{Architectures for neuro-computers: review and performance evaluation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.1950{\&}rep=rep1{\&}type=pdf},
year = {1993}
}
@article{Andersen|1966|a,
annote = {Journal Article Germany, west},
author = {Andersen, P and Blackstad, T W and Lomo, T},
journal = {Exp Brain Res},
keywords = {Animals Dendrites/anatomy {\&} histology Electrophysi},
number = {3},
pages = {236--248},
title = {{Location and identification of excitatory synapses on hippocampal pyramidal cells}},
volume = {1}
}
@article{GoldingOertel95,
author = {Golding, N L and Robertson, D and Oertel, D},
journal = {Journal of Neuroscience},
month = {apr},
number = {4},
pages = {3138--3153},
title = {{Recordings from slices indicate that octopus cells of the cochlear nucleus detect coincident firing of auditory nerve fibers with temporal precision}},
volume = {15},
year = {1995}
}
@article{Koch2000,
abstract = {Neurons carry out the many operations that extract meaningful information from sensory receptor arrays at the organism's periphery and translate these into action, imagery and memory. Within today's dominant computational paradigm, these operations, involving synapses, membrane ionic channels and changes in membrane potential, are thought of as steps in an algorithm or as computations. The role of neurons in these computations has evolved conceptually from that of a simple integrator of synaptic inputs until a threshold is reached and an output pulse is initiated, to a much more sophisticated processor with mixed analog-digital logic and highly adaptive synaptic elements.},
author = {Koch, C and Segev, I},
doi = {10.1038/81444},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cell Membrane,Cell Membrane: physiology,Cell Membrane: ultrastructure,Cell Size,Cell Size: physiology,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Humans,Ion Channels,Ion Channels: physiology,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Synapses,Synapses: physiology,Synapses: ultrastructure},
month = {nov},
pages = {1171--1177},
pmid = {11127834},
title = {{The role of single neurons in information processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11127834},
volume = {3 Suppl},
year = {2000}
}
@inproceedings{Sim99,
author = {Simoncelli, E},
booktitle = {Proc. SPIE, 44th Annual Meeting},
pages = {188--195},
title = {{Modeling the joint statistics of images in the wavelet domain}},
year = {1999}
}
@article{Mitra2009,
author = {Mitra, S and Fusi, S and Indiveri, G},
journal = {IEEE transactions on Biomedical Circuits and Systems},
number = {1},
pages = {32--42},
title = {{Real-time classification of complex patterns using spike-based learning in neuromorphic VLSI}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4693998},
volume = {3},
year = {2009}
}
@article{Eldan2015,
abstract = {We show that there are simple functions expressible by small 3-layer feedforward neural networks, which cannot be approximated by a 2-layer network, to more than a certain constant accuracy, unless its width is exponential in the dimension. The result holds for most continuous activation functions, such as rectified linear units and sigmoids, and formally demonstrates that depth -- even if increased by 1 -- can be exponentially more valuable than width for standard feedforward neural networks.},
archivePrefix = {arXiv},
arxivId = {1512.03965},
author = {Eldan, Ronen and Shamir, Ohad},
eprint = {1512.03965},
pages = {1--30},
title = {{The Power of Depth for Feedforward Neural Networks}},
url = {http://arxiv.org/abs/1512.03965},
year = {2015}
}
@article{Applicanda2012,
author = {Applicanda, Mathematica and Karbowski, J},
journal = {Mathematica Applicanda},
keywords = {1,and phrases,brain,computational neuroscience,do a non-traditional research,in theoretical,introduction,maticians or physicists,modeling,neurons,neuroscience,new field of computational,or theoretical neurobiology,present a relatively,review article is to,the purpose of this,to mathe-,who would like to},
number = {1},
pages = {27--37},
title = {{What can a mathematician do in neuroscience?}},
url = {http://www.mimuw.edu.pl/{~}ptm/wydawnictwa/index.php/matematyka-stosowana/article/viewArticle/277},
volume = {40},
year = {2012}
}
@article{ZDP98,
author = {Zemel, R and Dayan, P and Pouget, A},
journal = {Neural Computation},
pages = {403--430},
title = {{Probabilistic interpretation of population codes}},
volume = {10},
year = {1998}
}
@article{Misra2010,
author = {Misra, Janardan and Saha, Indranil},
doi = {10.1016/j.neucom.2010.03.021},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Analog neural design,CNN implementation,Digital neural design,FPGA based ANN implementation,Hybrid neural design,Neurochip,Neuromorphic system,Optical neural network,Parallel neural architecture,RAM based implementation,hardware neural network},
month = {dec},
number = {1-3},
pages = {239--255},
publisher = {Elsevier},
title = {{Artificial neural networks in hardware: A survey of two decades of progress}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S092523121000216X},
volume = {74},
year = {2010}
}
@article{Batenburg|2006|,
abstract = {We present a new algorithm for reconstructing binary images from their
projections along a small number of directions. Our algorithm performs
a sequence of related reconstructions, each using only two projections.
The algorithm makes extensive use of network flow algorithms for
solving the two-projection subproblems. Our experimental results
demonstrate that the algorithm can compute highly accurate reconstructions
from a small number of projections, even in the presence of noise.
Although the effectiveness of the algorithm is based on certain smoothness
assumptions about the image, even tiny, non-smooth details are reconstructed
exactly. The class of images for which the algorithm is most effective
includes images of convex objects, but images of objects that contain
holes or consist of multiple components can also be reconstructed
very well.},
annote = {The paper is about fast method for reconstructing binary images from{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}projections counting integer number of {\&}{\#}039;hits{\&}{\#}039; from {\&}{\#}039;atoms{\&}{\#}039; along{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the X-ray. It formulates the problem as linear-constrained optimization{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and uses a method of linear programming, coined network flow problem,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to suggest a fast solver.},
author = {Batenburg, K J},
keywords = {binary images,discrete tomography,image reconstruction,linear programming,mathematics,network flow},
title = {{A network flow algorithm for reconstructing binary images from discrete X-rays.}}
}
@article{Tolhurst83,
author = {{Tolhurst D. Movshon}, J A and Dean, A},
journal = {Vision Research},
pages = {775--785},
title = {{The statistical reliability of single neurons in cat and monkey visual cortex}},
volume = {23},
year = {1983}
}
@article{Timme2002,
annote = {2010IInum8.2},
author = {Timme, M and Wolf, F and Geisel, T},
journal = {Physical Review Letters},
title = {{Prevalence of unstable attractors in networks of pulse-coupled oscillators}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.89.154105},
year = {2002}
}
@article{Coates2013,
author = {Coates, Adam and Huval, Brody and Wang, Tao and Wu, D},
journal = {Proceedings of the 30th International Conference on Ma- chine Learning},
title = {{Deep learning with cots hpc systems}},
url = {http://jmlr.org/proceedings/papers/v28/coates13.html},
year = {2013}
}
@article{DiBernardo1999,
annote = {2011num18},
author = {{Di Bernardo}, M and Feigin, M I and Hogan, S J and Homer, M E},
issn = {0960-0779},
journal = {Chaos Solitons and Fractals},
number = {11},
pages = {1881--1908},
publisher = {Oxford; New York: Pergamon Press, c1991-},
title = {{Local analysis of C-bifurcations in n-dimensional piecewise-smooth dynamical systems}},
url = {http://wpage.unina.it/mdiberna/Pubblicazioni{\_}Selezionate/18.CSF99.pdf},
volume = {10},
year = {1999}
}
@article{Andrieu2007,
author = {Andrieu, C and Doucet, A and Holenstein, A},
journal = {Working paper},
title = {{Particle Markov chain Monte Carlo}},
year = {2007}
}
@book{Hestenes|1998|,
abstract = {This chapter summarizes and extends some of the basic ideas and results
of Geometric Algebra developed in a previous book NFCM (New Foundations
for Classical Mechanics). To make the summary self-contained, all
essential de{\^{A}}¯nitions and notations will be explained, and geometric
interpretations of algebraic expressions will be reviewed. However,
many algebraic identities and theorems from NFCM will be stated without
repeating proofs or detailed discussions. And some of the more elementary
results and common mathematical notions will be taken for granted.
As new theorems are introduced their proofs will be sketched, but
readers will be expected to {\^{A}}¯ll-in straightforward algebraic steps
as needed. Readers who have undue di{\^{A}}±culties with this chapter should
refer to NFCM for more details. Those who want a more advanced mathematical
treatment should refer to the book GC (Cli{\^{A}}{\textregistered}ord Algebra to Geometric
Calculus).},
annote = {This is a chapter from a book on new concepts of Geometric Calculus},
author = {Hestenes, D},
keywords = {geometric algebra,mathematics,physics,unread},
title = {{Geometric Algebra}}
}
@article{Sanches08,
author = {Sanches, J M and Nascimento, J C and Marques, J S},
journal = {Image Processing, IEEE Transactions on},
pages = {1522--1539},
title = {{Medical Image Noise Reduction Using the Sylvester-Lyapunov Equation}},
volume = {17},
year = {2008}
}
@inproceedings{Wright01,
author = {Wright, B D and Sen, Kamal and Bialek, William and Doupe, A J},
booktitle = {NIPS},
pages = {309--316},
title = {{Spike timing and the coding of naturalistic sounds in a central auditory area of songbirds.}},
year = {2001}
}
@article{Carlson2011,
abstract = {This study examined organizational levers that impact work-family experiences, participant health, and subsequent turnover. Using a sample of 179 women returning to full-time work 4 months after childbirth, we examined the associations of 3 job resources (job security, skill discretion, and schedule control) with work-to-family enrichment and the associations of 2 job demands (psychological requirements and nonstandard work schedules) with work-to-family conflict. Further, we considered subsequent impact of work-to-family conflict and enrichment on women's health (physical and mental health) 8 months after women returned to work and the impact of health on voluntary turnover 12 months after women returned to work. Having a nonstandard work schedule was directly and positively related to conflict, whereas schedule control buffered the effect of psychological requirements on conflict. Skill discretion and job security, both job resources, directly and positively related to enrichment. Work-to-family conflict was negatively related to both physical and mental health, but work-to-family enrichment positively predicted only physical health. Physical health and mental health both negatively influenced turnover. We discuss implications and opportunities for future research. (PsycINFO Database Record (c) 2011 APA, all rights reserved).},
author = {Carlson, Dawn S and Grzywacz, Joseph G and Ferguson, Merideth and Hunter, Emily M and Clinch, C Randall and Arcury, Thomas a},
doi = {10.1037/a0023964},
issn = {1939-1854},
journal = {The Journal of applied psychology},
month = {may},
pmid = {21604833},
title = {{Health and turnover of working mothers after childbirth via the work-family interface: An analysis across time.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21604833},
year = {2011}
}
@article{Press1987,
author = {Press, W H and Teukolsky, S A and Vetterling, W T and Flannery, B P},
isbn = {9780521880688},
title = {{Numerical Recipes: The art of scientific computing}},
url = {http://www.ulb.tu-darmstadt.de/tocs/184215021.pdf http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Numerical+Recipes+the+art+of+scientifi+computing{\#}0},
year = {1987}
}
@article{Mishchenko2012,
abstract = {In recent years, the problem of reconstructing the connectivity in large neural circuits ("connectomics") has re-emerged as one of the main objectives of neuroscience. Classically, reconstructions of neural connectivity have been approached anatomically, using electron or light microscopy and histological tracing methods. This paper describes a statistical approach for connectivity reconstruction that relies on relatively easy-to-obtain measurements using fluorescent probes such as synaptic markers, cytoplasmic dyes, transsynaptic tracers, or activity-dependent dyes. We describe the possible design of these experiments and develop a Bayesian framework for extracting synaptic neural connectivity from such data. We show that the statistical reconstruction problem can be formulated naturally as a tractable L₁-regularized quadratic optimization. As a concrete example, we consider a realistic hypothetical connectivity reconstruction experiment in C. elegans, a popular neuroscience model where a complete wiring diagram has been previously obtained based on long-term electron microscopy work. We show that the new statistical approach could lead to an orders of magnitude reduction in experimental effort in reconstructing the connectivity in this circuit. We further demonstrate that the spatial heterogeneity and biological variability in the connectivity matrix--not just the "average" connectivity--can also be estimated using the same method.},
author = {Mishchenko, Y and Paninski, L},
doi = {10.1007/s10827-012-0390-z},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Animals,Animals, Genetically Modified,Astrocytes,Astrocytes: physiology,Bayes Theorem,Caenorhabditis elegans,Connectome,Estimation,Green Fluorescent Proteins,Green Fluorescent Proteins: genetics,Image Processing, Computer-Assisted,Luminescent Agents,Luminescent Agents: metabolism,Microscopy, Fluorescence,Models, Neurological,Nerve Net,Nerve Net: anatomy {\&} histology,Nerve Net: metabolism,Neurons,Neurons: cytology,Neurons: metabolism,Neurons: physiology,Synapses,Synapses: metabolism,Synapses: physiology},
mendeley-tags = {Estimation},
month = {oct},
number = {2},
pages = {371--88},
pmid = {22437567},
title = {{A Bayesian compressed-sensing approach for reconstructing neural connectivity from subsampled anatomical data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22437567},
volume = {33},
year = {2012}
}
@article{Gillespie2007,
abstract = {Stochastic chemical kinetics describes the time evolution of a well-stirred chemically reacting system in a way that takes into account the fact that molecules come in whole numbers and exhibit some degree of randomness in their dynamical behavior. Researchers are increasingly using this approach to chemical kinetics in the analysis of cellular systems in biology, where the small molecular populations of only a few reactant species can lead to deviations from the predictions of the deterministic differential equations of classical chemical kinetics. After reviewing the supporting theory of stochastic chemical kinetics, I discuss some recent advances in methods for using that theory to make numerical simulations. These include improvements to the exact stochastic simulation algorithm (SSA) and the approximate explicit tau-leaping procedure, as well as the development of two approximate strategies for simulating systems that are dynamically stiff: implicit tau-leaping and the slow-scale SSA.},
author = {Gillespie, D T},
doi = {10.1146/annurev.physchem.58.032806.104637},
issn = {0066-426X},
journal = {Annual review of physical chemistry},
keywords = {Algorithms,Chemical,Computer Simulation,Kinetics,Models,Stochastic Processes},
month = {jan},
pages = {35--55},
pmid = {17037977},
title = {{Stochastic simulation of chemical kinetics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17037977},
volume = {58},
year = {2007}
}
@book{traub1991neuronal,
author = {Traub, R.D. and Miles, R.},
isbn = {0521364817},
publisher = {Cambridge Univ Pr},
title = {{Neuronal networks of the hippocampus}},
url = {http://www.google.com/books?hl=iw{\&}lr={\&}id=Ob7a5f0Nd7gC{\&}oi=fnd{\&}pg=PR9{\&}dq=Traub+RD,+Miles+R+{\%}281991{\%}29+Neuronal+networks+of+the+Hippocampus.+Cambridge+University+Press,+Cambridge{\&}ots=3eQmh8-h70{\&}sig=nc{\_}TsIuFHSq7Xonoq55pLQw9sRU},
year = {1991}
}
@article{Rolston:2007uq,
abstract = {Recurring patterns of neural activity, a potential substrate of both
information transfer and transformation in cortical networks, have
been observed in the intact brain and in brain slices. Do these patterns
require the inherent cortical microcircuitry of such preparations
or are they a general property of self-organizing neuronal networks?
In networks of dissociated cortical neurons from rats--which lack
evidence of the intact brain's intrinsic cortical architecture--we
have observed a robust set of spontaneously repeating spatiotemporal
patterns of neural activity, using a template-matching algorithm
that has been successful both in vivo and in brain slices. The observed
patterns in cultured monolayer networks are stable over minutes of
extracellular recording, occur throughout the culture's development,
and are temporally precise within milliseconds. The identification
of these patterns in dissociated cultures opens a powerful methodological
avenue for the study of such patterns, and their persistence despite
the topological and morphological rearrangements of cellular dissociation
is further evidence that precisely timed patterns are a universal
emergent feature of self-organizing neuronal networks.},
author = {Rolston, J D and Wagenaar, D A and Potter, S M},
doi = {10.1016/j.neuroscience.2007.05.025},
journal = {Neuroscience},
keywords = {networks},
mendeley-tags = {networks},
number = {1},
pages = {294--303},
pmid = {17614210},
title = {{Precisely timed spatiotemporal patterns of neural activity in dissociated cortical cultures}},
volume = {148},
year = {2007}
}
@article{Clark|2006|,
author = {Clark, R},
keywords = {codes,language,linguistics,mathematics,phonetics,pumping lemma},
title = {{Dependencies, the Pumping Lemma and Private Languages}}
}
@article{CaoAbbott93,
author = {Cao, B J and Abbott, L F},
journal = {Biophysical Journal},
number = {2},
pages = {303--313},
title = {{A new computational method for cable theory problems}},
volume = {64},
year = {1993}
}
@article{Loewenstein2011,
abstract = {What fundamental properties of synaptic connectivity in the neocortex stem from the ongoing dynamics of synaptic changes? In this study, we seek to find the rules shaping the stationary distribution of synaptic efficacies in the cortex. To address this question, we combined chronic imaging of hundreds of spines in the auditory cortex of mice in vivo over weeks with modeling techniques to quantitatively study the dynamics of spines, the morphological correlates of excitatory synapses in the neocortex. We found that the stationary distribution of spine sizes of individual neurons can be exceptionally well described by a log-normal function. We furthermore show that spines exhibit substantial volatility in their sizes at timescales that range from days to months. Interestingly, the magnitude of changes in spine sizes is proportional to the size of the spine. Such multiplicative dynamics are in contrast with conventional models of synaptic plasticity, learning, and memory, which typically assume additive dynamics. Moreover, we show that the ongoing dynamics of spine sizes can be captured by a simple phenomenological model that operates at two timescales of days and months. This model converges to a log-normal distribution, bridging the gap between synaptic dynamics and the stationary distribution of synaptic efficacies.},
author = {Loewenstein, Y and Kuras, A and Rumpel, S},
doi = {10.1523/JNEUROSCI.6130-10.2011},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {Animals,Auditory Cortex,Auditory Cortex: physiology,Dendritic Spines,Dendritic Spines: physiology,Male,Mice,Models,Neocortex,Neocortex: physiology,Neurological,Neurons,Neurons: physiology,Synapses,Synapses: physiology},
month = {jun},
number = {26},
pages = {9481--9488},
pmid = {21715613},
title = {{Multiplicative dynamics underlie the emergence of the log-normal distribution of spine sizes in the neocortex in vivo.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21715613},
volume = {31},
year = {2011}
}
@article{Nykamp2008,
author = {Nykamp, D Q},
doi = {10.1103/PhysRevE.78.021902},
issn = {1539-3755},
journal = {Physical Review E},
month = {aug},
number = {2},
pages = {021902},
title = {{Pinpointing connectivity despite hidden nodes within stimulus-driven networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.78.021902},
volume = {78},
year = {2008}
}
@article{Teich1989,
author = {Teich, M C},
journal = {IEEE Transactions on Biomedical Engineering},
number = {1},
pages = {150--160},
title = {{Fractal character of the auditory neural spike train}},
url = {http://people.bu.edu/teich/pdfs/IEEE-BME-36-150-1989.pdf},
volume = {36},
year = {1989}
}
@article{Hindmarsh1984,
author = {Hindmarsh, JL and Rose, RM},
journal = {Proceedings of the Royal society of London. Series B. Biological sciences},
number = {1222},
pages = {87--102},
publisher = {The Royal Society},
title = {{A model of neuronal bursting using three coupled first order differential equations}},
url = {http://rspb.royalsocietypublishing.org/content/221/1222/87.short},
volume = {221},
year = {1984}
}
@article{Catsigeras2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1003.2674v1},
author = {Catsigeras, Eleonora and Budelli, Ruben},
eprint = {arXiv:1003.2674v1},
journal = {Arxiv preprint arXiv:1003.2674},
keywords = {and phrases,periodic attractors,piecewise continuous maps,topological dynamics},
pages = {1--19},
title = {{Topological dynamics of generic piecewise continuous contractive maps in n dimensions}},
url = {http://arxiv.org/abs/1003.2674},
year = {2010}
}
@article{Darwiche2003,
author = {Darwiche, Adnan},
journal = {Journal of the ACM (JACM)},
title = {{A differential approach to inference in Bayesian networks}},
url = {http://dl.acm.org/citation.cfm?id=765570},
year = {2003}
}
@article{Arjovsky2017,
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
archivePrefix = {arXiv},
arxivId = {1701.07875},
author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'{e}}on},
eprint = {1701.07875},
title = {{Wasserstein GAN}},
url = {http://arxiv.org/abs/1701.07875},
year = {2017}
}
@article{Lu2017,
abstract = {In deep learning, $\backslash$textit{\{}depth{\}}, as well as $\backslash$textit{\{}nonlinearity{\}}, create non-convex loss surfaces. Then, does depth alone create bad local minima? In this paper, we prove that without nonlinearity, depth alone does not create bad local minima, although it induces non-convex loss surface. Using this insight, we greatly simplify a recently proposed proof to show that all of the local minima of feedforward deep linear neural networks are global minima. Our theoretical result generalizes previous results with fewer assumptions.},
archivePrefix = {arXiv},
arxivId = {1702.08580},
author = {Lu, Haihao and Kawaguchi, Kenji},
eprint = {1702.08580},
journal = {ArXiv},
number = {2014},
pages = {1--9},
title = {{Depth Creates No Bad Local Minima}},
url = {http://arxiv.org/abs/1702.08580},
year = {2017}
}
@article{Wu83,
author = {Wu, C},
journal = {Annals of Statistics},
pages = {95--103},
title = {{On the convergence properties of the {\{}EM{\}} algorithm}},
volume = {11},
year = {1983}
}
@article{Cox1980,
author = {Cox, D R and Isham, V},
title = {{Point processes}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=KWF2xY6s3PoC{\&}oi=fnd{\&}pg=PR9{\&}dq=Point+processes{\&}ots=Y5-P{\_}JSoNp{\&}sig=IuLkf91vv9P0ypEg6ySNUq63SYI},
year = {1980}
}
@article{Goodrich|1994|,
abstract = {We give an O(n log n)-time method for finding a best k-link piecewise
linear function approximating an n-point planar data set using the
well-known uniform metric to measure the error, epsilon {\textgreater} 0, of the
approximation. Our method is based upon new characterizations of
such functions, which we exploit to design an efficient algorithm
using a plane sweep in "epsilon space" followed by several applications
of the parameteric searching technique. The previous best running
time for this problem was O(n{\^{}}2).},
author = {Goodrich, M T},
keywords = {approximation,computational,mathematics,piece-wise linear,vectorization},
title = {{Efficient piecewise-linear function approximation using the uniform metric}}
}
@article{David2010,
abstract = {Despite their evolutionary significance, little is known about the adaptation dynamics of genomically rewired cells in evolution. We have confronted yeast cells carrying a rewired regulatory circuit with a severe and unforeseen challenge. The essential HIS3 gene from the histidine biosynthesis pathway was placed under the exclusive regulation of the galactose utilization system. Glucose containing medium strongly represses the GAL genes including HIS3 and these rewired cells are required to operate this essential gene. We show here that although there were no adapted cells prior to the encounter with glucose, a large fraction of cells adapted to grow in this medium and this adaptation was stably inherited. The adaptation relied on individual cells that switched into an adapted state and, thus, the adaptation was due to a response of many individual cells to the change in environment and not due to selection of rare advantageous phenotypes. The adaptation of numerous individual cells by heritable phenotypic switching in response to a challenge extends the common evolutionary framework and attests to the adaptive potential of regulatory circuits.},
annote = {

2010IInum12.5},
author = {David, Lior and Stolovicki, Elad and Haziz, Efrat and Braun, Erez},
doi = {10.2976/1.3353782},
issn = {1955-205X},
journal = {HFSP journal},
month = {jun},
number = {3-4},
pages = {131--41},
pmid = {20811567},
title = {{Inherited adaptation of genome-rewired cells in response to a challenging environment.}},
url = {http://link.aip.org/link/HFSPJX/v1/i1/p131/s1{\&}Agg=doi http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2929631{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2010}
}
@article{Bregman|1965|,
author = {Bregman, L M},
journal = {Soviet Mathematical Doklady},
pages = {688--692},
title = {{The method of successive projection for finding a common point of convex sets.}},
volume = {6}
}
@article{YoungCalhoun05,
author = {Young, Eric D and Calhoun, Barbara M},
journal = {Journal of Neurophysiology},
month = {dec},
number = {6},
pages = {4441--4454},
title = {{Nonlinear modeling of auditory-nerve rate responses to wideband stimuli}},
volume = {94},
year = {2005}
}
@article{Milotti1921,
annote = {

Contain many mistakes, according to sime guy from the Weizman Institute},
author = {Milotti, Edoardo},
journal = {Arxiv preprint physics/0204033},
title = {1 / f noise : a pedagogical review .},
url = {http://arxiv.org/abs/physics/0204033},
year = {1921}
}
@article{Chua2012,
author = {Chua, L and Sbitnev, Valery and Kim, Hyongsuk},
doi = {10.1142/S021812741230011X},
issn = {0218-1274},
journal = {International Journal of Bifurcation and Chaos},
keywords = {hodgkin,huxley,huxley axon,huxley circuit model},
number = {03},
pages = {1230011--1},
title = {{Hodgkin Huxley Axon Is Made of Memristors}},
url = {http://www.worldscinet.com/ijbc/22/2203/S021812741230011X.html},
volume = {22},
year = {2012}
}
@article{Clancy2002,
author = {Collen, EC and Yoram, R},
doi = {10.1161/hc1002.105183},
journal = {Circulation},
keywords = {1,10 in general,and brugada syndromes,arrhythmia ⅲ genes ⅲ,channel gene,long-qt,long-qt syndrome ⅲ brugada,lqt,number of defects in,scn5a have been linked,syndrome ⅲ sodium,the,the cardiac na ϩ,to congenital forms of},
title = {{Na channel mutation that causes both Brugada and long-QT syndrome phenotypes}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Na+Channel+Mutation+That+Causes+Both+Brugada+and+Long-QT+Syndrome+Phenotypes{\#}9},
year = {2002}
}
@article{McCrea2008a,
abstract = {Central pattern generators (CPGs) located in the spinal cord produce the coordinated activation of flexor and extensor motoneurons during locomotion. Previously proposed architectures for the spinal locomotor CPG have included the classical half-center oscillator and the unit burst generator (UBG) comprised of multiple coupled oscillators. We have recently proposed another organization in which a two-level CPG has a common rhythm generator (RG) that controls the operation of the pattern formation (PF) circuitry responsible for motoneuron activation. These architectures are discussed in relation to recent data obtained during fictive locomotion in the decerebrate cat. The data show that the CPG can maintain the period and phase of locomotor oscillations both during spontaneous deletions of motoneuron activity and during sensory stimulation affecting motoneuron activity throughout the limb. The proposed two-level CPG organization has been investigated with a computational model which incorporates interactions between the CPG, spinal circuits and afferent inputs. The model includes interacting populations of spinal interneurons and motoneurons modeled in the Hodgkin-Huxley style. Our simulations demonstrate that a relatively simple CPG with separate RG and PF networks can realistically reproduce many experimental phenomena including spontaneous deletions of motoneuron activity and a variety of effects of afferent stimulation. The model suggests plausible explanations for a number of features of real CPG operation that would be difficult to explain in the framework of the classical single-level CPG organization. Some modeling predictions and directions for further studies of locomotor CPG organization are discussed.},
author = {Mccrea, David a and Rybak, Ilya A},
doi = {10.1016/j.brainresrev.2007.08.006},
issn = {0165-0173},
journal = {Brain research reviews},
keywords = {Animals,Humans,Instinct,Locomotion,Locomotion: physiology,Mammals,Mammals: physiology,Nerve Net,Nerve Net: physiology,motor control},
mendeley-tags = {motor control},
month = {jan},
number = {1},
pages = {134--46},
pmid = {17936363},
title = {{Organization of mammalian locomotor rhythm and pattern generation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17936363 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2214837{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {57},
year = {2008}
}
@article{Plenz2007,
abstract = {Neuronal avalanches are spatiotemporal patterns of neuronal activity that occur spontaneously in superficial layers of the mammalian cortex under various experimental conditions. These patterns reflect fast propagation of local synchrony, display a rich spatiotemporal diversity and recur over several hours. The statistical organization of pattern sizes is invariant to the choice of spatial scale, demonstrating that the functional linking of cortical sites into avalanches occurs on all spatial scales with a fractal organization. These features suggest an underlying network of neuronal interactions that balances diverse representations with predictable recurrence, similar to what has been theorized for cell assembly formation. We propose that avalanches reflect the transient formation of cell assemblies in the cortex and discuss various models that provide mechanistic insights into the underlying dynamics, suggesting that they arise in a critical regime.},
annote = {2010num5.6},
author = {Plenz, D and Thiagarajan, Tara C},
doi = {10.1016/j.tins.2007.01.005},
issn = {0166-2236},
journal = {Trends in Neurosciences},
keywords = {Animals,Cell Communication,Cell Communication: physiology,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Cortical Synchronization,Humans,Models,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurological,Neurons,Neurons: cytology,Neurons: physiology,Signal Transduction,Signal Transduction: physiology},
number = {3},
pages = {101--10},
pmid = {17275102},
title = {{The organizing principles of neuronal avalanches: cell assemblies in the cortex?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17275102},
volume = {30},
year = {2007}
}
@article{ER99,
author = {Everson, R and Roberts, S},
journal = {IEEE Transactions on Signal Proceedings},
pages = {2083--2091},
title = {{Inferring the eigenvalues of covariance matrices from limited, noisy data}},
volume = {48},
year = {2000}
}
@article{Kamenev2008,
author = {Kamenev, Alex and Meerson, Baruch and Shklovskii, Boris},
doi = {10.1103/PhysRevLett.101.268103},
issn = {0031-9007},
journal = {Physical Review Letters},
number = {26},
pages = {1--4},
title = {{How Colored Environmental Noise Affects Population Extinction}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.101.268103},
volume = {101},
year = {2008}
}
@article{Churchland2010,
annote = {10.1038/nn.2501},
author = {Churchland, Mark M and Yu, Byron M and Cunningham, John P and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew A and Kohn, Adam and Movshon, J Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, K.V.},
isbn = {1097-6256},
journal = {Nat Neurosci},
keywords = {networks},
mendeley-tags = {networks},
month = {mar},
number = {3},
pages = {369--378},
publisher = {Nature Publishing Group},
title = {{Stimulus onset quenches neural variability: a widespread cortical phenomenon}},
url = {http://dx.doi.org/10.1038/nn.2501 http://www.nature.com/neuro/journal/v13/n3/suppinfo/nn.2501{\_}S1.html},
volume = {13},
year = {2010}
}
@article{Shoham05,
author = {Shoham, S and O'Connor, D H and Sarkisov, D V and Wang, S S},
journal = {Nature Methods},
number = {11},
pages = {837--843},
title = {{Rapid neurotransmitter uncaging in spatially defined patterns}},
volume = {2},
year = {2005}
}
@article{Nordlie2010,
author = {Nordlie, E and Tetzlaff, T and Einevoll, G T and Box, O},
doi = {10.3389/fncom.2010.00149},
journal = {Neuroscience},
keywords = {diffusion limit,finite synaptic weights,firing-rate model,leaky integrate-and-fire neuron,linear,linear response,nonlinear model,spiking neuron model,transfer function},
number = {December},
pages = {1--13},
title = {{Rate dynamics of leaky integrate-and-fire neurons with strong synapses}},
volume = {4},
year = {2010}
}
@article{Babadi08,
author = {Babadi, B and Casti, A and Xiao, Y and Paninski, L},
journal = {COSYNE},
title = {{Visual response in LGN neurons beyond the monosynaptic retinogeniculate transmission}},
year = {2008}
}
@article{Goyal2017,
abstract = {Deep learning thrives with large neural networks and large datasets. However, larger networks and larger datasets result in longer training times that impede re-search and development progress. Distributed synchronous SGD offers a potential solution to this problem by dividing SGD minibatches over a pool of parallel workers. Yet to make this scheme efficient, the per-worker workload must be large, which implies nontrivial growth in the SGD mini-batch size. In this paper, we empirically show that on the ImageNet dataset large minibatches cause optimization dif-ficulties, but when these are addressed the trained networks exhibit good generalization. Specifically, we show no loss of accuracy when training with large minibatch sizes up to 8192 images. To achieve this result, we adopt a linear scal-ing rule for adjusting learning rates as a function of mini-batch size and develop a new warmup scheme that over-comes optimization challenges early in training. With these simple techniques, our Caffe2-based system trains ResNet-50 with a minibatch size of 8192 on 256 GPUs in one hour, while matching small minibatch accuracy. Using commod-ity hardware, our implementation achieves ∼90{\%} scaling efficiency when moving from 8 to 256 GPUs. This system enables us to train visual recognition models on internet-scale data with high efficiency.},
archivePrefix = {arXiv},
arxivId = {1706.02677},
author = {Goyal, Priya and Doll{\'{a}}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Kaiming, Yangqing Jia and Facebook, He},
eprint = {1706.02677},
journal = {arXiv preprint},
title = {{Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour}},
url = {https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h3.pdf?},
year = {2017}
}
@article{Ozturk2007,
abstract = {The design of echo state network (ESN) parameters relies on the selection of the maximum eigenvalue of the linearized system around zero (spectral radius). However, this procedure does not quantify in a systematic manner the performance of the ESN in terms of approximation error. This article presents a functional space approximation framework to better understand the operation of ESNs and proposes an information-theoretic metric, the average entropy of echo states, to assess the richness of the ESN dynamics. Furthermore, it provides an interpretation of the ESN dynamics rooted in system theory as families of coupled linearized systems whose poles move according to the input signal dynamics. With this interpretation, a design methodology for functional approximation is put forward where ESNs are designed with uniform pole distributions covering the frequency spectrum to abide by the richness metric, irrespective of the spectral radius. A single bias parameter at the ESN input, adapted with the modeling error, configures the ESN spectral radius to the input-output joint space. Function approximation examples compare the proposed design methodology versus the conventional design.},
author = {Ozturk, Mustafa C and Xu, Dongming and Pr{\'{i}}ncipe, Jos{\'{e}} C},
doi = {10.1162/neco.2007.19.1.111},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Entropy,Linear Models,Neural Networks (Computer),Reservoir Computing},
mendeley-tags = {Reservoir Computing},
month = {jan},
number = {1},
pages = {111--38},
pmid = {17134319},
title = {{Analysis and design of echo state networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17134319},
volume = {19},
year = {2007}
}
@book{WainwrightJordan08,
author = {Wainwright, Martin J. and Jordan, Michael I.},
booktitle = {Foundations and Trends in Machine Learning},
doi = {10.1561/2200000001},
issn = {1935-8237},
number = {1-2},
pages = {1--305},
title = {{Graphical Models, Exponential Families, and Variational Inference.}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000001},
volume = {1},
year = {2008}
}
@article{Wallach2011a,
annote = {2011num31},
author = {Wallach, A and Marom, S},
title = {{Interactions Between Network Synchrony and the Dynamics of Neuronal Threshold}}
}
@article{Holden2006,
author = {Holden, A J and Robbins, D J and Stewart, W J and Smith, D R and Schultz, S and Wegener, M and Linden, S and Hormann, C and Enkrich, C and Soukoulis, C M and Schurig, D and Taylor, A J and Highstrete, C and Lee, M and Averitt, R D and Markos, P and Mcpeake, D and Ramakrishna, S A and Pendry, J B and Shalaev, V M and Maksimchuk, M and Umstadter, D and Chen, W and Shen, Y R and Moloney, J V},
number = {July},
pages = {504--507},
title = {{Reducing the Dimensionality of}},
volume = {313},
year = {2006}
}
@book{BUCK04,
author = {Bucklew, J},
publisher = {Springer},
title = {{Introduction to Rare Event Simulation}},
year = {2004}
}
@article{Negrov2015,
abstract = {We describe an approximation to backpropagation algorithm for training deep neural networks, which is designed to work with synapses implemented with memristors. The key idea is to represent the values of both the input signal and the backpropagated delta value with a series of pulses that trigger multiple positive or negative updates of the synaptic weight, and to use the min operation instead of the product of the two signals. In computational simulations, we show that the proposed approximation to backpropagation is well converged and may be suitable for memristor implementations of multilayer neural networks.},
archivePrefix = {arXiv},
arxivId = {1511.07076},
author = {Negrov, D. V. and Karandashev, I. M. and Shakirov, V. V. and Matveyev, Yu. A. and Dunin-Barkowski, W. L. and Zenkevich, A. V.},
eprint = {1511.07076},
file = {:C$\backslash$:/Users/Daniel/Downloads/e4be44c79b1fda60ebb73021b853350a2fc8.pdf:pdf},
pages = {1--14},
title = {{An Approximate Backpropagation Learning Rule for Memristor Based Neural Networks Using Synaptic Plasticity}},
url = {http://arxiv.org/abs/1511.07076},
year = {2015}
}
@article{Tamamaki|1987|,
abstract = {An intracellular horseradish peroxidase study combined with immunoperoxidase
techniques was carried out on hippocampal CA1 pyramidal neurons in
the rat. Most axon branches originating from a single CA1 pyramidal
neuron ran caudally and terminated in the subiculum. The individual
axon branches of the single pyramidal neurons bifurcated repeatedly
in the subiculum and finally formed a slab-like or columnar terminal
arborization (250-300 microns wide, 500-550 microns high and 1.8-2.2
mm long). The present results suggest, in association with other
data, that the CA1 pyramidal neurons receive afferent information
through lamellar organized connections and they send efferent information
to the subiculum through columnar organized connections.},
annote = {Journal Article Research Support, Non-U.S. Gov{\&}{\#}039;t Netherlands},
author = {Tamamaki, N and Abe, K and Nojyo, Y},
journal = {Brain Res},
keywords = {Animals Axons/*ultrastructure Hippocampus/cytology,Inbred Strains},
number = {1},
pages = {156--160},
title = {{Columnar organization in the subiculum formed by axon branches originating from single CA1 pyramidal neurons in the rat hippocampus}},
volume = {412}
}
@article{WouterloodMugnaini84,
author = {Wouterlood, F G and Mugnaini, E},
journal = {Journal of Comparative Neurology},
month = {jul},
number = {1},
pages = {136--157},
title = {{Cartwheel neurons of the dorsal cochlear nucleus: a {\{}G{\}}olgi-electron microscopic study in rat}},
volume = {227},
year = {1984}
}
@article{Lazar1998a,
author = {Lazar, Aurel A},
keywords = {er type conditions,fluid flow queue,hopf factorization,markov,modulated random walk,nential dependency,non-cram,subexpo-,subexponential distributions,supremum distribution,weiner},
number = {November 1995},
pages = {325--347},
title = {{SUBEXPONENTIAL ASYMPTOTICS OF A MARKOV-MODULATED}},
volume = {347},
year = {1998}
}
@article{Wabgaonkar|1990|,
abstract = {A broad class of neural nets can be viewed as devices that implement
multivariate function approximations. A famous result related to
the representation of multivariate functions by univariate functions
is the Kolmogorov superposition theorem. We describe some aspects
of the construction used in its proof and the difficulties associated
with its exact implementation. Finally, a modified approximation
scheme based on the theorem is proposed.},
annote = {The paper provides some general outline of Kolmogorov{\&}{\#}039;s superposition{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}theorem and discusses its fundamentals.},
author = {Wabgaonkar, H and Stubberud, A},
keywords = {13th Hilbert conjecture,Kolmogorov theorem,function representation by superposition,interpolation,many dimensional,mathematics},
title = {{The Kolmogorov superposition theorem and functional approximations in neural networks}}
}
@article{Innocenti2007,
abstract = {The dynamical phases of the Hindmarsh-Rose neuronal model are analyzed in detail by varying the external current I. For increasing current values, the model exhibits a peculiar cascade of nonchaotic and chaotic period-adding bifurcations leading the system from the silent regime to a chaotic state dominated by bursting events. At higher I-values, this phase is substituted by a regime of continuous chaotic spiking and finally via an inverse period doubling cascade the system returns to silence. The analysis is focused on the transition between the two chaotic phases displayed by the model: one dominated by spiking dynamics and the other by bursts. At the transition an abrupt shrinking of the attractor size associated with a sharp peak in the maximal Lyapunov exponent is observable. However, the transition appears to be continuous and smoothed out over a finite current interval, where bursts and spikes coexist. The beginning of the transition (from the bursting side) is signaled from a structural modification in the interspike interval return map. This change in the map shape is associated with the disappearance of the family of solutions responsible for the onset of the bursting chaos. The successive passage from bursting to spiking chaos is associated with a progressive pruning of unstable long-lasting bursts.},
author = {Innocenti, G and Morelli, A and Genesio, R and Torcini, A},
doi = {10.1063/1.2818153},
issn = {1054-1500},
journal = {Chaos},
keywords = {Action Potentials,Algorithms,Animals,Computer Simulation,Humans,Models,Neurological,Neurons,Neurons: pathology,Nonlinear Dynamics,Statistical,Synaptic Transmission,Systems Theory,Theoretical,Time Factors},
month = {dec},
number = {4},
pages = {043128},
pmid = {18163792},
title = {{Dynamical phases of the Hindmarsh-Rose neuronal model: studies of the transition from bursting to spiking chaos.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18163792},
volume = {17},
year = {2007}
}
@article{Vespignani1998,
author = {Vespignani, A and Dickman, R and Mu{\~{n}}oz, MA and Zapperi, S},
journal = {Physical review letters},
title = {{Driving, conservation, and absorbing states in sandpiles}},
url = {http://prl.aps.org/abstract/PRL/v81/i25/p5676{\_}1},
year = {1998}
}
@article{Cohn2009,
author = {Cohn, Henry},
doi = {10.1038/460801a},
issn = {1476-4687},
journal = {Nature},
month = {aug},
number = {7257},
pages = {801--2},
pmid = {19675632},
title = {{Mathematical physics: A tight squeeze.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19675632},
volume = {460},
year = {2009}
}
@article{Livni,
archivePrefix = {arXiv},
arxivId = {arXiv:1304.7045v1},
author = {Livni, Roi and Shalev-Shwartz, S and Shamir, O},
eprint = {arXiv:1304.7045v1},
journal = {arXiv preprint arXiv:1304.7045},
pages = {1--22},
title = {{A Provably Efficient Algorithm for Training Deep Networks}},
url = {http://arxiv.org/abs/1304.7045},
year = {2013}
}
@article{NimchinskySvoboda04,
abstract = {The number of receptors opening after glutamate release is critical

for understanding the sources of noise and the dynamic range of synaptic

transmission. We imaged [{\{}Ca{\}}{\^{}}{\{}2+{\}}] transients mediated by synaptically

activated NMDA receptors (NMDA-Rs) in individual spines in rat brain

slices. We show that {\{}Ca{\}}{\^{}}{\{}2+{\}} influx through single NMDA-Rs can

be reliably detected, allowing us to estimate the number of receptors

opening after synaptic transmission. This number is small: at the

peak of the synaptic response, less than one NMDA-R is open, on average.

Therefore, stochastic interactions between transmitter and receptor

contribute substantially to synaptic noise, and glutamate occupies

a small fraction of receptors. The number of receptors opening did

not scale with spine volume, and smaller spines experience larger

[{\{}Ca{\}}{\^{}}{\{}2+{\}}] transients during synaptic transmission. Our measurements

further demonstrate that optical recordings can be used to study

single receptors in intact systems.},
author = {Nimchinsky, Esther A and Yasuda, Ryohei and Oertner, Thomas G and Svoboda, Karel},
doi = {10.1523/JNEUROSCI.5066-03.2004},
journal = {J Neurosci},
keywords = {AMPA; Receptors,Animals; Calcium; Calcium Signaling; Dendrites; Ex,Confocal; Models,Glutamate; Receptors,N-Methyl-D-Aspartate; Sensitivity and Specificity,Neurological; Rats; Rats,Wistar; Receptors},
month = {feb},
number = {8},
pages = {2054--2064},
pmid = {14985448},
title = {{The number of glutamate receptors opened by synaptic stimulation in single hippocampal spines.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.5066-03.2004},
volume = {24},
year = {2004}
}
@article{GiepmansTsien06,
author = {Giepmans, Ben N G and Adams, Stephen R and Ellisman, Mark H and Tsien, Roger Y},
journal = {Science},
month = {apr},
number = {5771},
pages = {217--224},
title = {{The fluorescent toolbox for assessing protein location and function}},
volume = {312},
year = {2006}
}
@article{Sansom1989,
annote = {2009num4},
author = {Sansom, M S and Ball, F G and Kerry, C J and McGee, R. and Ramsey, R L and Usherwood, P N},
journal = {Biophysical Journal},
number = {6},
pages = {1229--1243},
publisher = {Elsevier},
title = {{Markov, fractal, diffusion, and related models of ion channel gating. A comparison with experimental data from two ion channels}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349589827705},
volume = {56},
year = {1989}
}
@article{Soudry2013,
author = {Soudry, D. and Meir, R},
journal = {under review},
title = {{Mean Field Backpropagation: scalable training of multilayer neural networks with binary weights}}
}
@article{Choi2015,
author = {Choi, Junil and Love, David J and Brown, D Richard and Member, Senior},
number = {13},
pages = {3537--3548},
title = {{Quantized Distributed Reception for MIMO Wireless Systems Using Spatial Multiplexing}},
volume = {63},
year = {2015}
}
@book{DeGennes|1993|,
address = {New York},
author = {{De Gennes}, P G and Prost, J},
publisher = {Oxford university press},
title = {{The physics of liquid crystals.}}
}
@inproceedings{Welling2011,
author = {Welling, Max and Teh, Yee Whye},
booktitle = {ICML '11},
keywords = {Bayesian learning,ICML,machine learning,online},
title = {{Bayesian Learning via Stochastic Gradient Langevin Dynamics}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/ICML2011Welling{\_}398.pdf},
year = {2011}
}
@article{KleinfeldGriesbeck05,
author = {Kleinfeld, David and Griesbeck, Oliver},
doi = {10.1371/journal.pbio.0030355},
journal = {PLoS Biol},
keywords = {Animals; Electrophysiology; Luminescent Proteins;,Confocal; Neurons; Neurophysiology; Reproducibili},
month = {oct},
number = {10},
pages = {e355},
pmid = {16207078},
title = {{From art to engineering? The rise of in vivo mammalian electrophysiology via genetically targeted labeling and nonlinear imaging.}},
url = {http://dx.doi.org/10.1371/journal.pbio.0030355},
volume = {3},
year = {2005}
}
@article{Mbelek|2004|,
abstract = {The anomalous time depending blueshift, the so-called {\"{i}}¾”Pioneer anomaly{\"{i}}¾”,
that was detected in the radio-metric data from Pioneer 10/11, Ulysses
and Galileo spacecraft may not result from a real change of velocity.
Rather, the Pioneer anomaly may be understood within the framework
of general relativity as a time depending gravitational frequency
shift accounting for the time dependence of the density of the dark
energy when the latter is identified with quintessence. Thus, instead
of being in conflict with Einstein equivalence principle, the main
Pioneer anomaly appears merely as a new validation of general relativity
in the weak field and low velocity limit.},
annote = {This paper is concerned with infamous anomalous slow-down of the{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Pioneer spacecraft at the outer edge of Solar system},
author = {Mbelek, J P},
journal = {arXiv},
keywords = {Pioneer anomaly,astrophysics,general relativity,physics,quintessence},
number = {0407023},
title = {{General relativity and quintessence explain the Pioneer anomaly}},
volume = {gr-qc}
}
@article{Rosenbaum2011a,
author = {Rosenbaum, Robert and Josi{\'{c}}, Kre{\v{s}}imir},
doi = {10.1162/NECO_a_00116},
issn = {0899-7667},
journal = {Neural Computation},
month = {may},
number = {5},
pages = {1261--1305},
title = {{Mechanisms That Modulate the Transfer of Spiking Correlations}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/NECO{\_}a{\_}00116},
volume = {23},
year = {2011}
}
@book{Gerstner2002,
address = {Cambridge},
annote = {2010num7.3 (partial)},
author = {Gerstner, W and Kistler, W M},
booktitle = {loc.gov},
publisher = {Cambridge Univ Pr},
title = {{Spiking Neuron Models: Single Neurons, Populations, Plasticity}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=Rs4oc7HfxIUC{\&}oi=fnd{\&}pg=PR11{\&}dq=Spiking+neuron+models:+Single+neurons,+populations,+plasticity{\&}ots=2Oe3xVeLZ2{\&}sig=pTqNb{\_}RZCxsPNjWbW4H7bhs5lcI http://books.google.com/books?hl=en{\&}lr={\&}id=Rs4oc7HfxIUC{\&}oi=fnd{\&}pg=PR11{\&}dq=Spiking+neuron+models:+Single+neurons,+populations,+plasticity{\&}ots=2PaYyUcN{\_}5{\&}sig=kKrgCuMV{\_}JBbATT4-3l1hX3HVlI http://books.google.com/books?hl=en{\&}lr={\&}id=Rs4oc7HfxIUC{\&}oi=fnd{\&}a},
year = {2002}
}
@article{Ramirez2013,
abstract = {Generalized linear models play an essential role in a wide variety of statistical applications. This paper discusses an approximation of the likelihood in these models that can greatly facilitate computation. The basic idea is to replace a sum that appears in the exact log-likelihood by an expectation over the model covariates; the resulting "expected log-likelihood" can in many cases be computed significantly faster than the exact log-likelihood. In many neuroscience experiments the distribution over model covariates is controlled by the experimenter and the expected log-likelihood approximation becomes particularly useful; for example, estimators based on maximizing this expected log-likelihood (or a penalized version thereof) can often be obtained with orders of magnitude computational savings compared to the exact maximum likelihood estimators. A risk analysis establishes that these maximum EL estimators often come with little cost in accuracy (and in some cases even improved accuracy) compared to standard maximum likelihood estimates. Finally, we find that these methods can significantly decrease the computation time of marginal likelihood calculations for model selection and of Markov chain Monte Carlo methods for sampling from the posterior parameter distribution. We illustrate our results by applying these methods to a computationally-challenging dataset of neural spike trains obtained via large-scale multi-electrode recordings in the primate retina.},
author = {Ramirez, A D and Paninski, L},
doi = {10.1007/s10827-013-0466-4},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Estimation},
mendeley-tags = {Estimation},
month = {apr},
number = {2},
pages = {215--234},
pmid = {23832289},
title = {{Fast inference in generalized linear models via expected log-likelihoods.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23832289},
volume = {36},
year = {2014}
}
@article{Versace2010,
annote = {2011num3},
author = {Versace, M and Chandler, B},
issn = {0018-9235},
journal = {Spectrum, IEEE},
month = {dec},
number = {12},
pages = {30--37},
publisher = {IEEE},
title = {{The brain of a new machine}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5644776},
volume = {47},
year = {2010}
}
@article{Zou2007,
author = {Zou, Quan},
doi = {10.1007/s00422-007-0155-3},
journal = {Biological Cybernetics},
month = {jul},
number = {1},
pages = {140--97},
title = {{Kinetic models of spike-timing dependent plasticity and their functional consequences in detecting correlations}},
volume = {370},
year = {2007}
}
@book{kutnerbook,
author = {Kutner, Michael H and Nachtsheim, Christopher J and Neter, John},
edition = {Fourth Int},
publisher = {McGraw-Hill/Irwin},
title = {{Applied Linear Regression Models}},
year = {2004}
}
@article{ZilanyBruce06,
author = {Zilany, Muhammad S A and Bruce, Ian C},
journal = {Journal of The Acoustical Society Of America},
month = {sep},
number = {3},
pages = {1446--1466},
title = {{Modeling auditory-nerve responses for high sound pressure levels in the normal and impaired auditory periphery}},
volume = {120},
year = {2006}
}
@article{WakLundstormFairHall07,
annote = {2009num43},
author = {Wark, Barry and Lundstrom, Brian N and Fairhall, A L},
journal = {Current Opinion in Neurobiology},
pages = {423--429},
title = {{Sensory adaptation}},
volume = {17},
year = {2007}
}
@inproceedings{Freeman2013,
author = {Freeman, J and Field, G and Li, P H and Greschner, M and Jepson, L and Rabinowitz, N and Pnevmatikakis, E A and Gunning, D E and Mathieson, K and Litke, A M},
booktitle = {Cosyne},
pages = {89--90},
title = {{Spatial structure and organization of nonlinear subunits in primate retina}},
year = {2013}
}
@article{Dimitrov2009,
author = {Dimitrov, D.},
doi = {10.1109/LED.2008.2012270},
issn = {0741-3106},
journal = {IEEE Electron Device Letters},
month = {mar},
number = {3},
pages = {294--297},
title = {{Spintronic Memristor Through Spin-Torque-Induced Magnetization Motion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4781542},
volume = {30},
year = {2009}
}
@article{Stumpf2012,
author = {Stumpf, Michael P H and Porter, Mason a},
doi = {10.1126/science.1216142},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
month = {feb},
number = {6069},
pages = {665--6},
pmid = {22323807},
title = {{Mathematics. Critical truths about power laws.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22323807},
volume = {335},
year = {2012}
}
@article{Solo1992,
author = {Solo, V.},
doi = {10.1137/0152014},
issn = {00361399},
journal = {SIAM Journal on Applied Mathematics},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
number = {1},
pages = {270},
publisher = {JSTOR},
title = {{Intrinsic Random Functions and the Paradox of 1 / f Noise}},
url = {http://www.jstor.org/stable/2102250 http://link.aip.org/link/SMJMAP/v52/i1/p270/s1{\&}Agg=doi},
volume = {52},
year = {1992}
}
@article{Anastassiou2011,
author = {Anastassiou, Costas A and Perin, Rodrigo and Markram, H and Koch, C},
doi = {10.1038/nn.2727},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {jan},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Neurosci},
title = {{Ephaptic coupling of cortical neurons}},
url = {http://dx.doi.org/10.1038/nn.2727},
volume = {advance on},
year = {2011}
}
@article{Ermentrout1998,
annote = {2008num38},
author = {Ermentrout, B},
journal = {Reports on progress in physics},
pages = {353--430},
publisher = {Institute of Physics Publishing},
title = {{Neural networks as spatio-temporal pattern-forming systems}},
url = {http://www.iop.org/EJ/abstract/0034-4885/61/4/002},
volume = {61},
year = {1998}
}
@incollection{LeCun2012,
address = {Heidelberg},
author = {LeCun, Y and Bottou, L and Orr, G B and M{\"{u}}ller, K R},
booktitle = {Neural networks: Tricks of the Trade},
edition = {2nd},
editor = {Montavon, G and Orr, G B and M{\"{u}}ller, K-R},
publisher = {Springer},
title = {{Efficient Backprop}},
url = {http://link.springer.com/chapter/10.1007/3-540-49430-8{\_}2 http://link.springer.com/chapter/10.1007/978-3-642-35289-8{\_}3},
year = {2012}
}
@article{Denisov2009,
annote = {2010num1.3



From Duplicate 3 ( Generalized Fokker-Planck equation: Derivation and exact solutions - )

2010num1.3







From Duplicate 2 ( Generalized Fokker-Planck equation : Derivation and exact - Denisov, S I; Horsthemke, W )
},
author = {Denisov, S I and Horsthemke, W and H{\"{a}}nggi, P},
doi = {10.1140/epjb/e2009-00126-3},
issn = {1434-6028},
journal = {The European Physical Journal B},
number = {4},
pages = {567--575},
publisher = {edpsciences. org},
title = {{Generalized Fokker-Planck equation: Derivation and exact solutions}},
url = {http://www.springerlink.com/index/10.1140/epjb/e2009-00126-3 http://epjb.edpsciences.org/articles/epjb/abs/2009/08/b081009/b081009.html},
volume = {68},
year = {2009}
}
@book{Brockwell2002,
author = {Brockwell, PJ and Davis, RA},
isbn = {0387953515},
title = {{Introduction to time series and forecasting}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=VHB4OSAmwcUC{\&}oi=fnd{\&}pg=PR7{\&}dq=Introduction+to+Time+Series+and+Forecasting{\&}ots=9jPurqXMA3{\&}sig=6xtMg-st6rfbM0WCoARveH7vzDc},
year = {2002}
}
@article{Alspector1993,
author = {Alspector, J and Meir, R and Yuhas, B and Jayakumer, A and Lippe, D},
journal = {Advances in neural information processing systems},
title = {{A parallel gradient descent method for learning in analog VLSI neural networks}},
url = {http://ci.nii.ac.jp/naid/10011751080/},
year = {1993}
}
@article{DIN01,
author = {DiNardo, E and Nobile, A and Pirozzi, E and Ricciardi, L},
journal = {Advances in Applied Probability},
pages = {453--482},
title = {{A computational approach to first-passage-time problems for {\{}G{\}}auss-{\{}M{\}}arkov processes}},
volume = {33},
year = {2001}
}
@article{LD89,
author = {Li, K and Duan, N},
journal = {Annals of Statistics},
pages = {1009--1052},
title = {{Regression analysis under link violation}},
volume = {17},
year = {1989}
}
@article{Hinchliffe|2000|,
abstract = {This paper presents a summary of the current status of determinations
of the strong coupling constant s.A detailed description of the definition,
scale dependence, and inherent theoretical ambiguities is given.
The various physical processes that can be used to determine $\alpha${\_}s
are reviewed and attention is given to the uncertainties, both theoretical
and experimental.},
author = {Hinchliffe, I and Manohar, A},
journal = {Annual Review of Nuclear and Particle Science},
keywords = {QCD,coupling constant,deep inelastic scattering,jets,nuclear,particles,physics,quantum field theory,tau-decay},
pages = {643},
title = {{The QCD coupling constant}},
volume = {50}
}
@article{Shlens09,
author = {Shlens, Jonathon and Field, Greg D and Gauthier, Jeffrey L and Greschner, Martin and Sher, Alexander and Litke, Alan M and Chichilnisky, E J},
journal = {J. Neurosci.},
pages = {5022--5031},
title = {{The Structure of Large-Scale Synchronized Firing in Primate Retina}},
volume = {29},
year = {2009}
}
@article{McDonald2010,
author = {McDonald, NR and Pino, R E},
journal = {{\ldots} (IJCNN), The 2010 {\ldots}},
title = {{Analysis of dynamic linear and non-linear memristor device models for emerging neuromorphic computing hardware design}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5596664},
year = {2010}
}
@article{Swanson|1994|,
abstract = {This paper is a generalization of previous work on the use of classical
canonical transformations to evaluate Hamiltonian path integrals
for quantum mechanical systems. Relevant aspects of the Hamiltonian
path integral and its measure are discussed and used to show that
the quantum mechanical version of the classical transformation does
not leave the measure of the path integral invariant, instead inducing
an anomaly. The relation to operator techniques and ordering problems
is discussed, and special attention is paid to incorporation of the
initial and nal states of the transition element into the boundary
conditions of the problem. Classical canonical transformations are
developed to render an arbitrary power potential cyclic. The resulting
Hamiltonian is analyzed as a quantum system to show its relation
to known quantum mechanical results. A perturbative argument is used
to suppress ordering related terms in the transformed Hamiltonian
in the event that the classical canonical transformation leads to
a nonquadratic cyclic Hamiltonian. The associated anomalies are analyzed
to yield general methods to evaluate the path integral's prefactor
for such systems. The methods are applied to several systems, including
linear and quadratic potentials, the velocity-dependent potential,
and the time-dependent harmonic oscillator.},
author = {Swanson, M S},
journal = {arXiv},
keywords = {canonical transformations,path integral,physics,quantum mechanics,unread},
pages = {9406167},
title = {{Canonical transformations and path integral measures}},
volume = {hep-th}
}
@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {LeCun, Y and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
eprint = {arXiv:1312.6184v5},
isbn = {3135786504},
issn = {0028-0836},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {26017442},
title = {{Deep learning}},
url = {http://dx.doi.org/10.1038/nature14539{\%}5Cn10.1038/nature14539},
volume = {521},
year = {2015}
}
@article{Rumsey2006,
author = {Rumsey, Clifton C and Abbott, L F},
doi = {10.1152/jn.00149.2006.},
journal = {Journal of Neurophysiology},
pages = {2307--2318},
title = {{Synaptic Democracy in Active Dendrites}},
year = {2006}
}
@article{HAB77,
author = {Haberman, S},
journal = {Annals of Statistics},
pages = {815--841},
title = {{Maximum likelihood estimation in exponential response models}},
volume = {5},
year = {1977}
}
@article{DestexheMarder04,
annote = {2009num44},
author = {Destexhe, A and Rudolph, M and Pare, D},
journal = {Nature Reviews Neuroscience},
pages = {739--751},
title = {{The high-conductance state of neocortical neurons in vivo}},
volume = {4},
year = {2003}
}
@article{Wilhelm2008,
author = {Wilhelm, Daniel and Bruck, J},
isbn = {9781424425716},
journal = {ISIT},
pages = {1388--1392},
title = {{Stochastic Switching Circuit Synthesis}},
year = {2008}
}
@phdthesis{Burton|1999|,
abstract = {A fast automated system for tracing neurons in parallel is described,
adequate to support a quantitative analysis of neuron morphology.
The system described here automates digitized neuron feature extraction
and reconstruction, thereby replacing current largely manual techniques
for tracing individual neurons. Serial sections of brain tissue are
created by physical sectioning. Sections are processed during scanning
to determine regions of interest (ROIs) and to quickly cull unnecessary
image data. An aggressive data culling and compression scheme reduces
the original volumetric data into a ROI-based image collection that
makes temporary secondary storage feasible. Neighboring ROIs are
then matched from successive sections for segment and ber tracing.
Reconstructed segments created from these matches are disambiguated,
resulting in an abbreviated structural description of the tissue's
neurons and ber tracts. },
author = {Burton, B},
keywords = {3D reconstruction,computational,electron micrograph,image processing,neuroanatomy,neurobiology,neuronal networks,segmentation},
title = {{Automated 3D reconstruction of neuronal structures from serial sections}}
}
@article{Wicks|1995|,
author = {Wicks, S R and Rankin, C H},
journal = {J. Neurosci.},
pages = {2434},
title = {{Integration of mechanosensory stimuli in Caenorhabditis elegans.}},
volume = {15}
}
@article{Laughlin2000,
abstract = {We discuss recent developments in our understanding of matter, broadly construed, and their implications for contemporary research in fundamental physics.},
author = {Laughlin, R B and Pines, D},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {jan},
number = {1},
pages = {28--31},
pmid = {10618365},
title = {{The theory of everything.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=26610{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {97},
year = {2000}
}
@article{WehrZador03,
author = {Wehr, M and Zador, A},
journal = {Nature},
pages = {442--446},
title = {{Balanced inhibition underlies tuning and sharpens spike timing in auditory cortex}},
volume = {426},
year = {2003}
}
@article{BF92,
author = {Ball, F and Rice, J},
journal = {Mathematical Bioscience},
pages = {189--206},
title = {{Stochastic models for ion channels: introduction and bibliography}},
volume = {112},
year = {1992}
}
@article{Feng2016,
abstract = {The question why deep learning algorithms perform so well in practice has attracted increasing research interest. However, most of well-established approaches, such as hypothesis capacity, robustness or sparseness, have not provided complete explanations, due to the high complexity of the deep learning algorithms and their inherent randomness. In this work, we introduce a new approach{\~{}}$\backslash$textendash{\~{}}ensemble robustness{\~{}}$\backslash$textendash{\~{}}towards characterizing the generalization performance of generic deep learning algorithms. Ensemble robustness concerns robustness of the $\backslash$emph{\{}population{\}} of the hypotheses that may be output by a learning algorithm. Through the lens of ensemble robustness, we reveal that a stochastic learning algorithm can generalize well as long as its sensitiveness to adversarial perturbation is bounded in average, or equivalently, the performance variance of the algorithm is small. Quantifying ensemble robustness of various deep learning algorithms may be difficult analytically. However, extensive simulations for seven common deep learning algorithms for different network architectures provide supporting evidence for our claims. Furthermore, our work explains the good performance of several published deep learning algorithms.},
archivePrefix = {arXiv},
arxivId = {1602.02389},
author = {Feng, Jiashi and Zahavy, Tom and Kang, Bingyi and Xu, Huan and Mannor, Shie},
eprint = {1602.02389},
file = {::},
journal = {ArXiv},
month = {feb},
title = {{Ensemble Robustness of Deep Learning Algorithms}},
url = {http://arxiv.org/abs/1602.02389},
year = {2016}
}
@article{ReiffBorst05,
abstract = {Genetically encoded fluorescent probes of neural activity represent

new promising tools for systems neuroscience. Here, we present a

comparative in vivo analysis of 10 different genetically encoded

calcium indicators, as well as the pH-sensitive synapto-pHluorin.

We analyzed their fluorescence changes in presynaptic boutons of

the Drosophila larval neuromuscular junction. Robust neural activity

did not result in any or noteworthy fluorescence changes when Flash-Pericam,

Camgaroo-1, and Camgaroo-2 were expressed. However, calculated on

the raw data, fractional fluorescence changes up to 18{\%} were reported

by synapto-pHluorin, Yellow Cameleon 2.0, 2.3, and 3.3, Inverse-Pericam,

GCaMP1.3, GCaMP1.6, and the troponin C-based calcium sensor TN-L15.

The response characteristics of all of these indicators differed

considerably from each other, with GCaMP1.6 reporting high rates

of neural activity with the largest and fastest fluorescence changes.

However, GCaMP1.6 suffered from photobleaching, whereas the fluorescence

signals of the double-chromophore indicators were in general smaller

but more photostable and reproducible, with TN-L15 showing the fastest

rise of the signals at lower activity rates. We show for GCaMP1.3

and YC3.3 that an expanded range of neural activity evoked fairly

linear fluorescence changes and a corresponding linear increase in

the signal-to-noise ratio (SNR). The expression level of the indicator

biased the signal kinetics and SNR, whereas the signal amplitude

was independent. The presented data will be useful for in vivo experiments

with respect to the selection of an appropriate indicator, as well

as for the correct interpretation of the optical signals.},
author = {Reiff, Dierk F and Ihring, Alexandra and Guerrero, Giovanna and Isacoff, Ehud Y and Joesch, Maximilian and Nakai, Junichi and Borst, Alexander},
doi = {10.1523/JNEUROSCI.4900-04.2005},
journal = {J Neurosci},
keywords = {Animals; Animals,Confocal; Molecular Probe Techniques; Neuromuscul,Genetically Modified; Dose-Response Relationship,Radiation; Drosophila; Electric Stimulation; Fluo},
month = {may},
number = {19},
pages = {4766--4778},
pmid = {15888652},
title = {{In vivo performance of genetically encoded indicators of neural activity in flies.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.4900-04.2005},
volume = {25},
year = {2005}
}
@book{Nilsson1965,
author = {Nilsson, Nils J.},
publisher = {McGraw-Hill New York},
title = {{Learning machines}},
year = {1965}
}
@article{Tkacik2010,
annote = {2010IIInum63},
author = {Tkacik, G. and Prentice, J. S. and Balasubramanian, V. and Schneidman, E},
doi = {10.1073/pnas.1004906107},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {jul},
title = {{Optimal population coding by noisy spiking neurons}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1004906107},
year = {2010}
}
@article{Wang2003b,
abstract = {Limiting redundancy in the real-world sensory inputs is of obvious benefit for efficient neural coding, but little is known about how this may be accomplished by biophysical neural mechanisms. One possible cellular mechanism is through adaptation to relatively constant inputs. Recent investigations in primary visual (V1) cortical neurons have demonstrated that adaptation to prolonged changes in stimulus contrast is mediated in part through intrinsic ionic currents, a Ca2+-activated K+ current (IKCa) and especially a Na+-activated K+ current (IKNa). The present study was designed to test the hypothesis that the activation of adaptation ionic currents may provide a cellular mechanism for temporal decorrelation in V1. A conductance-based neuron model was simulated, which included an IKCa and an IKNa. We show that the model neuron reproduces the adaptive behavior of V1 neurons in response to high contrast inputs. When the stimulus is stochastic with 1/f 2 or 1/f-type temporal correlations, these autocorrelations are greatly reduced in the output spike train of the model neuron. The IKCa is effective at reducing positive temporal correlations at approximately 100-ms time scale, while a slower adaptation mediated by IKNa is effective in reducing temporal correlations over the range of 1-20 s. Intracellular injection of stochastic currents into layer 2/3 and 4 (pyramidal and stellate) neurons in ferret primary visual cortical slices revealed neuronal responses that exhibited temporal decorrelation in similarity with the model. Enhancing the slow afterhyperpolarization resulted in a strengthening of the decorrelation effect. These results demonstrate the intrinsic membrane properties of neocortical neurons provide a mechanism for decorrelation of sensory inputs.},
author = {Wang, XJ Xiao-Jing and Liu, Yinghui and Sanchez-Vives, Maria V and McCormick, David a},
doi = {10.1152/jn.00242.2003},
issn = {0022-3077},
journal = {Journal of {\ldots}},
keywords = {Adaptation,Animals,Biological,Calcium-Activated,Calcium-Activated: physiology,Contrast Sensitivity,Contrast Sensitivity: physiology,Female,Ferrets,Male,Models,Neurons,Neurons: physiology,Perception,Perception: physiology,Physiological,Potassium Channels,Potassium Channels: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Time Factors,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = {jun},
number = {6},
pages = {3279--3293},
pmid = {12649312},
title = {{Adaptation and temporal decorrelation by single neurons in the primary visual cortex.}},
url = {http://jn.physiology.org/content/89/6/3279.short http://www.ncbi.nlm.nih.gov/pubmed/12649312},
volume = {89},
year = {2003}
}
@article{Ditlevsen2011,
author = {Ditlevsen, Susanne and Greenwood, Priscilla},
doi = {10.1007/s00285-012-0552-7},
journal = {Arxiv preprint arXiv:1108.0073},
keywords = {37n25,60g17,92bxx,92c20,conditional firing probability,diffusions,interspike intervals,mathematics subject classification,stochastic dynamics},
title = {{The Morris-Lecar neuron model embeds a leaky integrate-and-fire model}},
url = {http://arxiv.org/abs/1108.0073},
year = {2011}
}
@article{Ariav2003,
abstract = {The ability of cortical neurons to perform temporally accurate computations has been shown to be important for encoding of information in the cortex; however, cortical neurons are expected to be imprecise temporal encoders because of the stochastic nature of synaptic transmission and ion channel gating, dendritic filtering, and background synaptic noise. Here we show for the first time that fast local spikes in basal dendrites can serve to improve the temporal precision of neuronal output. Integration of coactivated, spatially distributed synaptic inputs produces temporally imprecise output action potentials within a time window of several milliseconds. In contrast, integration of closely spaced basal inputs initiates local dendritic spikes that amplify and sharpen the summed somatic potential. In turn, these fast basal spikes allow precise timing of output action potentials with submillisecond temporal jitter over a wide range of activation intensities and background synaptic noise. Our findings indicate that fast spikes initiated in individual basal dendrites can serve as precise "timers" of output action potentials in various network activity states and thus may contribute to temporal coding in the cortex.},
author = {Ariav, Gal and Polsky, A and Schiller, J},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Animals,Axons,Axons: physiology,Cells, Cultured,Computer Simulation,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Excitatory Postsynaptic Potentials,Kinetics,Patch-Clamp Techniques,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: physiology,Rats,Rats, Wistar,Sodium Channels,Sodium Channels: metabolism,Spike time neural coding,Synaptic Transmission},
mendeley-tags = {Spike time neural coding},
month = {aug},
number = {21},
pages = {7750--8},
pmid = {12944503},
title = {{Submillisecond precision of the input-output transformation function mediated by fast sodium dendritic spikes in basal dendrites of CA1 pyramidal neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12944503},
volume = {23},
year = {2003}
}
@article{Sudderth2010,
author = {Sudderth, EB and Ihler, AT and Isard, M},
doi = {10.1145/1831407},
journal = {Communications of the {\ldots}},
keywords = {Message passing},
mendeley-tags = {Message passing},
number = {June},
pages = {95--103},
title = {{Nonparametric belief propagation}},
url = {http://dl.acm.org/citation.cfm?id=1831431},
year = {2010}
}
@article{GEO82,
author = {Georgopoulos, A and Kalaska, J and Caminiti, R and Massey, J},
journal = {Journal of Neuroscience},
pages = {1527--1537},
title = {{On the relations between the direction of two-dimensional arm movements and cell discharge in primate motor cortex}},
volume = {2},
year = {1982}
}
@article{Reynolds|2004|,
abstract = {Single-unit recording studies in th macaque have carefully documented
the modulatory effects of attention on the response properties of
visual cortical neurons. Attention produces qualitatively different
effects on firing rate, depending on whether a stimulus appears alone
or accompanied by distracters. Studies of contrast gain control in
anesthetized mammals have found parallel patterns of results when
the luminance contrast of a stimulus increases. This finding suggests
that attention has coopted the circuits that mediate contrast gain
control and that it operates by increasing the effective contrast
of the attended stimulus. Consistent with this idea, microstimulation
of the frontal eye fields, one of several areas that control the
allocation of spatial attention, induces spatially local increases
in sensitivity both at the behavioral level and amont neurons in
area V4, where endogenously generated attention increases contrast
sensitivity. Studies in the slice have begun to explain how modulatory
signals might cause such increases in sensitivity.},
author = {Reynolds, J H and Chelazzi, L},
journal = {The annual Review of Neuroscience},
keywords = {contrast,feedback,limited capacity,macaque,neurobiology,unread,visual cortex},
pages = {611},
title = {{Attentional modulation of visual processing}},
volume = {27}
}
@article{Hayashi|2004|,
author = {Hayashi, T and Carthew, R W},
journal = {Nature},
keywords = {Animals *Body Patterning Cadherins/genetics/metabo,Biological Pigment Epithelium of Eye/cytology/emb},
number = {7009},
pages = {647--652},
title = {{Surface mechanics mediate pattern formation in the developing retina}},
volume = {431}
}
@article{Elston|2002|a,
author = {Elston, G N and DeFelipe, J},
journal = {Prog. Brain Res.},
pages = {109--133},
title = {{Spine distribution in cortical pyramidal cells: a common organizational principle across species.}},
volume = {136}
}
@article{Friedman2010,
author = {Friedman, Jerome H and Hastie, Trevor and Tibshirani, Rob},
journal = {Journal of Statistical Software},
pages = {1--22},
title = {{Regularization Paths for Generalized Linear Models via Coordinate Descent}},
volume = {33},
year = {2010}
}
@article{Wallach2011,
annote = {2011num29},
author = {Wallach, A and Eytan, D and Gal, A and Zrenner, C and Marom, S},
doi = {10.3389/fneng.2011.00003},
issn = {1662-6443},
journal = {Frontiers in Neuroengineering},
keywords = {clamp,closed-loop,firing rate,neuron,ring rate,threshold},
number = {April},
pages = {1--10},
title = {{Neuronal Response Clamp}},
url = {http://www.frontiersin.org/Neuroengineering/10.3389/fneng.2011.00003/abstract},
volume = {4},
year = {2011}
}
@article{Davis05,
author = {Davis, R and Rodriguez-Yam, G},
journal = {Statistica Sinica},
pages = {381--406},
title = {{Estimation for State-Space Models: an Approximate Likelihood Approach}},
volume = {15},
year = {2005}
}
@article{Cybenko1989,
author = {Cybenko, G},
journal = {Mathematics of Control, Signals, and Systems (MCSS)},
keywords = {approximation,completeness,neural networks},
pages = {303--314},
title = {{Approximation by superpositions of a sigmoidal function}},
url = {http://www.springerlink.com/index/N873J15736072427.pdf},
volume = {2},
year = {1989}
}
@article{TRW03,
author = {Tuckwell, Henry C and Rodriguez, Roger and Wan, Frederic Y M},
journal = {Neural Computation},
number = {1},
pages = {143--159},
title = {{Determination of Firing Times for the Stochastic Fitzhugh-Nagumo Neuronal Model}},
volume = {15},
year = {2003}
}
@article{Nepusz2012,
author = {Nepusz, T and Vicsek, T},
doi = {10.1038/NPHYS2327},
journal = {Nature Physics},
keywords = {Complex Networks},
mendeley-tags = {Complex Networks},
pages = {1--30},
title = {{Controlling edge dynamics in complex networks}},
url = {http://www.nature.com/nphys/journal/v8/n7/abs/nphys2327.html},
year = {2012}
}
@book{Oppenheim1983,
address = {Englewood Cliffs, NJ},
author = {Oppenheim, AV and Willsky, AS and Nawab, SH},
publisher = {Prentice Hall},
title = {{Signals and systems}},
url = {https://el-umrah.onlinegroups.net/groups/te2213/files/f/6519-2011-05-10T013902Z/scilabOW.pdf http://www.sptut.aakashlabs.org/files/textbooks/ProfSenthikumar/OW.pdf},
year = {1983}
}
@article{MVV00,
author = {Murphy, S and van der Vaart, A},
journal = {Journal of the American Statistical Association},
pages = {449--465},
title = {{On Profile Likelihood}},
volume = {95},
year = {2000}
}
@article{PAN99,
author = {Paninski, L and Fellows, M and Hatsopoulos, N and Donoghue, J},
journal = {Society for Neuroscience Abstracts},
pages = {665.9},
title = {{Coding dynamic variables in populations of motor cortex neurons}},
volume = {25},
year = {1999}
}
@article{Heskes-EP,
author = {Ypma, A and Heskes, T},
journal = {Neural Networks for Signal Processing, 2003},
pages = {219--228},
title = {{Iterated extended {\{}K{\}}alman smoothing with expectation-propagation}},
year = {2003}
}
@article{Nguyen2017,
abstract = {While the optimization problem behind deep neural networks is highly non-convex, it is frequently observed in practice that training deep networks seems possible without getting stuck in suboptimal points. It has been argued that this is the case as all local minima are close to being globally optimal. We show that this is (almost) true, in fact almost all local minima are globally optimal, for a fully connected network with squared loss and analytic activation function given that the number of hidden units of one layer of the network is larger than the number of training points and the network structure from this layer on is pyramidal.},
archivePrefix = {arXiv},
arxivId = {1704.08045},
author = {Nguyen, Quynh and Hein, Matthias},
eprint = {1704.08045},
journal = {Arxiv},
keywords = {dee,global optimality,local minima,loss surface},
title = {{The loss surface of deep and wide neural networks}},
url = {http://arxiv.org/abs/1704.08045},
year = {2017}
}
@article{Druckmann2008,
abstract = {Neuron models, in particular conductance-based compartmental models, often have numerous parameters that cannot be directly determined experimentally and must be constrained by an optimization procedure. A common practice in evaluating the utility of such procedures is using a previously developed model to generate surrogate data (e.g., traces of spikes following step current pulses) and then challenging the algorithm to recover the original parameters (e.g., the value of maximal ion channel conductances) that were used to generate the data. In this fashion, the success or failure of the model fitting procedure to find the original parameters can be easily determined. Here we show that some model fitting procedures that provide an excellent fit in the case of such model-to-model comparisons provide ill-balanced results when applied to experimental data. The main reason is that surrogate and experimental data test different aspects of the algorithm's function. When considering model-generated surrogate data, the algorithm is required to locate a perfect solution that is known to exist. In contrast, when considering experimental target data, there is no guarantee that a perfect solution is part of the search space. In this case, the optimization procedure must rank all imperfect approximations and ultimately select the best approximation. This aspect is not tested at all when considering surrogate data since at least one perfect solution is known to exist (the original parameters) making all approximations unnecessary. Furthermore, we demonstrate that distance functions based on extracting a set of features from the target data (such as time-to-first-spike, spike width, spike frequency, etc.)--rather than using the original data (e.g., the whole spike trace) as the target for fitting-are capable of finding imperfect solutions that are good approximations of the experimental data.},
author = {Druckmann, S and Berger, Thomas K and Hill, Sean and Sch{\"{u}}rmann, Felix and Markram, H and Segev, I},
doi = {10.1007/s00422-008-0269-2},
issn = {1432-0770},
journal = {Biological cybernetics},
keywords = {Algorithms,Animals,Models, Neurological,Neocortex,Neocortex: physiology,Neurons,Neurons: physiology,Organ Culture Techniques,Patch-Clamp Techniques,Rats,Rats, Wistar},
month = {nov},
number = {4-5},
pages = {371--9},
pmid = {19011925},
title = {{Evaluating automated parameter constraining procedures of neuron models by experimental and surrogate data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19011925},
volume = {99},
year = {2008}
}
@article{Janzamin2015,
abstract = {Training neural networks is a challenging non-convex optimization problem, and backpropagation or gradient descent can get stuck in spurious local optima. We propose a novel algorithm based on tensor decomposition for training a two-layer neural network. We prove efficient generalization bounds for our proposed method, with a polynomial sample complexity in the relevant parameters, such as input dimension and number of neurons. While learning arbitrary target functions is NP-hard, we provide transparent conditions on the function and the input for generalizability. Our training method is based on tensor decomposition, which provably converges to the global optimum, under a set of mild non-degeneracy conditions. It consists of simple embarrassingly parallel linear and multi-linear operations, and is competitive with standard stochastic gradient descent (SGD), in terms of computational complexity. Thus, for the first time, we have a computationally efficient method with guaranteed generalization bounds for training neural networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.08473v1},
author = {Janzamin, M and Sedghi, H and Anandkumar, A},
eprint = {arXiv:1506.08473v1},
journal = {ArXiv:1506.08473},
keywords = {generalization bound,method-of-moments,neural networks,tensor decomposition},
pages = {1--25},
title = {{Beating the Perils of Non-Convexity: Guaranteed Training of Neural Networks using Tensor Methods}},
year = {2015}
}
@article{Chklovskii2004a,
author = {Chklovskii, D B and Mel, BW and Svoboda, K},
journal = {Nature},
number = {OCTOBER},
title = {{Cortical rewiring and information storage}},
url = {http://www.nature.com/nature/journal/v431/n7010/abs/nature03012.html},
volume = {431},
year = {2004}
}
@article{Froemke2010,
annote = {2010IIInum22},
author = {Froemke, RC C and Letzkus, JJ J and Kampa, B M and Hang, GB B and GJ},
doi = {10.3389/fnsyn.2010.00029},
journal = {frontiersin.org},
keywords = {cortex,dendrites,ltd,ltp,nmda receptors,spikes,stdp,synaptic plasticity},
number = {July},
pages = {1--14},
title = {{Dendritic synapse location and neocortical spike-timing-dependent plasticity}},
url = {http://www.frontiersin.org/neuroscience/synapticneuroscience/paper/10.3389/fnsyn.2010.00029/pdf/},
volume = {2},
year = {2010}
}
@book{DFG01,
editor = {Doucet, A and de Freitas, N and Gordon, N},
publisher = {Springer},
title = {{Sequential Monte Carlo in Practice}},
year = {2001}
}
@article{Denk2012,
abstract = {High-resolution, comprehensive structural information is often the final arbiter between competing mechanistic models of biological processes, and can serve as inspiration for new hypotheses. In molecular biology, definitive structural data at atomic resolution are available for many macromolecules; however, information about the structure of the brain is much less complete, both in scope and resolution. Several technical developments over the past decade, such as serial block-face electron microscopy and trans-synaptic viral tracing, have made the structural biology of neural circuits conceivable: we may be able to obtain the structural information needed to reconstruct the network of cellular connections for large parts of, or even an entire, mouse brain within a decade or so. Given that the brain's algorithms are ultimately encoded by this network, knowing where all of these connections are should, at the very least, provide the data needed to distinguish between models of neural computation.},
author = {Denk, W and Briggman, Kevin L and Helmstaedter, Moritz},
doi = {10.1038/nrn3169},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Computational Biology,Computational Biology: methods,Computational Biology: trends,Electron,Electron: methods,Humans,Microscopy,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Nerve Net: ultrastructure,Neurobiology,Neurobiology: methods,Neurobiology: trends,Neurons,Neurons: cytology,Neurons: physiology,Neurons: ultrastructure},
month = {may},
number = {5},
pages = {351--358},
pmid = {22353782},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Rev Neurosci},
title = {{Structural neurobiology: missing link to a mechanistic understanding of neural computation.}},
url = {http://dx.doi.org/10.1038/nrn3169},
volume = {13},
year = {2012}
}
@article{Strassberg1993,
author = {Strassberg, Adam F. and DeFelice, Louis J.},
doi = {10.1162/neco.1993.5.6.843},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {neuron},
mendeley-tags = {neuron},
month = {nov},
number = {6},
pages = {843--855},
title = {{Limitations of the Hodgkin-Huxley Formalism: Effects of Single Channel Kinetics on Transmembrane Voltage Dynamics}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1993.5.6.843},
volume = {5},
year = {1993}
}
@article{OertelYoung04,
author = {Oertel, Donata and Young, Eric D},
journal = {Trends In Neurosciences},
month = {feb},
number = {2},
pages = {104--110},
title = {{What's a cerebellar circuit doing in the auditory system?}},
volume = {27},
year = {2004}
}
@article{Hood2002,
abstract = {PURPOSE: To better understand the cellular contributions to the human multifocal ERG (mfERG), rhesus monkey and human mfERGs were recorded using the same stimulus conditions. The monkey mfERGs were recorded before and after injections of pharmacologic agents known to selectively block activity of particular cells and circuits in the retina. METHODS: Photopic mfERGs were recorded with Dawson-Trick-Litzkow (DTL) fiber electrodes from 16 eyes of 10 anesthetized adult rhesus monkeys (Macaca mulatta) and from 4 normal humans. The display consisted of 103 equal-sized hexagons within 17 degrees of the fovea. Monkey mfERGs were obtained before and after inner retinal responses were suppressed with intravitreal injections of tetrodotoxin (TTX), TTX+N-methyl-D-aspartic acid (NMDA), TTX+NMDA with the gamma-aminobutyric acid (GABA(A{\&}C)) antagonist picrotoxin (PTX), or the inhibitory amino acid GABA and after L-2 amino-4-phosphonobutyric acid (APB) to block signal transmission to ON-bipolar cells. Finally, a combination of APB and cis-2,3 piperidine dicarboxylic acid (PDA) was used to isolate the contributions from the cone photoreceptors. RESULTS: TTX, which blocks sodium-based action potentials, removes a large contribution from the monkey's mfERG, but it does not remove all inner retinal influences. After administration of TTX, the mfERG is further modified by the addition of NMDA. TTX+NMDA, TTX+NMDA+PTX, or GABA alone have similar effects, suggesting that, at the concentrations used, they are largely removing the inner retinal contributions. After removing the inner retinal influences, the monkey's mfERG is mainly composed of ON- and OFF-bipolar contributions, as revealed after APB and PDA were injected. The leading edge of the first negative potential (N1) is largely shaped by the initial hyperpolarization of the OFF-bipolar cells. The photoreceptors also contribute to the leading edge of N1, but this contribution is small, except in the central 6 degrees. The depolarization of the ON-bipolars and the recovery of the OFF-bipolars contribute to the leading edge of the major positive component (P1), with the recovery of the ON-bipolars being the dominant influence on the trailing edge. The waveform of the human mfERG most closely resembles the rhesus monkey's mfERG after administration of TTX. CONCLUSIONS: The monkey's mfERG is shaped by large contributions from ON- and OFF-bipolar cells, combined with both spiking and nonspiking inner retinal contributions, and a small contribution from the photoreceptors. In comparison, the human mfERG resembles the monkey's mfERG after reduction of inner retinal contributions. Based on the pharmacologic dissection of the monkey's mfERG, a model of the waveform of the human mfERG is proposed. This model suggests that the waveform can be understood as a combination of overlapping ON- and OFF-bipolar cell contributions combined with smaller contributions from inner retina and photoreceptors.},
author = {Hood, Donald C and Frishman, Laura J and Saszik, Shannon and Viswanathan, Suresh},
isbn = {0146-0404},
issn = {01460404},
journal = {Investigative Ophthalmology and Visual Science},
number = {5},
pages = {1673--1685},
pmid = {11980890},
title = {{Retinal origins of the primate multifocal ERG: Implications for the human response}},
volume = {43},
year = {2002}
}
@misc{Jain2007,
author = {Jain, V and Murray, J and Roth, F and Turaga, S and Zhigulin, V and Briggman, K and Helmstaedter, M and Denk, W and Seung, H},
pages = {1--8},
title = {{Supervised learning of image restoration with convolutional networks.}},
year = {2007}
}
@article{Eckmann2010,
abstract = {We present a theoretical framework using quorum percolation for describing the initiation of activity in a neural culture. The cultures are modeled as random graphs, whose nodes are excitatory neurons with k(in) inputs and k(out) outputs, and whose input degrees k(in) = k obey given distribution functions p(k). We examine the firing activity of the population of neurons according to their input degree (k) classes and calculate for each class its firing probability $\Phi$(k)(t) as a function of t. The probability of a node to fire is found to be determined by its in-degree k, and the first-to-fire neurons are those that have a high k. A small minority of high-k-classes may be called "Leaders," as they form an interconnected sub-network that consistently fires much before the rest of the culture. Once initiated, the activity spreads from the Leaders to the less connected majority of the culture. We then use the distribution of in-degree of the Leaders to study the growth rate of the number of neurons active in a burst, which was experimentally measured to be initially exponential. We find that this kind of growth rate is best described by a population that has an in-degree distribution that is a Gaussian centered around k = 75 with width $\sigma$ = 31 for the majority of the neurons, but also has a power law tail with exponent -2 for 10{\%} of the population. Neurons in the tail may have as many as k = 4,700 inputs. We explore and discuss the correspondence between the degree distribution and a dynamic neuronal threshold, showing that from the functional point of view, structure and elementary dynamics are interchangeable. We discuss possible geometric origins of this distribution, and comment on the importance of size, or of having a large number of neurons, in the culture.},
annote = {2011num40},
author = {Eckmann, Jean-Pierre and Moses, Elisha and Stetter, Olav and Tlusty, Tsvi and Zbinden, Cyrille and Neuroscience, Computational},
doi = {10.3389/fncom.2010.00132},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {activation dynamics,graph theory,leaders,neuronal cultures,percolation,statistical mechanics of networks},
month = {jan},
number = {September},
pages = {1--12},
pmid = {20953239},
title = {{Leaders of neuronal cultures in a quorum percolation model.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2955434{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2010}
}
@article{GallConnRaks+1996,
author = {Gallant, J and Connor, C and Rakshit, S and Lewis, J and {Van Essen}, D},
journal = {Journal of Neurophysiology},
month = {oct},
number = {4},
pages = {2718--2739},
title = {{Neural responses to polar, hyperbolic, and Cartesian gratings in area {\{}V4{\}} of the macaque monkey.}},
volume = {76},
year = {1996}
}
@article{Dolan2006,
abstract = {The purpose of this study was to document the standard full field electroretinographic (ERG) and wide field multifocal electroretinographic (WF-mfERG) findings in eyes with recent onset hemi-retinal vein occlusion (HRVO) and to compare the electro-diagnostic findings in the affected and fellow eyes with reference to normative data. Eight patients with HRVO were assessed using ERG and WF-mfERG. WF-mfERG first order responses from the affected hemi-retinae and the unaffected hemi-retinae in each affected eye were compared. WF-mfERG responses from each affected hemi-retina and from the symmetrical hemi-retina of each fellow eye were compared. ERG responses between affected and unaffected eyes were also compared. All electrodiagnostic tests were compared to normative data (5-95{\%} confidence limits derived from age-related controls). WF-mfERG P1 and N1 implicit times were greater for the affected hemi-retinae than for the unaffected hemi-retinae (p {\textless}0.05). WF-mfERG N1 and P1 implicit times were prolonged (p {\textless} 0.05) and WF-mfERG P1/N1 amplitude ratios were significantly reduced (p {\textless} 0.05) for the affected eyes when compared with the fellow eyes. Maximal b-wave, cone b-wave and flicker implicit times were prolonged (p {\textless} 0.05) when comparing affected and fellow eyes. These results indicate that retinal injury due to HRVO culminates in significant delay of both ERG and WF-mfERG implicit times. These results suggest that WF-mfERG in combination with ERG may have a role in the management of HRVO.},
author = {Dolan, Fiona Mary and Parks, Stuart and Keating, David and Dutton, Gordon Neale},
doi = {10.1007/s10633-006-0003-0},
issn = {0012-4486},
journal = {Documenta ophthalmologica. Advances in ophthalmology},
keywords = {80 and over,Adult,Aged,Diagnosis,Differential,Electroretinography,Electroretinography: methods,Female,Follow-Up Studies,Humans,Male,Middle Aged,Retina,Retina: physiopathology,Retinal Vein Occlusion,Retinal Vein Occlusion: diagnosis,Retinal Vein Occlusion: physiopathology,Severity of Illness Index},
month = {jan},
number = {1},
pages = {43--52},
pmid = {16633725},
title = {{Wide field multifocal and standard full field electroretinographic features of hemi retinal vein occlusion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16633725},
volume = {112},
year = {2006}
}
@article{Hu2012,
author = {Hu, T and Chklovskii, D B},
journal = {arXiv preprint arXiv:1210.3741},
title = {{Online computation of sparse representations of time varying stimuli using a biologically motivated neural network}},
url = {http://arxiv.org/abs/1210.3741},
year = {2012}
}
@article{Soen2000,
abstract = {In the last few years it has been realized that the intervals of spontaneous spiking events in the intact heart exhibit coexisting scale-invariant count fluctuations and anticorrelated interspike intervals fluctuations. Here, we show experimentally that this feature is an intrinsic property of single isolated heart cells, which is preserved when the cells couple into networks. We present a model explaining this behavior at both the single cell and network levels.},
annote = {2008num2},
author = {Soen, Y and Braun, E},
issn = {1063-651X},
journal = {Physical Review E},
keywords = {Animals,Biological,Cells,Cultured,Heart,Heart Rate,Heart: physiology,Models,Myocardium,Myocardium: cytology,Newborn,Rats},
month = {mar},
number = {3},
pages = {R2216--9},
pmid = {11046684},
title = {{Scale-invariant fluctuations at different levels of organization in developing heart cell networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11046684},
volume = {61},
year = {2000}
}
@article{Briggman2006,
author = {Briggman, K L and Denk, W},
journal = {Curr. Opin. Neurobiol.},
pages = {562--570},
title = {{Towards neural circuit reconstruction with volume electron microscopy techniques}},
volume = {16},
year = {2006}
}
@article{SG96,
author = {Schurmann, T and Grassberger, P},
journal = {Chaos},
pages = {414--427},
title = {{Entropy estimation of symbol sequences}},
volume = {6},
year = {1996}
}
@article{Allman2009,
abstract = {While hidden class models of various types arise in many statistical applications, it is often difficult to establish the identifiability of their parameters. Focusing on models in which there is some structure of independence of some of the observed variables conditioned on hidden ones, we demonstrate a general approach for establishing identifiability utilizing algebraic arguments. A theorem of J. Kruskal for a simple latent-class model with finite state space lies at the core of our results, though we apply it to a diverse set of models. These include mixtures of both finite and nonparametric product distributions, hidden Markov models and random graph mixture models, and lead to a number of new results and improvements to old ones. In the parametric setting, this approach indicates that for such models, the classical definition of identifiability is typically too strong. Instead generic identifiability holds, which implies that the set of nonidentifiable parameters has measure zero, so that parameter inference is still meaningful. In particular, this sheds light on the properties of finite mixtures of Bernoulli products, which have been used for decades despite being known to have nonidentifiable parameters. In the nonparametric setting, we again obtain identifiability only when certain restrictions are placed on the distributions that are mixed, but we explicitly describe the conditions.},
archivePrefix = {arXiv},
arxivId = {0809.5032},
author = {Allman, Elizabeth S. and Matias, Catherine and Rhodes, John A.},
doi = {10.1214/09-AOS689},
eprint = {0809.5032},
isbn = {0090-5364},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Algebraic statistics,Conditional independence,Contingency table,Finite mixture,Identiflability,Latent structure,Multivariate Bernoulli mixture,Nonparametric mixture},
number = {6 A},
pages = {3099--3132},
title = {{Identifiability of parameters in latent structure models with many observed variables}},
volume = {37},
year = {2009}
}
@article{Lindeberg|1998|,
abstract = {When computing descriptors of image data, the type of information
that can be extracted may be strongly dependent on the scales at
which the image operators are applied. This article presents a systematic
methodology for addressing this problem. A mechanism is presented
for automatic selection of scale levels when detecting one-dimensional
image features, such as edges and ridges. A novel concept of a scale-space
edge is introduced, defined as a connected set of points in scale-space
at which: (i) the gradient magnitude a ssumes a local maximum in
the gradient direction, and (ii) a normalized measure of the strength
of the edge response is locally maximal over scales. An important
consequence of this defi nition is that it allows the scale levels
to vary along the edge. Two specific measures of edge strength are
analysed in detail, the gradient magnitude and a differential expression
derived from the third-order derivative in the gradient direction.
For a certain way of normalizing these differential descriptors,
by expressing them in terms of so-called -normalized derivatives,
an immediate consequence of this deffnition is that the edge detector
will adapt its scale levels to the local image structure. Specifically,
sharp edges will be detected at scales so as to reduce the shape
distortions due to scale-space smoothing, whereas sufficiently coarse
scales will be selected at diffuse edges, such that an edge model
is a valid abstraction of the intensity profile across the edge.
Since the scale-space edge is defined from the intersection of two
zero-crossing surfaces in scale-space, the edges will by definition
form closed curves. This simplified selection of salient edges, and
a novel significance measure is proposed, by integrating the edge
strength along the edge. Moreover, the scale information associated
with each edge provides useful clues to the physical nature of the
edge. With just slight modifications, similar ideas can be used for
formulating ridge detectors with automatic selection, having the
characteristic property that the selected scales on a scale-space
ridge instead reject the width of the ridge. It is shown how the
methodology can be implemented in terms of straightforward visual
front-end operations, and the validity of the approach is supported
by theoretical analysis as well as experiments on real-world and
synthetic data. Keywords: edge detection, ridge detection, scale
selection, diffuseness, normalized derivative, Gaussian derivative,
scale-space, multi-scale representation, feature detection, computer
vision},
annote = {This is nice paper on multiscale edge detection using LOG-type filters},
author = {Lindeberg, T},
journal = {International Journal of Computer Vission},
keywords = {automatic scale selection,computational,edge detection,image processing,multiscale,scale space},
number = {2},
title = {{Edge detection and ridge detection with automatic scale selection}},
volume = {30}
}
@article{DiBernardo2010,
abstract = {This paper presents an overview of the current state of the art in the analysis of discontinuity-induced bifurcations (DIBs) of piecewise smooth dynamical systems, a particularly relevant class of hybrid dynamical systems. Firstly, we present a classification of the most common types of DIBs involving non-trivial interactions of fixed points and equilibria of maps and flows with the manifolds in phase space where the system is non-smooth. We then analyse the case of limit cycles interacting with such manifolds, presenting grazing and sliding bifurcations. A description of possible classification strategies to predict and analyse the scenarios following such bifurcations is also discussed, with particular attention to those methodologies that can be applied to generic n-dimensional systems.},
author = {{Di Bernardo}, M and Hogan, S J},
doi = {10.1098/rsta.2010.0198},
issn = {1364-503X},
journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
keywords = {Models, Theoretical,Nonlinear Dynamics},
month = {nov},
number = {1930},
pages = {4915--35},
pmid = {20921004},
title = {{Discontinuity-induced bifurcations of piecewise smooth dynamical systems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20921004},
volume = {368},
year = {2010}
}
@article{Risler2004,
annote = {2010IInum8.9},
author = {Risler, T and Prost, J and J{\"{u}}licher, F},
journal = {Physical Review Letters},
title = {{Universal critical behavior of noisy coupled oscillators}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.93.175702},
year = {2004}
}
@article{Wang2015,
author = {Wang, Shengchu and Li, Yunzhou and Wang, Jing},
doi = {10.1109/TWC.2014.2382098},
issn = {1536-1276},
journal = {IEEE Transactions on Wireless Communications},
number = {4},
pages = {2156--2168},
title = {{Multiuser Detection in Massive Spatial Modulation MIMO with Low-Resolution ADCs}},
volume = {14},
year = {2015}
}
@article{Varshney2006,
abstract = {Experimental investigations have revealed that synapses possess interesting and, in some cases, unexpected properties. We propose a theoretical framework that accounts for three of these properties: typical central synapses are noisy, the distribution of synaptic weights among central synapses is wide, and synaptic connectivity between neurons is sparse. We also comment on the possibility that synaptic weights may vary in discrete steps. Our approach is based on maximizing information storage capacity of neural tissue under resource constraints. Based on previous experimental and theoretical work, we use volume as a limited resource and utilize the empirical relationship between volume and synaptic weight. Solutions of our constrained optimization problems are not only consistent with existing experimental measurements but also make nontrivial predictions.},
author = {Varshney, Lav R and Sj{\"{o}}str{\"{o}}m, PJ J and Chklovskii, D B},
doi = {10.1016/j.neuron.2006.10.017},
issn = {0896-6273},
journal = {Neuron},
keywords = {Animals,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Information Storage and Retrieval,Memory,Memory: physiology,Models,Neurological,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {nov},
number = {3},
pages = {409--23},
pmid = {17088208},
title = {{Optimal information storage in noisy synapses under resource constraints}},
url = {http://dx.doi.org/10.1016/j.neuron.2006.10.017},
volume = {52},
year = {2006}
}
@techreport{Diebolt1994,
author = {Diebolt, J and Ip, E and Olkin, I},
institution = {Stanford University},
title = {{A stochastic EM algorithm for approximating the maximum likelihood estimate}},
year = {1994}
}
@article{PT97,
author = {Plesser, H and Tanaka, S},
journal = {Physics Letters A},
pages = {228--234},
title = {{Stochastic resonance in a model neuron with reset}},
volume = {225},
year = {1997}
}
@article{CR72,
author = {Capocelli, R and Ricciardi, L},
journal = {Journal of Applied Probability},
pages = {270--287},
title = {{On the inverse of the first passage time probability problem}},
volume = {9},
year = {1972}
}
@misc{McCammon|2006|a,
annote = {this is discriminator response diagram for x-calorimeter experiment{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of McCammon},
author = {McCammon, D},
keywords = {astrophysics,discriminator,interacting dark matter,physics,x-calorimeter},
title = {{Discriminator response}}
}
@article{Dutta2007,
author = {Dutta, Partha Sharathi and Routroy, Bitihotra and Banerjee, Soumitro and Alam, S. S.},
doi = {10.1007/s11071-007-9318-y},
issn = {0924-090X},
journal = {Nonlinear Dynamics},
keywords = {border collision bifurcation,discontinuous map,form,normal,periodic solutions},
month = {dec},
number = {4},
pages = {369--380},
title = {{On the existence of low-period orbits in n-dimensional piecewise linear discontinuous maps}},
url = {http://www.springerlink.com/index/10.1007/s11071-007-9318-y},
volume = {53},
year = {2007}
}
@article{SZ96,
author = {Stevens, C and Zador, A},
journal = {NIPS},
pages = {103--109},
title = {{When is an integrate-and-fire neuron like a {\{}P{\}}oisson neuron?}},
volume = {8},
year = {1996}
}
@article{Amit2003,
abstract = {The collective behavior of a network, modeling a cortical module of spiking neurons connected by plastic synapses is studied. A detailed spike-driven synaptic dynamics is simulated in a large network of spiking neurons, implementing the full double dynamics of neurons and synapses. The repeated presentation of a set of external stimuli is shown to structure the network to the point of sustaining working memory (selective delay activity). When the synaptic dynamics is analyzed as a function of pre- and postsynaptic spike rates in functionally defined populations, it reveals a novel variation of the Hebbian plasticity paradigm: in any functional set of synapses between pairs of neurons (e.g., stimulated-stimulated, stimulated-delay, stimulated-spontaneous), there is a finite probability of potentiation as well as of depression. This leads to a saturation of potentiation or depression at the level of the ratio of the two probabilities. When one of the two probabilities is very high relative to the other, the familiar Hebbian mechanism is recovered. But where correlated working memory is formed, it prevents overlearning. Constraints relevant to the stability of the acquired synaptic structure and the regimes of global activity allowing for structuring are expressed in terms of the parameters describing the single-synapse dynamics. The synaptic dynamics is discussed in the light of experiments observing precise spike timing effects and related issues of biological plausibility.},
author = {Amit, Daniel J and Mongillo, Gianluigi},
doi = {10.1162/089976603321192086},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Humans,Memory,Memory: physiology,Models, Neurological,Synapses,Synapses: physiology},
month = {mar},
number = {3},
pages = {565--96},
pmid = {12620158},
title = {{Spike-driven synaptic dynamics generating working memory states.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12620158},
volume = {15},
year = {2003}
}
@article{Pitt1988,
author = {Pitt, Leonard and Valiant, Leslie G.},
doi = {10.1145/48014.63140},
issn = {00045411},
journal = {Journal of the ACM},
month = {oct},
number = {4},
pages = {965--984},
title = {{Computational limitations on learning from examples}},
url = {http://portal.acm.org/citation.cfm?doid=48014.63140},
volume = {35},
year = {1988}
}
@inproceedings{Mosk-Aoyama2006,
author = {Mosk-Aoyama, D. and Shah, D},
booktitle = {Proceedings of the twenty-fifth annual ACM symposium on Principles of distributed computing},
keywords = {Network functionality,data aggregation,gossip,randomized algorithms},
mendeley-tags = {Network functionality},
pages = {113--122},
publisher = {ACM},
title = {{Computing separable functions via gossip}},
url = {http://portal.acm.org/citation.cfm?id=1146381.1146401},
year = {2006}
}
@book{DT87,
address = {Berlin},
author = {Ditzian, Z and Totik, V},
publisher = {Springer-Verlag},
title = {{Moduli of smoothness}},
year = {1987}
}
@article{Frost07,
author = {Frost, W and Wang, J and Brandon, C},
journal = {Journal of Neuroscience Methods},
pages = {148--154},
title = {{A stereo-compound hybrid microscope for combined intracellular and optical recording of invertebrate neural network activity}},
volume = {162},
year = {2007}
}
@phdthesis{Csaji|2001|,
author = {Csaji, B C},
keywords = {approximation,computational,neural networks},
title = {{Approximation with Artificial Neural Networks}}
}
@book{Haykin2007,
author = {Haykin, SS},
title = {{Neural networks: a comprehensive foundation}},
url = {http://www.lavoisier.fr/livre/notice.asp?ouvrage=1100052},
year = {2007}
}
@article{GDW04,
author = {Godsill, S J and Doucet, A and West, M},
journal = {Journal of the American Statistical Association},
pages = {156--168},
title = {{Monte {\{}C{\}}arlo smoothing for non-linear time series}},
volume = {99},
year = {2004}
}
@inproceedings{Zhang2016,
abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
archivePrefix = {arXiv},
arxivId = {1611.03530},
author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
booktitle = {ICLR},
eprint = {1611.03530},
title = {{Understanding deep learning requires rethinking generalization}},
url = {http://arxiv.org/abs/1611.03530},
year = {2017}
}
@article{Zhou2006,
annote = {2010IInum9.7{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0604070v1},
author = {Zhou, C and Motter, A E and Kurths, J},
eprint = {0604070v1},
issn = {1079-7114},
journal = {Physical Review Letters},
number = {3},
pages = {34101},
primaryClass = {arXiv:cond-mat},
publisher = {APS},
title = {{Universality in the synchronization of weighted random networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.96.034101},
volume = {96},
year = {2006}
}
@article{BlitzerLandau05,
abstract = {Learning depends on positive or negative changes in synaptic transmission

that are synapse-specific and sustained. Synaptic signals can be

directly measured and respond to certain kinds of stimulation by

becoming persistently enhanced (long-term potentiation, LTP) or decreased

(long-term depression, LTD). Studying LTP and LTD opens a window

on to the molecular mechanisms of memory. Although changes in both

pre- and postsynaptic strength have been implicated in LTP and LTD,

most attention has been focused on changes in postsynaptic glutamate

receptor density. This is controlled by intracellular Ca(2+) ions

via a network of signaling molecules. Changes in postsynaptic Ca(2+)

concentration depend on the coincidence of appropriate synaptic signals,

as is found in learning situations. The long-term persistence of

LTP and LTD requires gene transcription and translation. It is posited

that local translation at the synapse, in a self-sustaining manner,

mediates the persistence of long-term changes despite constant turnover

of the synaptic components.},
author = {Blitzer, Robert D and Iyengar, Ravi and Landau, Emmanuel M},
doi = {10.1016/j.biopsych.2004.02.031},
journal = {Biol Psychiatry},
keywords = {Animals; Ca(2+)-Calmodulin Dependent Protein Kinas,Genetic,Glutamate; Synapses; Synaptic Transmission; Trans},
month = {jan},
number = {2},
pages = {113--119},
pmid = {15652868},
title = {{Postsynaptic signaling networks: cellular cogwheels underlying long-term plasticity.}},
url = {http://dx.doi.org/10.1016/j.biopsych.2004.02.031},
volume = {57},
year = {2005}
}
@article{YuhongYang12012005,
author = {Yang, Yuhong},
journal = {Biometrika},
number = {4},
pages = {937--950},
title = {{Can the strengths of AIC and BIC be shared? A conflict between model indentification and regression estimation}},
volume = {92},
year = {2005}
}
@article{Alibart2012,
abstract = {Using memristive properties common for titanium dioxide thin film devices, we designed a simple write algorithm to tune device conductance at a specific bias point to 1{\%} relative accuracy (which is roughly equivalent to seven-bit precision) within its dynamic range even in the presence of large variations in switching behavior. The high precision state is nonvolatile and the results are likely to be sustained for nanoscale memristive devices because of the inherent filamentary nature of the resistive switching. The proposed functionality of memristive devices is especially attractive for analog computing with low precision data. As one representative example we demonstrate hybrid circuitry consisting of an integrated circuit summing amplifier and two memristive devices to perform the analog multiply-and-add (dot-product) computation, which is a typical bottleneck operation in information processing.},
author = {Alibart, Fabien and Gao, Ligang and Hoskins, Brian D and Strukov, Dmitri B},
doi = {10.1088/0957-4484/23/7/075201},
issn = {1361-6528},
journal = {Nanotechnology},
keywords = {analog computation,memristor,resistive switching,thin film metal oxide},
month = {feb},
number = {7},
pages = {075201},
pmid = {22260949},
title = {{High precision tuning of state for memristive devices by adaptable variation-tolerant algorithm.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22260949},
volume = {23},
year = {2012}
}
@article{Hong2007,
annote = {

2010IInum8.6},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0701646v2},
author = {Hong, Hyunsuk and Chat{\'{e}}, H and Park, Hyunggyu and Tang, LH},
eprint = {0701646v2},
journal = {Physical Review Letters},
number = {4},
pages = {1--5},
primaryClass = {arXiv:cond-mat},
title = {{Entrainment transition in populations of random frequency oscillators}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.99.184101},
year = {2007}
}
@article{Liebovitch1989a,
annote = {2009num30},
author = {Liebovitch, L S},
journal = {Mathematical biosciences},
number = {1},
pages = {97},
title = {{Analysis of fractal ion channel gating kinetics: kinetic rates, energy levels, and activation energies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2520026},
volume = {93},
year = {1989}
}
@article{Bellemareetal2017,
archivePrefix = {arXiv},
arxivId = {1707.06887},
author = {Bellemare et al},
eprint = {1707.06887},
title = {{A Distributional Perspective on Reinforcement Learning}},
year = {2017}
}
@techreport{Stewart1990,
author = {Stewart, G W},
booktitle = {Technical Report},
title = {{Perturbation Theory for the Singular Value Decomposition}},
year = {1990}
}
@article{calvin1968synaptic,
annote = {2010IInum12.13},
author = {Calvin, W H and Stevens, CF F},
journal = {Journal of Neurophysiology},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
number = {4},
pages = {574},
publisher = {Am Physiological Soc},
title = {{Synaptic noise and other sources of randomness in motoneuron interspike intervals}},
url = {http://jn.physiology.org/cgi/reprint/31/4/574.pdf},
volume = {31},
year = {1968}
}
@article{PologrutoSvoboda04,
abstract = {Genetically encoded {\{}Ca{\}}{\^{}}{\{}2+{\}} indicators (GECIs) based on fluorescent

proteins (XFPs) and {\{}Ca{\}}{\^{}}{\{}2+{\}}-binding proteins [like calmodulin

(CaM)] have great potential for the study of subcellular {\{}Ca{\}}{\^{}}{\{}2+{\}}

signaling and for monitoring activity in populations of neurons.

However, interpreting GECI fluorescence in terms of neural activity

and cytoplasmic-free {\{}Ca{\}}{\^{}}{\{}2+{\}} concentration ([{\{}Ca{\}}{\^{}}{\{}2+{\}}]) is

complicated by the nonlinear interactions between {\{}Ca{\}}{\^{}}{\{}2+{\}} binding

and GECI fluorescence. We have characterized GECIs in pyramidal neurons

in cultured hippocampal brain slices, focusing on indicators based

on circularly permuted XFPs [GCaMP (Nakai et al., 2001), Camgaroo2

(Griesbeck et al., 2001), and Inverse Pericam (Nagai et al., 2001)].

Measurements of fluorescence changes evoked by trains of action potentials

revealed that GECIs have little sensitivity at low action potential

frequencies compared with synthetic [{\{}Ca{\}}{\^{}}{\{}2+{\}}] indicators with

similar affinities for {\{}Ca{\}}{\^{}}{\{}2+{\}}. The sensitivity of GECIs improved

for high-frequency trains of action potentials, indicating that GECIs

are supralinear indicators of neural activity. Simultaneous measurement

of GECI fluorescence and [{\{}Ca{\}}{\^{}}{\{}2+{\}}] revealed supralinear relationships.

We compared GECI fluorescence saturation with CaM {\{}Ca{\}}{\^{}}{\{}2+{\}}-dependent

structural transitions. Our data suggest that GCaMP and Camgaroo2

report CaM structural transitions in the presence and absence of

CaM-binding peptide, respectively.},
author = {Pologruto, Thomas A and Yasuda, Ryohei and Svoboda, Karel},
doi = {10.1523/JNEUROSCI.2854-04.2004},
journal = {J Neurosci},
keywords = {Action Potentials; Animals; Calcium; Calmodulin; C,Chemical; Neurons; Pyramidal Cells; Rats; Tissue,Confocal; Microscopy,Fluorescence,Multiphoton; Models},
month = {oct},
number = {43},
pages = {9572--9579},
pmid = {15509744},
title = {{Monitoring neural activity and [{\{}Ca{\}}{\^{}}{\{}2+{\}}] with genetically encoded {\{}Ca{\}}{\^{}}{\{}2+{\}} indicators.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.2854-04.2004},
volume = {24},
year = {2004}
}
@article{HOG75,
author = {Hogarth, R},
journal = {Journal of the American Statistical Association},
pages = {271--289},
title = {{Cognitive Processes and the Assessment of Subjective Probability Distributions}},
volume = {70},
year = {1975}
}
@misc{Pazienza2011,
author = {Pazienza, Giovanni E and Albo-canals, Jordi},
booktitle = {Ieee Circuits And Systems Magazine},
title = {{Memristors}},
year = {2011}
}
@book{KP99,
author = {Kloeden, P and Platen, E},
publisher = {Springer},
title = {{Numerical Solution of Stochastic Differential Equations}},
year = {1999}
}
@article{Small2009,
abstract = {Individual cortical synapses are known to exhibit a very complex short-time dynamic behaviour in response to simple "naturalistic" stimulation. We describe a computational study of the experimentally obtained excitatory post-synaptic potential trains of individual cortical synapses. By adopting a new nonlinear modelling scheme we construct robust and repeatable models of the underlying dynamics. These models suggest that cortical synapses exhibit a wide range of either periodic or chaotic dynamics. For stimulus at a fixed rate our models predict that the response of the individual synapse will vary from a fixed point to periodic and chaotic, depending on the frequency of stimulus. Dynamics for individual synapses vary widely, suggesting that the individual behaviour of synapses is highly tuned and that the dynamic behaviour of even a small network of synapse-coupled neurons could be extremely varied.},
annote = {2010IInum12.42},
author = {Small, Michael and Robinson, H P C and Kleppe, Ingo C and Tse, Chi Kong},
doi = {10.1007/s00285-009-0312-5},
issn = {1432-1416},
journal = {Journal of mathematical biology},
keywords = {2000,Neuron Model,bifurcation and chaos,cortical synaptic transmission,mathematics subject classification,modelling,nonlinear time,series analysis,synapse},
mendeley-tags = {Neuron Model,synapse},
month = {nov},
pmid = {19941138},
title = {{Uncovering bifurcation patterns in cortical synapses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19941138},
year = {2009}
}
@article{Beggs2003,
abstract = {Networks of living neurons exhibit diverse patterns of activity, including oscillations, synchrony, and waves. Recent work in physics has shown yet another mode of activity in systems composed of many nonlinear units interacting locally. For example, avalanches, earthquakes, and forest fires all propagate in systems organized into a critical state in which event sizes show no characteristic scale and are described by power laws. We hypothesized that a similar mode of activity with complex emergent properties could exist in networks of cortical neurons. We investigated this issue in mature organotypic cultures and acute slices of rat cortex by recording spontaneous local field potentials continuously using a 60 channel multielectrode array. Here, we show that propagation of spontaneous activity in cortical networks is described by equations that govern avalanches. As predicted by theory for a critical branching process, the propagation obeys a power law with an exponent of -3/2 for event sizes, with a branching parameter close to the critical value of 1. Simulations show that a branching parameter at this value optimizes information transmission in feedforward networks, while preventing runaway network excitation. Our findings suggest that "neuronal avalanches" may be a generic property of cortical networks, and represent a mode of activity that differs profoundly from oscillatory, synchronized, or wave-like network states. In the critical state, the network may satisfy the competing demands of information transmission and network stability.},
author = {Beggs, John M and Plenz, D},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Computer Simulation,Electrodes,Models, Neurological,Neocortex,Neocortex: cytology,Neocortex: physiology,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Rats,Synaptic Transmission,Synaptic Transmission: physiology},
month = {dec},
number = {35},
pages = {11167--77},
pmid = {14657176},
title = {{Neuronal avalanches in neocortical circuits.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14657176},
volume = {23},
year = {2003}
}
@article{Sherman2012,
author = {Sherman, Jerome and Epshtein, Daniel},
journal = {Review of Optometry},
number = {9},
pages = {52},
title = {{The ABCs of OCT - Take a guided tour of this innovative technology to better understand its relevance to your practice}},
url = {http://www.reviewofoptometry.com/content/d/technology/c/36644/ http://www.revoptom.com/content/c/36644/dnnprintmode/true/?skinsrc={\%}5Bl{\%}5Dskins/ro2009/pageprint{\&}containersrc={\%}5Bl{\%}5Dcontainers/ro2009/simple},
volume = {149},
year = {2012}
}
@article{BD01,
author = {Billera, L and Diaconis, P},
journal = {Statistical Science},
pages = {335--339},
title = {{Geometric interpretation of the {\{}M{\}}etropolis-{\{}H{\}}astings algorithm}},
volume = {16},
year = {2001}
}
@article{Bogacz|2001|,
abstract = {Much evidence indicates that recognition memory involves two separable
processes, recollection and familiarity discrimination, with familiarity
discrimination being dependent on the perirhinal cortex of the temporal
lobe. Here, we describe a new neural network model designed to mimic
the response patterns of perirhinal neurons that signal information
concerning the novelty or familiarity of stimuli. The model achieves
very fast and accurate familiarity discrimination while employing
biologically plausible parameters and Hebbian learning rules. The
fact that the activity patterns of the model{\"{i}}¾'s simulated neurons
are closely similar to those of neurons recorded from the primate
perirhinal cortex indicates that this brain region could discriminate
familiarity using principles akin to those of the model. If so, the
capacity of the model establishes that the perirhinal cortex alone
may discriminate the familiarity of many more stimuli than current
neural network models indicate could be recalled (recollected) by
all the remaining areas of the cerebral cortex. This efficiency and
speed of detecting novelty provides an evolutionary advantage, thereby
providing a reason for the existence of a familiarity discrimination
network in addition to networks used for recollection.},
author = {Bogacz, R and Brown, M W and Giraud-Carrier, C},
journal = {journal of computational neuroscience},
keywords = {cortex,decision making,discrimination,hippocampal region,model,neurobiology,novelty detection,recognition memory,spike-response},
pages = {5},
title = {{Model of Familiarity Discrimination in the Perirhinal Cortex}},
volume = {10}
}
@article{Tramontana2010,
author = {Tramontana, F and Gardini, L and Agliari, A},
issn = {0378-4754},
journal = {Mathematics and Computers in Simulation},
keywords = {math},
mendeley-tags = {math},
number = {8},
pages = {1--25},
publisher = {Elsevier},
title = {{Endogenous cycles in discontinuous growth models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378475410004027 http://www.sciencedirect.com/science/article/pii/S0378475410004027},
volume = {81},
year = {2010}
}
@article{Rossant2011,
abstract = {How do neurons compute? Two main theories compete: neurons could temporally integrate noisy inputs (rate-based theories) or they could detect coincident input spikes (spike timing-based theories). Correlations at fine timescales have been observed in many areas of the nervous system, but they might have a minor impact. To address this issue, we used a probabilistic approach to quantify the impact of coincidences on neuronal response in the presence of fluctuating synaptic activity. We found that when excitation and inhibition are balanced, as in the sensory cortex in vivo, synchrony in a very small proportion of inputs results in dramatic increases in output firing rate. Our theory was experimentally validated with in vitro recordings of cortical neurons of mice. We conclude that not only are noisy neurons well equipped to detect coincidences, but they are so sensitive to fine correlations that a rate-based description of neural computation is unlikely to be accurate in general.},
author = {Rossant, C and Leijon, S and Magnusson, A K and Brette, R},
doi = {10.1523/JNEUROSCI.2482-11.2011},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Electric Stimulation,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Female,Inbred C57BL,Inbred CBA,Male,Mice,Neurons,Neurons: physiology,Organ Culture Techniques,Pyramidal Cells,Pyramidal Cells: physiology},
month = {nov},
number = {47},
pages = {17193--206},
pmid = {22114286},
title = {{Sensitivity of noisy neurons to coincident inputs.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22114286},
volume = {31},
year = {2011}
}
@article{Corinto2012,
author = {Corinto, Fernando and Ascoli, Alon},
journal = {IEEE transactions on Circuits and Systems I: Regular Papers},
month = {may},
number = {11},
pages = {2713--2726},
title = {{A boundary condition-based approach to the modeling of memristor nanostructures}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6198300},
volume = {59},
year = {2012}
}
@article{zhou-journal,
abstract = {Several integrate-to-threshold models with differing temporal integration mechanisms have been proposed to describe the accumulation of sensory evidence to a prescribed level prior to motor response in perceptual decision-making tasks. An experiment and simulation studies have shown that the introduction of time-varying perturbations during integration may distinguish among some of these models. Here, we present computer simulations and mathematical proofs that provide more rigorous comparisons among one-dimensional stochastic differential equation models. Using two perturbation protocols and focusing on the resulting changes in the means and standard deviations of decision times, we show that, for high signal-to-noise ratios, drift-diffusion models with constant and time-varying drift rates can be distinguished from Ornstein-Uhlenbeck processes, but not necessarily from each other. The protocols can also distinguish stable from unstable Ornstein-Uhlenbeck processes, and we show that a nonlinear integrator can be distinguished from these linear models by changes in standard deviations. The protocols can be implemented in behavioral experiments.},
annote = {2008num40},
archivePrefix = {arXiv},
arxivId = {0901.2173},
author = {Zhou, Xiang and Wong-Lin, KongFatt and Holmes, Philip},
eprint = {0901.2173},
keywords = {Neurons and Cognition},
pages = {32},
title = {{Time-varying perturbations can distinguish among integrate-to-threshold models for perceptual decision-making in reaction time tasks}},
url = {http://arxiv.org/abs/0901.2173},
year = {2009}
}
@inproceedings{Ostrowski|1995|,
abstract = {This paper studies the mechanics of undulatory locomotion. This type
of locomotion is generated by a coupling of internal shape changes
to external nonholonomic constraints. Employing methods from geometric
mechanics, we use the dynamic symmetries and kinematic constraints
to develop a specialised form of the dynamic equations which govern
undulatory systems. These equations are written in terms of physically
meaningful and intuitively appealing variables that show the role
of internal shape changes in driving locomotion.},
annote = {The paper introduces a framework for treating locomotion in Lagrangian{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}formalism.},
author = {Ostrowski, J P and Burdick, J W and Lewis, A D and Murray, R M},
booktitle = {IEEE int'l conference on robotics and automation},
keywords = {c. elegans,constraints,locomotion,mechanics,neurobiology,physics,symmetries,worm},
title = {{The mechanics of undulatory locomotion: the mixed kinematic and dynamic case}}
}
@article{PILL05,
author = {Pillow, J W and Paninski, L and Shlens, J and Simoncelli, E and Chichilnisky, E J},
journal = {Comp. Sys. Neur. '05},
title = {{Modeling multi-neuronal responses in primate retinal ganglion cells}},
year = {2005}
}
@article{Boyd2010a,
author = {Boyd, Stephen},
doi = {10.1561/2200000016},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {1},
pages = {1--122},
title = {{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000016},
volume = {3},
year = {2010}
}
@article{Luo2008,
author = {Luo, L and Callaway, E M and Svoboda, K},
journal = {Neuron},
pages = {634--660},
title = {{Genetic dissection of neural circuits.}},
volume = {57},
year = {2008}
}
@article{Shlizerman2012a,
abstract = {We study the dynamics of a quadratic integrate-and-fire model of a single-compartment neuron with a slow recovery variable, as input current and parameters describing timescales, recovery variable, and postspike reset change. Analysis of a codimension 2 bifurcation reveals that the domain of attraction of a stable hyperpolarized rest state interacts subtly with reset parameters, which reposition the system state after spiking. We obtain explicit approximations of instantaneous firing rates for fixed values of the recovery variable, and use the averaging theorem to obtain asymptotic firing rates as a function of current and reset parameters. Along with the different phase-plane geometries, these computations provide explicit tools for the interpretation of different spiking patterns and guide parameter selection in modeling different cortical cell types.},
author = {Shlizerman, Eli and Holmes, Philip and Mathematics, Computational},
doi = {10.1162/NECO_a_00308},
issn = {1530-888X},
journal = {Neural computation},
keywords = {34a38,34c20,34c23,34c37,37gxx,92c20,Action Potentials,Action Potentials: physiology,Computer Simulation,Models,Neurological,Neurons,Neurons: physiology,Time Factors,ams subject classifications,asymptotic firing rates,averaging,codimension two bifurcation,cortical cell re-,instantaneous firing rates,slow-fast dynamics,sponses},
month = {aug},
number = {8},
pages = {2078--118},
pmid = {22509966},
title = {{Neural dynamics, bifurcations, and firing rates in a quadratic integrate-and-fire model with a recovery variable. I: Deterministic behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22509966},
volume = {24},
year = {2012}
}
@article{Kanamaru2010,
abstract = {The roles of inhibitory neurons in synchronous firing are examined in a network of excitatory and inhibitory neurons with Watts and Strogatz's rewiring. By examining the persistence of the synchronous firing that exists in the random network, it was found that there is a probability of rewiring at which a transition between the synchronous state and the asynchronous state takes place, and the dynamics of the inhibitory neurons play an important role in determining this probability.},
author = {Kanamaru, Takashi and Aihara, Kazuyuki},
doi = {10.1162/neco.2010.04-09-997},
issn = {1530-888X},
journal = {Neural Computation},
month = {may},
number = {5},
pages = {1383--1398},
pmid = {20100075},
title = {{Roles of inhibitory neurons in rewiring-induced synchronization in pulse-coupled neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20100075},
volume = {22},
year = {2010}
}
@article{GG71,
author = {Good, I and Gaskins, R},
journal = {Biometrika},
pages = {255--277},
title = {{Nonparametric roughness penalties for probability densities}},
volume = {58},
year = {1971}
}
@article{Alles|1996|,
abstract = {We have performed a high statistics Monte Carlo simulation to investigate
whether the two-dimensional O(n) non-linear sigma models are asymptotically
free or they show a Kosterlitz-Thouless-like phase transition. We
have calculated the mass gap and the magnetic susceptibility in the
O(8) model with standard action and the O(3) model with Symanzik
action. Our results for O(8) support the asymptotic freedom scenario.},
annote = {The paper deals from Monte Carlo approach with the issue of existing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of supposedly another phase transition near zero in O(3).},
author = {Alles, B and Buonanno, A and Cella, G},
journal = {arXiv},
keywords = {assymptotic freedom,monte-carlo,nonlinear sigma-model,phase transition,physics,quantum field theory,two-phase issue},
pages = {9608002},
title = {{The two-phase issue in the O(n) nonlinear sigma model: a Monte Carlo study}},
volume = {hep-lat}
}
@article{Grossman1997,
author = {Grossman, B Y Y and Parnas, I and Spira, M E},
journal = {Neuroscience},
pages = {307--322},
title = {{Ionic mechanisms involved in the differential conduction of action potentials at high freuquency in a branching axon}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0306452296005404},
year = {1997}
}
@article{Ma,
abstract = {Remarkable recent success of deep neural networks has not been easy to analyze theoretically. It has been particularly hard to disentangle relative significance of ar-chitecture and optimization in achieving accurate classification on large datasets. On the flip side, shallow methods (such as kernel methods) have encountered obstacles in scaling to large data, despite excellent performance on smaller datasets, and exten-sive theoretical analysis. Practical methods, such as variants of gradient descent used so successfully in deep learning, seem to perform below par when applied to kernel methods. This difficulty has sometimes been attributed to the limitations of shallow architecture. In this paper we identify a basic limitation in gradient descent-based optimization methods when used in conjunctions with smooth kernels. An analysis demonstrates that only a vanishingly small fraction of the function space is reachable after a fixed number of gradient descent iterations drastically limiting its power and resulting in severe over-regularization. The issue is purely algorithmic, persisting even in the limit of infinite data. To address this shortcoming in practice, we introduce EigenPro iteration, based on a simple preconditioning scheme using a small number of approximately computed eigenvectors. It turns out that even this small (and computationally inexpensive) amount of approximate second-order information results in significant improvement of performance for large-scale kernel methods. Using EigenPro in conjunction with stochastic gradient descent we demonstrate scalable state-of-the-art results for kernel methods on a modest computational budget of a few GPU-hours (compared to typi-cally much larger computational expenditures to obtain best results in the literature). Finally, we feel that these results show a need for a broader computational per-spective on modern large-scale learning to complement more traditional statistical and convergence analyses. In particular, systematic analysis concentrating on the approx-imation power of algorithms with a fixed budget of computation will lead to progress both in theory and practice.},
archivePrefix = {arXiv},
arxivId = {1703.10622},
author = {Ma, Siyuan and Belkin, Mikhail},
eprint = {1703.10622},
pages = {1--22},
title = {{Diving into the shallows: a computational perspective on large-scale shallow learning}},
url = {https://arxiv.org/pdf/1703.10622.pdf}
}
@article{Friedlander2009,
author = {Friedlander, T and Brenner, N},
journal = {Proceedings of the National Academy of Sciences},
number = {52},
pages = {22558},
publisher = {National Acad Sciences},
title = {{Adaptive response by state-dependent inactivation}},
url = {http://www.pnas.org/content/106/52/22558.abstract},
volume = {106},
year = {2009}
}
@article{Chatterjee13,
archivePrefix = {arXiv},
arxivId = {arXiv:1212.1247v5},
author = {Chatterjee, Sourav},
eprint = {arXiv:1212.1247v5},
journal = {Arxiv},
pages = {1--52},
title = {{Matrix estimation by Universal Singular Value Thresholding}},
url = {http://arxiv.org/abs/1212.1247},
volume = {1212.1247},
year = {2013}
}
@incollection{Simoncelli03a,
author = {Simoncelli, E P},
booktitle = {The Visual Neurosciences},
chapter = {109},
editor = {Chalupa, L M and Werner, J S},
month = {jan},
pages = {1616--1623},
publisher = {MIT Press},
title = {{Local Analysis of Visual Motion}},
year = {2003}
}
@article{PT04,
author = {Passaglia, C and Troy, J},
journal = {Journal of Neurophysiology},
pages = {1217--1229},
title = {{Information Transmission Rates of Cat Retinal Ganglion Cells}},
volume = {91},
year = {2004}
}
@inproceedings{LAMM00,
author = {Lamm, P},
booktitle = {Surveys on Solution Methods for Inverse Problems},
pages = {53--82},
publisher = {Springer},
title = {{A survey of regularization methods for first-kind {\{}V{\}}olterra equations}},
year = {2000}
}
@article{Bruce1999,
abstract = {Most models of neural response to electrical stimulation, such as the Hodgkin-Huxley equations, are deterministic, despite significant physiological evidence for the existence of stochastic activity. For instance, the range of discharge probabilities measured in response to single electrical pulses cannot be explained at all by deterministic models. Furthermore, there is growing evidence that the stochastic component of auditory nerve response to electrical stimulation may be fundamental to functionally significant physiological and psychophysical phenomena. In this paper we present a simple and computationally efficient stochastic model of single-fiber response to single biphasic electrical pulses, based on a deterministic threshold model of action potential generation. Comparisons with physiological data from cat auditory nerve fibers are made, and it is shown that the stochastic model predicts discharge probabilities measured in response to single biphasic pulses more accurately than does the equivalent deterministic model. In addition, physiological data show an increase in stochastic activity with increasing pulse width of anodic/cathodic biphasic pulses, a phenomenon not present for monophasic stimuli. These and other data from the auditory nerve are then used to develop a population model of the total auditory nerve, where each fiber is described by the single-fiber model.},
author = {Bruce, I C and White, M W and Irlicht, L S and O'Leary, S J and Dynes, S and Javel, E and Clark, G M},
issn = {0018-9294},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Action Potentials,Animals,Auditory Threshold,Cats,Electric Stimulation,Electrodes,Linear Models,Models, Neurological,Nerve Fibers,Nerve Fibers: physiology,Predictive Value of Tests,Reproducibility of Results,Stochastic Processes,Vestibulocochlear Nerve,Vestibulocochlear Nerve: physiology},
month = {jun},
number = {6},
pages = {617--29},
pmid = {10356868},
title = {{A stochastic model of the electrically stimulated auditory nerve: single-pulse response.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10356868},
volume = {46},
year = {1999}
}
@article{Kolind2012,
author = {Kolind, J and Hounsgaard, J and Berg, R W},
doi = {10.3389/fncom.2012.00040},
journal = {Front. Comput. Neurosci.},
keywords = {balanced,excitation,fluctuations,inhibition,intrinsic properties,ne,network,shunting},
number = {July},
pages = {1--16},
title = {{Opposing Effects of Intrinsic Conductance and Correlated Synaptic Input on V-Fluctuations during Network Activity}},
volume = {6},
year = {2012}
}
@article{Frieden1989a,
abstract = {Itis shown that the assumption that nature acts to makeoptimum estimates of position maximally in error leads to theSchr{\"{o}}dinger (energy) wave equation (SWE). In this way, the SWEfollows from a simple statement of uncertainty. The approach growsout of probability estimation theory, in particular the principle ofminimum Fisher information (or maximum Cramer–Rao bound). The minimized Fisherinformation turns out to be proportional to the mean kineticenergy of the particle. This approach is an attractive supplementto conventional ways of introducing quantum mechanics to students, sinceit avoids the use of imperfect physical models (such asvibrating strings) or the immediate need for complex momentum operators,and follows from a plausible assumption as to how natureworks. {\textcopyright}1989 American Association of Physics Teachers},
author = {Frieden, B R},
journal = {American Journal of Physics},
keywords = {PROBABILITY,QUANTUM MECHANICS,SCHROEDINGER EQUATION,UNCERTAINTY PRINCIPLE},
month = {nov},
number = {11},
pages = {1004--1008},
publisher = {AAPT},
shorttitle = {Am. J. Phys.},
title = {{Fisher information as the basis for the Schrodinger wave equation}},
url = {http://link.aip.org/link/?AJP/57/1004/1},
volume = {57},
year = {1989}
}
@article{Shuai2006,
abstract = {Through computational modeling we predict that small sodium ion channel clusters on small patches of membrane can encode electric signals most efficiently at certain magic cluster sizes. We show that this effect can be traced back to algebraic features of small integers and are universal for channels with a simple gating dynamics. We further explore physiologic conditions under which such effects can occur.},
annote = {2009num34},
author = {Shuai, J W and Jung, P},
doi = {10.1063/1.2210827},
issn = {1054-1500},
journal = {Chaos (Woodbury, N.Y.)},
keywords = {Animals,Cell Membrane,Cell Membrane: physiology,Cluster Analysis,Computer Simulation,Humans,Ion Channel Gating,Ion Channel Gating: physiology,Kinetics,Membrane Potentials,Membrane Potentials: physiology,Models,Neurological,Nonlinear Dynamics,Sodium,Sodium Channels,Sodium Channels: physiology,Sodium: metabolism},
number = {2},
pages = {26104},
pmid = {16822036},
title = {{The dynamics of small excitable ion channel clusters.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16822036},
volume = {16},
year = {2006}
}
@article{EK86,
author = {Ermentrout, G and Kopell, N},
journal = {SIAM Journal on Applied Math},
pages = {233--253},
title = {{Parabolic bursting in an excitable system coupled with a slow oscillation}},
volume = {2},
year = {1986}
}
@article{Ikegaya06,
author = {Sasaki, Takuya and Kimura, Rie and Tsukamoto, Masako and Matsuki, Norio and Ikegaya, Yuji},
journal = {J Physiol},
month = {jul},
number = {Pt 1},
pages = {195--208},
title = {{Integrative spike dynamics of rat CA1 neurons: a multineuronal imaging study}},
volume = {574},
year = {2006}
}
@article{NT00,
author = {Nykamp, D Q and Tranchina, D},
journal = {Journal of Computational Neuroscience},
pages = {19--50},
title = {{A population density approach that facilitates large-scale modeling of neural networks: analysis and an application to orientation tuning}},
volume = {8},
year = {2000}
}
@article{kobayashi2009made,
annote = {2009num55},
author = {Kobayashi, R and Tsubo, Y and Shinomoto, S},
publisher = {Frontiers Research Foundation},
title = {{Made-to-order spiking neuron model equipped with a multi-timescale adaptive threshold}},
year = {2009}
}
@article{ValeSanes02,
abstract = {The consequences of deafness on the central auditory nervous system

have been examined at many levels, from molecular to functional.

However, there has never been a direct and selective measurement

of excitatory synaptic function following total hearing loss. In

the present study, gerbils were deafened at postnatal day 9, an age

at which there is no deafferentation-induced cell death of ventral

cochlear nucleus neurons. One to five days after bilateral cochlear

ablation, the amplitude of evoked excitatory postsynaptic currents

(EPSC) was measured with whole-cell voltage-clamp recordings in an

inferior colliculus (IC) brain slice preparation in response to electrical

stimulation of the ipsilateral lateral lemniscus (LL) or the commissure

of the inferior colliculus (CIC). Deafness resulted in larger LL-

and CIC-evoked EPSC amplitudes and durations. This result was observed

at a depolarized holding potential. In addition, deafness caused

a decrease in excitatory neurotransmitter release at the LL pathway,

as assessed with a paired-pulse stimulation protocol. In contrast

to its effect on excitatory synapses, bilateral cochlear ablation

reduced inhibitory synaptic strength in IC neurons. The effects included

a postsynaptic decrease in IPSC conductance, a 25-mV depolarization

in the IPSC equilibrium potential and a decrease of neurotransmitter

release. Thus normal innervation differentially affects excitatory

and inhibitory synaptic strength in IC neurons, and these changes

may contribute to alterations in auditory coding properties following

sensory deprivation.},
author = {Vale, Carmen and Sanes, Dan H},
journal = {European Journal of Neuroscience},
keywords = {Animals; Animals,N-Methyl-D-Aspartate; Research Support,Newborn; Auditory Pathways; Cochlea; Deafness; El,P.H.S.; Synapses; Synaptic Transmission,U.S. Gov't},
month = {dec},
number = {12},
pages = {2394--2404},
pmid = {12492434},
title = {{The effect of bilateral deafness on excitatory and inhibitory synaptic strength in the inferior colliculus.}},
volume = {16},
year = {2002}
}
@article{KLEIN2000,
author = {KLEIN, JC VON VAUPEL},
journal = {CRUSTACEANA-INTERNATIONAL JOURNAL {\ldots}},
title = {{LS Liebovitch, 1998. Fractals and chaos-simplified for the life sciences}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Liebovitch+-+Fractals+And+Chaos+Simplified+For+The+Life+Sciences{\#}0},
year = {2000}
}
@article{Pershin,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.3053v1},
author = {Pershin, YV and Ventra, Massimiliano Di},
eprint = {arXiv:1011.3053v1},
journal = {Advances in Physics},
keywords = {capacitance,dynamical systems,inductance,memory,nanostructures,resistance},
pages = {1--59},
title = {{Memory effects in complex materials and nanoscale systems}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00018732.2010.544961},
year = {2011}
}
@article{ditlevsen:011907,
author = {Ditlevsen, Susanne and Lansky, Petr},
journal = {Physical Review E (Statistical, Nonlinear, and Soft Matter Physics)},
number = {1},
pages = {11907},
publisher = {APS},
title = {{Estimation of the input parameters in the Ornstein-Uhlenbeck neuronal model}},
url = {http://link.aps.org/abstract/PRE/v71/e011907},
volume = {71},
year = {2005}
}
@article{McLaughlin00,
author = {McLaughlin, D and Shapley, R and Shelley, M and Wielaard, J},
journal = {PNAS},
pages = {8087--8092},
title = {{A Neuronal Network Model of the Macaque Primary Visual Cortex {\{}V1{\}} Orientation Tuning and Dynamics in the Input Layer {\{}4C{\}}}},
volume = {97},
year = {2000}
}
@article{DenkSvoboda97,
author = {Denk, W and Svoboda, K},
journal = {Neuron},
month = {mar},
number = {3},
pages = {351--357},
title = {{Photon upmanship: why multiphoton imaging is more than a gimmick}},
volume = {18},
year = {1997}
}
@article{Rubin03,
author = {Rubin, N},
journal = {Trends in Neuroscience},
pages = {289--291},
title = {{Binocular rivalry and perceptual multi-stability}},
volume = {26},
year = {2003}
}
@article{Hines2008,
abstract = {When a multi-compartment neuron is divided into subtrees such that no subtree has more than two connection points to other subtrees, the subtrees can be on different processors and the entire system remains amenable to direct Gaussian elimination with only a modest increase in complexity. Accuracy is the same as with standard Gaussian elimination on a single processor. It is often feasible to divide a 3-D reconstructed neuron model onto a dozen or so processors and experience almost linear speedup. We have also used the method for purposes of load balance in network simulations when some cells are so large that their individual computation time is much longer than the average processor computation time or when there are many more processors than cells. The method is available in the standard distribution of the NEURON simulation program.},
author = {Hines, Michael L and Markram, H and Sch{\"{u}}rmann, Felix},
doi = {10.1007/s10827-008-0087-5},
isbn = {1082700800875},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Animals,Computer Simulation,Models, Neurological,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology},
month = {dec},
number = {3},
pages = {439--48},
pmid = {18379867},
title = {{Fully implicit parallel simulation of single neurons.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2760991{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {25},
year = {2008}
}
@article{Livni2014,
author = {Livni, Roi and Shalev-Shwartz, S and Shamir, Ohad},
journal = {NIPS},
title = {{On the Computational Efficiency of Training Neural Networks}},
year = {2014}
}
@article{Hekstra2012,
abstract = {Contingency, the persistent influence of past random events, pervades biology. To what extent, then, is each course of ecological or evolutionary dynamics unique, and to what extent are these dynamics subject to a common statistical structure? Addressing this question requires replicate measurements to search for emergent statistical laws. We establish a readily replicated microbial closed ecosystem (CES), sustaining its three species for years. We precisely measure the local population density of each species in many CES replicates, started from the same initial conditions and kept under constant light and temperature. The covariation among replicates of the three species densities acquires a stable structure, which could be decomposed into discrete eigenvectors, or "ecomodes." The largest ecomode dominates population density fluctuations around the replicate-average dynamics. These fluctuations follow simple power laws consistent with a geometric random walk. Thus, variability in ecological dynamics can be studied with CES replicates and described by simple statistical laws.},
author = {Hekstra, Doeke R and Leibler, Stanislas},
doi = {10.1016/j.cell.2012.03.040},
issn = {1097-4172},
journal = {Cell},
month = {may},
number = {5},
pages = {1164--73},
pmid = {22632978},
publisher = {Elsevier Inc.},
title = {{Contingency and statistical laws in replicate microbial closed ecosystems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22632978},
volume = {149},
year = {2012}
}
@article{Xie07,
author = {Xie, Ruili and Gittelman, Joshua X and Pollak, George D},
doi = {10.1523/JNEUROSCI.2865-07.2007},
journal = {J. Neurosci.},
number = {35},
pages = {9469--9481},
title = {{Rethinking Tuning: In Vivo Whole-Cell Recordings of the Inferior Colliculus$\backslash$ in Awake Bats}},
volume = {27},
year = {2007}
}
@article{IchiharaUemura96,
author = {Ichihara, A and Tanaami, T and Isozaki, K and Sugiyama, Y and Kosugi, Y and Mikuriya, K and Abe, M and Uemura, I},
journal = {Bioimages},
number = {2},
pages = {57--62},
title = {{High-speed confocal fluorescence microscopy using a Nipkow scanner with microlenses for 3D-imaging of single fluorescent molecule in real time}},
volume = {4},
year = {1996}
}
@techreport{Averbukh2010,
author = {Averbukh, I and Medan, G},
title = {{EE student project: Examining ionic channel models and their influence on the neuron}},
year = {2010}
}
@article{Rosenbaum2011,
author = {Rosenbaum, Robert and Marpeau, Fabien and Ma, Jianfu and Barua, Aditya and Josi{\'{c}}, Kre{\v{s}}imir},
doi = {10.1007/s00285-011-0451-3},
issn = {0303-6812},
journal = {Journal of Mathematical Biology},
keywords = {2000,correlations,finite volume methods,fokker,integrate-and-fire,mathematics subject classification,planck equation},
month = {jun},
title = {{Finite volume and asymptotic methods for stochastic neuron models with correlated inputs}},
url = {http://www.springerlink.com/index/10.1007/s00285-011-0451-3},
year = {2011}
}
@article{BSW99,
author = {Barron, A and Schervish, M and Wasserman, L},
journal = {Annals of Statistics},
pages = {536--561},
title = {{The consistency of posterior distributions in nonparametric problems}},
volume = {27},
year = {1999}
}
@article{Booth|1996|,
abstract = {The need for very good energy resolution in experiments in particle
and astroparticle physics and the need to detect very small energy
depositions are the major motivations for the development of low-temperature
particle detectors. Because the energy quanta associated with superconductors
and lattice vibrations (phonons) are more than one hundred times
smaller, substantial improvements have been obtained in energy resolution
and in sensitivity over conventional detectors. Furthermore, these
detection schemes permit tailoring of target or absorber materials
to match the physics requirements. In this article, the basic physics
principles behind various methods of detecting excitations induced
by particle interactions in bulk single-crystal materials at low
temperatures are reviewed. We also present an overview of progress
toward implementation of particle physics experiments, such as detection
of low-energy neutrinos, search for dark-matter particles, search
for neutrino-less double beta-decay, and beta- and gamma -ray spectroscopy
and X-ray astronomy using low-temperature detectors.},
annote = {This important review deals with cryogenic particle detectors},
author = {Booth, N E and Cabrera, B and Fiorini, E},
journal = {Annual Review of Nuclear and Particle Science},
keywords = {astrophysics,calorimeters,cryogenic detectors,dark matter,neutrino detectors,nuclear,particle,particle detectors,physics,quantum field theory,scintillators,underground experiments},
pages = {471},
title = {{Low-Temperature Particle Detectors}},
volume = {46}
}
@book{Braitenberg1991,
author = {Braitenberg, V and Sch{\"{u}}z, A},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Anatomy of the cortex: Statistics and geometry.}},
year = {1991}
}
@article{Mao01,
author = {Mao, B and Hamzei-Sichani, F and Aronov, D and Froemke, R and Yuste, R},
journal = {Neuron},
number = {5},
pages = {883--898},
title = {{Dynamics of spontaneous activity in neocortical slices}},
volume = {32},
year = {2001}
}
@book{JNT75,
address = {Oxford},
author = {Jack, J and Noble, D and Tsien, R},
publisher = {Calderon Press},
title = {{Electric Current Flow in Excitable Cells}},
year = {1975}
}
@article{NelsonCarney04,
author = {Nelson, Paul C and Carney, Laurel H},
journal = {Journal of The Acoustical Society Of America},
month = {oct},
number = {4 Pt 1},
pages = {2173--2186},
title = {{A phenomenological model of peripheral and central neural responses to amplitude-modulated tones}},
volume = {116},
year = {2004}
}
@article{Douglas2012,
author = {Douglas, S. M. and Bachelet, I. and Church, G. M.},
doi = {10.1126/science.1214081},
issn = {0036-8075},
journal = {Science},
month = {feb},
number = {6070},
pages = {831--834},
title = {{A Logic-Gated Nanorobot for Targeted Transport of Molecular Payloads}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1214081},
volume = {335},
year = {2012}
}
@article{Xie2016,
abstract = {Neural networks are a powerful class of functions that can be trained with simple gradient descent to achieve state-of-the-art performance on a variety of applications. Despite their practical success, there is a paucity of results that provide theoretical guarantees on why they are so effective. Lying in the center of the problem is the difficulty of analyzing the non-convex objective function with potentially numerous local minima and saddle points. Can neural networks corresponding to the stationary points of the objective function learn the true labeling function? If yes, what are the key factors contributing to such generalization ability? In this paper, we provide answers to these questions by analyzing one-hidden-layer neural networks with ReLU activation, and show that despite the non-convexity, neural networks with diverse units can learn the true function. We bypass the non-convexity issue by directly analyzing the first order condition, and show that the loss is bounded if the smallest singular value of the "extended feature matrix" is large enough. We make novel use of techniques from kernel methods and geometric discrepancy, and identify a new relation linking the smallest singular value to the spectrum of a kernel function associated with the activation function and to the diversity of the units. Our results also suggest a novel regularization function to promote unit diversity for potentially better generalization ability.},
archivePrefix = {arXiv},
arxivId = {1611.03131},
author = {Xie, Bo and Liang, Yingyu and Song, Le},
eprint = {1611.03131},
pages = {1--23},
title = {{Diversity Leads to Generalization in Neural Networks}},
url = {http://arxiv.org/abs/1611.03131},
year = {2016}
}
@article{Richmond2004,
author = {Richmond, Barry and Wiener, Matthew},
doi = {10.1038/nn0204-97},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Brain,Brain: physiology,Humans,Neurons,Neurons: physiology,Neurophysiological,Recruitment,Spike time neural coding},
mendeley-tags = {Spike time neural coding},
month = {feb},
number = {2},
pages = {97--98},
pmid = {14747828},
title = {{Recruitment order: a powerful neural ensemble code.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14747828},
volume = {7},
year = {2004}
}
@article{ReddRyugo00,
abstract = {It is well known that auditory deprivation affects the structure and

function of the central nervous system. Congenital deafness represents

one form of deprivation, and in the adult white cat, it has been

shown to have a clear effect upon the synaptic interface between

endbulbs of Held and spherical bushy cells. It is not known, however,

whether all primary synapses are affected and/or whether they are

affected in the same way and to the same extent. Thus, we studied

a second neuronal circuit in the deaf white cat involving modified

(small) endbulbs and globular bushy cells. Compared to normal hearing

cats, modified endbulbs of congenitally deaf cats were 52.2{\%} smaller

but unchanged in structural complexity. There was also a striking

loss of extracellular space between ending and cell body. The somata

of postsynaptic globular bushy cells were 13.4{\%} smaller and had

enlarged postsynaptic densities. These data reveal that axosomatic

synapses demonstrate abnormal structure as a consequence of deafness

and that the extent of the abnormalities can vary with respect to

the circuits involved. The implication of these observations is that

synaptic anomalies would introduce differential delays within separate

circuits, thereby desynchronizing neural activity from sound stimuli.

This loss of synchronization could in turn disrupt temporal processing

and compromise a host of related functions, including language comprehension.},
author = {Redd, E E and Pongstaporn, T and Ryugo, D K},
journal = {Hearing Research},
keywords = {Animals; Cats; Cochlear Nerve; Cochlear Nucleus; D,Auditory,Brain Stem; Humans; Male; Microscopy,Electron; Research Support,Non-U.S. Gov't; Research Support,P.H.S.; Sensory Deprivation; Speech Perception; S,U.S. Gov't},
month = {sep},
number = {1-2},
pages = {160--174},
pmid = {10962182},
title = {{The effects of congenital deafness on auditory nerve synapses and globular bushy cells in cats.}},
volume = {147},
year = {2000}
}
@article{Huber2012,
abstract = {The mechanisms linking sensation and action during learning are poorly understood. Layer 2/3 neurons in the motor cortex might participate in sensorimotor integration and learning; they receive input from sensory cortex and excite deep layer neurons, which control movement. Here we imaged activity in the same set of layer 2/3 neurons in the motor cortex over weeks, while mice learned to detect objects with their whiskers and report detection with licking. Spatially intermingled neurons represented sensory (touch) and motor behaviours (whisker movements and licking). With learning, the population-level representation of task-related licking strengthened. In trained mice, population-level representations were redundant and stable, despite dynamism of single-neuron representations. The activity of a subpopulation of neurons was consistent with touch driving licking behaviour. Our results suggest that ensembles of motor cortex neurons couple sensory input to multiple, related motor programs during learning.},
author = {Huber, D. and Gutnisky, D. a. and Peron, S. and OConnor, D H and Wiegert, J. S. and Tian, L. and Oertner, T. G. and Looger, L. L. and Svoboda, K. and O'Connor, D. H. and Wiegert, J. S. and Tian, L. and Oertner, T. G. and Looger, L. L. and Svoboda, K.},
doi = {10.1038/nature11039},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
month = {apr},
number = {7395},
pages = {473--478},
pmid = {22538608},
publisher = {Nature Publishing Group},
title = {{Multiple dynamic representations in the motor cortex during sensorimotor learning}},
url = {http://dx.doi.org/10.1038/nature11039 http://www.nature.com/doifinder/10.1038/nature11039},
volume = {484},
year = {2012}
}
@article{SMY03,
author = {Smyth, D and Willmore, B and Baker, G and Thompson, I and Tolhurst, D},
journal = {Journal of Neuroscience},
pages = {4746--4759},
title = {{The receptive-field organization of simple cells in primary visual cortex of ferrets under natural scene stimulation}},
volume = {23},
year = {2003}
}
@article{Grunewald|2003|,
abstract = {Herpes simplex virus, a DNA virus of high complexity, consists of
a nucleocapsid surrounded by the tegument{\^{A}}—a protein compartment{\^{A}}—and
the envelope. The latter components, essential for infectivity, are
pleiomorphic. Visualized in cryo{\^{A}}–electron tomograms of isolated
virions, the tegument was seen to form an asymmetric cap: On one
side, the capsid closely approached the envelope; on the other side,
they were separated by 35 nanometers of tegument. The tegument substructure
was particulate, with some short actin-like filaments. The envelope
contained 600 to 750 glycoprotein spikes that varied in length, spacing,
and in the angles at which they emerge from the membrane. Their distribution
was nonrandom, suggesting functional clustering.},
author = {Grunewald, K and Desai, P and Winkler, D C and Heymann, J Bernard and Belnap, D M and Baumeister, W and Steven, A C},
journal = {Science},
keywords = {computational,electron tomography,image processing,segmentation},
pages = {1396},
title = {{Three-dimensional structrue of herpes simplex virus from cryo-electron tomography}},
volume = {302}
}
@article{VIC06,
author = {Victor, J and Mechler, F and Repucci, M and Purpura, K and Sharpee, T},
journal = {Journal of Neurophysiology},
pages = {379--400},
title = {{Responses of {\{}V1{\}} neurons to two-dimensional Hermite Functions}},
volume = {95},
year = {2006}
}
@article{StemmlerKoch99,
annote = {2009num29},
author = {Stemmler, M and Koch, C},
journal = {Nature Neuroscience},
pages = {521--527},
publisher = {NATURE AMERICA},
title = {{How voltage-dependent conductances can adapt to maximize the information encoded by neuronal firing rate}},
volume = {2},
year = {1999}
}
@article{Soudry2010,
abstract = {Recent experiments have demonstrated that the timescale of adaptation of single neurons and ion channel populations to stimuli slows down as the length of stimulation increases; in fact, no upper bound on temporal time-scales seems to exist in such systems. Furthermore, patch clamp experiments on single ion channels have hinted at the existence of large, mostly unobservable, inactivation state spaces within a single ion channel. This raises the question of the relation between this multitude of inactivation states and the observed behavior. In this work we propose a minimal model for ion channel dynamics which does not assume any specific structure of the inactivation state space. The model is simple enough to render an analytical study possible. This leads to a clear and concise explanation of the experimentally observed exponential history-dependent relaxation in sodium channels in a voltage clamp setting, and shows that their recovery rate from slow inactivation must be voltage dependent. Furthermore, we predict that history-dependent relaxation cannot be created by overly sparse spiking activity. While the model was created with ion channel populations in mind, its simplicity and genericalness render it a good starting point for modeling similar effects in other systems, and for scaling up to higher levels such as single neurons which are also known to exhibit multiple time scales.},
annote = {From Duplicate 2 (History-dependent dynamics in a generic model of ion channels - an analytic study - Soudry, D; Meir, R)

2012num3},
author = {Soudry, D. and Meir, R.},
doi = {10.3389/fncom.2010.00003},
issn = {1662-5188},
journal = {Front. Comput. Neurosci.},
keywords = {History-dependence,Ion channels,Multiple timescales,Non-Markov,Renewal theory,Semi-Markov,Slow inactivation,history dependence,history-dependence,ion channels,multiple timescales,non Markov,non-markov,renewal,renewal theory,semi Markov,semi-markov,slow inactivation},
month = {jan},
number = {3},
pages = {1--10},
pmid = {20725633},
title = {{History-dependent dynamics in a generic model of ion channels - an analytic study}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2916672{\&}tool=pmcentrez{\&}rendertype=abstract www.frontiersin.org/neuroscience/computationalneuroscience/paper/10.3389/fncom.2010.00003 http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2916672/},
volume = {4},
year = {2010}
}
@article{Jolivet2004,
abstract = {We demonstrate that single-variable integrate-and-fire models can quantitatively capture the dynamics of a physiologically detailed model for fast-spiking cortical neurons. Through a systematic set of approximations, we reduce the conductance-based model to 2 variants of integrate-and-fire models. In the first variant (nonlinear integrate-and-fire model), parameters depend on the instantaneous membrane potential, whereas in the second variant, they depend on the time elapsed since the last spike [Spike Response Model (SRM)]. The direct reduction links features of the simple models to biophysical features of the full conductance-based model. To quantitatively test the predictive power of the SRM and of the nonlinear integrate-and-fire model, we compare spike trains in the simple models to those in the full conductance-based model when the models are subjected to identical randomly fluctuating input. For random current input, the simple models reproduce 70-80 percent of the spikes in the full model (with temporal precision of +/-2 ms) over a wide range of firing frequencies. For random conductance injection, up to 73 percent of spikes are coincident. We also present a technique for numerically optimizing parameters in the SRM and the nonlinear integrate-and-fire model based on spike trains in the full conductance-based model. This technique can be used to tune simple models to reproduce spike trains of real neurons.},
author = {Jolivet, Renaud and Lewis, Timothy J and Gerstner, W},
doi = {10.1152/jn.00190.2004},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Differential Threshold,Electric Conductivity,Electric Stimulation,Humans,Membrane Potentials,Models, Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Presynaptic Terminals,Presynaptic Terminals: physiology,Stochastic Processes,Time Factors},
month = {aug},
number = {2},
pages = {959--76},
pmid = {15277599},
title = {{Generalized integrate-and-fire models of neuronal activity approximate spike trains of a detailed model to a high degree of accuracy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15277599},
volume = {92},
year = {2004}
}
@inproceedings{Bhaskara2013,
abstract = {Low rank tensor decompositions are a powerful tool for learning generative models, and uniqueness results give them a significant advantage over matrix decomposition methods. However, tensors pose significant algorithmic challenges and tensors analogs of much of the matrix algebra toolkit are unlikely to exist because of hardness results. Efficient decomposition in the overcomplete case (where rank exceeds dimension) is particularly challenging. We introduce a smoothed analysis model for studying these questions and develop an efficient algorithm for tensor decomposition in the highly overcomplete case (rank polynomial in the dimension). In this setting, we show that our algorithm is robust to inverse polynomial error -- a crucial property for applications in learning since we are only allowed a polynomial number of samples. While algorithms are known for exact tensor decomposition in some overcomplete settings, our main contribution is in analyzing their stability in the framework of smoothed analysis. Our main technical contribution is to show that tensor products of perturbed vectors are linearly independent in a robust sense (i.e. the associated matrix has singular values that are at least an inverse polynomial). This key result paves the way for applying tensor methods to learning problems in the smoothed setting. In particular, we use it to obtain results for learning multi-view models and mixtures of axis-aligned Gaussians where there are many more "components" than dimensions. The assumption here is that the model is not adversarially chosen, formalized by a perturbation of model parameters. We believe this an appealing way to analyze realistic instances of learning problems, since this framework allows us to overcome many of the usual limitations of using tensor methods.},
archivePrefix = {arXiv},
arxivId = {1311.3651},
author = {Bhaskara, Aditya and Charikar, Moses and Moitra, Ankur and Vijayaraghavan, Aravindan},
booktitle = {Proceedings of the 46th Annual ACM Symposium on Theory of Computing.},
doi = {10.1145/2591796.2591881},
eprint = {1311.3651},
isbn = {1450327109},
issn = {07378017},
pages = {594--603},
title = {{Smoothed Analysis of Tensor Decompositions}},
url = {http://arxiv.org/abs/1311.3651},
year = {2014}
}
@article{AFG91,
author = {Abbott, L F and Farhi, E and Gutmann, S},
journal = {Biological Cybernetics},
pages = {49--60},
title = {{The path integral for dendritic trees}},
volume = {66},
year = {1991}
}
@article{Bell|1995|,
abstract = {We derive a new self-organising learning algorithm which maximises
the information transferred in a network of non-linear units. The
algorithm does not assume any knowledge of the input distributions,
and is defined here for the zero-noise limit. Under these conditions,
information maximisation has extra properties not found in the linear
case (Linsker 1989). The non-linearities in the transfer function
are able to pick up higher-order moments of the input distributions
and perform something akin to true redundancy reduction between units
in the output representation. This enables the network to separate
statistically independent components in the inputs: a higher-order
generalisation of Principal Components Analysis. We apply the network
to the source separation (or cocktail party) problem, successfully
separating unknown mixtures of up to ten speakers. We also show that
a variant on the network architecture is able to perform blind deconvolution
(cancellation of unknown echoes and reverberation in a speech signal).
Finally, we derive dependencies of information transfer on time delays.
We suggest that information maximisation provides a unifying framework
for problems in 'blind' signal processing.},
author = {Bell, A J and Sejnowski, T J},
journal = {Neural Computation},
keywords = {cluster,cocktail party,deconvolution,electroencyphalogram,information,mathematics,neurobiology,primary components analysis,source separation},
number = {6},
pages = {1004},
title = {{An information-maximisation approach to blind separation and blind deconvolution}},
volume = {7}
}
@article{Carroll2001,
author = {Carroll, Reed C and Beattie, Eric C and Zastrow, Mark Von and Malenka, Robert C and Einstein, Albert},
number = {May},
title = {{ROLE OF AMPA RECEPTOR}},
volume = {2},
year = {2001}
}
@article{Bradley08,
author = {Bradley, David C and Goyal, Manu S},
journal = {Nature Reviews Neuroscience},
pages = {686--695},
title = {{Velocity computation in the primate visual system}},
volume = {9},
year = {2008}
}
@article{Wandelt|2000|a,
abstract = {Spergel and Steinhardt have recently proposed the concept of dark
matter with strong self-interactions as a means to address numerous
discrepancies between observations of dark matter halos on subgalactic
scales and the predictions of the standard collisionless dark matter
picture. We review the motivations for this scenario and discuss
some recent, successful numerical tests. We also discuss the possibility
that the dark matter interacts strongly with ordinary baryonic matter,
as well as with itself. We present a new analysis of the experimental
constraints and re-evaluate the allowed range of cross-section and
mass.},
annote = {This is a good review of the status of SIDM for 2000.},
author = {Wandelt, B D and Dave, R and Farrar, C R and McGuire, P C and Spergel, D N and Steinhardt, P J},
journal = {arXiv},
keywords = {astrophysics,dark matter,experimental contraints,halo,interaction,physics,strongly interacting dark matter},
pages = {6344},
title = {{Self-Interacting Dark Matter}},
volume = {astro-ph}
}
@article{Elul1966,
author = {Elul, R and Adey, W R},
journal = {Nature},
keywords = {threshold},
month = {dec},
number = {5069},
pages = {1424--1425},
title = {{Instability of firing threshold and "remote" activation in cortical neurons}},
volume = {212},
year = {1966}
}
@article{Vidne2012,
author = {Vidne, Michael and Ahmadian, Y and Shlens, J and Pillow, J W and Kulkarni, J and Litke, A M and Chichilnisky, E J and Simoncelli, E and Paninski, L},
doi = {10.1007/s10827-011-0376-2.Modeling},
journal = {Journal of Computational Neuroscience},
month = {aug},
number = {1},
pages = {97--121},
publisher = {Springer Netherlands},
title = {{Modeling the impact of common noise inputs on the network activity of retinal ganglion cells}},
url = {http://link.springer.com/article/10.1007/s10827-011-0376-2},
volume = {33},
year = {2012}
}
@article{Paninski03,
author = {Paninski, Liam},
journal = {Network},
month = {aug},
number = {3},
pages = {437--464},
title = {{Convergence properties of three spike-triggered analysis techniques}},
volume = {14},
year = {2003}
}
@article{Scheper1999,
abstract = {A mathematical model for the intracellular circadian rhythm generator has been studied, based on a negative feedback of protein products on the transcription rate of their genes. The study is an attempt at examining minimal but biologically realistic requirements for a negative molecular feedback loop involving considerably faster reactions, to produce (slow) circadian oscillations. The model included mRNA and protein production and degradation, along with a negative feedback of the proteins upon mRNA production. The protein production process was described solely by its total duration and a nonlinear term, whereas also the feedback included nonlinear interactions among protein molecules. This system was found to produce robust oscillations in protein and mRNA levels over a wide range of parameter values. Oscillations were slow, with periods much longer than the time constants of any of the individual system parameters. Circadian oscillations were obtained for realistic values of the parameters. The system was readily entrainable to external periodic perturbations. Two distinct classes of phase response curves were found, viz. with or without a time domain within the circadian cycle in which external perturbations fail to induce a phase shift ("dead zone"). The delay and nonlinearity in the protein production and the cooperativity in the negative feedback (Hill coefficient) were for this model found to be necessary and sufficient to generate robust circadian oscillations. The similarities between model outcomes and empirical findings establish that circadian rhythmicity at the cellular level can plausibly emerge from interactions among molecular systems which are not in themselves rhythmic.},
author = {Scheper, T and Klinkenberg, D and Pennartz, C and van Pelt, J},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {Biological,Biological Transport,Circadian Rhytems,Circadian Rhythm,Circadian Rhythm: physiology,Feedback,Mathematics,Models,Nonlinear Dynamics,Oscillometry,Post-Translational,Protein Biosynthesis,Protein Processing},
mendeley-tags = {Circadian Rhytems},
month = {jan},
number = {1},
pages = {40--7},
pmid = {9870936},
title = {{A mathematical model for the intracellular circadian rhythm generator.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9870936},
volume = {19},
year = {1999}
}
@book{Billingsley1995,
author = {Billingsley, Patrick},
isbn = {0471007102},
publisher = {Wiley-Interscience; 3 edition},
title = {{Probability and Measure, 3rd Edition}},
url = {http://www.amazon.com/Probability-Measure-3rd-Patrick-Billingsley/dp/0471007102},
year = {1995}
}
@phdthesis{Keshner1979,
author = {Keshner, M S},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
title = {{Renewal process and diffusion models of 1/f noise}},
url = {http://en.scientificcommons.org/7795839},
year = {1979}
}
@article{Valiant2012,
author = {Valiant, Paul},
journal = {Proceedings of the 3rd Innovations in Theoretical {\ldots}},
pages = {1--14},
title = {{Distribution free evolvability of polynomial functions over all convex loss functions}},
url = {http://dl.acm.org/citation.cfm?id=2090248},
year = {2012}
}
@article{Renart2007,
abstract = {Spike trains from cortical neurons show a high degree of irregularity, with coefficients of variation (CV) of their interspike interval (ISI) distribution close to or higher than one. It has been suggested that this irregularity might be a reflection of a particular dynamical state of the local cortical circuit in which excitation and inhibition balance each other. In this "balanced" state, the mean current to the neurons is below threshold, and firing is driven by current fluctuations, resulting in irregular Poisson-like spike trains. Recent data show that the degree of irregularity in neuronal spike trains recorded during the delay period of working memory experiments is the same for both low-activity states of a few Hz and for elevated, persistent activity states of a few tens of Hz. Since the difference between these persistent activity states cannot be due to external factors coming from sensory inputs, this suggests that the underlying network dynamics might support coexisting balanced states at different firing rates. We use mean field techniques to study the possible existence of multiple balanced steady states in recurrent networks of current-based leaky integrate-and-fire (LIF) neurons. To assess the degree of balance of a steady state, we extend existing mean-field theories so that not only the firing rate, but also the coefficient of variation of the interspike interval distribution of the neurons, are determined self-consistently. Depending on the connectivity parameters of the network, we find bistable solutions of different types. If the local recurrent connectivity is mainly excitatory, the two stable steady states differ mainly in the mean current to the neurons. In this case, the mean drive in the elevated persistent activity state is suprathreshold and typically characterized by low spiking irregularity. If the local recurrent excitatory and inhibitory drives are both large and nearly balanced, or even dominated by inhibition, two stable states coexist, both with subthreshold current drive. In this case, the spiking variability in both the resting state and the mnemonic persistent state is large, but the balance condition implies parameter fine-tuning. Since the degree of required fine-tuning increases with network size and, on the other hand, the size of the fluctuations in the afferent current to the cells increases for small networks, overall we find that fluctuation-driven persistent activity in the very simplified type of models we analyze is not a robust phenomenon. Possible implications of considering more realistic models are discussed.},
author = {Renart, Alfonso and Moreno-Bote, Rub{\'{e}}n and Wang, Xiao-Jing and Parga, N{\'{e}}stor},
doi = {10.1162/neco.2007.19.1.1},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Afferent Pathways,Afferent Pathways: physiology,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Homeostasis,Humans,Memory,Memory: physiology,Nerve Net,Nerve Net: physiology,Neural Inhibition,Neural Inhibition: physiology,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Reaction Time},
month = {jan},
number = {1},
pages = {1--46},
pmid = {17134316},
title = {{Mean-driven and fluctuation-driven persistent activity in recurrent networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17134316},
volume = {19},
year = {2007}
}
@article{YU03,
author = {Yu, Y and Lee, T},
journal = {Physical Review E},
pages = {11901},
title = {{Dynamical mechanisms underlying contrast gain control in single neurons}},
volume = {68},
year = {2003}
}
@misc{Harris|2007|a,
annote = {This is a piece from Kristen Harris{\&}{\#}039;s grant proposal describing different{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}aspects of applications of electron microscopy in neuroscience, such{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}as dependence of structural plasticity in dendrites on their caliber,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}on fraction of surrounding axons, distance-dependent difference [aka{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}from soma] in dendrite structure and connectivity.},
author = {Harris, K M},
keywords = {automatic,electron microscopy,neurobiology,neurons,reconstruction},
title = {{Grant Proposal 2007}}
}
@article{HolmesMeddis04,
annote = {Comment},
author = {Holmes, Stephen D and Sumner, Christian J and O'Mard, Lowel P and Meddis, Ray},
journal = {Journal of The Acoustical Society Of America},
month = {dec},
number = {6},
pages = {3534--3545},
title = {{The temporal representation of speech in a nonlinear model of the guinea pig cochlea}},
volume = {116},
year = {2004}
}
@article{TKGA99,
author = {Tsodyks, M and Kenet, T and Grinvald, A and Arieli, A},
journal = {Science},
pages = {1943--1946},
title = {{Linking Spontaneous Activity of Single Cortical Neurons and the Underlying Functional Architecture}},
volume = {286},
year = {1999}
}
@article{Silver2010,
abstract = {The vast computational power of the brain has traditionally been viewed as arising from the complex connectivity of neural networks, in which an individual neuron acts as a simple linear summation and thresholding device. However, recent studies show that individual neurons utilize a wealth of nonlinear mechanisms to transform synaptic input into output firing. These mechanisms can arise from synaptic plasticity, synaptic noise, and somatic and dendritic conductances. This tool kit of nonlinear mechanisms confers considerable computational power on both morphologically simple and more complex neurons, enabling them to perform a range of arithmetic operations on signals encoded in a variety of different ways.},
annote = {2010IInum12.41},
author = {Silver, R A},
doi = {10.1038/nrn2864},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
keywords = {Neuron Model},
mendeley-tags = {Neuron Model},
month = {jun},
number = {July},
pages = {474--489},
pmid = {20531421},
title = {{Neuronal arithmetic}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20531421 http://www.nature.com/nrn/journal/vaop/ncurrent/full/nrn2864.html},
volume = {11},
year = {2010}
}
@article{RinbergGroisman05,
author = {Rinberg, D and Simonnet, C and Groisman, A},
journal = {Applied Physics Letters},
pages = {14103},
publisher = {AIP},
title = {{Pneumatic capillary gun for ballistic delivery of microparticles}},
volume = {87},
year = {2005}
}
@inproceedings{Stocker04b,
address = {Cambridge, MA},
author = {Stocker, A and Simoncelli, E P},
booktitle = {Adv. Neural Information Processing Systems (NIPS*04)},
editor = {Saul, Lawrence K and Weiss, Yair and Bottou, L{\'{e}}on},
publisher = {MIT Press},
title = {{Constraining a {\{}Bayesian{\}} model of human visual speed perception}},
volume = {17},
year = {2005}
}
@article{JLG03,
author = {Jolivet, R and Lewis, T and Gerstner, W},
journal = {Springer Lecture notes in computer science},
pages = {846--853},
title = {{The Spike Response Model: a Framework to Predict Neuronal Spike Trains}},
volume = {2714},
year = {2003}
}
@article{Knight2000,
abstract = {The response of a noninteracting population of identical neurons to a step change in steady synaptic input can be analytically calculated exactly from the dynamical equation that describes the population's evolution in time. Here, for model integrate-and-fire neurons that undergo a fixed finite upward shift in voltage in response to each synaptic event, we compare the theoretical prediction with the result of a direct simulation of 90,000 model neurons. The degree of agreement supports the applicability of the population dynamics equation. The theoretical prediction is in the form of a series. Convergence is rapid, so that the full result is well approximated by a few terms.},
author = {Knight, B W and Omurtag, a and Sirovich, L},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Models, Neurological,Neurons,Neurons: physiology,Population Dynamics,Synapses,Synapses: physiology},
month = {may},
number = {5},
pages = {1045--55},
pmid = {10905807},
title = {{The approach of a neuron population firing rate to a new equilibrium: an exact theoretical result.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10905807},
volume = {12},
year = {2000}
}
@article{Moran1979,
author = {Moran, P. A. P.},
journal = {Biometrika},
number = {1},
pages = {158--162},
title = {{The closest pair of N random points on the surface of a sphere‏}},
volume = {66},
year = {1979}
}
@article{Sutton2009,
author = {Sutton, RS and Maei, HR and Precup, Doina},
journal = {{\ldots} on Machine Learning},
title = {{Fast gradient-descent methods for temporal-difference learning with linear function approximation}},
url = {http://dl.acm.org/citation.cfm?id=1553501},
year = {2009}
}
@article{Jansons|1998|,
abstract = {For the dynamic pitchfork bifurcation in the presence of white noise,
the statistics of the last time at zero are calculated as a function
of the noise level, epsilon, and the rate of change of the parameter,
mu. The threshold crossing problem used, for example, to model the
firing of a single cortical neuron is considered, concentrating on
quantities that may be experimentally measurable but have so far
received little attention. Expressions for the statistics of the
pre-threshold excursions, occupation density and last crossing time
of zero are compared with results from numerical generation of paths.},
annote = {The paper reviews conceptuals of stochastic calculus and, specifically,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}considers problem of threshold crossing in pitchfork bifurcation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}in the presence of noise. Delay of the threshold crossing in the{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}presence of noise, particularly, is demonstrated.},
author = {Jansons, K M and Lythe, G D},
journal = {Journal of statistical physics},
keywords = {applied probability,dynamic bifyrcation,excursions,local time,mathematics,neurobiology,neuron dynamics,neuron firing,noise,pitchfork bifurcation,spike trains,stochastic calculus,threshold crossing},
pages = {227},
title = {{Stochastic calculus: application to dynamic bifurcation and threshold crossings}},
volume = {90}
}
@article{Markram1996,
author = {Markram, H and Tsodyks, M},
journal = {Nature},
title = {{Redistribution of synaptic efficacy between neocortical pyramidal neurons}},
url = {http://itb.biologie.hu-berlin.de/{~}kempter/HippoJC/Articles/markram96.pdf},
year = {1996}
}
@article{Baker|2005|,
author = {Baker, B J and Kosmidis, E K and Vucinic, D and Falk, C X and Cohen, L B and Djurisic, M and Zecevic, D},
journal = {Cellular and Molecular Neurobiology},
number = {2},
pages = {245--282},
title = {{Imaging brain activity with voltage- and calcium-sensitive dyes.}},
volume = {25}
}
@article{Lazar2004,
author = {Lazar, A A},
journal = {Neurocomputing},
number = {October 2003},
pages = {1--6},
title = {{Time encoding with an integrate-and-fire neuron with a refractory period}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231204000177},
year = {2004}
}
@article{Houston|1995|,
abstract = {A mass-independent, 3{\%} enrichment of heavy ozone isotopes in the stratosphere
can be assigned to a mechanism in which 1) short-wavelength photodissociation
of ozone produces O2(v{\^{A}}³26) + O, 2) the O2(v{\^{A}}³26) reacts with ground-state
O2 to produce O3 + O, and 3) each O atom recombines with O2 to form
O3. The overall reaction scheme, O3 + hn + 3O2 {\^{A}}{\textregistered} 3O3, produces more
ozone than it consumes. The dissociation channel which begins this
scheme is more probable for heavy ozone than for 48O3 and one of
the oxygen atoms in the original O3 is encorporated into a new O3.
Thus, this new ozone source tends to "distill" heavy oxygen atoms
into the O3 pool while depleting them from the O2 pool. The amount
of enrichment produced by this mechanism, while significant, is still
too small to account for the large observed stratospheric enrichment
of heavy ozone.},
annote = {The paper deals with mechanism for heavy ozone enrichment in the{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}upper layers of the stratosphere},
author = {Houston, P L and Suits, A G and Toumi, R},
journal = {Journal of Geophysical Research},
keywords = {geophysics,isotope,isotopic enrichment,ozone layer,physics},
title = {{Isotopic enrichment of heavy ozone in the stratosphere}}
}
@article{Sayer1990,
author = {Sayer, R J and Friedlander, M J and Redman, S J},
journal = {J. Neurosci.},
pages = {826--836},
title = {{The time course and amplitude of EPSPs evoked at synapses between pairs of {\{}CA3/CA1{\}} neurons in the hippocampal slice}},
volume = {10},
year = {1990}
}
@book{ShumwayStoffer06,
author = {Shumway, R and Stoffer, D},
publisher = {Springer},
title = {{Time Series Analysis and Its Applications}},
year = {2006}
}
@article{Valiant|1984|,
abstract = {Humans appear to be able to learn new concepts without needing to
be programmed explicitly in any conventional sense. In this paper
we regard learning as the phenomenon of knowledge acquisition in
the absence of explicit programming. We give a precise methodology
for studying this phenomenon from a computational viewpoint. It consists
of choosing an appropriate information gathering mechanism, the learning
protocol, and exploring the class of concepts that can be learned
using it in a reasonable (polynomial) number of steps. Although inherent
algorithmic complexity appears to set serious limits to the range
of concepts that can be learned, we show that there are some important
nontrivial classes of propositional concepts that can be learned
in a realistic sense.},
annote = {The paper considers learning boolean functions of finite number of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}variable. Essentially works by postulating that random sample from{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}the set of variables would identify with high probability the variables{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}on which boolean function depends.},
author = {Valiant, L G},
journal = {ACM Transactions on Programming Language and Systems},
keywords = {computational,formal language,learning,mathematics},
number = {11},
pages = {1134},
title = {{A theory of learnable}},
volume = {27}
}
@article{YaksiFriedrich07,
abstract = {Odors are initially represented in the olfactory bulb (OB) by patterns

of sensory input across the array of glomeruli. Although activated

glomeruli are often widely distributed, glomeruli responding to stimuli

sharing molecular features tend to be loosely clustered and thus

establish a fractured chemotopic map. Neuronal circuits in the OB

transform glomerular patterns of sensory input into spatiotemporal

patterns of output activity and thereby extract information about

a stimulus. It is, however, unknown whether the chemotopic spatial

organization of glomerular inputs is maintained during these computations.

To explore this issue, we measured spatiotemporal patterns of odor-evoked

activity across thousands of individual neurons in the zebrafish

OB by temporally deconvolved two-photon {\{}Ca{\}}{\^{}}{\{}2+{\}} imaging. Mitral

cells and interneurons were distinguished by transgenic markers and

exhibited different response selectivities. Shortly after response

onset, activity patterns exhibited foci of activity associated with

certain chemical features throughout all layers. During the subsequent

few hundred milliseconds, however, MC activity was locally sparsened

within the initial foci in an odor-specific manner. As a consequence,

chemotopic maps disappeared and activity patterns became more informative

about precise odor identity. Hence, chemotopic maps of glomerular

input activity are initially transmitted to OB outputs, but not maintained

during pattern processing. Nevertheless, transient chemotopic maps

may support neuronal computations by establishing important synaptic

interactions within the circuit. These results provide insights into

the functional topology of neural activity patterns and its potential

role in circuit function.},
author = {Yaksi, Emre and Judkewitz, Benjamin and Friedrich, Rainer W},
doi = {10.1371/journal.pbio.0050178},
journal = {PLoS Biol},
month = {jul},
number = {7},
pages = {e178},
pmid = {17608564},
title = {{Topological Reorganization of Odor Representations in the Olfactory Bulb.}},
url = {http://dx.doi.org/10.1371/journal.pbio.0050178},
volume = {5},
year = {2007}
}
@article{DufourMcCarthy06,
author = {Dufour, P and Pich{\'{e}}, M and {De Koninck}, Y and McCarthy, N},
journal = {Applied Optics},
number = {36},
pages = {9246--9252},
publisher = {OSA},
title = {{Two-photon excitation fluorescence microscopy with a high depth of field using an axicon}},
volume = {45},
year = {2006}
}
@article{kamioka1996spontaneous,
author = {Kamioka, H and Maeda, E and Jimbo, Y and Robinson, H P C and Kawana, A},
journal = {Neuroscience Letters},
keywords = {networks},
mendeley-tags = {networks},
number = {2-3},
pages = {109--112},
publisher = {Elsevier},
title = {{Spontaneous periodic synchronized bursting during formation of mature patterns of connections in cortical cultures}},
volume = {206},
year = {1996}
}
@article{NiellSmith05,
author = {Niell, Cristopher M and Smith, Stephen J},
doi = {10.1016/j.neuron.2005.01.047},
journal = {Neuron},
keywords = {Animals; Calcium Signaling; Cell Differentiation;,Fluorescence; Photic Stimulation; Retinal Ganglio},
month = {mar},
number = {6},
pages = {941--951},
pmid = {15797554},
title = {{Functional imaging reveals rapid development of visual response properties in the zebrafish tectum.}},
url = {http://dx.doi.org/10.1016/j.neuron.2005.01.047},
volume = {45},
year = {2005}
}
@article{Lee|2006|,
abstract = {We study the statistical properties of the sampled scale-free networks,
deeply related to the proper identification of various real-world
networks. We exploit three methods of sampling and investigate the
topological properties such as degree and betweenness centrality
distribution, average path length, assortativity, and clustering
coefficient of sampled networks compared with those of original networks.
It is found that the quantities related to those properties in sampled
networks appear to be estimated quite differently for each sampling
method.We explain why such a biased estimation of quantities would
emerge from the sampling procedure and give appropriate criteria
for each sampling method to prevent the quantities from being overestimated
or underestimated.},
annote = {The paper studies on few examples statistical biases in estimated{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}various network parameters via sampling. Considered are degree exponent,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}degree distribution, betweeness, assortativity, clustering coefficient.},
author = {Lee, S H and Kim, P.-J. and Jeong, H},
journal = {Physical review E},
keywords = {mathematics,networks,physics,sampling,statistical},
pages = {16102},
title = {{Statistical properties of sampled networks}},
volume = {73}
}
@article{SuzukiBrown05,
author = {Suzuki, Wendy A and Brown, Emery N},
journal = {Behav Cogn Neurosci Rev},
number = {2},
pages = {67--95},
title = {{Behavioral and Neurophysiological Analyses of Dynamic Learning Processes}},
volume = {4},
year = {2005}
}
@article{Grewe2010,
abstract = {Two-photon calcium imaging of neuronal populations enables optical recording of spiking activity in living animals, but standard laser scanners are too slow to accurately determine spike times. Here we report in vivo imaging in mouse neocortex with greatly improved temporal resolution using random-access scanning with acousto-optic deflectors. We obtained fluorescence measurements from 34-91 layer 2/3 neurons at a 180-490 Hz sampling rate. We detected single action potential-evoked calcium transients with signal-to-noise ratios of 2-5 and determined spike times with near-millisecond precision and 5-15 ms confidence intervals. An automated 'peeling' algorithm enabled reconstruction of complex spike trains from fluorescence traces up to 20-30 Hz frequency, uncovering spatiotemporal trial-to-trial variability of sensory responses in barrel cortex and visual cortex. By revealing spike sequences in neuronal populations on a fast time scale, high-speed calcium imaging will facilitate optical studies of information processing in brain microcircuits.},
author = {Grewe, Benjamin F and Langer, Dominik and Kasper, Hansj{\"{o}}rg and Kampa, Bj{\"{o}}rn M and Helmchen, Fritjof},
doi = {10.1038/nmeth.1453},
issn = {1548-7105},
journal = {Nature methods},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Calcium Signaling,Calcium Signaling: physiology,Evoked Potentials,Evoked Potentials: physiology,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Mice,Microscopy, Confocal,Microscopy, Confocal: methods,Microscopy, Fluorescence,Neocortex,Neocortex: physiology,Neurons,Neurons: physiology,Visual Cortex,Visual Cortex: physiology},
month = {may},
number = {5},
pages = {399--405},
pmid = {20400966},
title = {{High-speed in vivo calcium imaging reveals neuronal network activity with near-millisecond precision.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20400966},
volume = {7},
year = {2010}
}
@article{Cox55,
author = {Cox, D},
journal = {Journal of the Royal Statistical Society, Series B},
pages = {129--164},
title = {{Some statistical methods connected with series of events}},
volume = {17},
year = {1955}
}
@article{Brainard08,
author = {Brainard, D and Williams, D and Hofer, H},
journal = {Vision Research},
pages = {1--23},
title = {{Trichromatic Reconstruction from the Interleaved Cone Mosaic: {\{}B{\}}ayesian Model and The Color Appearance Of Small Spots}},
volume = {8},
year = {2008}
}
@article{Knopfel06,
author = {Knopfel, T and Diez-Garcia, J and Akemann, W},
journal = {Trends in Neurosciences},
pages = {160--166},
title = {{Optical probing of neuronal circuit dynamics: genetically encoded versus classical fluorescent sensors}},
volume = {29},
year = {2006}
}
@article{OertnerSvoboda02,
abstract = {Many synapses can change their strength rapidly in a use-dependent

manner, but the mechanisms of such short-term plasticity remain unknown.

To understand these mechanisms, measurements of neurotransmitter

release at single synapses are required. We probed transmitter release

by imaging transient increases in [{\{}Ca{\}}{\^{}}{\{}2+{\}}] mediated by synaptic

N-methyl-D-aspartate receptors (NMDARs) in individual dendritic spines

of CA1 pyramidal neurons in rat brain slices, enabling quantal analysis

at single synapses. We found that changes in release probability,

produced by paired-pulse facilitation (PPF) or by manipulation of

presynaptic adenosine receptors, were associated with changes in

glutamate concentration in the synaptic cleft, indicating that single

synapses can release a variable amount of glutamate per action potential.

The relationship between release probability and response size is

consistent with a binomial model of vesicle release with several

({\textgreater}5) independent release sites per active zone, suggesting that multivesicular

release contributes to facilitation at these synapses.},
author = {Oertner, Thomas G and Sabatini, Bernardo L and Nimchinsky, Esther A and Svoboda, Karel},
doi = {10.1038/nn867},
journal = {Nat Neurosci},
keywords = {2-Chloroadenosine; Action Potentials; Animals; Cal,N-Methyl-D-Aspartate; Receptors,Purinergic P1; Sensory Thresholds; Synapses},
month = {jul},
number = {7},
pages = {657--664},
pmid = {12055631},
title = {{Facilitation at single synapses probed with optical quantal analysis.}},
url = {http://dx.doi.org/10.1038/nn867},
volume = {5},
year = {2002}
}
@phdthesis{Maleki2010,
author = {Maleki, MA},
number = {November},
title = {{Approximate message passing algorithms for compressed sensing}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=9qNJqlWxpEgC{\&}oi=fnd{\&}pg=PR5{\&}dq=APPROXIMATE+MESSAGE+PASSING+ALGORITHMS+FOR+COMPRESSED+SENSING{\&}ots=2T9u3{\_}ObBX{\&}sig=yNYUAMLUy1MeTqwwTu1mPvhRUno http://books.google.com/books?hl=en{\&}lr={\&}id=9qNJqlWxpEgC{\&}oi=fnd{\&}pg=PR5{\&}dq=APPROXIMATE+MESSAGE+PASSING+ALGORITHMS+FOR+COMPRESSED+SENSING{\&}ots=2T8w6-RduX{\&}sig=Cq0yHpGGAyGsiWVYH0IXW6nGJNU},
year = {2010}
}
@article{Kellyetal07,
author = {Kelly, R and Smith, M and Samonds, J and Kohn, A and {Bonds A.B. Movshon}, J A and Lee, T S},
journal = {Journal of Neuroscience},
pages = {261--264},
title = {{Comparison of Recordings from Microelectrode Arrays and Single Electrodes in the Visual Cortex}},
volume = {27},
year = {2007}
}
@article{GelmanMeng98,
author = {Gelman, A and Meng, X},
journal = {Statistical Science},
pages = {163--185},
title = {{Simulating normalizing constants: From importance sampling to bridge sampling to path sampling}},
volume = {13},
year = {1998}
}
@article{Wu2017a,
abstract = {It is widely observed that deep learning models with learned parameters generalize well, even with much more model parameters than the number of training samples. We systematically investigate the underlying reasons why deep neural networks often generalize well, and reveal the difference between the minima (with the same training error) that generalize well and those they don't. We show that it is the characteristics the landscape of the loss function that explains the good generalization capability. For the landscape of loss function for deep networks, the volume of basin of attraction of good minima dominates over that of poor minima, which guarantees optimization methods with random initialization to converge to good minima. We theoretically justify our findings through analyzing 2-layer neural networks; and show that the low-complexity solutions have a small norm of Hessian matrix with respect to model parameters. For deeper networks, extensive numerical evidence helps to support our arguments.},
archivePrefix = {arXiv},
arxivId = {1706.10239},
author = {Wu, Lei and Zhu, Zhanxing and E, Weinan},
eprint = {1706.10239},
file = {:C$\backslash$:/Users/Daniel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Zhu, E - 2017 - Towards Understanding Generalization of Deep Learning Perspective of Loss Landscapes(3).pdf:pdf},
journal = {arXiv},
month = {jun},
title = {{Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes}},
url = {http://arxiv.org/abs/1706.10239},
year = {2017}
}
@article{Pajevic2009,
abstract = {Cascading activity is commonly found in complex systems with directed interactions such as metabolic networks, neuronal networks, or disease spreading in social networks. Substantial insight into a system's organization can be obtained by reconstructing the underlying functional network architecture from the observed activity cascades. Here we focus on Bayesian approaches and reduce their computational demands by introducing the Iterative Bayesian (IB) and Posterior Weighted Averaging (PWA) methods. We introduce a special case of PWA, cast in nonparametric form, which we call the normalized count (NC) algorithm. NC efficiently reconstructs random and small-world functional network topologies and architectures from subcritical, critical, and supercritical cascading dynamics and yields significant improvements over commonly used correlation methods. With experimental data, NC identified a functional and structural small-world topology and its corresponding traffic in cortical networks with neuronal avalanche dynamics.},
annote = {2011num36},
author = {Pajevic, Sinisa and Plenz, D},
doi = {10.1371/journal.pcbi.1000271},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {Algorithms,Animals,Bayes Theorem,Cerebral Cortex,Cerebral Cortex: physiology,Computational Biology,Computational Biology: methods,Models, Neurological,Models, Statistical,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Rats,Statistics, Nonparametric},
month = {jan},
number = {1},
pages = {e1000271},
pmid = {19180180},
title = {{Efficient network reconstruction from dynamical cascades identifies small-world topology of neuronal avalanches.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2615076{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@article{Farrar|1998|,
abstract = {I summarize recent devlopments in supersynnnetry scenarios which leave
some or all gauginos light. emphasis is on experimental and phenomenological
progress in the past year.},
author = {Farrar, G R},
journal = {Nuclear Physics B},
keywords = {gaugino,physics,quantum field theory,susy},
pages = {485},
title = {{Status of Light Gaugino Scenarios}},
volume = {62A-C}
}
@article{TAL95,
author = {Talagrand, M},
journal = {Publ. Math. IHES},
pages = {73--205},
title = {{Concentration of measure and isoperimetric inequalities in product spaces}},
volume = {81},
year = {1995}
}
@article{PAN05f,
author = {Paninski, L},
journal = {Neural Computation},
pages = {2592--2616},
title = {{The spike-triggered average of the integrate-and-fire cell driven by {\{}G{\}}aussian white noise}},
volume = {18},
year = {2006}
}
@article{PGM67,
author = {Perkel, D and Gerstein, G and Moore, G},
journal = {Biophysical Journal},
pages = {391--440},
title = {{Neuronal spike trains and stochastic point processes}},
volume = {7},
year = {1967}
}
@misc{Durand|2006|,
annote = {This powerpoing presentation deals with nonlinear filter implementing{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}idea of "grayscale-distance" based separation inside a filtering{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}kernel. Also describes other image processing techniques, very useful{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}general presentation on image processing and nonlinear gaussian filtering.},
author = {Durand, F and Dorsey, J},
keywords = {computational,edge-detection,edge-preserving,image processing,nonlinear filters},
title = {{Fast bilateral filtering for the display of high-dynamic-range images}}
}
@article{Taillefumier2012,
author = {Taillefumier, T and Touboul, J},
journal = {Neural Computation},
title = {{Exact Event-Driven Implementation for Recurrent Networks of Stochastic Perfect Integrate-and-Fire Neurons}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/NECO{\_}a{\_}00346},
year = {2012}
}
@article{Hafting05,
author = {Hafting, T and Fyhn, M and Molden, S and Moser, M and Moser, E},
journal = {Nature},
pages = {801--806},
title = {{Microstructure of a spatial map in the entorhinal cortex}},
volume = {436},
year = {2005}
}
@incollection{Ryugo92,
author = {Ryugo, D K},
booktitle = {The Mammalian Auditory Pathway: Neuroanatomy. New York: Springer-Verlag},
pages = {23--65},
title = {{The auditory nerve: peripheral innervation, cell body morphology, and central projections}},
year = {1992}
}
@article{Frieden1990,
author = {Frieden, B R},
journal = {Physical Review A},
title = {fisher information, disorder and the equilibrium distributions of physics},
url = {http://link.aps.org/doi/10.1103/PhysRevA.41.4265},
year = {1990}
}
@misc{DavidMac,
author = {MacKay, D J C},
title = {{Course Notes: Bayesian Methods for Neural Networks: Theory and Applications}}
}
@misc{MNIST,
title = {http://yann.lecun.com/exdb/mnist/}
}
@article{Rickgauer2014,
author = {Rickgauer, John Peter and Deisseroth, Karl and Tank, David W},
doi = {10.1038/nn.3866},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {nov},
number = {12},
pages = {1816--1824},
publisher = {Nature Publishing Group},
title = {{Simultaneous cellular-resolution optical perturbation and imaging of place cell firing fields}},
url = {http://www.nature.com/doifinder/10.1038/nn.3866},
volume = {17},
year = {2014}
}
@article{RBB95,
author = {Rieke, F and Bodnar, D and Bialek, W},
journal = {Proc. R. Soc. Lond. B},
pages = {259--265},
title = {{Naturalistic stimuli increase the rate and efficiency of information transmission by primary auditory afferents}},
volume = {262},
year = {1995}
}
@article{Senn2005,
author = {Senn, W and Fusi, S},
doi = {10.1103/PhysRevE.71.061907},
issn = {1539-3755},
journal = {Physical Review E},
number = {6},
pages = {061907},
title = {{Convergence of stochastic learning in perceptrons with binary synapses}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.71.061907},
volume = {71},
year = {2005}
}
@article{clyde96equivalence,
author = {Clyde, Merlise and Chaloner, Kathryn},
journal = {Journal of the American Statistical Association},
number = {435},
pages = {1236--1244},
title = {{The Equivalence of Constrained and Weighted Designs in Multiple Objective Design Problems}},
url = {citeseer.nj.nec.com/clyde96equivalence.html},
volume = {91},
year = {1996}
}
@misc{BlueBrainProject,
title = {http://bluebrain.epfl.ch/}
}
@article{Binzegger04,
author = {Binzegger, Tom and Douglas, Rodney J and Martin, Kevan A C},
journal = {J. Neurosci.},
number = {39},
pages = {8441--8453},
title = {{A Quantitative Map of the Circuit of Cat Primary Visual Cortex}},
volume = {24},
year = {2004}
}
@article{Choromanska2014,
abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large- and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.},
archivePrefix = {arXiv},
arxivId = {1412.0233},
author = {Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\'{e}}rard Ben and LeCun, Y},
eprint = {1412.0233},
journal = {AISTATS15},
title = {{The Loss Surfaces of Multilayer Networks}},
url = {http://arxiv.org/abs/1412.0233{\%}5Cnhttp://www.arxiv.org/pdf/1412.0233.pdf},
volume = {38},
year = {2015}
}
@article{Eytan:2003le,
abstract = {A key property of neural systems is their ability to adapt selectively to stimuli with different features. Using multisite electrical recordings from networks of cortical neurons developing ex vivo, we show that neurons adapt selectively to different stimuli invading the network. We focus on selective adaptation to frequent and rare stimuli; networks were stimulated at two sites with two different stimulus frequencies. When both stimuli were presented within the same period, neurons in the network attenuated their responsiveness to the more frequent input, whereas their responsiveness to the rarely delivered stimuli showed a marked average increase. The amplification of the response to rare stimuli required the presence of the other, more frequent stimulation source. By contrast, the decreased response to the frequent stimuli occurred regardless of the presence of the rare stimuli. Analysis of the response of single units suggests that both of these effects are caused by changes in synaptic transmission. By using synaptic blockers, we find that the increased responsiveness to the rarely stimulated site depends specifically on fast GABAergic transmission. Thus, excitatory synaptic depression, the inhibitory sub-network, and their balance play an active role in generating selective gain control. The observation that selective adaptation arises naturally in a network of cortical neurons developing ex vivo indicates that this is an inherent feature of spontaneously organizing cortical networks.},
annote = {2008num7},
author = {Eytan, D and Brenner, N and Marom, S},
journal = {Journal of Neuroscience},
keywords = {Action Potentials/physiology Adaptation,Cultured Cerebral Cortex/cytology/*physiology Ele,Newborn Cells,Non-P.H.S. Synaptic Transmission/physiology gamma,Non-U.S. Gov't Research Support,Physiological/*physiology Animals Animals,U.S. Gov't,networks},
mendeley-tags = {networks},
number = {28},
pages = {9349--9356},
title = {{Selective adaptation in networks of cortical neurons}},
volume = {23},
year = {2003}
}
@article{Deolalikar2001,
abstract = {In this paper, the ability of a binary neural-network comprising only neurons with zero thresholds and binary weights to map given samples of a Boolean function is studied. A mathematical model describing a network with such restrictions is developed. It is shown that this model is quite amenable to algebraic manipulation. A key feature of the model is that it replaces the two input and output variables with a single "normalized" variable. The model is then used to provide a priori criteria, stated in terms of the new variable, that a given Boolean function must satisfy in order to be mapped by a network having one or two layers. These criteria provide necessary, and in the case of a one-layer network, sufficient conditions for samples of a Boolean function to be mapped by a binary neural network with zero thresholds. It is shown that the necessary conditions imposed by the two-layer network are, in some sense, minimal.},
author = {Deolalikar, V},
doi = {10.1109/72.925568},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
month = {jan},
number = {3},
pages = {639--42},
pmid = {18249898},
title = {{Mapping Boolean functions with neural networks having binary weights and zero thresholds.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18249898},
volume = {12},
year = {2001}
}
@article{BlackstadMugnaini84,
author = {Blackstad, T W and Osen, K K and Mugnaini, E},
journal = {Neuroscience},
number = {3},
pages = {827--854},
title = {{Pyramidal neurones of the dorsal cochlear nucleus: a Golgi and computer reconstruction study in cat}},
volume = {13},
year = {1984}
}
@article{Ratcliff03,
author = {Ratcliff, R and Cherian, A and Segraves, M},
journal = {Journal of Neurophysiology},
pages = {1392--1407},
title = {{A comparison of macaque behaviorand superior colliculus neuronal activity to predictions from models of two-choice decisions}},
volume = {90},
year = {2003}
}
@article{Chiel2009,
abstract = {Although it is widely recognized that adaptive behavior emerges from the ongoing interactions among the nervous system, the body, and the environment, it has only become possible in recent years to experimentally study and to simulate these interacting systems. We briefly review work on molluscan feeding, maintenance of postural control in cats and humans, simulations of locomotion in lamprey, insect, cat and salamander, and active vibrissal sensing in rats to illustrate the insights that can be derived from studies of neural control and sensing within a biomechanical context. These studies illustrate that control may be shared between the nervous system and the periphery, that neural activity organizes degrees of freedom into biomechanically meaningful subsets, that mechanics alone may play crucial roles in enforcing gait patterns, and that mechanics of sensors is crucial for their function.},
author = {Chiel, Hillel J and Ting, Lena H and Ekeberg, Orjan and Hartmann, Mitra J Z},
doi = {10.1523/JNEUROSCI.3338-09.2009},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Biological,Biomechanics,Brain,Brain: physiology,Computer Simulation,Environment,Humans,Models,Movement,Movement: physiology,Muscle Contraction,Muscle Contraction: physiology,Nonlinear Dynamics,Postural Balance,Sensation,Sensation: physiology,motor control},
mendeley-tags = {motor control},
month = {oct},
number = {41},
pages = {12807--12814},
pmid = {19828793},
title = {{The brain in its body: motor control and sensing in a biomechanical context.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2794418{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {29},
year = {2009}
}
@book{Landau1981,
address = {Oxford},
author = {Landau, L. D. and Lifshitz, L. M.},
edition = {3},
isbn = {0750635398},
publisher = {Butterworth-Heinemann},
title = {{Quantum Mechanics Non-Relativistic Theory, Third Edition: Volume 3}},
url = {http://www.amazon.com/Quantum-Mechanics-Non-Relativistic-Theory-Third/dp/0750635398},
year = {1981}
}
@article{Galli|1996|,
abstract = {We present a new Monte Carlo algorithm for simulating quantum spin
systems which is able to suppress the negative sign problem. This
algorithm has only a linear complexity in the lattice size used for
the simulation. A general description and a rigorous proof of its
correctness is given. Its efficiency is tested on a simple 2-dimensional
fermionic model. For this model we show that our algorithm eliminates
the sign problem.},
annote = {This is somewhat mathematically overloaded paper about elimination{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of the fermion sign problem from quantum monte carlo.},
author = {Galli, A},
journal = {arXiv},
keywords = {fermionic systems,physics,quantum monte carlo,sign problem,unread},
pages = {9605026},
title = {{Suppression of the negative sign problem in quantum monte carlo}},
volume = {hep-lat}
}
@article{Mo2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.02735v1},
author = {Mo, Jianhua and Member, Student and Schniter, Philip},
eprint = {arXiv:1610.02735v1},
journal = {Arxiv},
pages = {1--13},
title = {{Channel Estimation in Broadband Millimeter Wave MIMO Systems with Few-Bit ADCs}},
year = {2017}
}
@article{Kirov|2004|,
author = {Kirov, S A and Petrak, L J and Fiala, J C and Harris, K M},
journal = {Neuroscience},
keywords = {Animals Calcium/deficiency Cell Size/physiology Ce,Electron Neuronal Plasticity/*physiology Sucrose/,Transgenic Microscopy},
number = {1},
pages = {69--80},
title = {{Dendritic spines disappear with chilling but proliferate excessively upon rewarming of mature hippocampus}},
volume = {127}
}
@article{salman1997voltage,
annote = {2008num6},
author = {Salman, H and Braun, E},
journal = {Physical Review E},
number = {1},
pages = {852--864},
publisher = {APS},
title = {{Voltage dynamics of single-type voltage-gated ion-channel protein ensembles}},
volume = {56},
year = {1997}
}
@article{Lecoq2014,
abstract = {Fluorescence Ca(2+) imaging enables large-scale recordings of neural activity, but collective dynamics across mammalian brain regions are generally inaccessible within single fields of view. Here we introduce a two-photon microscope possessing two articulated arms that can simultaneously image two brain areas (∼0.38 mm(2) each), either nearby or distal, using microendoscopes. Concurrent Ca(2+) imaging of ∼100-300 neurons in primary visual cortex (V1) and lateromedial (LM) visual area in behaving mice revealed that the variability in LM neurons' visual responses was strongly dependent on that in V1, suggesting that fluctuations in sensory responses propagate through extended cortical networks.},
author = {Lecoq, J{\'{e}}r{\^{o}}me and Savall, Joan and Vu{\v{c}}ini{\'{c}}, Dejan and Grewe, Benjamin F and Kim, Hyun and Li, Jin Zhong and Kitch, Lacey J and Schnitzer, Mark J},
doi = {10.1038/nn.3867},
journal = {Nature neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Calcium,Calcium: metabolism,Female,Male,Mice,Mice, 129 Strain,Mice, Inbred C57BL,Microscopy, Fluorescence, Multiphoton,Microscopy, Fluorescence, Multiphoton: methods,Photic Stimulation,Photic Stimulation: methods,Visual Cortex,Visual Cortex: chemistry,Visual Cortex: physiology,Visual Pathways,Visual Pathways: chemistry,Visual Pathways: physiology},
month = {nov},
number = {12},
pages = {1825--1829},
pmid = {25402858},
title = {{Visualizing mammalian brain area interactions by dual-axis two-photon calcium imaging.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25402858},
volume = {17},
year = {2014}
}
@article{SF06,
author = {Skaug, H and Fournier, D},
journal = {Computational Statistics and Data Analysis},
pages = {699--709},
title = {{Automatic approximation of the marginal likelihood in non-Gaussian hierarchical models}},
volume = {51},
year = {2006}
}
@article{Raichle2010,
abstract = {Traditionally studies of brain function have focused on task-evoked responses. By their very nature, such experiments tacitly encourage a reflexive view of brain function. Although such an approach has been remarkably productive, it ignores the alternative possibility that brain functions are mainly intrinsic, involving information processing for interpreting, responding to and predicting environmental demands. Here I argue that the latter view best captures the essence of brain function, a position that accords well with the allocation of the brain's energy resources. Recognizing the importance of intrinsic activity will require integrating knowledge from cognitive and systems neuroscience with cellular and molecular neuroscience where ion channels, receptors, components of signal transduction and metabolic pathways are all in a constant state of flux.},
annote = {2010IInum12.29},
author = {Raichle, Marcus E},
doi = {10.1016/j.tics.2010.01.008},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
month = {apr},
number = {4},
pages = {180--190},
pmid = {20206576},
publisher = {Elsevier Ltd},
title = {{Two views of brain function.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20206576},
volume = {14},
year = {2010}
}
@article{Documents2010,
author = {Documents, Sharing},
number = {October},
title = {{Getting started with Mendeley}},
year = {2010}
}
@article{MayVetter02,
author = {May, Bradford J and Prosen, Cynthia A and Weiss, Donna and Vetter, Douglas},
journal = {Hearing Research},
month = {sep},
number = {1-2},
pages = {142--157},
title = {{Behavioral investigation of some possible effects of the central olivocochlear pathways in transgenic mice}},
volume = {171},
year = {2002}
}
@phdthesis{Wainrib2011a,
author = {Wainrib, G},
booktitle = {Convergence},
title = {{Randomness in neurons : a multiscale probabilistic analysis}},
year = {2011}
}
@article{Jelenkovic1999,
author = {Jelenkovic, P R and Lazar, A A},
journal = {Advances in Applied Probability},
keywords = {distributions,er type conditions,fluid flow queue,g,long-range dependency,long-tailed,m,network multiplexer,non-cram,subexponential distributions},
number = {2},
pages = {394--421},
publisher = {Applied Probability Trust},
title = {{Asymptotic results for multiplexing subexponential on-off processes}},
url = {http://www.jstor.org/stable/1428116},
volume = {31},
year = {1999}
}
@article{BurianGstoettner88,
author = {Burian, M and Gstoettner, W},
journal = {Neuroscience Letters},
month = {jan},
number = {1},
pages = {13--17},
title = {{Projection of primary vestibular afferent fibres to the cochlear nucleus in the guinea pig}},
volume = {84},
year = {1988}
}
@article{Lamport|1982|,
abstract = {Reliable computer systems must handle malfunctioning components that
give conflicting information to different parts of the system. This
situation can be expressed abstractly in terms of a group of generals
of the Byzantine army camped with their troops around an enemy city.
Communicating only by messenger, the generals must agree upon a common
battle plan. However, one or more of them may be traitors who will
try to confuse the others. The problem is to find an algorithm to
ensure that the loyal generals will reach agreement. It is shown
that, using only oral messages, this problem is solvable if and only
if more than two-thurds of the generals are loyal; so a single traitor
can confound two loyal generals. With unforgeable written messages,
the problem is solvable for any number of generals and possible traitors.
Applications of the solutions to reliable computer systems are then
discussed.},
author = {Lamport, L and Shostak, R and Pease, M},
journal = {ACM Transactions on Programming Language and Systems},
keywords = {computational,consensus,disruption,interactive consistency,mathematics,network communication,reliability},
number = {3},
pages = {382},
title = {{The Byzantine Generals Problem}},
volume = {4}
}
@article{Fologea2011,
abstract = {Lysenin, a 297 amino acid pore-forming protein extracted from the coelomic fluid of the earthworm E. foetida, inserts constitutively open large conductance channels in natural and artificial lipid membranes containing sphingomyelin. The inserted channels show voltage regulation and slowly close at positive applied voltages. We report on the consequences of slow voltage-induced gating of lysenin channels inserted into a planar Bilayer Lipid Membrane (BLM), and demonstrate that these pore-forming proteins constitute memory elements that manifest gating bi-stability in response to variable external voltages. The hysteresis in macroscopic currents dynamically changes when the time scale of the voltage variation is smaller or comparable to the characteristic conformational equilibration time, and unexpectedly persists for extremely slow-changing external voltage stimuli. The assay performed on a single lysenin channel reveals that hysteresis is a fundamental feature of the individual channel unit and an intrinsic component of the gating mechanism. The investigation conducted at different temperatures reveals a thermally stable reopening process, suggesting that major changes in the energy landscape and kinetics diagram accompany the conformational transitions of the channels. Our work offers new insights on the dynamics of pore-forming proteins and provides an understanding of how channel proteins may form an immediate record of the molecular history which then determines their future response to various stimuli. Such new functionalities may uncover a link between molecular events and macroscopic processing and transmission of information in cells, and may lead to applications such as high density biologically-compatible memories and learning networks.},
author = {Fologea, Daniel and Krueger, Eric and Mazur, Yuriy I and Stith, Christine and Okuyama, Yui and Henry, Ralph and Salamo, Greg J},
doi = {10.1016/j.bbamem.2011.09.005},
issn = {0006-3002},
journal = {Biochimica et biophysica acta},
keywords = {Ion Channel Gating,Probability,Toxins, Biological,Toxins, Biological: chemistry},
month = {dec},
number = {12},
pages = {2933--9},
pmid = {21945404},
publisher = {Elsevier B.V.},
title = {{Bi-stability, hysteresis, and memory of voltage-gated lysenin channels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21945404},
volume = {1808},
year = {2011}
}
@article{Kivinen1997,
author = {Kivinen, J},
doi = {10.1006/inco.1996.2612},
issn = {08905401},
journal = {Information and Computation},
month = {jan},
number = {1},
pages = {1--63},
title = {{Exponentiated Gradient versus Gradient Descent for Linear Predictors}},
url = {http://linkinghub.elsevier.com/retrieve/doi/10.1006/inco.1996.2612},
volume = {132},
year = {1997}
}
@article{Gal2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1301.7747v1},
author = {Gal, A and Marom, S},
eprint = {arXiv:1301.7747v1},
journal = {The Journal of Neuroscience},
number = {18},
pages = {7912--7918},
title = {{Entrainment of the intrinsic dynamics of single isolated neurons by natural-like input}},
url = {http://arxiv.org/abs/1301.7747 http://www.jneurosci.org/content/33/18/7912.short},
volume = {33},
year = {2013}
}
@article{Adams14,
author = {Linderman, Scott and Adams, Ryan},
journal = {Arxiv},
title = {{Discovering Latent Network Structure in Point Process Data}},
volume = {1402.0914},
year = {2014}
}
@book{schuster1988,
author = {Schuster, H G and Just, W},
edition = {4th},
isbn = {9783527404155},
publisher = {Wiley},
title = {{Deterministic Chaos: An Introduction}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09500348814551201},
year = {2005}
}
@article{Dresbach|2006|,
author = {Dresbach, T and Torres, V and Wittenmayer, N and Altrock, W D and Zamorano, P and Zuschratter, W and Nawrotzki, R and Ziv, N E and Garner, C C and Gunderlfinger, E D},
journal = {J Biol Chem},
number = {9},
pages = {6038--6047},
title = {{Assembly of active zone precursor vesicles: obligatory trafficking of presynaptic cytomatrix proteins Bassoon and Piccolo via a trans-Golgi compartment.}},
volume = {281}
}
@article{Rodolfo1988,
author = {Rodolfo, R},
title = {{The Intrinsic Electrophysiological Properties of Mammalian Neurons : Insights ...}},
year = {1988}
}
@article{Agu01,
author = {y Arcas, B and Fairhall, A and Bialek, W},
journal = {NIPS},
pages = {75--81},
title = {{What can a single neuron compute?}},
volume = {13},
year = {2001}
}
@article{bel2005weak,
annote = {2009num57},
author = {Bel, G and Barkai, E},
journal = {Physical Review Letters},
number = {24},
pages = {240602},
publisher = {APS},
title = {{Weak ergodicity breaking in the continuous-time random walk}},
volume = {94},
year = {2005}
}
@article{MusicantHind90,
author = {Musicant, A D and Chan, J C and Hind, J E},
journal = {Journal of The Acoustical Society Of America},
month = {feb},
number = {2},
pages = {757--781},
title = {{Direction-dependent spectral properties of cat external ear: new data and cross-species comparisons}},
volume = {87},
year = {1990}
}
@article{CoxGriffith01,
author = {Cox, S and Griffith, B},
journal = {Journal of Computational Neuroscience},
pages = {95--110},
title = {{Recovering Quasi-Active properties of dendrites from dual potential recordings}},
volume = {11},
year = {2001}
}
@article{Blondel2000,
author = {Blondel, Vincent D and Tsitsiklis, John N},
keywords = {control,discrete-event systems,discrete-time systems,hybrid systems,markov decision processes,mathematical systems theory,networks,neural,nonlinear systems,time-varying systems,turing machines},
title = {{A survey of computational complexity results in systems and control}},
volume = {36},
year = {2000}
}
@article{Chen|2005|,
author = {Chen, X and Vinade, L and Leapman, R D and Petersen, J D and Nakagawa, T and Phillips, T M and Sheng, M and Reese, T S},
journal = {PNAS},
pages = {11551--6.},
title = {{Mass of the postsynaptic density and enumeration of three key molecules.}},
volume = {102}
}
@article{Cepero2012,
author = {Cepero, E and Evan, G and Solimini, N L and Elledge, S J and Mitsiades, C and Hideshima, T and Anderson, K C and Evan, G I and Nass, S J and Dickson, R B and Trock, B J and Olopade, O I and Jang, J W and Sintasath, L and Chodosh, L A and Claassen, G F and Hann, S R and Cole, M D and Wang, Y and Nasoff, M and Deveraux, Q L and Quon, K C},
number = {January},
pages = {353--356},
title = {{References and Notes 1.}},
volume = {335},
year = {2012}
}
@misc{Paninski2007,
annote = {2011num49},
author = {Paninski, L},
booktitle = {Neuroscience},
pages = {1--35},
publisher = {Citeseer},
title = {{Statistical analysis of neural data: Generalized linear models for spike trains}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.6241{\&}rep=rep1{\&}type=pdf},
year = {2007}
}
@article{LW04,
author = {Ledoit, O and Wolf, M},
journal = {Journal of Portfolio Management},
pages = {110--119},
title = {{Honey, I shrunk the sample covariance matrix}},
volume = {30},
year = {2004}
}
@article{Daniely2016,
abstract = {We develop a general duality between neural networks and compositional kernels, striving towards a better understanding of deep learning. We show that initial representations generated by common random initializations are sufficiently rich to express all functions in the dual kernel space. Hence, though the training objective is hard to optimize in the worst case, the initial weights form a good starting point for optimization. Our dual view also reveals a pragmatic and aesthetic perspective of neural networks and underscores their expressive power.},
archivePrefix = {arXiv},
arxivId = {1602.05897},
author = {Daniely, Amit and Frostig, Roy and Singer, Yoram},
eprint = {1602.05897},
file = {::},
journal = {ArXiv:1602.05897},
month = {feb},
title = {{Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity}},
url = {http://arxiv.org/abs/1602.05897},
year = {2016}
}
@article{Lecun1998,
abstract = {Multilayer neural networks trained with the back-propagation$\backslash$nalgorithm constitute the best example of a successful gradient based$\backslash$nlearning technique. Given an appropriate network architecture,$\backslash$ngradient-based learning algorithms can be used to synthesize a complex$\backslash$ndecision surface that can classify high-dimensional patterns, such as$\backslash$nhandwritten characters, with minimal preprocessing. This paper reviews$\backslash$nvarious methods applied to handwritten character recognition and$\backslash$ncompares them on a standard handwritten digit recognition task.$\backslash$nConvolutional neural networks, which are specifically designed to deal$\backslash$nwith the variability of 2D shapes, are shown to outperform all other$\backslash$ntechniques. Real-life document recognition systems are composed of$\backslash$nmultiple modules including field extraction, segmentation recognition,$\backslash$nand language modeling. A new learning paradigm, called graph transformer$\backslash$nnetworks (GTN), allows such multimodule systems to be trained globally$\backslash$nusing gradient-based methods so as to minimize an overall performance$\backslash$nmeasure. Two systems for online handwriting recognition are described.$\backslash$nExperiments demonstrate the advantage of global training, and the$\backslash$nflexibility of graph transformer networks. A graph transformer network$\backslash$nfor reading a bank cheque is also described. It uses convolutional$\backslash$nneural network character recognizers combined with global training$\backslash$ntechniques to provide record accuracy on business and personal cheques.$\backslash$nIt is deployed commercially and reads several million cheques per day$\backslash$n},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {LeCun, Y and Bottou, L and Bengio, Y and Haffner, P},
doi = {10.1109/5.726791},
eprint = {1102.0183},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Convolutional neural networks,Document recognition,Finite state transducers,Gradient-based learning,Graph transformer networks,Machine learning,Neural networks,Optical character recognition (OCR)},
number = {11},
pages = {2278--2323},
pmid = {15823584},
title = {{Gradient-based learning applied to document recognition}},
volume = {86},
year = {1998}
}
@article{BrechtOsten04,
author = {Brecht, Michael and Fee, Michale S and Garaschuk, Olga and Helmchen, Fritjof and Margrie, Troy W and Svoboda, Karel and Osten, Pavel},
doi = {10.1523/JNEUROSCI.3344-04.2004},
journal = {Journal of Neuroscience},
keywords = {Animals; Electrophysiology; Genetic Techniques; Mi,Physiologic; Neurons; Neurosciences},
month = {oct},
number = {42},
pages = {9223--9227},
pmid = {15496655},
title = {{Novel approaches to monitor and manipulate single neurons in vivo.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.3344-04.2004},
volume = {24},
year = {2004}
}
@inproceedings{Zhang,
author = {Zhang, Tong},
booktitle = {NIPS},
title = {{Adaptive forward-backward greedy algorithm for sparse learning with linear models}},
url = {http://papers.nips.cc/paper/3586-adaptive-forward-backward-greedy-algorithm-for-sparse-learning-with-linear-models},
year = {2009}
}
@article{PhysRevE.69.021104,
annote = {2009num27},
author = {Goychuk, Igor and H{\"{a}}nggi, P.},
doi = {10.1103/PhysRevE.69.021104},
journal = {Physical Review B},
number = {2},
pages = {21104},
publisher = {American Physical Society},
title = {{Theory of non-Markovian stochastic resonance}},
volume = {69},
year = {2004}
}
@article{Urquijo2000,
author = {Gomez-Urquijo, S M and Reblet, C and Bueno-Lopez, J L and Gutierrez-Ibarluzea, I},
journal = {Brain Res},
pages = {171--179},
title = {{GABAergic neurons in the rabbit visual cortex: percentage, distribution and cortical projections}},
volume = {862},
year = {2000}
}
@article{Staub1997,
abstract = {The epithelial Na+ channel (ENaC), composed of three subunits (alpha beta gamma), plays a critical role in salt and fluid homeostasis. Abnormalities in channel opening and numbers have been linked to several genetic disorders, including cystic fibrosis, pseudohypoaldosteronism type I and Liddle syndrome. We have recently identified the ubiquitin-protein ligase Nedd4 as an interacting protein of ENaC. Here we show that ENaC is a short-lived protein (t1/2 approximately 1 h) that is ubiquitinated in vivo on the alpha and gamma (but not beta) subunits. Mutation of a cluster of Lys residues (to Arg) at the N-terminus of gamma ENaC leads to both inhibition of ubiquitination and increased channel activity, an effect augmented by N-terminal Lys to Arg mutations in alpha ENaC, but not in beta ENaC. This elevated channel activity is caused by an increase in the number of channels present at the plasma membrane; it represents increases in both cell-surface retention or recycling of ENaC and incorporation of new channels at the plasma membrane, as determined by Brefeldin A treatment. In addition, we find that the rapid turnover of the total pool of cellular ENaC is attenuated by inhibitors of both the proteasome and the lysosomal/endosomal degradation systems, and propose that whereas the unassembled subunits are degraded by the proteasome, the assembled alpha beta gamma ENaC complex is targeted for lysosomal degradation. Our results suggest that ENaC function is regulated by ubiquitination, and propose a paradigm for ubiquitination-mediated regulation of ion channels.},
author = {Staub, O and Gautschi, I and Ishikawa, T and Breitschopf, K and Ciechanover, A and Schild, L and Rotin, D},
doi = {10.1093/emboj/16.21.6325},
issn = {0261-4189},
journal = {The EMBO Journal},
keywords = {Acetylcysteine,Acetylcysteine: analogs {\&} derivatives,Acetylcysteine: pharmacology,Amino Acid Sequence,Animals,Biomolecular,Brefeldin A,Calcium-Binding Proteins,Calcium-Binding Proteins: metabolism,Cell Line,Chloroquine,Chloroquine: pharmacology,Cyclopentanes,Cyclopentanes: pharmacology,Cysteine Endopeptidases,Cysteine Endopeptidases: metabolism,Dogs,Endosomal Sorting Complexes Required for Transport,Endosomes,Endosomes: metabolism,Epithelial Sodium Channel,Epithelium,Epithelium: metabolism,Half-Life,Ion Channel Gating,Ion Channel Gating: physiology,Ion Transport,Ligases,Lysosomes,Lysosomes: metabolism,Molecular Sequence Data,Multienzyme Complexes,Multienzyme Complexes: metabolism,Mutagenesis,Mutation,Nuclear Magnetic Resonance,Oocytes,Point Mutation,Post-Translational,Protease Inhibitors,Protease Inhibitors: pharmacology,Proteasome Endopeptidase Complex,Protein Conformation,Protein Processing,Rats,Recombinant Fusion Proteins,Recombinant Fusion Proteins: metabolism,Site-Directed,Sodium,Sodium Channels,Sodium Channels: physiology,Sodium: metabolism,Transfection,Ubiquitin-Protein Ligases,Ubiquitins,Ubiquitins: physiology,Up-Regulation,Up-Regulation: physiology,Xenopus laevis},
month = {nov},
number = {21},
pages = {6325--6336},
pmid = {9351815},
publisher = {European Molecular Biology Organization},
shorttitle = {EMBO J},
title = {{Regulation of stability and function of the epithelial Na+ channel (ENaC) by ubiquitination.}},
url = {http://dx.doi.org/10.1093/emboj/16.21.6325},
volume = {16},
year = {1997}
}
@article{Zhou2017,
abstract = {This paper studies the landscape of empirical risk of deep neural networks by theoretically analyzing its convergence behavior to the population risk as well as its stationary points and properties. For an {\$}l{\$}-layer linear neural network, we prove its empirical risk uniformly converges to its population risk at the rate of {\$}\backslashmathcal{\{}O{\}}(r{\^{}}{\{}2l{\}}\backslashsqrt{\{}d\backslashlog(l){\}}/\backslashsqrt{\{}n{\}}){\$} with training sample size of {\$}n{\$}, the total weight dimension of {\$}d{\$} and the magnitude bound {\$}r{\$} of weight of each layer. We then derive the stability and generalization bounds for the empirical risk based on this result. Besides, we establish the uniform convergence of gradient of the empirical risk to its population counterpart. We prove the one-to-one correspondence of the non-degenerate stationary points between the empirical and population risks with convergence guarantees, which describes the landscape of deep neural networks. In addition, we analyze these properties for deep nonlinear neural networks with sigmoid activation functions. We prove similar results for convergence behavior of their empirical risks as well as the gradients and analyze properties of their non-degenerate stationary points. To our best knowledge, this work is the first one theoretically characterizing landscapes of deep learning algorithms. Besides, our results provide the sample complexity of training a good deep neural network. We also provide theoretical understanding on how the neural network depth {\$}l{\$}, the layer width, the network size {\$}d{\$} and parameter magnitude determine the neural network landscapes.},
annote = {Unofortunately, the bound ifor the non-linear case is {\textgreater}1 , when the number of parameters (d) {\textgreater} number of samples (n).},
archivePrefix = {arXiv},
arxivId = {1705.07038},
author = {Zhou, Pan and Feng, Jiashi},
eprint = {1705.07038},
file = {::},
month = {may},
title = {{The Landscape of Deep Learning Algorithms}},
url = {http://arxiv.org/abs/1705.07038},
year = {2017}
}
@article{Schrodel2013,
abstract = {Recent efforts in neuroscience research have been aimed at obtaining detailed anatomical neuronal wiring maps as well as information on how neurons in these networks engage in dynamic activities. Although the entire connectivity map of the nervous system of Caenorhabditis elegans has been known for more than 25 years, this knowledge has not been sufficient to predict all functional connections underlying behavior. To approach this goal, we developed a two-photon technique for brain-wide calcium imaging in C. elegans, using wide-field temporal focusing (WF-TeFo). Pivotal to our results was the use of a nuclear-localized, genetically encoded calcium indicator, NLS-GCaMP5K, that permits unambiguous discrimination of individual neurons within the densely packed head ganglia of C. elegans. We demonstrate near-simultaneous recording of activity of up to 70{\%} of all head neurons. In combination with a lab-on-a-chip device for stimulus delivery, this method provides an enabling platform for establishing functional maps of neuronal networks.},
author = {Schr{\"{o}}del, Tina and Prevedel, Robert and Aumayr, Karin and Zimmer, Manuel and Vaziri, Alipasha},
doi = {10.1038/nmeth.2637},
issn = {1548-7105},
journal = {Nature methods},
keywords = {Animals,Animals, Genetically Modified,Behavior, Animal,Behavior, Animal: drug effects,Behavior, Animal: radiation effects,Brain,Brain: physiology,Brain: radiation effects,Caenorhabditis elegans,Caenorhabditis elegans: genetics,Caenorhabditis elegans: physiology,Calcium Signaling,Calcium Signaling: genetics,Equipment Design,Green Fluorescent Proteins,Green Fluorescent Proteins: genetics,Imaging, Three-Dimensional,Imaging, Three-Dimensional: instrumentation,Imaging, Three-Dimensional: methods,Lab-On-A-Chip Devices,Light,Microscopy, Fluorescence,Models, Neurological,Neural Pathways,Neural Pathways: physiology,Neural Pathways: radiation effects,Neuroimaging,Neurons,Neurons: physiology,Neurons: radiation effects,Oxygen,Oxygen: pharmacology,Recombinant Fusion Proteins,Recombinant Fusion Proteins: genetics,Stimulation, Chemical},
month = {oct},
number = {10},
pages = {1013--20},
pmid = {24013820},
title = {{Brain-wide 3D imaging of neuronal activity in Caenorhabditis elegans with sculpted light.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24013820},
volume = {10},
year = {2013}
}
@article{Pakdaman2010b,
author = {Pakdaman, K and Thieullen, M and Wainrib, G},
journal = {Advances in Applied Probability},
keywords = {2010 mathematics subject classification,60f17,60j75,fluid limit,hodgkin,huxley,kinetic model,langevin approximation,lecar,morris,neuron model,piecewise-deterministic markov process,primary 60f05,stochastic hybrid system,stochastic ion channels},
number = {3},
pages = {761--794},
publisher = {Applied Probability Trust},
title = {{Fluid limit theorems for stochastic hybrid systems with application to neuron models}},
url = {http://projecteuclid.org/euclid.aap/1282924062},
volume = {42},
year = {2010}
}
@book{Eddy1996,
author = {Elliott, R J and Aggoun, Lakhdar and Moore, J B},
booktitle = {Current opinion in structural biology},
isbn = {0387943641},
title = {{Hidden markov models}},
year = {1991}
}
@article{Jo2009a,
author = {Jo, SH and Kim, KH and Lu, Wei},
journal = {Nano letters},
number = {December 2008},
pages = {496--500},
title = {{Programmable resistance switching in nanoscale two-terminal devices}},
url = {http://pubs.acs.org/doi/abs/10.1021/nl803669s},
volume = {9},
year = {2008}
}
@article{CZANNER04,
author = {Czanner, G and Iyengar, S},
journal = {COSYNE},
title = {{Expectation-{\{}M{\}}aximization ({\{}EM{\}}) Estimation of an Integrate-and-Fire Model with Spike-Frequency Adaptation}},
year = {2004}
}
@article{Eppler1997,
author = {Eppler, W and Fisher, T and Gemmeke, H and Becher, T and Kock, G},
journal = {Proc. MicroNeuro},
title = {{High speed neural network chip on PCI-board}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.30.5855{\&}rep=rep1{\&}type=pdf},
year = {1997}
}
@article{Softky1993,
abstract = {How random is the discharge pattern of cortical neurons? We examined recordings from primary visual cortex (V1; Knierim and Van Essen, 1992) and extrastriate cortex (MT; Newsome et al., 1989a) of awake, behaving macaque monkey and compared them to analytical predictions. For nonbursting cells firing at sustained rates up to 300 Hz, we evaluated two indices of firing variability: the ratio of the variance to the mean for the number of action potentials evoked by a constant stimulus, and the rate-normalized coefficient of variation (Cv) of the interspike interval distribution. Firing in virtually all V1 and MT neurons was nearly consistent with a completely random process (e.g., Cv approximately 1). We tried to model this high variability by small, independent, and random EPSPs converging onto a leaky integrate-and-fire neuron (Knight, 1972). Both this and related models predicted very low firing variability (Cv {\textless}{\textless} 1) for realistic EPSP depolarizations and membrane time constants. We also simulated a biophysically very detailed compartmental model of an anatomically reconstructed and physiologically characterized layer V cat pyramidal cell (Douglas et al., 1991) with passive dendrites and active soma. If independent, excitatory synaptic input fired the model cell at the high rates observed in monkey, the Cv and the variability in the number of spikes were both very low, in agreement with the integrate-and-fire models but in strong disagreement with the majority of our monkey data. The simulated cell only produced highly variable firing when Hodgkin-Huxley-like currents (INa and very strong IDR) were placed on distal dendrites. Now the simulated neuron acted more as a millisecond-resolution detector of dendritic spike coincidences than as a temporal integrator. We argue that neurons that act as temporal integrators over many synaptic inputs must fire very regularly. Only in the presence of either fast and strong dendritic nonlinearities or strong synchronization among individual synaptic events will the degree of predicted variability approach that of real cortical neurons.},
author = {Softky, WR R and Koch, C},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Computer Simulation,Dendrites,Dendrites: physiology,Humans,Models,Neurological,Neurons,Neurons: physiology,Random Allocation,Reaction Time,Synapses,Synapses: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,a wake monkey,randomness},
number = {January},
pages = {334},
pmid = {8423479},
publisher = {Soc Neuroscience},
title = {{The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs}},
url = {http://www.jneurosci.org/content/13/1/334.short http://www.jneurosci.org/cgi/content/abstract/13/1/334},
volume = {13},
year = {1993}
}
@book{DH72,
address = {New York},
author = {Duda, R and Hart, P},
publisher = {Wiley},
title = {{Pattern classification and scene analysis}},
year = {1972}
}
@article{White1998,
abstract = {Neurons of the superficial medial entorhinal cortex (MEC), which deliver neocortical input to the hippocampus, exhibit intrinsic, subthreshold oscillations with slow dynamics. These intrinsic oscillations, driven by a persistent Na+ current and a slow outward current, may help to generate the theta rhythm, a slow rhythm that plays an important role in spatial and declarative learning. Here we show that the number of persistent Na+ channels underlying subthreshold oscillations is relatively small ({\textless}10(4)) and use a physiologically based stochastic model to argue that the random behavior of these channels may contribute crucially to cellular-level responses. In acutely isolated MEC neurons under voltage clamp, the mean and variance of the persistent Na+ current were used to estimate the single channel conductance and voltage-dependent probability of opening. A hybrid stochastic-deterministic model was built by using voltage-clamp descriptions of the persistent and fast-inactivating Na+ conductances, along with the fast and slow K+ conductances. All voltage-dependent conductances were represented with nonlinear ordinary differential equations, with the exception of the persistent Na+ conductance, which was represented as a population of stochastic ion channels. The model predicts that the probabilistic nature of Na+ channels increases the cell's repertoire of qualitative behaviors; although deterministic models at a particular point in parameter space can generate either subthreshold oscillations or phase-locked spikes (but rarely both), models with an appropriate level of channel noise can replicate physiological behavior by generating both patterns of electrical activity for a single set of parameters. Channel noise may contribute to higher order interspike interval statistics seen in vitro with DC current stimulation. Models with channel noise show evidence of spike clustering seen in brain slice experiments, although the effect is apparently not as prominent as seen in experimental results. Channel noise may contribute to cellular responses in vivo as well; the stochastic system has enhanced sensitivity to small periodic stimuli in a form of stochastic resonance that is novel (in that the relevant noise source is intrinsic and voltage-dependent) and potentially physiologically relevant. Although based on a simple model that does not include all known membrane mechanisms of MEC stellate cells, these results nevertheless imply that the stochastic nature of small collections of molecules may have important effects at the cellular and network levels.},
author = {White, J A and Klink, R and Alonso, A and Kay, A R},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Animals,Electric Stimulation,Entorhinal Cortex,Entorhinal Cortex: physiology,Ion Channel Gating,Male,Models,Neurological,Neurons,Neurons: drug effects,Neurons: physiology,Potassium Channels,Potassium Channels: physiology,Probability,Rats,Sodium Channels,Sodium Channels: drug effects,Sodium Channels: physiology,Stochastic Processes,Tetrodotoxin,Tetrodotoxin: pharmacology},
month = {jul},
number = {1},
pages = {262--9},
pmid = {9658048},
title = {{Noise from voltage-gated ion channels may influence neuronal dynamics in the entorhinal cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9658048},
volume = {80},
year = {1998}
}
@article{BIA87,
author = {Bialek, W},
journal = {Annual Review of Biophysics and Biomolecular Structure},
pages = {455--478},
title = {{Physical Limits To Sensation And Perception}},
volume = {16},
year = {1987}
}
@phdthesis{Barak2009,
annote = {2010num6.1 (only smal part - review of topology)},
author = {Barak, E},
booktitle = {Electrical Engineering},
pages = {162},
title = {{A model for "what" and "where" information in the cortex}},
year = {2009}
}
@article{EngertBonhoeffer99,
abstract = {Long-term enhancement of synaptic efficacy in the hippocampus is an

important model for studying the cellular mechanisms of neuronal

plasticity, circuit reorganization, and even learning and memory.

Although these long-lasting functional changes are easy to induce,

it has been very difficult to demonstrate that they are accompanied

or even caused by morphological changes on the subcellular level.

Here we combined a local superfusion technique with two-photon imaging,

which allowed us to scrutinize specific regions of the postsynaptic

dendrite where we knew that the synaptic changes had to occur. We

show that after induction of long-lasting (but not short-lasting)

functional enhancement of synapses in area CA1, new spines appear

on the postsynaptic dendrite, whereas in control regions on the same

dendrite or in slices where long-term potentiation was blocked, no

significant spine growth occurred.},
author = {Engert, F and Bonhoeffer, T},
doi = {10.1038/19978},
journal = {Nature},
keywords = {Animals; Dendrites; Excitatory Postsynaptic Potent},
month = {may},
number = {6731},
pages = {66--70},
pmid = {10331391},
title = {{Dendritic spine changes associated with hippocampal long-term synaptic plasticity.}},
url = {http://dx.doi.org/10.1038/19978},
volume = {399},
year = {1999}
}
@article{Englitz2008a,
author = {Englitz, Bernhard and Stiefel, Klaus M and Sejnowski, Terrence J},
number = {Cv},
pages = {44--64},
title = {{Irregular Firing of Isolated Cortical Interneurons in Vitro}},
volume = {64},
year = {2008}
}
@article{Starzyk2014,
author = {Starzyk, JA},
doi = {10.1109/TCSI.2014.2304653},
issn = {1549-8328},
journal = {ieeexplore.ieee.org},
pages = {1--12},
title = {{Memristor Crossbar Architecture for Synchronous Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6779676 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6779676},
year = {2014}
}
@article{JainShamma07,
author = {Jain, M and Elhilali, M and Vaswani, N and Fritz, J and Shamma, S},
journal = {Submitted for publication},
title = {{A particle filter for tracking adaptive neural responses in auditory cortex}},
year = {2007}
}
@article{Goll06,
author = {Gollisch, Tim},
journal = {Network: Computation in Neural Systems},
month = {jun},
number = {2},
pages = {103--129},
title = {{Estimating Receptive Fields in the Presence of Spike-Time Jitter}},
volume = {17},
year = {2006}
}
@article{KouhSharpee09,
author = {Kouh, M and Sharpee, T},
journal = {Network: Computation in Neural Systems},
pages = {49--68},
title = {{Estimating linear-nonlinear models using Renyi divergences}},
volume = {20},
year = {2009}
}
@article{NelkenYoung94,
author = {Nelken, I and Young, E D},
journal = {Journal of Neurophysiology},
month = {jun},
number = {6},
pages = {2446--2462},
title = {{Two separate inhibitory mechanisms shape the responses of dorsal cochlear nucleus type IV units to narrowband and wideband stimuli}},
volume = {71},
year = {1994}
}
@article{Salakhutdinov2012,
author = {Salakhutdinov, R and Hinton, G E},
keywords = {Deep Learning},
mendeley-tags = {Deep Learning},
pages = {1967--2006},
title = {{An efficient learning procedure for deep Boltzmann machines}},
url = {http://www.utstat.toronto.edu/{~}rsalakhu/papers/MIT-CSAIL-TR-2010-037.pdf},
volume = {2006},
year = {2010}
}
@article{Hasenstaub2010,
abstract = {The brain contains an astonishing diversity of neurons, each expressing only one set of ion channels out of the billions of potential channel combinations. Simple organizing principles are required for us to make sense of this abundance of possibilities and wealth of related data. We suggest that energy minimization subject to functional constraints may be one such unifying principle. We compared the energy needed to produce action potentials singly and in trains for a wide range of channel densities and kinetic parameters and examined which combinations of parameters maximized spiking function while minimizing energetic cost. We confirmed these results for sodium channels using a dynamic current clamp in neocortical fast spiking interneurons. We find further evidence supporting this hypothesis in a wide range of other neurons from several species and conclude that the ion channels in these neurons minimize energy expenditure in their normal range of spiking.},
author = {Hasenstaub, Andrea and Otte, Stephani and Callaway, Edward and Sejnowski, T J},
doi = {10.1073/pnas.0914886107},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
month = {jul},
number = {27},
pages = {12329--34},
pmid = {20616090},
title = {{Metabolic cost as a unifying principle governing neuronal biophysics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20616090},
volume = {107},
year = {2010}
}
@article{Swirszcz2016,
abstract = {There has been a lot of recent interest in trying to characterize the error surface of deep models. This stems from a long standing question. Given that deep networks are highly nonlinear systems optimized by local gradient methods, why do they not seem to be affected by bad local minima? It is widely believed that training of deep models using gradient methods works so well because the error surface either has no local minima, or if they exist they need to be close in value to the global minimum. It is known that such results hold under very strong assumptions which are not satisfied by real models. In this paper we present examples showing that for such theorem to be true additional assumptions on the data, initialization schemes and/or the model classes have to be made. We look at the particular case of finite size datasets. We demonstrate that in this scenario one can construct counter-examples (datasets or initialization schemes) when the network does become susceptible to bad local minima over the weight space.},
archivePrefix = {arXiv},
arxivId = {1611.06310},
author = {Swirszcz, Grzegorz and Czarnecki, Wojciech Marian and Pascanu, Razvan},
eprint = {1611.06310},
journal = {arXiv:1611.06310},
pages = {1--13},
title = {{Local minima in training of deep networks}},
url = {http://arxiv.org/abs/1611.06310},
year = {2016}
}
@article{nadler1996random,
author = {Nadler, W and Huang, T and Stein, D I L},
issn = {1063-651X},
journal = {Physical Review E},
month = {oct},
number = {4},
pages = {4037--4047},
pmid = {9965552},
publisher = {APS},
title = {{Random walks on random partitions in one dimension}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9965552},
volume = {54},
year = {1996}
}
@article{CJ01,
author = {Chib, S and Jelizkov, I},
journal = {Journal of the American Statistical Association},
pages = {270--281},
title = {{Marginal Likelihood From the {\{}M{\}}etropolis-{\{}H{\}}astings output}},
volume = {96},
year = {2001}
}
@article{XuWu05,
abstract = {Repetitive nerve firings cause short-term depression (STD) of release

at many synapses. Its underlying mechanism is largely attributed

to depletion of a readily releasable vesicle pool (RRP) and a decreased

probability of releasing a readily releasable vesicle during an action

potential. Which of these two mechanisms is dominant and the mechanism

that decreases the release probability remain debated. Here, we report

that a decreased release probability is caused by a calcium-induced

inhibition of presynaptic calcium channels, particularly P/Q-type

channels at the calyx of Held in rat brainstem. This mechanism was

the dominant cause of STD in a wide range of stimulation conditions,

such as during 2 to 20 action potential-equivalent stimuli (AP-e)

at 0.2-30 Hz and after 2 to 20 AP-e at 0.2-100 Hz. Only during {\textgreater}

or = 100 Hz AP-e was depletion the dominant mechanism.},
author = {Xu, Jianhua and Wu, Ling-Gang},
doi = {10.1016/j.neuron.2005.03.024},
journal = {Neuron},
keywords = {Action Potentials; Animals; Animals,Biological; Neural Inhibition; Nuclear Proteins;,Newborn; Barium; Brain Stem; CREB-Binding Protein,Radiation; Egtazic Acid; Electric Capacitance; El,Wistar; Synapses; Time Factors; Trans-Activators},
month = {may},
number = {4},
pages = {633--645},
pmid = {15944131},
title = {{The decrease in the presynaptic calcium current is a major cause of short-term depression at a calyx-type synapse.}},
url = {http://dx.doi.org/10.1016/j.neuron.2005.03.024},
volume = {46},
year = {2005}
}
@article{BH99,
author = {Brunel, N and Hakim, V},
journal = {Neural Computation},
pages = {1621--1671},
title = {{Fast global oscillations in networks of integrate-and-fire neurons with low firing rates}},
volume = {11},
year = {1999}
}
@article{ganguli2008memory,
annote = {2008num23},
author = {Ganguli, S and Huh, D and Sompolinsky, H},
journal = {Proceedings of the National Academy of Sciences},
number = {48},
pages = {18970},
publisher = {National Acad Sciences},
title = {{Memory traces in dynamical systems}},
volume = {105},
year = {2008}
}
@article{FeketeRyugo84,
author = {Fekete, D M and Rouiller, E M and Liberman, M C and Ryugo, D K},
journal = {Journal of comparative neurology(1911)},
number = {3},
pages = {432--450},
publisher = {Wiley-Liss},
title = {{The central projections of intracellularly labeled auditory nerve fibers in cats}},
volume = {229},
year = {1984}
}
@article{Eliasmith|2001|,
abstract = {There are currently a number of models that use spiking neurons in
recurrent net- works to encode a stable Gaussian {\"{i}}¾‘bump{\"{i}}¾' of activation.
These models successfully capture some behaviors of various neural
systems (e.g., storing a single spatial location in parietal cortex).
We extend this previous work by showing how to construct and ana-
lyze realistic spiking networks that encode smooth n-dimensional
functions drawn from a finite functional space. These new networks
can capture additional experimentally observed behavior (e.g., storing
multiple spatial locations at the same time).},
annote = {The paper introduces very nice prescription for representing attractor{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}neuronal networks using the concept of neural population code. In{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}this sense, the representation of the input function f in terms of{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}neural {\&}{\#}039;spiking rate{\&}{\#}039; a can be obtain via a linear convolution f{\^{}}=},
author = {Eliasmith, C and Anderson, C H},
keywords = {attractors,computational,neurobiology,neuronal models,neuronal networks},
title = {{Beyond Bumps: Spiking Networks that Store Smooth n-Dimensional Functions}}
}
@article{Llinas1988,
abstract = {This article reviews the electroresponsive properties of single neurons in the mammalian central nervous system (CNS). In some of these cells the ionic conductances responsible for their excitability also endow them with autorhythmic electrical oscillatory properties. Chemical or electrical synaptic contacts between these neurons often result in network oscillations. In such networks, autorhythmic neurons may act as true oscillators (as pacemakers) or as resonators (responding preferentially to certain firing frequencies). Oscillations and resonance in the CNS are proposed to have diverse functional roles, such as (i) determining global functional states (for example, sleep-wakefulness or attention), (ii) timing in motor coordination, and (iii) specifying connectivity during development. Also, oscillation, especially in the thalamo-cortical circuits, may be related to certain neurological and psychiatric disorders. This review proposes that the autorhythmic electrical properties of central neurons and their connectivity form the basis for an intrinsic functional coordinate system that provides internal context to sensory input.},
annote = {2010IInum12.18{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}מאמר עם רשימה של הרבה מסוגי תעלות שקיימות{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Llin{\'{a}}s, R R},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
keywords = {Animals,Brain,Brain: physiology,Cell Membrane,Cell Membrane: physiology,Central Nervous System,Central Nervous System: physiology,Electric Conductivity,Electrophysiology,Ions,Neuron Model,Neurons,Neurons: physiology},
mendeley-tags = {Neuron Model},
month = {dec},
number = {4886},
pages = {1654--1664},
pmid = {3059497},
title = {{The intrinsic electrophysiological properties of mammalian neurons: insights into central nervous system function}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3059497},
volume = {242},
year = {1988}
}
@article{GeorgeFoster00,
author = {George, E I and Foster, D},
journal = {Biometrika},
number = {4},
pages = {731--747},
title = {{Calibration and empirical Bayes variable selection}},
volume = {87},
year = {2000}
}
@article{LMN00,
author = {Laubach, M and Wessberg, J and Nicolelis, M},
journal = {Nature},
pages = {567--571},
title = {{Cortical ensemble activity increasingly predicts behavior outcomes during learning of a motor task}},
volume = {405},
year = {2000}
}
@article{Wainrib2011,
abstract = {We introduce a method for systematically reducing the dimension of biophysically realistic neuron models with stochastic ion channels exploiting time-scales separation. Based on a combination of singular perturbation methods for kinetic Markov schemes with some recent mathematical developments of the averaging method, the techniques are general and applicable to a large class of models. As an example, we derive and analyze reductions of different stochastic versions of the Hodgkin Huxley (HH) model, leading to distinct reduced models. The bifurcation analysis of one of the reduced models with the number of channels as a parameter provides new insights into some features of noisy discharge patterns, such as the bimodality of interspike intervals distribution. Our analysis of the stochastic HH model shows that, besides being a method to reduce the number of variables of neuronal models, our reduction scheme is a powerful method for gaining understanding on the impact of fluctuations due to finite size effects on the dynamics of slow fast systems. Our analysis of the reduced model reveals that decreasing the number of sodium channels in the HH model leads to a transition in the dynamics reminiscent of the Hopf bifurcation and that this transition accounts for changes in characteristics of the spike train generated by the model. Finally, we also examine the impact of these results on neuronal coding, notably, reliability of discharge times and spike latency, showing that reducing the number of channels can enhance discharge time reliability in response to weak inputs and that this phenomenon can be accounted for through the analysis of the reduced model.},
author = {Wainrib, G and Thieullen, M and Pakdaman, K},
doi = {10.1007/s10827-011-0355-7},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {averaging method,stochastic ion channels,time-scales separation},
month = {aug},
number = {2},
pages = {327--346},
pmid = {21842259},
title = {{Reduction of stochastic conductance-based neuron models with time-scales separation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21842259},
volume = {32},
year = {2011}
}
@article{Zumdieck2004,
author = {Zumdieck, A and Timme, M and Geisel, T and Wolf, F},
journal = {Physical Review Letters},
title = {{Long chaotic transients in complex networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.93.244103},
year = {2004}
}
@article{DiMaio2008,
abstract = {The largest part of information passed among neurons in the brain occurs by the means of chemical synapses connecting the axons of presynaptic neurons to the dendritic tree of the postsynaptic ones. In the present paper, the most relevant open problems related to the mechanisms of control of the information passing among neurons by synaptic transmission will be shortly reviewed. The "cross talking" between synapses, their mutual interactions and the control of the information flow between different areas of the dendritic tree will be also considered. The threshold mechanism based on the "reversal potential" will be considered for its role in the control of information transfer among neurons and also for its contribution to the information flow among different areas of the dendritic tree and to the computational ability of the single neuron. The concept of "competition for plasticity" will be proposed as a mechanism of competition based on the synaptic activation time.},
annote = {2010IIInum21},
author = {{Di Maio}, Vito},
doi = {10.1016/j.brainres.2008.06.016},
issn = {0006-8993},
journal = {Brain Research},
keywords = {Animals,Brain,Brain: physiology,Computer Simulation,Dendrites,Dendrites: physiology,Dendritic Spines,Dendritic Spines: physiology,Humans,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = {aug},
pages = {26--38},
pmid = {18586017},
title = {{Regulation of information passing by synaptic transmission: a short review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18586017},
volume = {1225},
year = {2008}
}
@article{Yu1994,
author = {Yu, Xiao-hu},
number = {5},
pages = {4--5},
title = {{Comments on "Can Backpropagation Error Surface Not Have Local Minima"}},
volume = {5},
year = {1994}
}
@article{Dunn2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1301.7275v1},
author = {Dunn, Benjamin and Roudi, Y},
eprint = {arXiv:1301.7275v1},
journal = {Physical Review E},
title = {{Learning and inference in a nonequilibrium Ising model with hidden nodes}},
url = {http://pre.aps.org/abstract/PRE/v87/i2/e022127},
year = {2013}
}
@article{Popov|2003|,
abstract = {Literature data and our own data on the synaptic plastici ty and remodel
ing of synaptic organelles in the central nervous system were general
ized. Modern techniques of confocal laser scanning microscopy and
serial thin sectioning for in vi vo and in vi tro studies of dendri
tic spines were discussed, including the relationship between morphological
changes and the synaptic transmission ef ficiency, in particular,
using {\~{A}} model of long-term potentiation. Various categories of dendri
tic spines and postsynaptic densi ti es, and also the role of filopodia
in spine genesis were analyzed. The serial thin sectioning technique
was shown to be most efficient for unbiased quantitative stereological
analysis and three-dimensional reconstructions. Using {\~{A}} ref ined
technique of serial thin sectioning and {\~{A}} computer program, giant
mi tochondria in dendr ites of neurons in various regions of the
hippocampus were demonstrated. Smooth endoplasmic reticulum was shown
to form {\~{A}} continuum with the outer membrane of the mitochondrial
envelope. It was assumed that {\~{A}}{\S}{\~{A}}¨{\~{A}}±{\~{A}}¯ {\~{A}} continuum ensures calcium
{\~{A}}¾ {\~{A}}¯ tunnel ing, thus favoring the functioning of the intracellular
signal transduction system during synaptic transmission. Data were
presented on the existence of gap j unctions ("electruc synapses"
) at mammalian brain synapses, and also between glial processes and
gl ial cel ls and neurons. Using our own and li terature data, we
showed that glial cell processes form {\~{A}} glial network, which could
modulate the functioning of the neuronal network. The connection
of dendri tic spines with the glial network was shown by the example
of three-dimensional reconstructions of neuropil volumes in the {\~{A}}‘{\~{A}}€
1 area of the hippocampus of ground squi rrels in three functional
states: in the normothermia, in 2.5 h after the beginning {\~{A}}{\textregistered} 1 awakening
from hibernation, and in cold torpor at {\~{A}} brain temperature below
6' {\~{A}}‘. Our own data were discussed on the formation of more than
f ive synapses both on mushroom dendritic spines of {\~{A}}‘{\~{A}}€ 1 neurons
and on thorny excrescences of CA3 neurons. The results of the analysis
of the data presented suggest new paradigms organization and functioning
of synapses.},
annote = {The paper presents a wide review of what is known about microscopic{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}neuroanatomy of brain, including comprehensive review of synapse{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}types, dendritic and axonal microscopic organization and development.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}References to literature as well as reference to own data, obtained{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}with serial thin sectioning of ground squirrel hippocampus, are presented{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and discussed. 3D reconstructions of spines are presented. Some propositions{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}are made, such as presence of giant mitochondria in dendrites, possibility{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of spines retraction and restoration during hibernation in the squirrel.},
author = {Popov, V I and Medvedev, N I and Rogachevskii, V V and Ignat`ev, D A and Stewart, M G and Fesenko, E E},
journal = {Biophysics},
keywords = {3D reconstruction,dendritic spine,gap junction,glial cell,hippocampus,neurobiology,neuron,postsynaptic density,serial section electron micrograph,serial thin sectioning,synapse,three-dimensional reconstruction},
number = {2},
pages = {272},
title = {{Three-Dimensional Synapses and Astroglia in the Hippocampus of Rats and Ground Squirrels: New Structural-Functional Paradigms on the Functioning of the Synapse}},
volume = {48}
}
@article{WickesbergOertel90,
abstract = {To understand how auditory information is processed in the cochlear

nuclei, it is crucial to know what circuitry exists and how it functions.

Previous anatomical experiments have shown that neurons in the deep

layer of the dorsal cochlear nucleus (DCN) project topographically

to the anteroventral cochlear nucleus (AVCN) (Wickesberg and Oertel,

1988). Because interneurons in the DCN and their targets in AVCN

are excited by the same group of auditory nerve fibers, the projection

is frequency-specific. Here we report that microinjections of glutamate

in the DCN evoke trains of IPSPs in individual, impaled AVCN neurons

in brain slices of the cochlear nuclear complex. Only injections

along a rostrocaudal band in the DCN, matching the anatomical projection

of tuberculoventral neurons, evoke IPSPs; elsewhere, there were no

responses to the glutamate. The inhibition is blocked by 0.5 microM

strychnine. Both bushy and stellate cells are targets of the inhibitory

projection. Inhibition in the AVCN is delayed by an additional synaptic

delay with respect to the excitation. Delayed, frequency-specific

inhibition allows the first wavefront to be transmitted to higher

auditory centers by bushy and stellate cells, while following inputs

encoding signals of similar frequencies are attenuated at least for

the duration of an IPSP. These findings are consistent with results

from psychoacoustic experiments and suggest that this circuit provides

a source of monaural echo suppression.},
author = {Wickesberg, R E and Oertel, D},
journal = {Journal of Neuroscience},
keywords = {Animals; Auditory Pathways; Biomechanics; Brain; C,Inbred CBA; Neural Inhibition; Psychoacoustics; R,P.H.S.; Sound; Synaptic Transmission,U.S. Gov't},
month = {jun},
number = {6},
pages = {1762--1768},
pmid = {1972392},
title = {{Delayed, frequency-specific inhibition in the cochlear nuclei of mice: a mechanism for monaural echo suppression.}},
volume = {10},
year = {1990}
}
@article{BL03,
author = {Brunel, N and Latham, P},
journal = {Neural Computation},
pages = {2281--2306},
title = {{Firing Rate of the Noisy Quadratic Integrate-and-Fire Neuron}},
volume = {15},
year = {2003}
}
@article{MR03,
author = {Wiener, M and Richmond, B},
journal = {Journal of Neuroscience},
pages = {2394--2406},
title = {{Decoding spike trains instant by instant using order statistics and the mixture-of-{\{}P{\}}oissons model}},
volume = {23},
year = {2003}
}
@article{Atar2010,
annote = {2011num28},
archivePrefix = {arXiv},
arxivId = {arXiv:1101.0302v1},
author = {Atar, Rami and Weissman, Tsachy},
eprint = {arXiv:1101.0302v1},
journal = {Arxiv preprint arXiv:1101.0302},
number = {grant 2008466},
pages = {1--24},
title = {{Mutual Information, Relative Entropy, and Estimation in the Poisson Channel}},
url = {http://arxiv.org/abs/1101.0302},
year = {2010}
}
@inproceedings{Beal03,
author = {Beal, M and Ghahramani, Z},
booktitle = {Bayesian Statistics 7},
publisher = {Oxford},
title = {{The Variational {\{}Bayesian EM{\}} Algorithm for Incomplete Data: with Application to Scoring Graphical Model Structures}},
year = {2003}
}
@inproceedings{Su2007,
author = {Su, J.Y. and Wang, X J and Cai, K.Y.},
booktitle = {Automation and Logistics, 2007 IEEE International Conference on},
doi = {10.1109/ICAL.2007.4338794},
isbn = {978-1-4244-1530-4},
month = {aug},
number = {60474006},
pages = {1425--1430},
publisher = {IEEE},
title = {{Periodic Orbit Analysis of Switched Linear Systems}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4338794},
year = {2007}
}
@article{Cohen|1997|,
abstract = {A new boundary detection approach for shape modeling is presented.
It detects the global minimum of an active contour model{\"{i}}¾'s energy
between two end points. Initialization is made easier and the curve
is not trapped at a local minimum by spurious edges. We modify the
{\"{i}}¾“snake{\"{i}}¾” energy by including the internal regularization term
in the external potential term. Our method is based on finding a
path of minimal length in a Riemannian metric. We then make use of
a new efficient numerical method to find this shortest path. It is
shown that the proposed energy, though based only on a potential
integrated along the curve, imposes a regularization effect like
snakes. We explore the relation between the maximum curvature along
the resulting contour and the potential generated from the image.
The method is capable to close contours, given only one point on
the objects{\"{i}}¾' boundary by using a topology-based saddle search routine.
We show examples of our method applied to real aerial and medical
images. },
author = {Cohen, L D and Kimmel, R},
journal = {International Journal of Computer Vission},
keywords = {active contour,active shape,computational,curve evoluti,deformable models,energy minimzation,feature extraction,image processing,level sets,minimization,partial differential equations,path of minimal cost,segmentation,shape modeling,snakes},
number = {1},
pages = {57},
title = {{Global minimum for active contour models: a minimum path approach}},
volume = {24}
}
@article{BHHW83,
author = {Begun, J and Hall, W and Huang, W and Wellner, J},
journal = {Annals of Statistics},
pages = {432--452},
title = {{Information and asymptotic efficiency in parametric-nonparametric models}},
volume = {11},
year = {1983}
}
@article{Neyshabur2017a,
abstract = {With a goal of understanding what drives generalization in deep networks, we consider several recently suggested explanations, including norm-based control, sharpness and robustness. We study how these measures can ensure generalization, highlighting the importance of scale normalization, and making a connection between sharpness and PAC-Bayes theory. We then investigate how well the measures explain different observed phenomena.},
archivePrefix = {arXiv},
arxivId = {1706.08947},
author = {Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nathan},
eprint = {1706.08947},
file = {:C$\backslash$:/Users/Daniel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Neyshabur et al. - 2017 - Exploring Generalization in Deep Learning.pdf:pdf},
journal = {arXiv},
month = {jun},
title = {{Exploring Generalization in Deep Learning}},
url = {http://arxiv.org/abs/1706.08947},
year = {2017}
}
@article{OF05,
author = {Olshausen, B and Field, D},
journal = {Neural Computation},
pages = {1665--1699},
title = {{How Close Are We to Understanding {\{}V1{\}}?}},
volume = {17},
year = {2005}
}
@article{Pitkow07,
author = {Pitkow, X and Sompolinsky, H and Meister, M},
journal = {PLOS Biology},
title = {{A Neural Computation for Visual Acuity in the Presence of Eye Movements}},
volume = {5},
year = {2007}
}
@article{Pardas,
abstract = {This paper addresses the application of active contours or snakes
for tracking of contours in image sequences. We propose to use the
dynamic programming implementation of the snakes in order to restrict
the possible candidates for a given snaxel to those that have a high
correlation with the corresponding snaxel in the previous frame.
Besides, we claim that, in tracking applications, the motion compensation
error has to be introduced in the external energy of the snake to
be able to track generic contours.},
author = {Pardas, M and Sayrol, E},
keywords = {active contours,computational,dynamic programming,image processing,motion,snake,tracking},
title = {{Motion Estimation Based Tracking of Active Contours}}
}
@book{Redner01,
author = {Redner, S},
publisher = {Cambridge University Press},
title = {{A Guide to First-Passage Processes}},
year = {2001}
}
@book{Brent2011,
address = {New York},
archivePrefix = {arXiv},
arxivId = {arXiv:1004.4710v1},
author = {Brent, R P and Zimmermann, P},
eprint = {arXiv:1004.4710v1},
publisher = {Cambridge University Press},
title = {{Modern computer arithmetic}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=-8wuH5AwbwMC{\&}oi=fnd{\&}pg=PR9{\&}dq=Modern+Computer+Arithmetic{\&}ots=tWd6cwJfRc{\&}sig=fn4V2fMjzly1m{\_}1q8ByCZ5iEcrA},
year = {2011}
}
@article{Pemantle1990,
author = {Pemantle, R},
journal = {The Annals of Probability},
number = {2},
pages = {698--712},
title = {{Nonconvergence to unstable points in urn models and stochastic approximations}},
volume = {18},
year = {1990}
}
@article{Feldman2011,
author = {Feldman, Vitaly},
journal = {arXiv preprint arXiv:1103.4904},
pages = {1--14},
title = {{Distribution-independent evolvability of linear threshold functions}},
url = {http://arxiv.org/abs/1103.4904},
year = {2011}
}
@article{Yoshida|2000|,
abstract = {We study how the internal structure of dark halos is affected if Cold
Dark Matter particles are assumed to have a large cross-section for
elastic collisions. We identify a cluster halo in a large cosmological
N-body simulation and resimulate its formation with progressively
increasing resolution. We compare the structure found in the two
cases where dark matter is treated as collisionless or as a fluid.
For the collisionless case the overall ellipticity of the cluster,
the central density cusp and the amount of surviving substructure
are all similar to those found in earlier high resolution simulations.
Collisional dark matter results in a cluster which is more nearly
spherical at all radii, has a steeper central density cusp, and has
less, but still substantial surviving substructure. As in the colisionless
case, these results for a {\"{i}}¾“fluid{\"{i}}¾” cluster halo are expected to
carry over approximately to smaller mass systems. The observed rotation
curves of dwarf galaxies then argue that self-interacting dark matter
can only be viable if intermediate cross-sections produce structure
which does not lie between the extremes we have simulated.},
author = {Yoshida, N and Springel, V and White, S D M},
journal = {arXiv},
keywords = {astrophysics,clumpiness,dark matter,halos structure,interaction,physics,simulation,strongly interacting dark matter},
pages = {2362},
title = {{Collisional Dark Matter and the Structure of Dark Halos}},
volume = {astro-ph}
}
@article{HWFT04,
author = {Hsu, A and Woolley, S and Fremouw, T and Theunissen, F},
journal = {Journal of Neuroscience},
pages = {9201--9221},
title = {{Modulation and phase spectrum of natural sounds enhance neural discrimination performed by single auditory neurons}},
volume = {24},
year = {2004}
}
@article{KAU88,
author = {Kautz, R},
journal = {Physical Review A},
pages = {2066--2080},
title = {{Thermally Induced Escape: the Principle of Minimum Available Noise Energy}},
volume = {38},
year = {1988}
}
@article{Prezioso2015,
author = {Prezioso, M and Merrikh-Bayat, F and Hoskins, BD},
journal = {Nature},
title = {{Training and operation of an integrated neuromorphic network based on metal-oxide memristors}},
url = {http://www.nature.com/nature/journal/v521/n7550/abs/nature14441.html},
year = {2015}
}
@article{Field10,
author = {Field et al.},
journal = {Under review},
title = {{Mapping a Neural Circuit: A Complete Input-Output Diagram in the Primate Retina}},
year = {2010}
}
@article{Lars,
abstract = {Reservoir computing (RC) systems are powerful models for online computations on input sequences. They consist of a memoryless readout neuron that is trained on top of a randomly connected recurrent neural network. RC systems are commonly used in two flavors: with analog or binary (spiking) neurons in the recurrent circuits. Previous work indicated a fundamental difference in the behavior of these two implementations of the RC idea. The performance of an RC system built from binary neurons seems to depend strongly on the network connectivity structure. In networks of analog neurons, such clear dependency has not been observed. In this letter, we address this apparent dichotomy by investigating the influence of the network connectivity (parameterized by the neuron in-degree) on a family of network models that interpolates between analog and binary networks. Our analyses are based on a novel estimation of the Lyapunov exponent of the network dynamics with the help of branching process theory, rank measures that estimate the kernel quality and generalization capabilities of recurrent networks, and a novel mean field predictor for computational performance. These analyses reveal that the phase transition between ordered and chaotic network behavior of binary circuits qualitatively differs from the one in analog circuits, leading to differences in the integration of information over short and long timescales. This explains the decreased computational performance observed in binary circuits that are densely connected. The mean field predictor is also used to bound the memory function of recurrent circuits of binary neurons.},
author = {B{\"{u}}sing, L and Schrauwen, Benjamin and Legenstein, Robert and Lars, B},
doi = {10.1162/neco.2009.01-09-947},
issn = {1530-888X},
journal = {Neural computation},
keywords = {Algorithms,Animals,Computer Simulation,Memory,Neural Networks (Computer),Neurons,Time Factors},
number = {5},
pages = {1272--311},
pmid = {20028227},
title = {{Connectivity , Dynamics , and Memory in Reservoir Computing with Binary and Analog Neurons}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20028227 http://www.mitpressjournals.org/doi/abs/10.1162/neco.2009.01-09-947},
volume = {22},
year = {2010}
}
@article{VanRullen2003,
abstract = {The ventral visual pathway implements object recognition and categorization in a hierarchy of processing areas with neuronal selectivities of increasing complexity. The presence of massive feedback connections within this hierarchy raises the possibility that normal visual processing relies on the use of computational loops. It is not known, however, whether object recognition can be performed at all without such loops (i.e., in a purely feed-forward mode). By analyzing the time course of reaction times in a masked natural scene categorization paradigm, we show that the human visual system can generate selective motor responses based on a single feed-forward pass. We confirm these results using a more constrained letter discrimination task, in which the rapid succession of a target and mask is actually perceived as a distractor. We show that a masked stimulus presented for only 26 msec - and often not consciously perceived - can fully determine the earliest selective motor responses: The neural representations of the stimulus and mask are thus kept separated during a short period corresponding to the feed-forward "sweep." Therefore, feedback loops do not appear to be "mandatory" for visual processing. Rather, we found that such loops allow the masked stimulus to reverberate in the visual system and affect behavior for nearly 150 msec after the feed-forward sweep.},
author = {VanRullen, R and Koch, C},
doi = {10.1162/089892903321208141},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Attention,Attention: physiology,Discrimination Learning,Discrimination Learning: physiology,Feedback,Humans,Male,Pattern Recognition,Perceptual Masking,Perceptual Masking: physiology,Psychological,Psychological: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Spike time neural coding,Time,Visual,Visual Pathways,Visual Pathways: physiology,Visual: physiology},
mendeley-tags = {Spike time neural coding},
month = {feb},
number = {2},
pages = {209--217},
pmid = {12676058},
title = {{Visual selective behavior can be triggered by a feed-forward process.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12676058},
volume = {15},
year = {2003}
}
@article{RSS97,
author = {Ringach, D and G., Sapiro and Shapley, R},
journal = {Vision Research},
pages = {2455--2464},
title = {{A subspace reverse correlation technique for the study of visual neurons}},
volume = {37},
year = {1997}
}
@article{Semerjian2002,
abstract = {We revisit the derivation of the density of states of sparse random matrices. We derive a recursion relation that allows one to compute the spectrum of the matrix of incidence for finite trees that determines completely the low concentration limit. Using the iterative scheme introduced by Biroli and Monasson [J. Phys. A 32, L255 (1999)] we find an approximate expression for the density of states expected to hold exactly in the opposite limit of large but finite concentration. The combination of the two methods yields a very simple simple geometric interpretation of the tails of the spectrum. We test the analytic results with numerical simulations and we suggest an indirect numerical method to explore the tails of the spectrum.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0202406},
author = {Semerjian, Guilhem and Cugliandolo, Leticia F},
doi = {10.1088/0305-4470/35/23/303},
eprint = {0202406},
issn = {03054470},
journal = {Journal of Physics A: Mathematical and General},
keywords = {Condensed Matter},
month = {jun},
number = {23},
pages = {4837--4851},
primaryClass = {cond-mat},
title = {{Sparse random matrices: the eigenvalue spectrum revisited}},
url = {http://arxiv.org/abs/cond-mat/0202406},
volume = {35},
year = {2002}
}
@article{Duine2007,
author = {Duine, R. and N{\'{u}}{\~{n}}ez, a. and MacDonald, a.},
doi = {10.1103/PhysRevLett.98.056605},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {feb},
number = {5},
pages = {056605},
title = {{Thermally Assisted Current-Driven Domain-Wall Motion}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.98.056605},
volume = {98},
year = {2007}
}
@article{Bennett76,
author = {Bennett, C H},
journal = {Journal of Computational Physics},
pages = {245--268},
title = {{Efficient estimation of free energy divergences from {\{}M{\}}onte {\{}C{\}}arlo data}},
volume = {22},
year = {1976}
}
@article{marder2002modeling,
annote = {2010num5.8},
author = {Marder, E and Prinz, A A},
journal = {Bioessays},
number = {12},
pages = {1145--1154},
publisher = {Citeseer},
title = {{Modeling stability in neuron and network function: the role of activity in homeostasis}},
volume = {24},
year = {2002}
}
@article{Zhou,
author = {Zhou, Hongchao and Bruck, J},
title = {{On the Expressibility of Stochastic Switching Circuits}},
year = {2009}
}
@article{Chichilnisky2003,
author = {Chichilnisky, E J and Kalmar, R},
journal = {Journal of Neuroscience},
number = {17},
pages = {6681--6689},
title = {{Temporal resolution of ensemble visual motion signals in primate retina}},
volume = {23},
year = {2003}
}
@article{Adams2009,
address = {New York, New York, USA},
annote = {2011num44},
author = {Adams, Ryan Prescott and Murray, Iain and MacKay, D J C},
doi = {10.1145/1553374.1553376},
isbn = {9781605585161},
journal = {Proceedings of the 26th Annual International Conference on Machine Learning - ICML '09},
pages = {1--8},
publisher = {ACM Press},
title = {{Tractable nonparametric Bayesian inference in Poisson processes with Gaussian process intensities}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553376},
year = {2009}
}
@article{Bhattacharyya|2004|,
abstract = {Molecular profiling studies can generate abundance measurements for
thousands of transcripts, proteins, metabolites, or other species
in, for example, normal and tumor tissue samples. Treating such measurements
as features and the samples as labeled data points, sparse hyperplanes
provide a statistical methodology for classifying data points into
one of two categories (classification and prediction) and defining
a small subset of discriminatory features (relevant feature identification).
However, this and other extant classification methods address only
implicitly the issue of observed data being a combination of underlying
signals and noise. Recently, robust optimization has emerged as a
powerful framework for handling uncertain data explicitly. Here,
ideas from this field are exploited to develop robust sparse hyperplanes,
i.e., classification and relevant feature identification algorithms
that are resilient to variation in the data. Specifically, each data
point is associated with an explicit data uncertainty model in the
form of an ellipsoid parameterized by a center and covariance matrix.
The task of learning a robust sparse hyperplane from such data is
formulated as a second order cone program (SOCP). Gaussian and distribution-free
data uncertainty models are shown to yield SOCPs that are equivalent
to the SCOP based on ellipsoidal uncertainty. The real-world utility
of robust sparse hyperplanes is demonstrated via retrospective analysis
of breast cancer related transcript profiles. Data-dependent heuristics
are used to compute the parameters of each ellipsoidal data uncertainty
model. The generalization performance of a specific implementation,
designated {\"{i}}¾“robust Liknon,{\"{i}}¾” is better than its nominal counterpart.
Finally, the strengths and limitations of robust sparse hyperplanes
are discussed.},
annote = {This paper deals with hyperplane classification under uncertain data-points.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Bhattacharyya, C and Grate, L R and Jordan, M I and Ghaoui, L E L and Mian, I S},
journal = {Journal of computational biology},
keywords = {computational,high-dimensional data,linear programming,mathematics,molecular profiling,robust sparse hyperplanes,second-order cone program,two-class},
number = {6},
pages = {1073},
title = {{Robust Sparse Hyperplane Classifiers: Application to Uncertain Molecular Profiling Data}},
volume = {11}
}
@article{Gilbert1968,
author = {Gilbert, B},
journal = {Solid-State Circuits, IEEE Journal of},
number = {4},
title = {{A precise four-quadrant multiplier with subnanosecond response}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1049925},
year = {1968}
}
@article{HancockVoigt99,
author = {Hancock, K E and Voigt, H F},
journal = {Annals of Biomedical Engineering},
month = {jan},
number = {1},
pages = {73--87},
title = {{Wideband inhibition of dorsal cochlear nucleus type IV units in cat: a computational model}},
volume = {27},
year = {1999}
}
@article{Li2007a,
abstract = {Spontaneous synchronized bursts seem to play a key role in brain functions such as learning and memory. Still controversial is the characterization of spontaneous synchronized bursts in neuronal networks after learning training, whether depression or promotion. By taking advantages of the main features of the microelectrode array (MEA) technology (i.e. multisite recordings, stable and long-term coupling with the biological preparation), we analyzed changes of spontaneous synchronized bursts in cultured hippocampal neuronal networks after learning training. And for this purpose, a learning model at networking level on MEA system was constructed, and analysis of spontaneous synchronized burst activity modulation was presented. Preliminary results show that, the number of burst was increased by 154{\%}, burst duration was increased by 35{\%}, and the number of spikes per burst was increased by 124{\%}, while interburst interval decreased by 44{\%} with learning. In particular, correlation and synchrony of neuronal activities in networks were enhanced by 51{\%} and 36{\%}, respectively, with learning. In contrast, dynamic properties of neuronal networks were not changed much when the network was under "non-learning" condition. These results indicate that firing, association and synchrony of spontaneous bursts in neuronal networks were promoted by learning. Furthermore, from these observations, we are encouraged to think of a more engineered system based on in vitro hippocampal neurons, as a novel sensitive system for electrophysiological evaluations.},
author = {Li, Yanling and Zhou, Wei and Li, Xiangning and Zeng, Shaoqun and Liu, Man and Luo, Qingming},
doi = {10.1016/j.bios.2006.12.018},
issn = {0956-5663},
journal = {Biosensors {\&} bioelectronics},
keywords = {Animals,Cells,Cultured,Electric Stimulation,Hippocampus,Hippocampus: physiology,Learning,Microelectrodes,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Rats},
number = {12},
pages = {2976--2982},
pmid = {17240134},
title = {{Characterization of synchronized bursts in cultured hippocampal neuronal networks with learning training on microelectrode arrays.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17240134},
volume = {22},
year = {2007}
}
@inproceedings{Freestone2016,
author = {{D. R. Freestone, P. J. Karoly, D. Soudry, L. Kuhlmann}, M.Cook},
booktitle = {CNS},
title = {{Estimation, Data-driven neural models part I: state and parameter estimation}},
year = {2016}
}
@article{May1992,
author = {May, Received},
title = {and aging in disordered systems},
year = {1992}
}
@article{KK08,
author = {Koyama, S and Kass, R},
journal = {Neural Computation},
title = {{Spike Train Probability Models for Stimulus-Driven Leaky Integrate-and-Fire Neurons}},
volume = {In press},
year = {2008}
}
@article{Chacron05,
author = {Chacron, M},
journal = {Journal of Neurophysiology},
pages = {2933--2946},
title = {{Nonlinear Information Processing in a Model Sensory System}},
volume = {95},
year = {2005}
}
@article{Feizi,
abstract = {Neural networks have been used prominently in several machine learning and statistics appli-cations. In general, the underlying optimization of neural networks is non-convex which makes their performance analysis challenging. In this paper, we take a novel approach to this problem by asking whether one can constrain neural network weights to make its optimization landscape have good theoretical properties while at the same time, be a good approximation for the uncon-strained one. For two-layer neural networks, we provide affirmative answers to these questions by introducing Porcupine Neural Networks (PNNs) whose weight vectors are constrained to lie over a finite set of lines. We show that most local optima of PNN optimizations are global while we have a characterization of regions where bad local optimizers may exist. Moreover, our theo-retical and empirical results suggest that an unconstrained neural network can be approximated using a polynomially-large PNN.},
archivePrefix = {arXiv},
arxivId = {1710.02196},
author = {Feizi, Soheil and Javadi, Hamid and Zhang, Jesse and Tse, David},
eprint = {1710.02196},
file = {:C$\backslash$:/Users/Daniel/Downloads/1710.02196.pdf:pdf},
journal = {arXiv},
number = {Figure 1},
title = {{Porcupine Neural Networks: (Almost) All Local Optima are Global}},
url = {https://arxiv.org/pdf/1710.02196.pdf}
}
@article{Hochberg2012,
abstract = {Paralysis following spinal cord injury, brainstem stroke, amyotrophic lateral sclerosis and other disorders can disconnect the brain from the body, eliminating the ability to perform volitional movements. A neural interface system could restore mobility and independence for people with paralysis by translating neuronal activity directly into control signals for assistive devices. We have previously shown that people with long-standing tetraplegia can use a neural interface system to move and click a computer cursor and to control physical devices. Able-bodied monkeys have used a neural interface system to control a robotic arm, but it is unknown whether people with profound upper extremity paralysis or limb loss could use cortical neuronal ensemble signals to direct useful arm actions. Here we demonstrate the ability of two people with long-standing tetraplegia to use neural interface system-based control of a robotic arm to perform three-dimensional reach and grasp movements. Participants controlled the arm and hand over a broad space without explicit training, using signals decoded from a small, local population of motor cortex (MI) neurons recorded from a 96-channel microelectrode array. One of the study participants, implanted with the sensor 5 years earlier, also used a robotic arm to drink coffee from a bottle. Although robotic reach and grasp actions were not as fast or accurate as those of an able-bodied person, our results demonstrate the feasibility for people with tetraplegia, years after injury to the central nervous system, to recreate useful multidimensional control of complex devices directly from a small sample of neural signals.},
author = {Hochberg, Leigh R and Bacher, Daniel and Jarosiewicz, Beata and Masse, Nicolas Y and Simeral, John D and Vogel, Joern and Haddadin, Sami and Liu, Jie and Cash, Sydney S and van der Smagt, Patrick and Donoghue, John P},
doi = {10.1038/nature11076},
issn = {1476-4687},
journal = {Nature},
keywords = {Aged,Arm,Arm: physiology,Calibration,Drinking,Drinking: physiology,Female,Hand,Hand Strength,Hand Strength: physiology,Hand: physiology,Humans,Male,Man-Machine Systems,Microelectrodes,Middle Aged,Motor Cortex,Motor Cortex: cytology,Motor Cortex: physiology,Movement,Movement: physiology,Psychomotor Performance,Quadriplegia,Quadriplegia: physiopathology,Robotics,Robotics: instrumentation,Robotics: methods,Time Factors},
month = {may},
number = {7398},
pages = {372--5},
pmid = {22596161},
publisher = {Nature Publishing Group},
title = {{Reach and grasp by people with tetraplegia using a neurally controlled robotic arm.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22596161},
volume = {485},
year = {2012}
}
@article{Hoopen1963,
author = {Hoopen, M and Verveen, A A},
journal = {Brain},
keywords = {axon,neuron,neuron model,noise,response probability},
pages = {8--21},
title = {{Nerve-Model Experiments on Fluctuation in Excitability}},
year = {1963}
}
@article{Othmer|2005|,
author = {Othmer, J},
keywords = {markov,mathematics,metastability},
title = {{Metastability in Markovian Systems}}
}
@article{RIN76,
author = {Rinott, Y},
journal = {Annals of Probability},
pages = {1020--1026},
title = {{On convexity of measures}},
volume = {4},
year = {1976}
}
@article{Lazar2010a,
author = {Lazar, A A and Slutskiy, Y B},
journal = {NiPs},
pages = {1--9},
title = {{Identifying Dendritic Processing}},
url = {http://videolectures.net/site/normal{\_}dl/tag=82206/nips2010{\_}lazar{\_}idp{\_}01.pdf},
year = {2010}
}
@article{Sudhof2008a,
abstract = {Classical physiological work by Katz, Eccles, and others revealed the central importance of synapses in brain function, and characterized the mechanisms involved in synaptic transmission. Building on this work, major advances in the past two decades have elucidated how synapses work molecularly. In the present perspective, we provide a short description of our personal view of these advances, suggest a series of important future questions about synapses, and discuss ideas about how best to achieve further progress in the field.},
author = {S{\"{u}}dhof, TC Thomas C and Malenka, RC Robert C and Su, Thomas C},
doi = {10.1016/j.neuron.2008.10.011},
issn = {1097-4199},
journal = {Neuron},
keywords = {AMPA,AMPA: metabolism,Brain,Brain: physiology,Calcium,Calcium: metabolism,Dendrites,Dendrites: metabolism,Dendrites: ultrastructure,Endocannabinoids,Endocannabinoids: metabolism,Humans,Learning,Learning: physiology,Membrane Fusion,Membrane Fusion: physiology,Memory,Memory: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurosciences,Neurotransmitter Agents,Neurotransmitter Agents: metabolism,Receptors,Signal Transduction,Signal Transduction: physiology,Synapses,Synapses: physiology,Synapses: ultrastructure,Synaptic Transmission,Synaptic Transmission: physiology,Synaptic Vesicles,Synaptic Vesicles: metabolism,Synaptotagmins,Synaptotagmins: metabolism},
number = {3},
pages = {469--476},
pmid = {18995821},
title = {{Understanding synapses: past, present, and future}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18995821 http://www.sciencedirect.com/science/article/pii/S0896627308008842},
volume = {60},
year = {2008}
}
@article{Golea1993,
author = {Golea, Mostefa and Marchand, Mario},
doi = {10.1162/neco.1993.5.5.767},
issn = {0899-7667},
journal = {Neural Computation},
month = {sep},
number = {5},
pages = {767--782},
title = {{On Learning Perceptrons with Binary Weights}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1993.5.5.767},
volume = {5},
year = {1993}
}
@phdthesis{FarivarPhd,
author = {Farivar, S},
school = {Caltech},
title = {{Cytoarchitecture of the locust olfactory system}},
year = {2005}
}
@inproceedings{Socher2010,
author = {Socher, R and Manning, C D and Ng, A Y},
booktitle = {NIPS-2010 Deep Learning and Unsupervised Feature Learning Workshop},
pages = {1--9},
title = {{Learning continuous phrase representations and syntactic parsing with recursive neural networks}},
url = {http://nlp.stanford.edu/pubs/2010SocherManningNg.pdf},
year = {2010}
}
@article{Niebur07,
author = {Niebur, Ernst},
journal = {Neural Computation},
number = {7},
pages = {1720--1738},
title = {{Generation of Synthetic Spike Trains with Defined Pairwise Correlations}},
volume = {19},
year = {2007}
}
@article{Bloom73,
author = {Bloom, D},
journal = {The American Mathematical Monthly},
pages = {1141--1142},
title = {{A birthday problem}},
volume = {80},
year = {1973}
}
@book{VW96,
address = {New York},
author = {van der Vaart, A and Wellner, J},
publisher = {Springer-Verlag},
title = {{Weak convergence and empirical processes}},
year = {1996}
}
@article{Paninski2004,
author = {Paninski, L},
doi = {10.1088/0954-898X/15/4/002},
issn = {0954-898X},
journal = {Network: Computation in Neural Systems},
month = {nov},
number = {4},
pages = {243--262},
title = {{Maximum likelihood estimation of cascade point-process neural encoding models}},
url = {http://www.informaworld.com/openurl?genre=article{\&}doi=10.1088/0954-898X/15/4/002{\&}magic=crossref{\%}7C{\%}7CD404A21C5BB053405B1A640AFFD44AE3},
volume = {15},
year = {2004}
}
@article{WilsonMcNaughton93,
author = {Wilson, M A and McNaughton, B L},
journal = {Science},
month = {aug},
number = {5124},
pages = {1055--1058},
title = {{Dynamics of the hippocampal ensemble code for space}},
volume = {261},
year = {1993}
}
@article{REN61,
author = {Renyi, A},
journal = {Proc. 4th Berk. Symp. Math. Stat. and Prob.},
pages = {547--561},
title = {{On measures of entropy and information}},
volume = {1},
year = {1961}
}
@article{DH02,
author = {Dodd, T and Harris, C},
journal = {International Journal of Systems Science},
pages = {737--750},
title = {{Identification of nonlinear time series via kernels}},
volume = {33},
year = {2002}
}
@article{Ward2007,
author = {Ward, Lawrence and Greenwood, Priscilla},
doi = {10.4249/scholarpedia.1537},
issn = {1941-6016},
journal = {Scholarpedia},
month = {dec},
number = {12},
pages = {1537},
title = {1/f noise},
url = {http://www.scholarpedia.org/article/1/f{\_}noise},
volume = {2},
year = {2007}
}
@inproceedings{Simard2003,
address = {Edinburgh},
author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
booktitle = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
doi = {10.1109/ICDAR.2003.1227801},
isbn = {0-7695-1960-1},
month = {aug},
number = {Icdar},
pages = {958--963},
publisher = {IEEE Comput. Soc},
title = {{Best practices for convolutional neural networks applied to visual document analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227801},
volume = {1},
year = {2003}
}
@article{Xu2010,
abstract = {The cerebral cortex has diverse types of inhibitory neurons. In rat cortex, past research has shown that parvalbumin (PV), somatostatin (SOM), calretinin (CR), and cholecystokinin (CCK) label four distinct chemical classes of GABAergic interneurons. However, in contrast to rat cortex, previous studies indicate that there is significant colocalization of SOM and CR in mouse cortical inhibitory neurons. In the present study we further characterized immunochemical distinctions among mouse inhibitory cortical neurons by double immunochemical labeling with chemical markers. We found that, PV, SOM, and vasointenstinal peptide (VIP) reliably identify three nonoverlapping distinct subpopulations, as there was no overlap of immunoreactivity between PV and all the other chemical markers tested, and SOM and VIP did not show any overlap in labeled neurons in all the cortical areas. In comparison, there was significant overlap in combinations of other chemical markers. With some laminar and regional variations, the average overlap of SOM/CR (percentage of SOM+ cells expressing CR) and SOM/neuropeptide tyrosine (NPY) across all examined layers and cortical regions was 21.6{\%} and 7.1{\%}, respectively. The average overlap of VIP/CR, VIP/NPY, and CR/NPY was 34.2{\%}, 9.5{\%}, and 10{\%}, respectively. We quantified and assessed the percentages of marker-positive GABAergic cells, and showed that the nonoverlapping subpopulations (i.e., PV+, SOM+ and VIP+ cells) accounted for about 60{\%} of the GABAergic cell population. Taken together, our data reveal important chemical distinctions between mouse inhibitory cortical neurons and indicate that PV, SOM, and VIP can differentially label a majority of mouse inhibitory cortical neurons.},
author = {Xu, Xiangmin and Roby, Keith D and Callaway, Edward M},
doi = {10.1002/cne.22229},
file = {::},
issn = {1096-9861},
journal = {The Journal of comparative neurology},
keywords = {Animals,Biological Markers,Brain Chemistry,Brain Chemistry: physiology,Calbindin 2,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: metabolism,Glutamate Decarboxylase,Glutamate Decarboxylase: genetics,Green Fluorescent Proteins,Green Fluorescent Proteins: genetics,Immunohistochemistry,Interneurons,Interneurons: classification,Interneurons: cytology,Interneurons: metabolism,Mice,Mice, Inbred C57BL,Mice, Transgenic,Neural Inhibition,Neural Inhibition: physiology,Neuropeptide Y,Neuropeptide Y: metabolism,Neuropeptides,Neuropeptides: metabolism,Parvalbumins,Parvalbumins: metabolism,Phenotype,Recombinant Fusion Proteins,Recombinant Fusion Proteins: genetics,S100 Calcium Binding Protein G,S100 Calcium Binding Protein G: metabolism,Somatostatin,Somatostatin: metabolism,Synaptic Transmission,Synaptic Transmission: physiology,Vasoactive Intestinal Peptide,Vasoactive Intestinal Peptide: metabolism,gamma-Aminobutyric Acid,gamma-Aminobutyric Acid: metabolism},
month = {feb},
number = {3},
pages = {389--404},
pmid = {19950390},
title = {{Immunochemical characterization of inhibitory mouse cortical neurons: three chemically distinct classes of inhibitory cells.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2804902{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {518},
year = {2010}
}
@article{NelkenKimYoung97,
author = {Nelken, I and Kim, P J and Young, E D},
journal = {Journal of Neurophysiology},
month = {aug},
number = {2},
pages = {800--811},
title = {{Linear and nonlinear spectral integration in type IV neurons of the dorsal cochlear nucleus II Predicting responses with the use of nonlinear models}},
volume = {78},
year = {1997}
}
@article{Card,
author = {Card, H and McNeill, D.K.},
doi = {10.1109/CCECE.1996.548067},
isbn = {0-7803-3143-5},
journal = {Proceedings of 1996 Canadian Conference on Electrical and Computer Engineering},
pages = {182--185},
publisher = {Ieee},
title = {{On-chip learning in neurocomputers}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=548067},
volume = {1}
}
@article{FS98,
author = {Friedman, N and Singer, Y},
journal = {NIPS},
title = {{Efficient Bayesian Parameter Estimation in Large Discrete Domains}},
year = {1998}
}
@article{Shuryak|1980|,
abstract = {At high enough density and/or temperature ordinary matter undergoes
a transition into a plasma-like phase, consisting ofquarks and gluons
rather than of separate hadrons. Due to asymptotic freedom, the asymptotic
properties of such matter can be calculated perturbatively, while
in the discussion of phase transitions one should concentrate on
nonperturbative effects. Recent progress in this theory is reviewed,
as well as its applications to such topics as hadronic structure{\~{}}neutron
stars{\~{}}high energy collisions of hadrons, etc.},
annote = {Seminal review of QCD for 1980.},
author = {Shuryak, E V},
journal = {Physics Reports},
keywords = {QCD,physics,quantum field theory},
number = {2},
pages = {71},
title = {{Quantum Chromodynamics and the theory of superdense matter}},
volume = {61}
}
@article{Hood2000,
abstract = {With the multifocal technique, as developed by Erich Sutter and colleagues, scores of focal electroretinogram (ERG) responses can be obtained in a matter of minutes. Although this technique is relatively new, it has already provided insights into the mechanisms of retinal disease. However, because it is new, there also remain questions about how it works and what it measures. This chapter considers some of these insights and some of these questions. The first part (Section 2) describes how the multifocal ERG (mERG) is recorded and considers its relationship to the full-field ERG. The mERG responses are shown to be from relatively local regions of the retina and are comprised of the same components as the full-field ERG. The diagnostic advantage of the mERG as compared to the full-field ERG is also illustrated. In Section 3, the effects of damage to different cell layers of the retina are shown to affect the mERG differently, and these changes are summarized within a conceptual framework. It is argued, for example, that when diseases of the receptor outer segment, like retinitis pigmentosa, result in small, depressed mERG responses, then the damage is, as expected, at the outer segment. However, when these diseases result in mERG responses that are reasonably large but very delayed, then the damage is beyond the outer segment, probably in the outer plexiform layer. The implicit time of the mERG, not amplitude, is the more sensitive measure of damage in degenerative diseases of the receptors. On the other hand, diseases, like glaucoma, which act on the ganglion axon, do not result in easily identified changes to the mERG unless inner retinal damage is involved as well. Inner retinal damage changes the waveform of the mERG and decreases the naso-temporal variation normally observed. Finally, diseases, like diabetes, that act on more than one layer of the retina can have a range of effects. In Section 4, recent work with the monkey mERG is reviewed, with emphasis on the relevance to human diseases. For example, blocking the sodium-based action potentials produced by ganglion and amacrine cells eliminates the naso-temporal variation in the monkey mERG and these altered mERG responses resemble those from some patients with diabetes or glaucoma. Finally, in Section 5 the second-order kernel is described. The presence of a second-order kernel has important implications for understanding the shape of the mERG response (first-order kernel). Full-field simulations of the mERG paradigm illustrate that the first-order kernel is comprised of responses with different waveforms. Further, it is argued that the nonlinear, adaptive mechanisms that produce the second-order kernel are involved in shaping the time course of the response. Patients with large, but abnormally delayed mERG responses (first-order kernel), do not have a detectable second-order kernel. It is speculated that a markedly diminished second-order kernel is diagnostic of outer plexiform layer damage, not inner plexiform layer damage as is commonly assumed.},
author = {Hood, D C},
issn = {1350-9462},
journal = {Progress in retinal and eye research},
keywords = {Animals,Electroretinography,Electroretinography: methods,Haplorhini,Haplorhini: physiology,Humans,Retina,Retina: physiology,Retinal Diseases,Retinal Diseases: diagnosis,Retinal Diseases: pathology,Retinal Diseases: physiopathology},
month = {sep},
number = {5},
pages = {607--46},
pmid = {10925245},
title = {{Assessing retinal function with the multifocal technique.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10925245},
volume = {19},
year = {2000}
}
@article{Saxe2013,
abstract = {Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.},
archivePrefix = {arXiv},
arxivId = {1312.6120},
author = {Saxe, A M and McClelland, J L. and Ganguli, S},
eprint = {1312.6120},
journal = {ICLR},
title = {{Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.}},
url = {http://arxiv.org/abs/1312.6120},
year = {2014}
}
@book{SM91,
author = {Snyder, D and Miller, M},
publisher = {Springer-Verlag},
title = {{Random Point Processes in Time and Space}},
year = {1991}
}
@inproceedings{Shababo2013,
author = {Shababo, B and Brooks, P and Pakman, A and Paninski, L},
booktitle = {Neural Information Processing Systems},
pages = {1--9},
title = {{Bayesian inference and online experimental design for mapping neural microcircuits}},
year = {2013}
}
@article{FlusbergSchnitzer05b,
abstract = {We introduce a compact two-photon fluorescence microendoscope based

on a compound gradient refractive index endoscope probe, a DC micromotor

for remote adjustment of the image plane, and a flexible photonic

bandgap fiber for near distortion-free delivery of ultrashort excitation

pulses. The imaging head has a mass of only 3.9 g and provides micrometer-scale

resolution. We used portable two-photon microendoscopy to visualize

hippocampal blood vessels in the brains of live mice.},
author = {Flusberg, Benjamin A and Jung, Juergen C and Cocker, Eric D and Anderson, Erik P and Schnitzer, Mark J},
journal = {Opt Lett},
keywords = {Animals; Endoscopes; Equipment Design; Equipment F,Fluorescence,Multiphoton; Miniaturization},
month = {sep},
number = {17},
pages = {2272--2274},
pmid = {16190441},
title = {{In vivo brain imaging using a portable 3.9 gram two-photon fluorescence microendoscope.}},
volume = {30},
year = {2005}
}
@incollection{LorentedeNo49,
author = {de No, R},
booktitle = {Physiology of the Nervous System},
pages = {228--330},
publisher = {Oxford University Press},
title = {{Cerebral Cortex: Architecture, intracortical connections, motor projections}},
year = {1949}
}
@book{Tuck89,
author = {Tuckwell, H},
publisher = {SIAM},
title = {{Stochastic Processes in the Neurosciences}},
year = {1989}
}
@article{CS02,
author = {Cucker, F and Smale, S},
journal = {Bulletins of the American Mathematical Society},
pages = {1--49},
title = {{On the mathematical foundations of learning}},
volume = {39},
year = {2002}
}
@article{CandesTao10,
author = {Cand{\`{e}}s, Emmanuel J and Tao, Terence},
journal = {IEEE Transactions on Information Theory},
pages = {2053--2080},
title = {{The power of convex relaxation: near-optimal matrix completion}},
volume = {56},
year = {2010}
}
@article{Plaxton|2003|,
annote = {The presentation discusses probabilistic approximation of metric{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}spaces by tree metrics and their use for solving buy-at-bulk cost-distance{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}problem. Best approximation to cost-distance problem is mentioned.},
author = {Plaxton, G},
keywords = {buy-at-bulk,continuous networks,cost-distance,distance,internet,metric,network metrics,networks,tree-metrics},
title = {{Metric Spaces: Buy-at-Bulk Network Design}}
}
@article{Bouchaud1990a,
author = {Bouchaud, J P and Comtet, A and Georges, A and {Le Doussal}, P and Ledoussal, P},
doi = {10.1016/0003-4916(90)90043-N},
issn = {00034916},
journal = {Annals of Physics},
month = {aug},
number = {2},
pages = {285--341},
title = {{Classical diffusion of a particle in a one-dimensional random force field}},
url = {http://linkinghub.elsevier.com/retrieve/pii/000349169090043N},
volume = {201},
year = {1990}
}
@article{Szymanski2008,
author = {Szymanski, BK and Chen, GG},
doi = {10.1093/comjnl/bxm109},
journal = {The Computer Journal},
keywords = {computing paradigm,neural network,received 14 november 2007,revised 14 november 2007,routing,sensor network},
title = {{Computing with time: from neural networks to sensor networks}},
url = {http://comjnl.oxfordjournals.org/content/51/4/511.short},
year = {2008}
}
@article{Fusi2000,
author = {Fusi, Stefano and Annunziato, M and Badoni, D},
journal = {Neural Computation},
pages = {2227--2258},
title = {{Spike-driven synaptic plasticity: theory, simulation, VLSI implementation}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976600300014917},
volume = {2258},
year = {2000}
}
@article{Thiruvarudchelvan2012,
author = {Thiruvarudchelvan, Vaenthan and Bossomaier, Terry},
doi = {10.1109/IJCNN.2012.6252368},
isbn = {978-1-4673-1490-9},
journal = {The 2012 International Joint Conference on Neural Networks (IJCNN)},
month = {jun},
pages = {1--8},
publisher = {Ieee},
title = {{Towards realtime stance classification by spiking neural network}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6252368},
year = {2012}
}
@article{Sutton2012,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
author = {Sutton, Richard S and Barto, Andrew G},
doi = {10.1109/MED.2013.6608833},
isbn = {0262193981},
issn = {18726240},
journal = {Learning},
title = {{Reinforcement learning}},
url = {http://incompleteideas.net/sutton/book/the-book.html{\%}5Cnhttps://www.dropbox.com/s/f4tnuhipchpkgoj/book2012.pdf},
volume = {3},
year = {2012}
}
@article{Bapat1985,
abstract = {Suppose A, D1,{\ldots},Dm are n × n matrices where A is self-adjoint, and let X = $\Sigma$mk = 1DkAD∗k. It is shown that if $\Sigma$DkD∗k = $\Sigma$D∗ kDk = I, then the spectrum of X is majorized by the spectrum of A. In general, without assuming any condition on D1,{\ldots},Dm, a result is obtained in terms of weak majorization. If each Dk is a diagonal matrix, then X is equal to the Schur (entrywise) product of A with a positive semidefinite matrix. Thus the results are applicable to spectra of Schur products of positive semidefinite matrices. If A, B are self-adjoint with B positive semidefinite and if bii = 1 for each i, it follows that the spectrum of the Schur product of A and B is majorized by that of A. A stronger version of a conjecture due to Marshall and Olkin is also proved.},
author = {Bapat, R.B. and Sunder, V.S.},
doi = {10.1016/0024-3795(85)90147-8},
file = {::},
issn = {00243795},
journal = {Linear Algebra and its Applications},
month = {dec},
pages = {107--117},
title = {{On majorization and Schur products}},
url = {http://www.sciencedirect.com/science/article/pii/0024379585901478},
volume = {72},
year = {1985}
}
@article{Markram1998,
abstract = {The nature of information stemming from a single neuron and conveyed simultaneously to several hundred target neurons is not known. Triple and quadruple neuron recordings revealed that each synaptic connection established by neocortical pyramidal neurons is potentially unique. Specifically, synaptic connections onto the same morphological class differed in the numbers and dendritic locations of synaptic contacts, their absolute synaptic strengths, as well as their rates of synaptic depression and recovery from depression. The same axon of a pyramidal neuron innervating another pyramidal neuron and an interneuron mediated frequency-dependent depression and facilitation, respectively, during high frequency discharges of presynaptic action potentials, suggesting that the different natures of the target neurons underlie qualitative differences in synaptic properties. Facilitating-type synaptic connections established by three pyramidal neurons of the same class onto a single interneuron, were all qualitatively similar with a combination of facilitation and depression mechanisms. The time courses of facilitation and depression, however, differed for these convergent connections, suggesting that different pre-postsynaptic interactions underlie quantitative differences in synaptic properties. Mathematical analysis of the transfer functions of frequency-dependent synapses revealed supra-linear, linear, and sub-linear signaling regimes in which mixtures of presynaptic rates, integrals of rates, and derivatives of rates are transferred to targets depending on the precise values of the synaptic parameters and the history of presynaptic action potential activity. Heterogeneity of synaptic transfer functions therefore allows multiple synaptic representations of the same presynaptic action potential train and suggests that these synaptic representations are regulated in a complex manner. It is therefore proposed that differential signaling is a key mechanism in neocortical information processing, which can be regulated by selective synaptic modifications.},
author = {Jolla, La and Markram, H and Wang, Y and Tsodyks, M},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Animals,Brain Mapping,Interneurons,Interneurons: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Somatosensory Cortex,Synapses,Synapses: ultrastructure,Synaptic Transmission,Wistar,synapse},
mendeley-tags = {synapse},
number = {9},
pages = {5323--8},
pmid = {9560274},
title = {{Differential signaling via the same axon of neocortical pyramidal neurons.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=20259{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {95},
year = {1998}
}
@article{Maneva2007,
author = {Maneva, Elitza and Mossel, Elchanan and Wainwright, Martin J.},
doi = {10.1145/1255443.1255445},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {Message passing},
mendeley-tags = {Message passing},
month = {jul},
number = {4},
pages = {17--es},
title = {{A new look at survey propagation and its generalizations}},
url = {http://portal.acm.org/citation.cfm?doid=1255443.1255445},
volume = {54},
year = {2007}
}
@article{VIC02,
author = {Victor, J},
journal = {Physical Review E},
pages = {51903--51918},
title = {{Binless strategies for estimation of information from neural data}},
volume = {66},
year = {2002}
}
@article{Pillow2006,
author = {Pillow, J W and Simoncelli, E P},
journal = {Journal of Vision},
pages = {414--428},
title = {{Dimensionality reduction in neural models: An information-theoretic generalization of spike-triggered average and covariance analysis}},
volume = {6},
year = {2006}
}
@article{Schottky,
author = {Schottky, Bernhard and Saad, D},
journal = {Journal of Physics A: Mathematical and {\ldots}},
title = {{Statistical mechanics of EKF learning in neural networks}},
url = {http://iopscience.iop.org/0305-4470/32/9/009},
volume = {1605},
year = {1999}
}
@article{CAR69,
author = {Carlton, A},
journal = {Psychological Bulletin},
pages = {108--109},
title = {{On the bias of information estimates}},
volume = {71},
year = {1969}
}
@article{Hunter1982,
annote = {Eq. 4.13 for the stationary distriubtion is quite simple},
author = {Hunter, J J},
journal = {Linear Algebra and Its Applications},
keywords = {stationary distribution},
mendeley-tags = {stationary distribution},
pages = {157--198},
publisher = {Elsevier},
title = {{Generalized inverses and their application to applied probability problems}},
url = {http://www.sciencedirect.com/science/article/pii/002437958290218X},
volume = {45},
year = {1982}
}
@article{Gross|2006|,
abstract = {We present a universal approach to the investigation of the dynamics
in generalized models. In these models the processes that are taken
into account are not restricted to specific functional forms. Therefore
a single generalized models can describe a class of systems which
share a similar structure. Despite this generality, the proposed
approach allows us to study the dynamical properties of generalized
models efficiently in the framework of local bifurcation theory.
The approach is based on a normalization procedure that is used to
identify natural parameters of the system. The Jacobian in a steady
state is then derived as a function of these parameters. The analytical
computation of local bifurcations using computer algebra reveals
conditions for the local asymptotic stability of steady states and
provides certain insights on the global dynamics of the system. The
proposed approach yields a close connection between modelling and
nonlinear dynamics. We illustrate the investigation of generalized
models by considering examples from three different disciplines of
science: a socioeconomic model of dynastic cycles in china, a model
for a coupled laser system and a general ecological food web.},
author = {Gross, T and Feudel, U},
journal = {Physical review E},
keywords = {complex systems,dynamical systems,mathematics,models,nonlinear,physics},
pages = {16205},
title = {{Generalized models as a universal approach to the analysis of nonlinear dynamical systems}},
volume = {73}
}
@article{Models1998a,
author = {Models, Kinetic and Synaptic, O F},
pages = {1--25},
title = {{1 Introduction : the kinetic interpretation of ion channel gating}},
year = {1998}
}
@article{Universily1966,
abstract = {This paper is concerned with the properties of convex cones and their dual cones generated by points randomly distributed on the surface of a d-sphere. For radially symmetric distributions on the points, the expected number of k-faces and natural measure of the set of k-faces will be found. The expected number of vertices, or extreme points, of convex hulls of random points in E2 and E3 has been investigated by R{\'{e}}nyi and Sulanke [4] and Efron [2]. In general these results depend critically on the distribution of the points. However, for points on a sphere, the situation is much simpler. Except for a requirement of radial symmetry of the distribution on the points, the properties developed in this paper will be distribution-free. (This lack of dependence on the underlying distribution suggests certain simple nonparametric tests for radial symmetry--we shall not pursue this matter here, however.) Our approach is combinatorial and geometric, involving the systematic description of the partitioning of Ed by N hyperplanes through the origin. After a series of theorems counting the number of faces of cones and their duals, we are led to Theorem 5 and its probabilistic counterpart Theorem 2', the primary result of this paper, in which the expected solid angle is found of the convex cone spanned by N random vectors in Ed.},
author = {Cover, T M and Efron, B},
doi = {DOI 10.1214/aoms/1177699073},
isbn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
number = {1},
pages = {213--220},
title = {{Geometrical Probability and Random Points on a Hypersphere}},
url = {http://www.jstor.org/stable/2238884{\%}5Cnpapers2://publication/uuid/0171A898-D373-40B6-BA60-091777FA5305},
volume = {38},
year = {1967}
}
@article{CornelisseMansvelder07,
abstract = {Rapid calcium concentration changes in postsynaptic structures are

crucial for synaptic plasticity. Thus far, the determinants of postsynaptic

calcium dynamics have been studied predominantly based on the decay

kinetics of calcium transients. Calcium rise times in spines in response

to single action potentials (AP) are almost never measured due to

technical limitations, but they could be crucial for synaptic plasticity.

With high-speed, precisely-targeted, two-photon point imaging we

measured both calcium rise and decay kinetics in spines and secondary

dendrites in neocortical pyramidal neurons. We found that both rise

and decay kinetics of changes in calcium-indicator fluorescence are

about twice as fast in spines. During AP trains, spine calcium changes

follow each AP, but not in dendrites. Apart from the higher surface-to-volume

ratio (SVR), we observed that neocortical dendritic spines have a

markedly smaller endogenous buffer capacity with respect to their

parental dendrites. Calcium influx time course and calcium extrusion

rate were both in the same range for spines and dendrites when fitted

with a dynamic multi-compartment model that included calcium binding

kinetics and diffusion. In a subsequent analysis we used this model

to investigate which parameters are critical determinants in spine

calcium dynamics. The model confirmed the experimental findings:

a higher SVR is not sufficient by itself to explain the faster rise

time kinetics in spines, but only when paired with a lower buffer

capacity in spines. Simulations at zero calcium-dye conditions show

that calmodulin is more efficiently activated in spines, which indicates

that spine morphology and buffering conditions in neocortical spines

favor synaptic plasticity.},
author = {Cornelisse, L Niels and van Elburg, Ronald A J and Meredith, Rhiannon M and Yuste, R and Mansvelder, Huibert D},
doi = {10.1371/journal.pone.0001073},
institution = {Department of Experimental Neurophysiology, Centre for Neurogenomics and Cognitive Research (CNCR), Vrije Universiteit Amsterdam, Amsterdam, The Netherlands.},
journal = {PLoS ONE},
number = {10},
pages = {e1073},
pmid = {17957255},
title = {{High speed two-photon imaging of calcium dynamics in dendritic spines: consequences for spine calcium kinetics and buffer capacity.}},
url = {http://dx.doi.org/10.1371/journal.pone.0001073},
volume = {2},
year = {2007}
}
@article{IzhikevichEdelman04,
annote = {Evaluation Studies},
author = {Izhikevich, Eugene M and Gally, Joseph A and Edelman, Gerald M},
journal = {Cerebral Cortex},
month = {aug},
number = {8},
pages = {933--944},
title = {{Spike-timing dynamics of neuronal groups}},
volume = {14},
year = {2004}
}
@article{Brainbow07,
author = {Livet, J and Weissman, T A and Kang, H and Draft, R W and Lu, J and Bennis, R A and Sanes, J R and Lichtman, J W},
journal = {Nature},
pages = {56--62},
title = {{Transgenic strategies for combinatorial expression of fluorescent proteins in the nervous system.}},
volume = {450},
year = {2007}
}
@article{Steriade2004,
annote = {2010IInum12.40},
author = {Steriade, M},
doi = {10.1038/nrn1325},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {1/f noise,Action Potentials,Action Potentials: physiology,Animals,Biological Clocks,Biological Clocks: physiology,Humans,Neocortex,Neocortex: cytology,Neocortex: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: classification,Neurons: cytology,Neurons: physiology,Sleep,Sleep: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Wakefulness,Wakefulness: physiology},
mendeley-tags = {1/f noise},
month = {feb},
number = {2},
pages = {121--34},
pmid = {14735115},
title = {{Neocortical cell classes are flexible entities.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14735115},
volume = {5},
year = {2004}
}
@article{Ames2000a,
abstract = {Large amounts of energy are required to maintain the signaling activities of CNS cells. Because of the fine-grained heterogeneity of brain and the rapid changes in energy demand, it has been difficult to monitor rates of energy generation and consumption at the cellular level and even more difficult at the subcellular level. Mechanisms to facilitate energy transfer within cells include the juxtaposition of sites of generation with sites of consumption and the transfer of approximately P by the creatine kinase/creatine phosphate and the adenylate kinase systems. There is evidence that glycolysis is separated from oxidative metabolism at some sites with lactate becoming an important substrate. Carbonic anhydrase may play a role in buffering activity-induced increases in lactic acid. Relatively little energy is used for 'vegetative' processes. The great majority is used for signaling processes, particularly Na(+) transport. The brain has very small energy reserves, and the margin of safety between the energy that can be generated and the energy required for maximum activity is also small. It seems probable that the supply of energy may impose a limit on the activity of a neuron under normal conditions. A number of mechanisms have evolved to reduce activity when energy levels are diminished.},
author = {Ames, A},
journal = {Brain research. Brain research reviews},
keywords = {Adenosine Triphosphate,Adenosine Triphosphate: metabolism,Animals,Brain,Brain: cytology,Brain: metabolism,Brain: physiology,Carbonic Anhydrases,Carbonic Anhydrases: physiology,Energy Metabolism,Guanosine Triphosphate,Guanosine Triphosphate: physiology,Humans,Lactic Acid,Lactic Acid: metabolism,Neurons,Neurons: metabolism,Oxygen,Oxygen: metabolism},
month = {nov},
number = {1-2},
pages = {42--68},
pmid = {11086186},
title = {{CNS energy metabolism as related to function.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11086186},
volume = {34},
year = {2000}
}
@article{Sompolinsky1990,
author = {Sompolinsky, H and Tishby, N and Seung, H S},
journal = {Physical Review Letters},
title = {{Learning from examples in large neural networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.65.1683},
year = {1990}
}
@article{ReidAlonso95,
author = {Reid, R and Alonso, J.-M.},
journal = {Nature},
pages = {281--284},
title = {{Specificity of monosynaptic connections from thalamus to visual cortex}},
volume = {378},
year = {1995}
}
@article{SIMM79,
author = {Simmons, J},
journal = {Science},
pages = {1336--1338},
title = {{Perception of echo phase in bat sonar}},
volume = {204},
year = {1979}
}
@article{Felkel|2001|,
abstract = {In this paper, we describe the results of the literature review focused
on the peripheral vessel segmentation in 3D medical datasets, acquired
by Computer tomography angiography (CTA) of the human leg. The fundamental
aim of such a segmentation task is a robust method for the detection
of main vessels in the leg that simultaneously preserves the vessel
calcification (the sediment is called plaque) and allows localization
of vessel narrowings (called stenoses). This segmentation has to
be free from artifacts, i.e., without false detections of stenoses
and without false omitting of any stenotic part. The paper collects
seven methods applicable for vessel segmentation.},
author = {Felkel, P and Wegenkittl, R and Kanitsar, A},
keywords = {computational,image processing,pipes,vessel tracking},
title = {{Vessel Tracking in Peripheral CTA Datasets - An Overview}}
}
@article{Lichtsteiner2008,
author = {Lichtsteiner, P and Posch, C and Delbruck, T},
journal = {Solid-State Circuits, IEEE {\ldots}},
number = {2},
pages = {566--576},
title = {{A 128 X 128 120 dB 15 microsecond latency asynchronous temporal contrast vision sensor}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4444573},
volume = {43},
year = {2008}
}
@article{Baldassi2007a,
abstract = {Recent experimental studies indicate that synaptic changes induced by neuronal activity are discrete jumps between a small number of stable states. Learning in systems with discrete synapses is known to be a computationally hard problem. Here, we study a neurobiologically plausible on-line learning algorithm that derives from belief propagation algorithms. We show that it performs remarkably well in a model neuron with binary synapses, and a finite number of "hidden" states per synapse, that has to learn a random classification task. Such a system is able to learn a number of associations close to the theoretical limit in time that is sublinear in system size. This is to our knowledge the first on-line algorithm that is able to achieve efficiently a finite number of patterns learned per binary synapse. Furthermore, we show that performance is optimal for a finite number of hidden states that becomes very small for sparse coding. The algorithm is similar to the standard "perceptron" learning algorithm, with an additional rule for synaptic transitions that occur only if a currently presented pattern is "barely correct." In this case, the synaptic changes are metaplastic only (change in hidden states and not in actual synaptic state), stabilizing the synapse in its current state. Finally, we show that a system with two visible states and K hidden states is much more robust to noise than a system with K visible states. We suggest that this rule is sufficiently simple to be easily implemented by neurobiological systems or in hardware.},
author = {Baldassi, C and Braunstein, A and Brunel, N and Zecchina, R},
doi = {10.1073/pnas.0700324104},
issn = {1091-6490},
journal = {PNAS},
keywords = {Algorithms,Learning,Message passing,Models,Nerve Net,Neural Networks (Computer),Neurological,Synapses},
mendeley-tags = {Message passing},
number = {26},
pages = {11079--84},
pmid = {17581884},
title = {{Efficient supervised learning in networks with binary synapses.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1904114{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {104},
year = {2007}
}
@article{Urbanczik2009,
annote = {2010IIInum38},
author = {Urbanczik, Robert and Senn, W},
journal = {Neural Computation},
pages = {340--352},
title = {{A gradient learning rule for the tempotron}},
url = {http://www.mitpressjournals.org/doi/full/10.1162/neco.2008.09-07-605?select23=Choose},
volume = {352},
year = {2009}
}
@article{aldrich1983reinterpretation,
author = {Aldrich, RW W and Corey, DP P and Stevens, CF F},
journal = {Nature},
number = {5942},
pages = {436--441},
title = {{A reinterpretation of mammalian sodium channel gating based on single channel recording}},
url = {http://corey.med.harvard.edu/PDFs/1983 Aldrich Corey recording.pdf http://corey.med.harvard.edu/PDFs/1983 Aldrich Corey recording.pdf},
volume = {306},
year = {1983}
}
@article{HuysPaninski06b,
author = {Huys, Quentin and Paninski, Liam},
journal = {CNS meeting},
title = {{Model-based optimal interpolation and filtering for noisy, intermittent biophysical recordings}},
year = {2006}
}
@article{Minnichelli1989,
author = {Minnichelli, R.J. and Anagnost, J.J. and Desoer, C.a.},
doi = {10.1109/9.35816},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
number = {9},
pages = {995--998},
title = {{An elementary proof of Kharitonov's stability theorem with extensions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=35816},
volume = {34},
year = {1989}
}
@article{Torikai,
author = {Torikai, Hiroyulu and Saito, Toshimichi},
journal = {Analysis},
number = {4},
pages = {717--720},
title = {{Integrate-and-Fire Model with Periodic Inputs}}
}
@article{ZhangKaltenbach98,
author = {Zhang, J S and Kaltenbach, J A},
journal = {Neuroscience Letters},
month = {jul},
number = {3},
pages = {197--200},
title = {{Increases in spontaneous activity in the dorsal cochlear nucleus of the rat following exposure to high-intensity sound}},
volume = {250},
year = {1998}
}
@article{Nguyen03,
author = {Nguyen, D and Frank, L and Brown, E},
journal = {Network},
pages = {61--82},
title = {{An application of reversible-jump {\{}Markov chain Monte Carlo{\}} to spike classification of multi-unit extracellular recordings}},
volume = {14},
year = {2003}
}
@article{Georgiou2012,
author = {Georgiou, P. S. and Yaliraki, S. N. and Drakakis, E. M. and Barahona, M.},
doi = {10.1098/rspa.2011.0585},
issn = {1364-5021},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
month = {mar},
number = {2144},
pages = {2210--2229},
title = {{Quantitative measure of hysteresis for memristors through explicit dynamics}},
url = {http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.2011.0585},
volume = {468},
year = {2012}
}
@article{PRE73,
author = {Prekopa, A},
journal = {Acad Sci. Math.},
pages = {335--343},
title = {{On logarithmic concave measures and functions}},
volume = {34},
year = {1973}
}
@article{Herbst08,
author = {Herbst, Joshua A and Gammeter, Stephan and Ferrero, David and Hahnloser, Richard H R},
journal = {Journal of Neuroscience Methods},
number = {1},
pages = {126--134},
title = {{Spike sorting with hidden Markov models}},
volume = {174},
year = {2008}
}
@article{Jung2001,
abstract = {Voltage-dependent conductance of ion channels is key for the generation of action potentials. Ion
 channels are opening and closing stochastically due to thermal noise and introduce internal noise
 into the membrane potential of the cell. The noise power depends on the size of the ion channel
 cluster that generates the action potential (the hillock). We show that the encoding of small
 sinusoidal signals in terms of spikes can be enhanced by channel noise if the cluster size is in a
 certain range.},
author = {Jung, P and Shuai, J. W},
doi = {10.1209/epl/i2001-00483-y},
issn = {0295-5075},
journal = {Europhysics Letters (EPL)},
month = {oct},
number = {1},
pages = {29--35},
title = {{Optimal sizes of ion channel clusters}},
url = {http://stacks.iop.org/0295-5075/56/i=1/a=029},
volume = {56},
year = {2001}
}
@article{ChaseYoung06,
author = {Chase, Steven M and Young, Eric D},
journal = {Journal of Neuroscience},
month = {apr},
number = {15},
pages = {3889--3898},
title = {{Spike-timing codes enhance the representation of multiple simultaneous sound-localization cues in the inferior colliculus}},
volume = {26},
year = {2006}
}
@article{Chung2013a,
abstract = {With potential relevance for brain-mapping work, hydrogel-based structures can now be built from within biological tissue to allow subsequent removal of lipids without mechanical disassembly of the tissue. This process creates a tissue-hydrogel hybrid that is physically stable, that preserves fine structure, proteins and nucleic acids, and that is permeable to both visible-spectrum photons and exogenous macromolecules. Here we highlight relevant challenges and opportunities of this approach, especially with regard to integration with complementary methodologies for brain-mapping studies.},
author = {Chung, Kwanghun and Deisseroth, Karl},
doi = {10.1038/nmeth.2481},
issn = {1548-7105},
journal = {Nature methods},
keywords = {Animals,Brain Mapping,Brain Mapping: methods,Diagnostic Imaging,Diagnostic Imaging: methods,Humans,Hydrogel,Hydrogel: chemistry,Microscopy,Synapses,Synapses: physiology},
month = {jun},
number = {6},
pages = {508--13},
pmid = {23722210},
title = {{CLARITY for mapping the nervous system.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23722210},
volume = {10},
year = {2013}
}
@book{Schutter2010,
address = {Cambridge, Massachusetts},
author = {Schutter, E.D.},
publisher = {The MIT Press},
title = {{Computational modeling methods for neuroscientists}},
url = {http://www.lavoisier.fr/notice/frXWOL32RAO3WX3O.html http://dl.acm.org/citation.cfm?id=1822639},
year = {2009}
}
@article{ManisMolitor96,
author = {Manis, P B and Molitor, S C},
journal = {Journal of Neurophysiology},
month = {sep},
number = {3},
pages = {1639--1656},
title = {{N-methyl-D-aspartate receptors at parallel fiber synapses in the dorsal cochlear nucleus}},
volume = {76},
year = {1996}
}
@article{PPS03,
author = {Pillow, J W and Paninski, L and Simoncelli, E},
journal = {NIPS},
title = {{Maximum Likelihood Estimation of a Stochastic Integrate-and-Fire Neural Model}},
volume = {17},
year = {2003}
}
@article{Krizhevsky2014,
abstract = {I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales signiﬁcantly better than all alternatives when applied to modern convolutional neural networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1404.5997v2},
author = {Krizhevsky, Alex},
eprint = {arXiv:1404.5997v2},
journal = {arXiv:1404.5997},
title = {{One weird trick for parallelizing convolutional neural networks}},
url = {http://arxiv.org/abs/1404.5997},
year = {2014}
}
@article{Lewi08,
author = {Lewi, J and Butera, R and Paninski, L},
journal = {Neural Computation},
pages = {619--687},
title = {{Sequential optimal design of neurophysiology experiments}},
volume = {21},
year = {2009}
}
@article{Bruna2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1203.1513v2},
author = {Bruna, Joan and Mallat, S},
eprint = {arXiv:1203.1513v2},
journal = {Pattern Analysis and Machine Intelligence},
pages = {1--15},
title = {{Invariant scattering convolution networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6522407},
year = {2013}
}
@article{Benda2003,
annote = {2010num4.4},
author = {Benda, J and Herz, AVM V M},
journal = {Neural Computation},
title = {{A universal model for spike-frequency adaptation}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976603322385063},
year = {2003}
}
@article{Singh2009,
abstract = {The economies of scale in modern communication systems are enabled by architectures that take advantage of Moore's law to implement most transceiver functionalities in digital signal processing (DSP). The bottleneck in scaling such ldquomostly digitalrdquo architectures to multi-Gigabit rates becomes the analog-to-digital converter (ADC): high-speed, high-precision ADCs are either not available, or are too costly and power-hungry. In this paper, we report on recent results on two approaches towards addressing this bottleneck. The first is to simply use drastically low-precision (1-4 bit) ADCs than current practice. This could be suitable for applications that require limited dynamic range (e.g., line-of-sight communication using small constellations), but there are fundamental and algorithmic questions as to whether all the functions of a communication receiver can be realized with such a significant nonlinearity early in the processing. The second is to use a time-interleaved ADC, where a large number of low-speed, high-precision ADCs are employed in parallel to realize a high-speed, high-precision ADC. This is more generally applicable to applications requiring large dynamic range (e.g., large constellations and/or dispersive channels), but the important question is how to effectively address the mismatch between the component ADCs, which leads to a performance floor if left uncompensated.},
author = {Singh, Jaspreet and Ponnuru, Sandeep and Madhow, Upamanyu},
doi = {10.1109/ICUWB.2009.5288814},
isbn = {9781424429318},
journal = {Proceedings - 2009 IEEE International Conference on Ultra-Wideband, ICUWB 2009},
pages = {22--27},
title = {{Multi-Gigabit communication: The ADC bottleneck}},
year = {2009}
}
@article{Breu|1995|,
abstract = {Two linear time (and hence asymptotically optimal) algorithms for
computing the Euclidean distance transform of a two-dimensional binary
image are presented. The algorithms are based on the construction
and regular sampling of the Voronoi diagram whose sites consist of
the unit (feature) pixels in the image. The first algorithm, which
is of primarily theoretical interest, constructs the complete Voronoi
diagram. The second, more practical, algorithm constructs the Voronoi
diagram where it intersects the horizontal lines passing through
the image pixel centers. Extensions to higher dimensional images
and to other distance functions are also discussed.},
annote = {This excellent paper introduces extremely fast algorithm for accurate{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}computation of distance transform {\&} nearest neighbor transform in{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}2D based on 1D scans supplemented with pixel ordering information.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Algorithm used in matlab for distance transform.},
author = {Breu, H and Gil, J and Kirkpatrick, D},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {algorithm,computational,distance transform,euclidean distance,image processing,voronoi diagram},
number = {5},
pages = {529},
title = {{Linear time Euclidean distance transform algoruthms}},
volume = {17}
}
@article{OO03,
author = {Oakley, J and O'Hagan, A},
journal = {Biometrika},
title = {{Uncertainty in prior elicitations: a nonparametric approach}},
volume = {under revi},
year = {2003}
}
@article{Yeramian1986,
author = {Yeramian, E. and Trautmann, A. and Claverie, P.},
doi = {10.1016/S0006-3495(86)83459-2},
issn = {0006-3495},
journal = {Biophysical journal},
month = {aug},
number = {August},
pages = {253--263},
publisher = {Elsevier},
title = {{Acetylcholine receptors are not functionally independent}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349586834592 http://www.sciencedirect.com/science/article/pii/S0006349586834592},
volume = {50},
year = {1986}
}
@article{SvobodaDenk96,
abstract = {Characterization of the diffusional and electrotonic coupling of spines

to the dendritic shaft is crucial to understanding neuronal integration

and synaptic plasticity. Two-photon photobleaching and photorelease

of fluorescein dextran were used to generate concentration gradients

between spines and shafts in rat CA1 pyramidal neurons. Diffusional

reequilibration was monitored with two-photon fluorescence imaging.

The time course of reequilibration was exponential, with time constants

in the range of 20 to 100 milliseconds, demonstrating chemical compartmentalization

on such time scales. These values imply that electrical spine neck

resistances are unlikely to exceed 150 megohms and more likely range

from 4 to 50 megohms.},
author = {Svoboda, K and Tank, D W and Denk, W},
journal = {Science},
keywords = {Animals; Dendrites; Dextrans; Diffusion; Electric,Neurological; Neuronal Plasticity; Pyramidal Cell},
month = {may},
number = {5262},
pages = {716--719},
pmid = {8614831},
title = {{Direct measurement of coupling between dendritic spines and shafts.}},
volume = {272},
year = {1996}
}
@article{DeWeese2005,
abstract = {It is unclear why there are so many more neurons in sensory cortex than in the sensory periphery. One possibility is that these "extra" neurons are used to overcome cortical noise and faithfully represent the acoustic stimulus. Another possibility is that even after overcoming cortical noise, there is "excess representational bandwidth" available and that this bandwidth is used to represent conjunctions of auditory and nonauditory information for computation. Here, we discuss recent data about neuronal reliability in auditory cortex showing that cortical noise may not be as high as was previously believed. Although at present, the data suggest that auditory cortex neurons can be more reliable than those in the visual cortex, we speculate that the principles governing cortical computation are universal and that visual and other cortical areas can also exploit strategies based on similarly high-fidelity activity.},
author = {DeWeese, Michael R and Hrom{\'{a}}dka, Tom{\'{a}}s and Zador, A M},
doi = {10.1016/j.neuron.2005.10.016},
issn = {0896-6273},
journal = {Neuron},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: physiology,Humans,Neurons,Neurons: classification,Neurons: physiology,Noise,Reproducibility of Results,Time Factors,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Wakefulness,Wakefulness: physiology},
month = {nov},
number = {3},
pages = {479--88},
pmid = {16269364},
title = {{Reliability and representational bandwidth in the auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16269364},
volume = {48},
year = {2005}
}
@article{Bray2007,
abstract = {We calculate the average number of critical points of a Gaussian field on a high-dimensional space as a function of their energy and their index. Our results give a complete picture of the organization of critical points and are of relevance to glassy and disordered systems, and to landscape scenarios coming from the anthropic approach to string theory.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0611023},
author = {Bray, Alan J. and Dean, David S.},
doi = {10.1103/PhysRevLett.98.150201},
eprint = {0611023},
issn = {00319007},
journal = {Physical Review Letters},
number = {15},
pages = {1--5},
pmid = {17501322},
primaryClass = {cond-mat},
title = {{Statistics of critical points of Gaussian fields on large-dimensional spaces}},
volume = {98},
year = {2007}
}
@article{Manem2012,
author = {Manem, H and Rajendran, J and Rose, G S},
journal = {Circuits and Systems I: Regular Papers},
month = {may},
number = {5},
pages = {1051--1060},
title = {{Stochastic Gradient Descent Inspired Training Technique for a CMOS/Nano Memristive Trainable Threshold Gate Array}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6189064},
volume = {59},
year = {2012}
}
@article{Packer2014,
author = {Packer, Adam M and Russell, Lloyd E and Dalgleish, Henry W P and H{\"{a}}usser, Michael},
doi = {10.1038/nmeth.3217},
journal = {Nature Methods},
number = {2},
pages = {140--146},
pmid = {25532138},
title = {{Simultaneous all-optical manipulation and recording of neural circuit activity with cellular resolution in vivo}},
volume = {12},
year = {2014}
}
@article{Segev2000,
author = {Segev, I and London, M},
doi = {10.1126/science.290.5492.744},
issn = {00368075},
journal = {Science},
month = {oct},
number = {5492},
pages = {744--750},
title = {{Untangling Dendrites with Quantitative Models}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.290.5492.744},
volume = {290},
year = {2000}
}
@article{Bender|1979|a,
abstract = {We derive a simple and general diagrammatic procedure for obtaining
the strong-coupling expansion of a d-dimensional quantum field theory,
starting from its Euclidean path-integral representation. At intermediate
stages we are required to evaluate diagrams on a lattice; the lattice
spacing provides a cutoff for the theory. We formulate a simple Pade-type
prescription for extrapolating to zero lattice spacing and thereby
obtain a series of approximants to the true strong-coupling expansion
of the theory. No infinite quantitites appear at any stage of the
calculation. Moreover, all diagrams are simple to evaluate (unlike
the diagrams of the ordinary weak-coupling expansion) because nothing
more than algebra is required, and no diagram, no matter how complex,
generates any transcendental quantities. We explain our approach
in the context of a g phi{\^{}}4 field theory and calculate the two-point
and four-point Green's functions. Then we specialize to d=1 (the
anharmonic oscillator) and compare the locations of the poles of
the Green's functions with the tabulated numerical values of the
energy levels. The agreement is excellent. Finally, we discuss the
application of these techniques to other models such as g phi{\^{}}2N,
g (bar psi psi) {\^{}}2 and quantum electrodynamics.},
annote = {This fundamental paper goes long way in deriving systematic strong{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}coupling expansion from largangian path integral by treating kinetic{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}term as perturbation. Such expansion posesses a number of attractive{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}features, especially invariability regarding number of dimensions,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}simple algebraic integrals, convergence for all values of coupling{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}etc. Diagramatic rules are derived and explicit computation for some{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}quantuties up to 4th - 5th order are presented. Prescription for{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}dealing with divergent integrals is given but not quite well argumented.{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Some numerical results are presented showing good agreement with{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}previously known facts about unharmonic oscillator. Overall, this{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}is a great paper that lays fundamentals for any consequative work,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}however prescription for dealing with infinities is not convincing,{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}and as such this presents serious obstacle on the way of application{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}of this theory.},
author = {Bender, C M and Cooper, F and Guralnik, G S and Sharp, D H},
journal = {Physical Review D},
keywords = {derivatives expansion,feynman diagrams,hopping expansion,phi{\^{}}4,physics,quantum field theory,strong coupling expansion},
number = {6},
pages = {1865},
title = {{Strong-coupling expansion in quantum field theory}},
volume = {19}
}
@article{KaltenbachZhang04,
author = {Kaltenbach, J A and Zhang, J S},
journal = {Journal of Neuroscience Research},
month = {dec},
number = {6},
pages = {908--917},
title = {{In vivo optical imaging of tone-evoked activity in the dorsal cochlear nucleus with a voltage sensitive dye}},
volume = {78},
year = {2004}
}
@article{WMT99,
author = {Wagner, M and Michalek, S and Timmer, J},
journal = {Proceedings of the Royal Society London B},
pages = {1919--1926},
title = {{Estimating transition rates in aggregated Markov models of ion-channel gating with loops and with nearly equal dwell times}},
volume = {266},
year = {1999}
}
@article{IL97,
author = {Iyengar, S and Liao, Q},
journal = {Biological Cybernetics},
pages = {289--295},
title = {{Modeling neural activity using the generalized inverse {\{}G{\}}aussian distribution}},
volume = {77},
year = {1997}
}
@article{Wu05,
author = {Wu, Wei Biao},
journal = {Proceedings of The National Academy Of Sciences Of The United States Of America},
month = {oct},
number = {40},
pages = {14150--14154},
title = {{Nonlinear system theory: another look at dependence}},
volume = {102},
year = {2005}
}
@article{Galan2008,
abstract = {Use of spike timing to encode information requires that neurons respond with high temporal precision and with high reliability. Fast fluctuating stimuli are known to result in highly reproducible spike times across trials, whereas constant stimuli result in variable spike times. Here, we first studied mathematically how spike-time reliability depends on the rapidness of aperiodic stimuli. Then, we tested our theoretical predictions in computer simulations of neuron models (Hodgkin-Huxley and modified quadratic integrate-and-fire), as well as in patch-clamp experiments with real neurons (mitral cells in the olfactory bulb and pyramidal cells in the neocortex). As predicted by our theory, we found that for firing frequencies in the beta/gamma range, spike-time reliability is maximal when the time scale of the input fluctuations (autocorrelation time) is in the range of a few milliseconds (2-5 ms), coinciding with the time scale of fast synapses, and decreases substantially for faster and slower inputs. Finally, we comment how these findings relate to mechanisms causing neuronal synchronization.},
author = {Gal{\'{a}}n, RF F and Ermentrout, B and Urban, N N},
doi = {10.1152/jn.00563.2007},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Computer Simulation,Cortical Synchronization,Mice,Models,Neocortex,Neocortex: physiology,Neural Pathways,Neural Pathways: physiology,Neurological,Olfactory Bulb,Olfactory Bulb: physiology,Organ Culture Techniques,Pyramidal Cells,Pyramidal Cells: physiology,Reaction Time,Reaction Time: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
month = {jan},
number = {1},
pages = {277--83},
pmid = {17928562},
title = {{Optimal time scale for spike-time reliability: theory, simulations, and experiments.}},
url = {http://jn.physiology.org/content/99/1/277.short http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2533711{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {99},
year = {2008}
}
@article{Khurana2011,
abstract = {In neurons of the medial superior olive (MSO), voltage-gated ion channels control the submillisecond time resolution of binaural coincidence detection, but little is known about their interplay during trains of synaptic activity that would be experienced during auditory stimuli. Here, using modeling and patch-clamp recordings from MSO principal neurons in gerbil brainstem slices, we examined interactions between two major currents controlling subthreshold synaptic integration: a low-voltage-activated potassium current (I(K-LVA)) and a hyperpolarization-activated cation current (I(h)). Both I(h) and I(K-LVA) contributed strongly to the resting membrane conductance and, during trains of simulated EPSPs, exhibited cumulative deactivation and inactivation, respectively. In current-clamp recordings, regular and irregular trains of simulated EPSCs increased input resistance up to 60{\%}, effects that accumulated and decayed (after train) over hundreds of milliseconds. Surprisingly, the mean voltage and peaks of EPSPs increased by only a few millivolts during trains. Using a model of an MSO cell, we demonstrated that the nearly uniform response during modest depolarizing stimuli relied on changes in I(h) and I(K-LVA), such that their sum remained nearly constant over time. Experiments and modeling showed that, for simplified binaural stimuli (EPSC pairs in a noisy background), spike probability gradually increased in parallel with the increasing input resistance. Nevertheless, the interplay between I(h) and I(K-LVA) helps to maintain a nearly uniform shape of individual synaptic responses, and we show that the time resolution of synaptic coincidence detection can be maintained during trains if EPSC size gradually decreases (as in synaptic depression), counteracting slow increases in excitability.},
author = {Khurana, Sukant and Remme, Michiel W H and Rinzel, John and Golding, Nace L},
doi = {10.1523/JNEUROSCI.1079-11.2011},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Animals,Biophysics,Cardiotonic Agents,Cardiotonic Agents: pharmacology,Computer Simulation,Electric Stimulation,Electric Stimulation: methods,Female,Gerbillinae,Ion Channel Gating,Ion Channel Gating: drug effects,Ion Channel Gating: physiology,Male,Models,Neurological,Neurons,Neurons: drug effects,Neurons: physiology,Newborn,Nonlinear Dynamics,Normal Distribution,Olivary Nucleus,Olivary Nucleus: cytology,Patch-Clamp Techniques,Peptides,Peptides: pharmacology,Potassium Channels,Pyrimidines,Pyrimidines: pharmacology,Synaptic Potentials,Synaptic Potentials: drug effects,Synaptic Potentials: physiology,Time Factors,Voltage-Gated,Voltage-Gated: drug effects,Voltage-Gated: physiology},
month = {jun},
number = {24},
pages = {8936--47},
pmid = {21677177},
title = {{Dynamic interaction of Ih and IK-LVA during trains of synaptic potentials in principal neurons of the medial superior olive.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3137272{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {31},
year = {2011}
}
@article{Chang2012a,
author = {Chang, Ting and Sheridan, Patrick and Lu, Wei},
isbn = {9781467302890},
journal = {{\ldots} Networks and Their Applications {\ldots}},
number = {c},
pages = {6--8},
title = {{Modeling and implementation of oxide memristors for neuromorphic applications}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6331462},
year = {2012}
}
@article{Krause08,
author = {Krause, A and Singh, A and Guestrin, C},
journal = {Journal of Machine Learning Research},
pages = {235--284},
title = {{Near-Optimal Sensor placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies}},
volume = {9},
year = {2008}
}
@book{Kleinert|2005|a,
author = {Kleinert, H},
publisher = {World Scientific},
title = {{Gauge Fields in Condensed Matter}},
volume = {1-4}
}
@article{Harris07,
author = {Luczak, A and Bartho, P and Marguet, S and Buzsaki, G and Harris, K},
journal = {PNAS},
pages = {347--352},
title = {{Sequential structure of neocortical spontaneous activity in vivo}},
volume = {104},
year = {2007}
}
@article{SHO03a,
author = {Shoham, S and Fellows, M and Normann, R},
journal = {Journal of Neuroscience Methods},
pages = {111--122},
title = {{Robust, automatic spike sorting using mixtures of multivariate t-distributions}},
volume = {127},
year = {2003}
}
@article{Dion2003,
author = {Dion, J.M. M Jean-Michel and Commault, Christian and van der Woude, Jacob},
doi = {10.1016/S0005-1098(03)00104-3},
issn = {00051098},
journal = {Automatica},
keywords = {Reservoir Computing,genericity,graph theory,linear systems,structured systems},
mendeley-tags = {Reservoir Computing},
month = {jul},
number = {7},
pages = {1125--1144},
publisher = {Elsevier},
title = {{Generic properties and control of linear structured systems: a survey}},
url = {http://www.sciencedirect.com/science/article/pii/S0005109803001043 http://linkinghub.elsevier.com/retrieve/pii/S0005109803001043},
volume = {39},
year = {2003}
}
@article{Slepian1962,
author = {Slepian, D},
journal = {Bell System Technical Journal},
title = {{The One Sided Problem for Gaussian Noise}},
year = {1962}
}
@article{Denk94,
author = {Denk, W},
journal = {PNAS},
number = {14},
pages = {6629--6633},
title = {{Two-photon scanning photochemical microscopy: mapping ligand-gated ion channel distributions}},
volume = {91},
year = {1994}
}
@article{CASTI06,
author = {Casti, A and Kaplan, E and Lubliner, K and Xiao, Y},
journal = {Society for Neuroscience Abstracts},
number = {506.19},
title = {{Effects of cortical feedback on the {\{}LGN{\}}: Information transmission and dynamics}},
year = {2006}
}
@book{Rojas2013,
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-38679-4},
editor = {Rojas, Ignacio and Joya, Gonzalo and Gabestany, Joan},
isbn = {978-3-642-38678-7},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Advances in Computational Intelligence}},
url = {http://link.springer.com/10.1007/978-3-642-38679-4},
volume = {7902},
year = {2013}
}
@article{Pachitariu2013,
author = {Pachitariu, M. and Packer, A. M. and Pettit, N. and Dalgleish, H. and Hausser, M. and M, Sahani.},
journal = {Advances in Neural Processing (NIPS)},
pages = {1--10},
title = {{Extracting regions of interest from biological images with convolutional sparse block coding}},
url = {http://papers.nips.cc/paper/5167-extracting-regions-of-interest-from-biological-images-with-convolutional-sparse-block-coding},
year = {2013}
}
@article{Gunter2001,
author = {Gunter, AI},
journal = {Image and Signal Processing and Analysis, 2001.},
number = {5},
pages = {452--457},
title = {{Bias and variance of averaged and smoothed periodogram-based log-amplitude spectra}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=938672},
year = {2001}
}
@article{Tuckwell|1999|,
abstract = {The use of cortical field potentials rather than the details of spike
trains as the basis for cognitive information processing is proposed.
This results in a space of cognitive elements with natural metrics.
Sets of spike trains may also be considered to be points in a multidimen-
sional metric space. The closeness of sets of spike trains in such
a space implies the closeness of points in the resulting function
space of potential distributions.},
annote = {The paper introduces some vague notion of averaged membrane potentials{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}(cortical field potential) and tries to argue about their relation{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}to cognitive processing.},
author = {Tuckwell, H C},
journal = {arXiv},
keywords = {cognitive processing,electroencyphalogram,local cortical field potentials,magnetoencephalograms,neurobiology,spike trains},
pages = {9902011},
title = {{Cortical potential distributions and cognitive information processing}},
volume = {cond-mat}
}
@article{adrian1969rectification,
author = {Adrian, RH},
issn = {0079-6107},
journal = {Progress in biophysics and molecular biology},
number = {2},
pages = {339},
title = {{Rectification in muscle membrane}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/5383813},
volume = {19},
year = {1969}
}
@article{FC80,
author = {Fetz, E and Cheney, P},
journal = {Journal of Neurophysiology},
pages = {751--772},
title = {{Postspike facilitation of forelimb muscle activity by primate corticomotoneuronal cells}},
volume = {44},
year = {1980}
}
@article{Rieke1999,
annote = {2010num6.2},
author = {Rieke, F and Warland, D.K. and Bialek, W},
title = {{Spikes: exploring the neural code}},
url = {http://scholar.google.com/scholar?q=Spikes{\%}3A+Exploring+the+Neural+Code{\#}0},
year = {1999}
}
@article{Lee2006,
abstract = {Intracellular recording, which allows direct measurement of the membrane potential and currents of individual neurons, requires a very mechanically stable preparation and has thus been limited to in vitro and head-immobilized in vivo experiments. This restriction constitutes a major obstacle for linking cellular and synaptic physiology with animal behavior. To overcome this limitation we have developed a method for performing whole-cell recordings in freely moving rats. We constructed a miniature head-mountable recording device, with mechanical stabilization achieved by anchoring the recording pipette rigidly in place after the whole-cell configuration is established. We obtain long-duration recordings (mean of approximately 20 min, maximum 60 min) in freely moving animals that are remarkably insensitive to mechanical disturbances, then reconstruct the anatomy of the recorded cells. This head-anchored whole-cell recording technique will enable a wide range of new studies involving detailed measurement and manipulation of the physiological properties of identified cells during natural behaviors.},
author = {Lee, Albert K and Manns, Ian D and Sakmann, Bert and Brecht, Michael and Mc, Erasmus},
doi = {10.1016/j.neuron.2006.07.004},
issn = {0896-6273},
journal = {Neuron},
keywords = {Animal,Animals,Behavior,Brain,Brain: cytology,Electrodes,Implanted,Male,Membrane Potentials,Membrane Potentials: physiology,Microelectrodes,Neurons,Neurons: physiology,Newborn,Patch-Clamp Techniques,Patch-Clamp Techniques: instrumentation,Patch-Clamp Techniques: methods,Rats,Sprague-Dawley,Wakefulness,Wakefulness: physiology,Wistar},
month = {aug},
number = {4},
pages = {399--407},
pmid = {16908406},
title = {{Whole-cell recordings in freely moving rats.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16908406},
volume = {51},
year = {2006}
}
@article{Keijzer2002,
author = {Keijzer, F},
doi = {10.1016/S1389-0417(02)00043-8},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {1,a criticism of the,as important factors of,cognition,cognition is now,dynamical and embodied cognition,new themes are acknowledged,representation,the last few years,use of representations},
month = {sep},
number = {3},
pages = {275--288},
title = {{Representation in dynamical and embodied cognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041702000438},
volume = {3},
year = {2002}
}
@article{Garofalo09,
author = {Garofalo, Matteo and Nieus, Thierry and Massobrio, Paolo and Martinoia, Sergio},
journal = {PLoS ONE},
pages = {e6482},
title = {{Evaluation of the Performance of Information Theory-Based Methods and Cross-Correlation to Estimate the Functional Connectivity in Cortical Networks}},
volume = {4},
year = {2009}
}
@article{Vilin2001,
abstract = {Slow inactivation in voltage-gated sodium channels is a biophysical process that governs the availability of sodium channels over extended periods of time. Slow inactivation, therefore, plays an important role in controlling membrane excitability, firing properties, and spike frequency adaptation. Defective slow inactivation is associated with several diseases of cell excitability, such as hyperkalemic periodic paralysis, myotonia, idiopathic ventricular fibrillation and long-QT syndrome. These associations underscore the physiological importance of this phenomenon. Nevertheless, our understanding of the molecular substrates for slow inactivation is still fragmentary. This review covers the current state of knowledge concerning the molecular underpinnings of slow inactivation, and its relationship with other biophysical processes of voltage-gated sodium channels.},
author = {Vilin, Y Y and Ruben, P C},
doi = {10.1385/CBB:35:2:171},
issn = {1085-9195},
journal = {Cell biochemistry and biophysics},
keywords = {Animals,Electrophysiology,Humans,Kinetics,Long QT Syndrome,Long QT Syndrome: metabolism,Mutation,Myotonia,Myotonia: metabolism,Paralysis,Paralysis: metabolism,Protein Binding,Protein Conformation,Sodium Channels,Sodium Channels: genetics,Sodium Channels: metabolism,Time Factors,Ventricular Fibrillation,Ventricular Fibrillation: metabolism},
month = {jan},
number = {2},
pages = {171--90},
pmid = {11892790},
title = {{Slow inactivation in voltage-gated sodium channels: molecular substrates and contributions to channelopathies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11892790},
volume = {35},
year = {2001}
}
@article{Bemporad1999,
author = {Bemporad, a},
doi = {10.1016/S0005-1098(98)00178-2},
issn = {00051098},
journal = {Automatica},
keywords = {binary logic systems,boolean logic,dynamic models,hybrid systems,mixed-integer programming,optimization problems,predictive control},
month = {mar},
number = {3},
pages = {407--427},
title = {{Control of systems integrating logic, dynamics, and constraints}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0005109898001782},
volume = {35},
year = {1999}
}
@article{CGJ96,
author = {Cohn, D and Ghahramani, Z and Jordan, M},
journal = {Journal of Artificial Intelligence Research},
pages = {129--145},
title = {{Active learning with statistical models}},
volume = {4},
year = {1996}
}
@article{Pakman2013,
author = {Pakman, A and Paninski, L},
doi = {10.1080/10618600.2013.788448},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Estimation,bayesian modeling,hamiltonian monte carlo,markov chain monte carlo,sians,truncated multivariate gaus-},
mendeley-tags = {Estimation},
month = {jun},
pages = {130610142855008},
title = {{Exact Hamiltonian Monte Carlo for Truncated Multivariate Gaussians}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2013.788448},
year = {2013}
}
@book{stratonovich1967topics,
author = {Stratonovich, R L},
publisher = {Routledge},
title = {{Topics in the theory of random noise}},
year = {1967}
}
@article{Mouttet2012,
author = {Mouttet, Blaise},
journal = {arXiv preprint arXiv:1201.2626},
keywords = {- non-linear dynamic systems,and unity,memresistor,micron technology,new,phase change memory,reram,rram,samsung,semiconductor began experimenting with,sharp},
title = {{Memresistors and non-memristive zero-crossing hysteresis curves}},
url = {http://arxiv.org/abs/1201.2626},
volume = {2012},
year = {2012}
}
@article{Zhang2015a,
abstract = {Using a very low-resolution analog-to-digital convertor (ADC) unit at each antenna can remarkably reduce the hardware cost and power consumption of a massive multiple-input multiple-output (MIMO) system. However, such a pure low-resolution ADC architecture also complicates parameter estimation problems such as time/frequency synchronization and channel estimation. A mixed-ADC architecture, where most of the antennas are equipped with low-precision ADCs while a few antennas have full-precision ADCs, can solve these issues and actualize the potential of the pure low-resolution ADC architecture. In this paper, we present a unified framework to develop a family of detectors over the massive MIMO uplink system with the mixed-ADC receiver architecture by exploiting probabilistic Bayesian inference. As a basic setup, an optimal detector is developed to provide a minimum mean-squared-error (MMSE) estimate on data symbols. Considering the highly nonlinear steps involved in the quantization process, we also investigate the potential for complexity reduction on the optimal detector by postulating the common $\backslash$emph{\{}pseudo-quantization noise{\}} (PQN) model. In particular, we provide asymptotic performance expressions including the MSE and bit error rate for the optimal and suboptimal MIMO detectors. The asymptotic performance expressions can be evaluated quickly and efficiently; thus, they are useful in system design optimization. We show that in the low signal-to-noise ratio (SNR) regime, the distortion caused by the PQN model can be ignored, whereas in the high-SNR regime, such distortion may cause 1-bit detection performance loss. The performance gap resulting from the PQN model can be narrowed by a small fraction of high-precision ADCs in the mixed-ADC architecture.},
archivePrefix = {arXiv},
arxivId = {1509.07950},
author = {Zhang, Ti-Cao and Wen, Chao-Kai and Jin, Shi and Jiang, Tao},
doi = {10.1109/TWC.2016.2606592},
eprint = {1509.07950},
issn = {15361276 (ISSN)},
journal = {arXiv preprint arXiv:1509.07950},
number = {11},
pages = {1--14},
title = {{Mixed-ADC Massive MIMO Detectors: Performance Analysis and Design Optimization}},
url = {http://arxiv.org/abs/1509.07950},
volume = {15},
year = {2015}
}
@article{Candes2008a,
author = {Cand{\`{e}}s, Emmanuel J. and Wakin, Michael B. and Boyd, Stephen P.},
doi = {10.1007/s00041-008-9045-x},
issn = {1069-5869},
journal = {Journal of Fourier Analysis and Applications},
month = {oct},
number = {5-6},
pages = {877--905},
title = {{Enhancing Sparsity by Reweighted ℓ1 Minimization}},
url = {http://link.springer.com/10.1007/s00041-008-9045-x},
volume = {14},
year = {2008}
}
@article{Kinouchi2006,
author = {Kinouchi, Osame and Copelli, Mauro},
doi = {10.1038/nphys289},
issn = {1745-2473},
journal = {Nature Physics},
month = {apr},
number = {5},
pages = {348--351},
title = {{Optimal dynamical range of excitable networks at criticality}},
url = {http://www.nature.com/doifinder/10.1038/nphys289},
volume = {2},
year = {2006}
}
@article{SchynsOliva94,
author = {Schyns, P and Oliva, A},
journal = {Psychological Science},
pages = {195--200},
title = {{From blobs to boundary edges: Evidence for time and spatial-scale-dependent scene recognition.}},
volume = {5},
year = {1994}
}
@article{DeBello2008,
abstract = {How does the brain encode life experiences? Recent results derived from vital imaging, computational modeling, cellular physiology and systems neuroscience have pointed to local changes in synaptic connectivity as a powerful substrate, here termed micro-rewiring. To examine this hypothesis, I first review findings on micro-structural dynamics with focus on the extension and retraction of dendritic spines. Although these observations demonstrate a biological mechanism, they do not inform us of the specific changes in circuit configuration that might occur during learning. Here, computational models have made testable predictions for both the neuronal and circuit levels. Integrative approaches in the mammalian neocortex and the barn owl auditory localization pathway provide some of the first direct evidence in support of these 'synaptic-clustering' mechanisms. The implications of these data and the challenges for future research are discussed.},
author = {DeBello, William M},
doi = {10.1016/j.tins.2008.08.006},
issn = {0166-2236},
journal = {Trends in Neurosciences},
keywords = {Animals,Biological,Brain,Brain: cytology,Brain: physiology,Dendritic Spines,Dendritic Spines: physiology,Humans,Learning,Learning: physiology,Models,Neurons,Neurons: cytology,Neurons: physiology,Synapses,Synapses: physiology},
number = {11},
pages = {577--584},
pmid = {18817991},
title = {{Micro-rewiring as a substrate for learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18817991},
volume = {31},
year = {2008}
}
@misc{rsnaglib,
annote = {C library documentation for NAG},
keywords = {computational,documentation,library,nag},
title = {{NAG C Library Function Document}}
}
@article{AguerayArcas2003,
abstract = {A spiking neuron "computes" by transforming a complex dynamical input into a train of action potentials, or spikes. The computation performed by the neuron can be formulated as dimensional reduction, or feature detection, followed by a nonlinear decision function over the low-dimensional space. Generalizations of the reverse correlation technique with white noise input provide a numerical strategy for extracting the relevant low-dimensional features from experimental data, and information theory can be used to evaluate the quality of the low-dimensional approximation. We apply these methods to analyze the simplest biophysically realistic model neuron, the Hodgkin-Huxley (HH) model, using this system to illustrate the general methodological issues. We focus on the features in the stimulus that trigger a spike, explicitly eliminating the effects of interactions between spikes. One can approximate this triggering "feature space" as a two-dimensional linear subspace in the high-dimensional space of input histories, capturing in this way a substantial fraction of the mutual information between inputs and spike time. We find that an even better approximation, however, is to describe the relevant subspace as two dimensional but curved; in this way, we can capture 90{\%} of the mutual information even at high time resolution. Our analysis provides a new understanding of the computational properties of the HH model. While it is common to approximate neural behavior as "integrate and fire," the HH model is not an integrator nor is it well described by a single threshold.},
author = {{Ag{\"{u}}era Y Arcas}, B and Fairhall, A L and Bialek, W},
doi = {10.1162/08997660360675017},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Models,Neurological,Neurons,Neurons: physiology},
month = {aug},
number = {8},
pages = {1715--49},
pmid = {14511510},
title = {{Computation in a single neuron: Hodgkin and Huxley revisited.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14511510},
volume = {15},
year = {2003}
}
@article{Chung2013,
author = {Chung, K and Wallace, J and Kim, S and Kalyanasundaram, S and Andalman, A S and Davidson, T J and Mirzabekov, J J and Zalocusky, K A and Mattis, J and Denisin, A K and Pak, S and Bernstein, H and Ramakrishnan, C and Grosenick, L and Gradinaru, V and Deisseroth, K},
doi = {10.1038/nature12107},
issn = {0028-0836},
journal = {Nature},
month = {apr},
pages = {332--337},
publisher = {Nature Publishing Group},
title = {{Structural and molecular interrogation of intact biological systems}},
url = {http://www.nature.com/doifinder/10.1038/nature12107},
volume = {497},
year = {2013}
}
@article{WangAxel03,
abstract = {An understanding of the logic of odor perception requires a functional

analysis of odor-evoked patterns of activity in neural assemblies

in the brain. We have developed a sensitive imaging system in the

Drosophila brain that couples two-photon microscopy with the specific

expression of the calcium-sensitive fluorescent protein, G-CaMP.

At natural odor concentration, each odor elicits a distinct and sparse

spatial pattern of activity in the antennal lobe that is conserved

in different flies. Patterns of glomerular activity are similar upon

imaging of sensory and projection neurons, suggesting the faithful

transmission of sensory input to higher brain centers. Finally, we

demonstrate that the response pattern of a given glomerulus is a

function of the specificity of a single odorant receptor. The development

of this imaging system affords an opportunity to monitor activity

in defined neurons throughout the fly brain with high sensitivity

and excellent spatial resolution.},
author = {Wang, Jing W and Wong, Allan M and Flores, Jorge and Vosshall, Leslie B and Axel, Richard},
journal = {Cell},
keywords = {Animals; Axons; Brain; Calcium; Calcium Signaling;,Invertebrate; Odors; Olfactory Pathways; Olfactor},
month = {jan},
number = {2},
pages = {271--282},
pmid = {12553914},
title = {{Two-photon calcium imaging reveals an odor-evoked map of activity in the fly brain.}},
volume = {112},
year = {2003}
}
@article{Smith2003,
abstract = {OBJECTIVES: To determine whether parachutes are effective in preventing major trauma related to gravitational challenge. Design Systematic review of randomised controlled trials. DATA SOURCES: Medline, Web of Science, Embase, and the Cochrane Library databases; appropriate internet sites and citation lists. STUDY SELECTION: Studies showing the effects of using a parachute during free fall. MAIN OUTCOME MEASURE: Death or major trauma, defined as an injury severity score {\textgreater} 15. RESULTS: We were unable to identify any randomised controlled trials of parachute intervention. CONCLUSIONS: As with many interventions intended to prevent ill health, the effectiveness of parachutes has not been subjected to rigorous evaluation by using randomised controlled trials. Advocates of evidence based medicine have criticised the adoption of interventions evaluated by using only observational data. We think that everyone might benefit if the most radical protagonists of evidence based medicine organised and participated in a double blind, randomised, placebo controlled, crossover trial of the parachute.},
author = {Smith, Gordon C S and Pell, Jill P},
issn = {0893-2174},
journal = {The International journal of prosthodontics},
number = {2},
pages = {126--8},
pmid = {16602356},
title = {{Parachute use to prevent death and major trauma related to gravitational challenge: systematic review of randomised controlled trials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16602356},
volume = {19},
year = {2003}
}
@article{CSK88,
author = {Chornoboy, E S and Schramm, L P and Karr, A F},
journal = {Biological Cybernetics},
number = {4-5},
pages = {265--275},
title = {{Maximum likelihood identification of neural point process systems}},
volume = {59},
year = {1988}
}
@article{Bache2013,
author = {Bache, K and Lichman, M},
journal = {http://archive.ics.uci.edu/ml},
title = {{UCI Machine Learning Repository}},
year = {2013}
}
@article{Diego,
author = {Diego, Ferran and Reichinnek, Susanne and Both, Martin and Hamprecht, Fred A},
pages = {2--5},
title = {{AUTOMATED IDENTIFICATION OF NEURONAL ACTIVITY FROM CALCIUM IMAGING BY SPARSE DICTIONARY LEARNING HCI , IWR , University of Heidelberg , 69115 Heidelberg , Germany Institute for Physiology and Pathophysiology , University of Heidelberg , 69120 Heidelberg ,}}
}
@article{ErgunBrown07,
abstract = {The stochastic state point process filter (SSPPF) and steepest descent

point process filter (SDPPF) are adaptive filter algorithms for state

estimation from point process observations that have been used to

track neural receptive field plasticity and to decode the representations

of biological signals in ensemble neural spiking activity. The SSPPF

and SDPPF are constructed using, respectively, Gaussian and steepest

descent approximations to the standard Bayes and Chapman-Kolmogorov

(BCK) system of filter equations. To extend these approaches for

constructing point process adaptive filters, we develop sequential

Monte Carlo (SMC) approximations to the BCK equations in which the

SSPPF and SDPPF serve as the proposal densities. We term the two

new SMC point process filters SMC-PPFs and SMC-PPFD, respectively.

We illustrate the new filter algorithms by decoding the wind stimulus

magnitude from simulated neural spiking activity in the cricket cercal

system. The SMC-PPFs and SMC-PPFD provide more accurate state estimates

at low number of particles than a conventional bootstrap SMC filter

algorithm in which the state transition probability density is the

proposal density. We also use the SMC-PPFs algorithm to track the

temporal evolution of a spatial receptive field of a rat hippocampal

neuron recorded while the animal foraged in an open environment.

Our results suggest an approach for constructing point process adaptive

filters using SMC methods.},
author = {Erg{\"{u}}n, Ayla and Barbieri, Riccardo and Eden, Uri T and Wilson, Matthew A and Brown, Emery N},
journal = {IEEE Trans Biomed Eng},
month = {mar},
number = {3},
pages = {419--428},
pmid = {17355053},
title = {{Construction of point process adaptive filter algorithms for neural systems using sequential Monte Carlo methods.}},
volume = {54},
year = {2007}
}
@article{WF90,
author = {Watson, A and Fitzhugh, A},
journal = {Perception and Psychophysics},
pages = {87--91},
title = {{The method of constant stimuli is inefficient}},
volume = {47},
year = {1990}
}
@book{KOO88,
author = {Koosis, P},
publisher = {Cambridge University Press},
title = {{The logarithmic integral}},
year = {1988}
}
@article{Middleton2003,
abstract = {We study the statistics of the firing patterns of a perfect integrate and fire neuron model driven by additive long-range correlated Ornstein-Uhlenbeck noise. Using a quasistatic weak noise approximation we obtain expressions for the interspike interval (ISI) probability density, the power spectral density, and the spike count Fano factor. We find unimodal, long-tailed ISI densities, Lorenzian power spectra at low frequencies, and a minimum in the Fano factor as a function of counting time. The implications of these results for signal detection are discussed.},
author = {Middleton, J. and Chacron, M. and Lindner, B and Longtin, A.},
doi = {10.1103/PhysRevE.68.021920},
issn = {1063-651X},
journal = {Physical Review E},
keywords = {1/f noise},
mendeley-tags = {1/f noise},
month = {aug},
number = {2},
pages = {021920},
publisher = {American Physical Society},
shorttitle = {Phys. Rev. E},
title = {{Firing statistics of a neuron model driven by long-range correlated noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.68.021920},
volume = {68},
year = {2003}
}
@article{Ahrens2013,
abstract = {Brain function relies on communication between large populations of neurons across multiple brain areas, a full understanding of which would require knowledge of the time-varying activity of all neurons in the central nervous system. Here we use light-sheet microscopy to record activity, reported through the genetically encoded calcium indicator GCaMP5G, from the entire volume of the brain of the larval zebrafish in vivo at 0.8 Hz, capturing more than 80{\%} of all neurons at single-cell resolution. Demonstrating how this technique can be used to reveal functionally defined circuits across the brain, we identify two populations of neurons with correlated activity patterns. One circuit consists of hindbrain neurons functionally coupled to spinal cord neuropil. The other consists of an anatomically symmetric population in the anterior hindbrain, with activity in the left and right halves oscillating in antiphase, on a timescale of 20 s, and coupled to equally slow oscillations in the inferior olive.},
author = {Ahrens, M B and Orger, Michael B and Robson, Drew N and Li, Jennifer M and Keller, Philipp J},
doi = {10.1038/nmeth.2434},
journal = {Nature methods},
keywords = {Animals,Brain,Brain: metabolism,Brain: physiology,Microscopy,Microscopy: methods,Zebrafish},
month = {may},
number = {5},
pages = {413--420},
pmid = {23524393},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Meth},
title = {{Whole-brain functional imaging at cellular resolution using light-sheet microscopy}},
url = {http://dx.doi.org/10.1038/nmeth.2434},
volume = {10},
year = {2013}
}
@article{Shin2001,
abstract = {Shin, Koch and Douglas [Shin, J., Koch, C., {\&} Douglas, R. (1999). Adaptive neural coding dependent on the time-varying statistics of the somatic input current. Neural Computation, 11, 1983-2003] proposed an adaptive neural coding model that makes spiking neurons adapt its input/output relation to the stimulus statistics. In a surprisingly precise manner, the adaptive neural coding model has been supported by recent experiments. However, the previous report has two problems: (a) although the adaptive neural coding model was developed based on the noise shaping neural coding hypothesis, their connection was not explained clearly in the previous report; and (b) the previous model did not suggest a biologically plausible method to estimate the stimulus mean and variance from spike-evoked intracellular calcium concentration. In this paper, I present how the noise shaping neural coding hypothesis produced such a precise model without any available experimental data at that time. Moreover, I propose a computational model for a biologically plausible signal statistics extraction from spike-evoked intracellular calcium concentration. An asymmetry in contrast adaptation time between increasing and decreasing variance, observed in biological experiments, is explained using the signal statistics extraction method. In addition, a new perspective on the relationship between the spike train of spiking neurons and EEG (or local field potential (LFP)) is suggested based on the noise shaping neural coding hypothesis.},
author = {Shin, J},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Animals,Artifacts,Calcium Signaling,Calcium Signaling: physiology,Cell Compartmentation,Cell Compartmentation: physiology,Humans,Models,Neurological,Neurons,Neurons: physiology,Physiological,Physiological: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
number = {6-7},
pages = {907--19},
pmid = {11665781},
title = {{Adaptation in spiking neurons based on the noise shaping neural coding hypothesis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11665781},
volume = {14},
year = {2001}
}
@article{Soudry2015,
abstract = {{\textcopyright} 2015 Soudry et al.Inferring connectivity in neuronal networks remains a key challenge in statistical neuroscience. The “common input” problem presents a major roadblock: it is difficult to reliably distinguish causal connections between pairs of observed neurons versus correlations induced by common input from unobserved neurons. Available techniques allow us to simultaneously record, with sufficient temporal resolution, only a small fraction of the network. Consequently, naive connectivity estimators that neglect these common input effects are highly biased. This work proposes a “shotgun” experimental design, in which we observe multiple sub-networks briefly, in a serial manner. Thus, while the full network cannot be observed simultaneously at any given time, we may be able to observe much larger subsets of the network over the course of the entire experiment, thus ameliorating the common input problem. Using a generalized linear model for a spiking recurrent neural network, we develop a scalable approximate expected loglikelihood-based Bayesian method to perform network inference given this type of data, in which only a small fraction of the network is observed in each time bin. We demonstrate in simulation that the shotgun experimental design can eliminate the biases induced by common input effects. Networks with thousands of neurons, in which only a small fraction of the neurons is observed in each time bin, can be quickly and accurately estimated, achieving orders of magnitude speed up over previous approaches.},
author = {Soudry, D. and Keshri, Suraj and Stinson, Patrick and Oh, Min-hwan M.-H. and Iyengar, Garud and Paninski, Liam},
doi = {10.1371/journal.pcbi.1004464},
issn = {1553-7358},
journal = {PLOS Computational Biology},
number = {10},
pages = {e1004464},
title = {{Efficient "Shotgun" Inference of Neural Connectivity from Highly Sub-sampled Activity Data}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1004464},
volume = {11},
year = {2015}
}
@article{Dittman2000,
abstract = {Synapses display remarkable alterations in strength during repetitive use. Different types of synapses exhibit distinctive synaptic plasticity, but the factors giving rise to such diversity are not fully understood. To provide the experimental basis for a general model of short-term plasticity, we studied three synapses in rat brain slices at 34 degrees C: the climbing fiber to Purkinje cell synapse, the parallel fiber to Purkinje cell synapse, and the Schaffer collateral to CA1 pyramidal cell synapse. These synapses exhibited a broad range of responses to regular and Poisson stimulus trains. Depression dominated at the climbing fiber synapse, facilitation was prominent at the parallel fiber synapse, and both depression and facilitation were apparent in the Schaffer collateral synapse. These synapses were modeled by incorporating mechanisms of short-term plasticity that are known to be driven by residual presynaptic calcium (Ca(res)). In our model, release is the product of two factors: facilitation and refractory depression. Facilitation is caused by a calcium-dependent increase in the probability of release. Refractory depression is a consequence of release sites becoming transiently ineffective after release. These sites recover with a time course that is accelerated by elevations of Ca(res). Facilitation and refractory depression are coupled by their common dependence on Ca(res) and because increased transmitter release leads to greater synaptic depression. This model captures the behavior of three different synapses for various stimulus conditions. The interplay of facilitation and depression dictates synaptic strength and variability during repetitive activation. The resulting synaptic plasticity transforms the timing of presynaptic spikes into varying postsynaptic response amplitudes.},
author = {Dittman, J S and Kreitzer, a C and Regehr, W G},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {Animals,Basal Ganglia,Basal Ganglia: physiology,Calcium,Calcium: physiology,Cerebellum,Cerebellum: physiology,Electric Stimulation,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Hippocampus,Hippocampus: physiology,Kinetics,Models, Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Presynaptic Terminals,Presynaptic Terminals: physiology,Purkinje Cells,Purkinje Cells: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Rats, Sprague-Dawley,Synapses,Synapses: physiology},
month = {feb},
number = {4},
pages = {1374--85},
pmid = {10662828},
title = {{Interplay between facilitation, depression, and residual calcium at three presynaptic terminals.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10662828},
volume = {20},
year = {2000}
}
@article{QuianQuiroga07,
author = {{Quian Quiroga}, R},
journal = {Scholarpedia},
title = {{Spike sorting}},
volume = {http://www},
year = {2007}
}
@article{Shannon|1948|,
annote = {The seminal paper by C. Shannon on information theory, coding and{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}channel capacities},
author = {Shannon, C E},
journal = {The Bell system technical journal},
keywords = {information theory,mathematics},
pages = {379},
title = {{A mathematical theory of communication}},
volume = {27}
}
@article{Brutzkus2017,
abstract = {Deep learning models are often successfully trained using gradient descent, despite the worst case hardness of the underlying non-convex optimization problem. The key question is then under what conditions can one prove that optimization will succeed. Here we provide a strong result of this kind. We consider a neural net with one hidden layer and a convolutional structure with no overlap and a ReLU activation function. For this architecture we show that learning is NP-complete in the general case, but that when the input distribution is Gaussian, gradient descent converges to the global optimum in polynomial time. To the best of our knowledge, this is the first global optimality guarantee of gradient descent on a convolutional neural network with ReLU activations.},
archivePrefix = {arXiv},
arxivId = {1702.07966},
author = {Brutzkus, Alon and Globerson, Amir},
eprint = {1702.07966},
journal = {arXiv},
title = {{Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs}},
url = {http://arxiv.org/abs/1702.07966},
year = {2017}
}
@misc{SupplementalMaterial,
author = {{The Supplementary Material is available online on the author's website}},
title = {https://sites.google.com/site/danielsoudry/}
}
@misc{Jonas2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1407.4137v1},
author = {Jonas, Eric and Kording, Konrad},
booktitle = {arXiv preprint arXiv:1407.4137},
eprint = {arXiv:1407.4137v1},
howpublished = {http://arxiv.org/abs/1407.4137},
pages = {1--19},
title = {{Automatic discovery of cell types and microcircuitry from neural connectomics}},
url = {http://arxiv.org/abs/1407.4137},
urldate = {2014-11-14},
year = {2014}
}
@article{Hermans2013,
author = {Hermans, Michiel and Schrauwen, Benjamin},
journal = {Neural Information Processing Systems},
pages = {1--9},
title = {{Training and Analysing Deep Recurrent Neural Networks}},
url = {http://papers.nips.cc/paper/5166-training-and-analysing-deep-recurrent-neural-networks},
year = {2013}
}
@article{Galan2008a,
author = {Gal{\'{a}}n, RF},
doi = {10.1371/Citation},
journal = {PLoS One},
number = {5},
pages = {1--10},
title = {{On how network architecture determines the dominant patterns of spontaneous neural activity}},
url = {http://dx.plos.org/10.1371/journal.pone.0002148},
volume = {3},
year = {2008}
}
@article{stevens1996integrate,
annote = {2010IInum12.3},
author = {Stevens, C F and Zador, A M},
journal = {Advances in neural information processing systems},
pages = {103--109},
publisher = {Citeseer},
title = {{When Is an Integrate-and-fire Neuron like a Poisson Neuron?}},
year = {1996}
}
@article{Lundstrom2010,
abstract = {Adaptive processes over many timescales endow neurons with sensitivity to stimulus changes over a similarly wide range of scales. Although spike timing of single neurons can precisely signal rapid fluctuations in their inputs, the mean firing rate can convey information about slower-varying properties of the stimulus. Here, we investigate the firing rate response to a slowly varying envelope of whisker motion in two processing stages of the rat vibrissa pathway. The whiskers of anesthetized rats were moved through a noise trajectory with an amplitude that was sinusoidally modulated at one of several frequencies. In thalamic neurons, we found that the rate response to the stimulus envelope was also sinusoidal, with an approximately frequency-independent phase advance with respect to the input. Responses in cortex were similar but with a phase shift that was about three times larger, consistent with a larger amount of rate adaptation. These response properties can be described as a linear transformation of the input for which a single parameter quantifies the phase shift as well as the degree of adaptation. These results are reproduced by a model of adapting neurons connected by synapses with short-term plasticity, showing that the observed linear response and phase lead can be built up from a network that includes a sequence of nonlinear adapting elements. Our study elucidates how slowly varying envelope information under passive stimulation is preserved and transformed through the vibrissa processing pathway.},
annote = {2010IInum12.36},
author = {Lundstrom, Brian N and Fairhall, A L and Maravall, Miguel},
doi = {10.1523/JNEUROSCI.2193-09.2010},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Animals,Cerebral Cortex,Cerebral Cortex: physiology,Electric Stimulation,Electric Stimulation: methods,Neurons,Neurons: physiology,Physiological,Physiological: physiology,Rats,Thalamus,Thalamus: physiology,Time Factors,Vibrissae,Vibrissae: physiology,Wistar},
month = {apr},
number = {14},
pages = {5071--7},
pmid = {20371827},
title = {{Multiple timescale encoding of slowly varying whisker stimulus envelope in cortical and thalamic neurons in vivo.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20371827},
volume = {30},
year = {2010}
}
@misc{Sylvester1852,
author = {Sylvester, James Joseph},
booktitle = {Philos. Mag. IV},
number = {23},
pages = {138--142},
title = {{A demonstration of the theorem that every homogeneous quadratic polynomial is reducible by real orthogonal substitutions to the form of a sum of positive and negative squares}},
url = {http://www.maths.ed.ac.uk/{~}aar/sylv/inertia.pdf},
volume = {4},
year = {1852}
}
@article{Xu2013,
abstract = {We use a supervised multi-spike learning algorithm for spiking neural networks (SNNs) with temporal encoding to simulate the learning mechanism of biological neurons in which the SNN output spike trains are encoded by firing times. We first analyze why existing gradient-descent-based learning methods for SNNs have difficulty in achieving multi-spike learning. We then propose a new multi-spike learning method for SNNs based on gradient descent that solves the problems of error function construction and interference among multiple output spikes during learning. The method could be widely applied to single spiking neurons to learn desired output spike trains and to multilayer SNNs to solve classification problems. By overcoming learning interference among multiple spikes, our method has high learning accuracy when there are a relatively large number of output spikes in need of learning. We also develop an output encoding strategy with respect to multiple spikes for classification problems. This effectively improves the classification accuracy of multi-spike learning compared to that of single-spike learning.},
author = {Xu, Yan and Zeng, Xiaoqin and Han, Lixin and Yang, Jing},
doi = {10.1016/j.neunet.2013.02.003},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {multi-spike learning,single-spike learning,spiking neural networks},
month = {jul},
pages = {99--113},
pmid = {23500504},
publisher = {Elsevier Ltd},
title = {{A supervised multi-spike learning algorithm based on gradient descent for spiking neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23500504},
volume = {43},
year = {2013}
}
@article{Angeletti2014,
author = {Angeletti, Florian and Touchette, Hugo and Bertin, Eric and Abry, Patrice},
doi = {10.1088/1742-5468/2014/02/P02003},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
month = {feb},
number = {2},
pages = {P02003},
title = {{Large deviations for correlated random variables described by a matrix product ansatz}},
url = {http://stacks.iop.org/1742-5468/2014/i=2/a=P02003?key=crossref.6f3fa4e316c1407dc3b87e2d56c67b0f},
volume = {2014},
year = {2014}
}
@article{Thorne|2006|,
author = {Thorne, R G and Nicholson, C},
journal = {Proc. Natl. Acad. Sci. USA},
number = {14},
pages = {5567--5572},
title = {{In vivo diffusion analysis with quantum dots and dextrans predicts the width of brain extracellular space.}},
volume = {103}
}
@article{HirschOertel88,
abstract = {1. Intracellular recordings were made from the dorsal cochlear nucleus

(DCN) in slices of the cochlear nuclear complex. Probably the larger

and most frequent cells were impaled. 2. The steady-state current-voltage

(I-V) properties of all cells impaled were nonlinear. The I-V curve

was steepest in the voltage range depolarized from the resting potential

and most shallow when the cell was hyperpolarized from rest by more

than about 10 mV. Thus, the inwardly rectifying I-V characteristics

of cells in the DCN distinguish them from those of ventral cochlear

nuclear neurones (Oertel, 1983). 3. When depolarized with current,

most cells fired trains of large, all-or-none action potentials.

The undershoot after single spikes comprised an initial, fast component

followed by a second, slower wave. A few cells (15{\%}) generated bursts

of smaller, graded spikes in addition to the large ones. 4. Repetitive

firing evoked by depolarizing pulses of current was followed by an

after-hyperpolarization whose magnitude depended on the strength

and duration of the preceding current pulse. 5. Blocking the large

action potentials with tetrodotoxin (TTX) revealed Ca2+-dependent

spikes in all cells examined. 6. The steady-state I-V relationship

became linear in the presence of TTX, suggesting that a persistent

Na+ conductance probably mediates the inward rectification seen above

the resting potential. 7. Muscarine at micromolar concentrations

excited cells and increased their input resistance.},
author = {Hirsch, J A and Oertel, D},
journal = {J Physiol},
keywords = {4-Aminopyridine; Action Potentials; Aminopyridines},
month = {feb},
pages = {535--548},
pmid = {2457693},
title = {{Intrinsic properties of neurones in the dorsal cochlear nucleus of mice, in vitro.}},
volume = {396},
year = {1988}
}
@article{Li2017,
archivePrefix = {arXiv},
arxivId = {1705.09886},
author = {Li, Yuanzhi and Yuan, Yang},
eprint = {1705.09886},
file = {:C$\backslash$:/Users/Daniel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Yuan - 2017 - Convergence Analysis of Two-layer Neural Networks with ReLU Activation.pdf:pdf},
journal = {arXiv},
month = {may},
title = {{Convergence Analysis of Two-layer Neural Networks with ReLU Activation}},
url = {http://arxiv.org/abs/1705.09886 https://arxiv.org/pdf/1705.09886.pdf},
year = {2017}
}
@article{Lee2016a,
abstract = {Circuits in the cerebral cortex consist of thousands of neurons connected by millions of synapses. A precise understanding of these local networks requires relating circuit activity with the underlying network structure. For pyramidal cells in superficial mouse visual cortex (V1), a consensus is emerging that neurons with similar visual response properties excite each other1–5, but the anatomical basis of this recurrent synaptic network is unknown. Here we combined physiological imaging and large-scale electron microscopy to study an excitatory network in V1. We found that layer 2/3 neurons organized into subnetworks defined by anatomical connectivity, with more connections within than between groups. More specifically, we found that pyramidal neurons with similar orientation selectivity preferentially formed synapses with each other, despite the fact that axons and dendrites of all orientation selectivities pass near ({\textless}5 µm) each other with roughly equal probability. Therefore, we predict that mechanisms of functionally specific connectivity take place at the length scale of spines. Neurons with similar orientation tuning formed larger synapses, potentially enhancing the net effect of synaptic specificity. With the ability to study thousands of connections in a single circuit, functional connectomics is proving a powerful method to uncover the organizational logic of cortical networks.},
author = {Lee, Wei-chung Allen and Bonin, Vincent and Reed, Michael and Graham, Brett J and Hood, Greg and Glattfelder, Katie and Reid, R. Clay},
doi = {10.1038/nature17192},
isbn = {1476-4687},
issn = {0028-0836},
journal = {Nature},
keywords = {10,1038,an excitatory network in,anatomy and function of,doi,nature17192},
number = {Table 1},
pages = {1--18},
pmid = {27018655},
title = {{Anatomy and function of an excitatory network in the visual cortex}},
url = {http://dx.doi.org/10.1038/nature17192},
volume = {532},
year = {2016}
}
@article{SalomeBourdieu06,
author = {Salome, R and Kremer, Y and Dieudonne, S and Leger, J-F and Krichevsky, O and Wyart, C and Chatenay, D and Bourdieu, L},
journal = {Journal of Neuroscience Methods},
month = {jun},
number = {1-2},
pages = {161--174},
title = {{Ultrafast random-access scanning in two-photon microscopy using acousto-optic deflectors}},
volume = {154},
year = {2006}
}
@article{Meyer2013,
abstract = {The cellular organization of the cortex is of fundamental importance for elucidating the structural principles that underlie its functions. It has been suggested that reconstructing the structure and synaptic wiring of the elementary functional building block of mammalian cortices, the cortical column, might suffice to reverse engineer and simulate the functions of entire cortices. In the vibrissal area of rodent somatosensory cortex, whisker-related "barrel" columns have been referred to as potential cytoarchitectonic equivalents of functional cortical columns. Here, we investigated the structural stereotypy of cortical barrel columns by measuring the 3D neuronal composition of the entire vibrissal area in rat somatosensory cortex and thalamus. We found that the number of neurons per cortical barrel column and thalamic "barreloid" varied substantially within individual animals, increasing by ∼2.5-fold from dorsal to ventral whiskers. As a result, the ratio between whisker-specific thalamic and cortical neurons was remarkably constant. Thus, we hypothesize that the cellular architecture of sensory cortices reflects the degree of similarity in sensory input and not columnar and/or cortical uniformity principles.},
author = {Meyer, Hanno S and Egger, Robert and Guest, Jason M and Foerster, Rita and Reissl, Stefan and Oberlaender, Marcel},
doi = {10.1073/pnas.1312691110},
file = {::},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Afferent Pathways,Afferent Pathways: cytology,Animals,Cell Count,Image Processing, Computer-Assisted,Microscopy, Confocal,Models, Neurological,Rats,Rats, Wistar,Somatosensory Cortex,Somatosensory Cortex: cytology,Vibrissae,Vibrissae: innervation},
month = {nov},
number = {47},
pages = {19113--8},
pmid = {24101458},
title = {{Cellular organization of cortical barrel columns is whisker-specific.}},
url = {http://www.pnas.org/content/110/47/19113.full},
volume = {110},
year = {2013}
}
@article{Friedrich2013,
abstract = {The clever choice of animal models has been instrumental for many breakthrough discoveries in life sciences. One of the outstanding challenges in neuroscience is the in-depth analysis of neuronal circuits to understand how interactions between large numbers of neurons give rise to the computational power of the brain. A promising model organism to address this challenge is the zebrafish, not only because it is cheap, transparent and accessible to sophisticated genetic manipulations but also because it offers unique advantages for quantitative analyses of circuit structure and function. One of the most important advantages of zebrafish is its small brain size, both at larval and adult stages. Small brains enable exhaustive measurements of neuronal activity patterns by optical imaging and facilitate large-scale reconstructions of wiring diagrams by electron microscopic approaches. Such information is important, and probably essential, to obtain mechanistic insights into neuronal computations underlying higher brain functions and dysfunctions. This review provides a brief overview over current methods and motivations for dense reconstructions of neuronal activity and connectivity patterns. It then discusses selective advantages of zebrafish and provides examples how these advantages are exploited to study neuronal computations in the olfactory bulb.},
author = {Friedrich, Rainer W and Genoud, Christel and Wanner, Adrian a},
doi = {10.3389/fncir.2013.00071},
issn = {1662-5110},
journal = {Frontiers in neural circuits},
keywords = {a series of seminal,activ,activity pattern,by discrete action,constructed modularly from distinct,discoveries demon-,during the last century,neuronal circuit,of neurons,olfactory system,reconstruction,strated that brains are,that information is transmitted,types,zebrafish},
month = {jan},
pmid = {23630467},
title = {{Analyzing the structure and function of neuronal circuits in zebrafish.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3632777{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Curto2009,
abstract = {The responses of neocortical cells to sensory stimuli are variable and state dependent. It has been hypothesized that intrinsic cortical dynamics play an important role in trial-to-trial variability; the precise nature of this dependence, however, is poorly understood. We show here that in auditory cortex of urethane-anesthetized rats, population responses to click stimuli can be quantitatively predicted on a trial-by-trial basis by a simple dynamical system model estimated from spontaneous activity immediately preceding stimulus presentation. Changes in cortical state correspond consistently to changes in model dynamics, reflecting a nonlinear, self-exciting system in synchronized states and an approximately linear system in desynchronized states. We propose that the complex and state-dependent pattern of trial-to-trial variability can be explained by a simple principle: sensory responses are shaped by the same intrinsic dynamics that govern ongoing spontaneous activity.},
author = {Curto, Carina and Sakata, Shuzo and Marguet, Stephan and Itskov, Vladimir and Harris, Kenneth D},
doi = {10.1523/JNEUROSCI.2053-09.2009},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Anesthetics, Intravenous,Anesthetics, Intravenous: pharmacology,Animals,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: drug effects,Auditory Cortex: physiology,Electric Stimulation,Electric Stimulation: methods,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Models, Neurological,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: drug effects,Neurons: physiology,Nonlinear Dynamics,Pedunculopontine Tegmental Nucleus,Pedunculopontine Tegmental Nucleus: physiology,Rats,Rats, Sprague-Dawley,Urethane,Urethane: pharmacology},
month = {aug},
number = {34},
pages = {10600--12},
pmid = {19710313},
title = {{A simple model of cortical dynamics explains variability and state dependence of sensory responses in urethane-anesthetized auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19710313},
volume = {29},
year = {2009}
}
@misc{Manchanda|2005|,
annote = {Lecture covers basics of neurons in brain, from molecular level to{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}morphology.},
author = {Manchanda, R},
keywords = {artificial intelligence,brain,morphology,neurobiology,neurons,overview,physiology},
title = {{Artificial Intelligence Lecture: Biological Neurons}}
}
@article{Rock93,
author = {Rockafellar, R T},
journal = {SIAM Review},
pages = {183--238},
title = {{Lagrange multipliers and optimality}},
volume = {35},
year = {1993}
}
@article{Rakshit2010,
abstract = {In recent years the theory of border collision bifurcations has been developed for piecewise smooth maps that are continuous across the border and has been successfully applied to explain nonsmooth bifurcation phenomena in physical systems. However, there exist a large number of switching dynamical systems that have been found to yield two-dimensional piecewise smooth maps that are discontinuous across the border. In this paper we present a systematic approach to the problem of analyzing the bifurcation phenomena in two-dimensional discontinuous maps, based on a piecewise linear approximation in the neighborhood of the border. We first motivate the analysis by considering the bifurcations occurring in a familiar physical system-the static VAR compensator used in electrical power systems-and then proceed to formulate the theory needed to explain the bifurcation behavior of such systems. We then integrate the observed bifurcation phenomenology of the compensator with the theory developed in this paper. This theory may be applied similarly to other systems that yield two-dimensional discontinuous maps.},
annote = {2011num23},
author = {Rakshit, Biswambhar and Apratim, Manjul and Banerjee, Soumitro},
doi = {10.1063/1.3422475},
issn = {1089-7682},
journal = {Chaos (Woodbury, N.Y.)},
month = {sep},
number = {3},
pages = {033101},
pmid = {20887041},
title = {{Bifurcation phenomena in two-dimensional piecewise smooth discontinuous maps.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20887041},
volume = {20},
year = {2010}
}
@article{Negahban2012,
author = {Negahban, Sahand N and Ravikumar, Pradeep and Wainwright, Martin J},
keywords = {and phrases,cambridge ma 02139,department of eecs,e-mail,edu,group lasso,high-dimensional statistics,lasso,m -estimator,massachusetts institute of technology,mit,nuclear norm,pradeep ravikumar,sahand negahban,sahandn,sparsity,ℓ 1 -regularization},
title = {{A unified framework for high-dimensional analysis of M -estimators with decomposable regularizers}},
volume = {78701},
year = {2012}
}
@article{Venter1998,
address = {Institute for Genomic Research, Rockville, MD 20850, USA.},
author = {Venter, J C and Adams, M D and Sutton, G G and Kerlavage, A R and Smith, H O and Hunkapiller, M},
journal = {Science},
keywords = {algorithms,analysis,animal,base,cloning,complementary,databases,dna,dna-instrumentation-methods,drosophila,factual,genetic,genetics,genome,human,markers,melanogaster-genetics,molecular,patents,polymorphism,project,sequence,sites,tagged},
pages = {1540--1542},
title = {{Shotgun sequencing of the human genome}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve{\&}{\#}38;db=PubMed{\&}{\%}2338;dopt=Citation{\&}{\%}2338;list{\_}uids=9644018},
volume = {280},
year = {1998}
}
@inproceedings{SMO99,
author = {Platt, J},
booktitle = {Advances in Kernel Methods - Support Vector Learning},
pages = {185--208},
publisher = {MIT Press},
title = {{Fast Training of Support Vector Machines using Sequential Minimal Optimization}},
year = {1999}
}
@inproceedings{Dauphin2014,
author = {Dauphin, YN and Pascanu, Razvan and Gulcehre, Caglar},
booktitle = {NIPS},
pages = {1--9},
title = {{Identifying and attacking the saddle point problem in high-dimensional non-convex optimization}},
url = {http://papers.nips.cc/paper/5486-sparse-pca-via-covariance-thresholding},
year = {2014}
}
@article{Menon2009,
abstract = {Realistic computational models of single neurons require component ion channels that reproduce experimental findings. Here, a topology-mutating genetic algorithm that searches for the best state diagram and transition-rate parameters to model macroscopic ion-channel behavior is described. Important features of the algorithm include a topology-altering strategy, automatic satisfaction of equilibrium constraints (microscopic reversibility), and multiple-protocol fitting using sequential goal programming rather than explicit weighting. Application of this genetic algorithm to design a sodium-channel model exhibiting both fast and prolonged inactivation yields a six-state model that produces realistic activity-dependent attenuation of action-potential backpropagation in current-clamp simulations of a CA1 pyramidal neuron.},
author = {Menon, Vilas and Spruston, Nelson and Kath, William L},
doi = {10.1073/pnas.0903766106},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Algorithms,Cell Membrane,Cell Membrane: metabolism,Ion Channels,Ion Channels: chemistry,Ion Channels: genetics,Models,Mutation,Neurons,Neurons: physiology,Sodium Channels,Sodium Channels: chemistry,Sodium Channels: genetics,Theoretical,slow sodium inactivation},
mendeley-tags = {slow sodium inactivation},
month = {sep},
number = {39},
pages = {16829--34},
pmid = {19805381},
title = {{A state-mutating genetic algorithm to design ion-channel models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19805381 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2757850{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {106},
year = {2009}
}
@article{ADR26,
author = {Adrian, E},
journal = {Journal of Physiology},
pages = {49--72},
title = {{The impulses produced by sensory nerve endings}},
volume = {61},
year = {1926}
}
@article{KleinShamma00,
author = {Klein, D J and Depireux, D A and Simon, J Z and Shamma, S A},
journal = {Journal of Computational Neuroscience},
month = {jul},
number = {1},
pages = {85--111},
title = {{Robust spectrotemporal reverse correlation for the auditory system: optimizing stimulus design}},
volume = {9},
year = {2000}
}
@article{nicolelis2009principles,
annote = {2008num34},
author = {Nicolelis, M A L and Lebedev, M A},
journal = {Nature Reviews Neuroscience},
number = {7},
pages = {530--540},
publisher = {Nature Publishing Group},
title = {{Principles of neural ensemble physiology underlying the operation of brain--machine interfaces}},
volume = {10},
year = {2009}
}
@article{Cheng07,
author = {Cheng, J and Zhou, X and Miller, E and Witt, R and Zhu, J and Sabatini, B and Wong, S},
journal = {Journal of Neuroscience Methods},
title = {{A Novel Computational Approach for Automatic Dendrite Spines Detection in Two-Photon Laser Scan Microscopy}},
volume = {To appear},
year = {2007}
}
@article{Assaf2006a,
annote = {2010num1.8},
author = {Assaf, Michael and Meerson, Baruch},
doi = {10.1103/PhysRevLett.97.200602},
issn = {0031-9007},
journal = {Physical Review Letters},
number = {20},
pages = {1--4},
title = {{Spectral Theory of Metastability and Extinction in Birth-Death Systems}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.97.200602},
volume = {97},
year = {2006}
}
@article{Mukamel2009,
abstract = {Recent advances in fluorescence imaging permit studies of Ca(2+) dynamics in large numbers of cells, in anesthetized and awake behaving animals. However, unlike for electrophysiological signals, standardized algorithms for assigning optically recorded signals to individual cells have not yet emerged. Here, we describe an automated sorting procedure that combines independent component analysis and image segmentation for extracting cells' locations and their dynamics with minimal human supervision. In validation studies using simulated data, automated sorting significantly improved estimation of cellular signals compared to conventional analysis based on image regions of interest. We used automated procedures to analyze data recorded by two-photon Ca(2+) imaging in the cerebellar vermis of awake behaving mice. Our analysis yielded simultaneous Ca(2+) activity traces for up to {\textgreater}100 Purkinje cells and Bergmann glia from single recordings. Using this approach, we found microzones of Purkinje cells that were stable across behavioral states and in which synchronous Ca(2+) spiking rose significantly during locomotion.},
author = {Mukamel, Eran a and Nimmerjahn, Axel and Schnitzer, Mark J},
doi = {10.1016/j.neuron.2009.08.009},
issn = {1097-4199},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Calcium,Calcium Signaling,Calcium Signaling: physiology,Calcium: metabolism,Cerebellum,Cerebellum: cytology,Cerebellum: physiology,Diagnostic Imaging,Diagnostic Imaging: methods,Flow Cytometry,Flow Cytometry: methods,Humans,Image Interpretation, Computer-Assisted,Locomotion,Locomotion: physiology,Male,Mice,Mice, Inbred C57BL,Nonlinear Dynamics,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Purkinje Cells,Purkinje Cells: cytology,Purkinje Cells: metabolism,Statistics as Topic},
month = {sep},
number = {6},
pages = {747--60},
pmid = {19778505},
publisher = {Elsevier Ltd},
title = {{Automated analysis of cellular signals from large-scale calcium imaging data.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3282191{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {63},
year = {2009}
}
@article{Brodsky|2003|,
abstract = {Light-front wavefunctions provide a frame-independent representation
of hadrons in terms of their physical quark and gluon degrees of
freedom. The light-front Hamiltonian formalism provides new nonperturbative
methods for obtaining the QCD spectrum and eigensolutions, including
resolvant methods, variational techniques, and discretized light-front
quantization. A new method for quantizing gauge theories in light-cone
gauge using Dirac brackets to implement constraints is presented.
In the case of the electroweak theory, this method of light-front
quantization leads to a unitary and renormalizable theory of massive
gauge particles, automatically incorporating the Lorentz and {\"{i}}¾'t
Hooft conditions as well as the Goldstone boson equivalence theorem.
Spontaneous symmetry breaking is represented by the appearance of
zero modes of the Higgs field leaving the light-front vacuum equal
to the perturbative vacuum. I also discuss an {\"{i}}¾“event amplitude
generator{\"{i}}¾” for automatically computing renormalized amplitudes
in perturbation theory. The importance of final-state interactions
for the interpretation of diffraction, shadowing, and single-spin
symmetries in inclusive reactions such as deep inelastic lepton-hadron
scattering is emphasized.},
author = {Brodsky, S J},
journal = {arXiv},
keywords = {generalized parton distribution,light front dynamics,perturbation theory,physics,quantum chromodynamics,unread},
pages = {304106},
title = {{Light-front quantization of gauge theories}},
volume = {hep-th}
}
@article{Rajeshwari2005,
author = {Rajeshwari, K and Kishore, DIV Lal},
keywords = {bayesian classifier,image distortion model,invariance features,neighbor algorithms,object recognition,tangent distance,tangent vectors,techniques like k- nearest},
pages = {916--922},
title = {{OBJECT RECOGNITION BASED ON INVARIANCE FEATURES FOR IMAGE CLASSIFICATION}},
url = {http://jatit.org/volumes/research-papers/Vol4No10/4Vol4No10.pdf},
year = {2005}
}
@article{GoldingOertel97,
author = {Golding, N L and Oertel, D},
journal = {Journal of Neurophysiology},
month = {jul},
number = {1},
pages = {248--260},
title = {{Physiological identification of the targets of cartwheel cells in the dorsal cochlear nucleus}},
volume = {78},
year = {1997}
}
@article{Liebovitch1987b,
annote = {2009num3},
author = {Liebovitch, L S and Sullivan, JM M},
journal = {Biophysical Journal},
number = {6},
pages = {979--988},
publisher = {Elsevier},
title = {{Fractal analysis of a voltage-dependent potassium channel from cultured mouse hippocampal neurons}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349587832903},
volume = {52},
year = {1987}
}
@article{Dalva94,
author = {Dalva, M B and Katz, L C},
journal = {Science},
number = {5169},
pages = {255--8.},
title = {{Rearrangements of synaptic connections in visual cortex revealed by laser photostimulation}},
volume = {265},
year = {1994}
}
@article{Fetter|1998|,
abstract = {This set of four lectures reviews various aspects of the theory of
a dilute low-temperature trapped Bose gas, starting with (I) a review
of the Bogoliubov description of the elementary excitations in a
uniform system. The treatment is then generalized (II) to include
the new physical efects of a confining harmonic trap potential on
the condensate and its normal modes. An equivalent hydrodynamic description
(III) focuses directly on the density and velocity uctuations. The
physics of vortices (IV) in an incompressible fluid is summarized
and extended to the case of a trapped Bose condensate.},
annote = {This article provides an excellent overview and introduction into{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}theory of Bose condensate and use of Bogoliubov description of elementary{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}excitations.},
author = {Fetter, A L},
journal = {arXiv},
keywords = {bogoliubov transformation,dillute bose-condensate,low temperature,physics,quantum mechanics,quasi-particles,superfluidity},
pages = {9811366},
title = {{Theory of dilute low-temperature trapped bose condensate}},
volume = {cond-mat}
}
@article{Wang1992,
author = {Wang, Hongmo},
isbn = {0780305930},
journal = {Circuits and Systems, 1992. ISCAS'92. Proceedings., {\ldots}},
pages = {1296--1299},
title = {{$\Sigma$$\Delta$ modulation from the perspective of nonlinear dynamics}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=230267},
year = {1992}
}
@article{Rasch2008,
annote = {On the relation between LFP and spikes},
author = {Rasch, M.J. J and Gretton, Arthur and Murayama, Yusuke and Maass, W and Logothetis, N.K. K},
doi = {10.1152/jn.00919.2007.},
journal = {Journal of neurophysiology},
number = {3},
pages = {1461},
publisher = {Am Physiological Soc},
title = {{Inferring spike trains from local field potentials}},
url = {http://jn.physiology.org/content/99/3/1461.short},
volume = {99},
year = {2008}
}
@article{DeRoo2008,
abstract = {Dendritic spines are the main postsynaptic site of excitatory contacts between neurons in the central nervous system. On cortical neurons, spines undergo a continuous turnover regulated by development and sensory activity. However, the functional implications of this synaptic remodeling for network properties remain currently unknown. Using repetitive confocal imaging on hippocampal organotypic cultures, we find that learning-related patterns of activity that induce long-term potentiation act as a selection mechanism for the stabilization and localization of spines. Through a lasting N-methyl-D-aspartate receptor and protein synthesis-dependent increase in protrusion growth and turnover, induction of plasticity promotes a pruning and replacement of nonactivated spines by new ones together with a selective stabilization of activated synapses. Furthermore, most newly formed spines preferentially grow in close proximity to activated synapses and become functional within 24 h, leading to a clustering of functional synapses. Our results indicate that synaptic remodeling associated with induction of long-term potentiation favors the selection of inputs showing spatiotemporal interactions on a given neuron.},
annote = {2010IIInum19},
author = {{De Roo}, Mathias and Klauser, Paul and Muller, Dominique},
doi = {10.1371/journal.pbio.0060219},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Animals,Dendritic Spines,Dendritic Spines: metabolism,Dendritic Spines: ultrastructure,Electrophysiology,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: physiology,Hippocampus,Hippocampus: cytology,Long-Term Potentiation,Long-Term Potentiation: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: cytology,Neurons: metabolism,Pyramidal Cells,Pyramidal Cells: cytology,Pyramidal Cells: metabolism,Rats,Synapses,Synapses: physiology,Synapses: ultrastructure,Synaptic Transmission,Synaptic Transmission: physiology,Tissue Culture Techniques},
month = {sep},
number = {9},
pages = {e219},
pmid = {18788894},
title = {{LTP promotes a selective long-term stabilization and clustering of dendritic spines.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18788894},
volume = {6},
year = {2008}
}
@article{Ham2006,
author = {Ham, Michael I and Gintautas, Vadas and Gross, Guenter W},
journal = {Cell},
pages = {8--11},
title = {{Spontaneous coordinated activity in cultured networks: analysis of multiple ignition sites, primary circuits, and burst phase delay distributions}},
year = {2006}
}
@article{Fearnhead2003,
author = {Fearnhead, P and Clifford, P},
journal = {J. R. Statist. Soc. B},
pages = {887--899},
title = {{On-line inference for hidden Markov models with particle filters}},
volume = {65},
year = {2003}
}
@article{izhikevich2004model,
annote = {2009num54},
author = {Izhikevich, E M},
journal = {IEEE transactions on neural networks},
number = {5},
pages = {1063--1070},
publisher = {Citeseer},
title = {{Which model to use for cortical spiking neurons?}},
volume = {15},
year = {2004}
}
@article{Memmesheimer2014,
abstract = {To signal the onset of salient sensory features or execute well-timed motor sequences, neuronal circuits must transform streams of incoming spike trains into precisely timed firing. To address the efficiency and fidelity with which neurons can perform such computations, we developed a theory to characterize the capacity of feedforward networks to generate desired spike sequences. We find the maximum number of desired output spikes a neuron can implement to be 0.1-0.3 per synapse. We further present a biologically plausible learning rule that allows feedforward and recurrent networks to learn multiple mappings between inputs and desired spike sequences. We apply this framework to reconstruct synaptic weights from spiking activity and study the precision with which the temporal structure of ongoing behavior can be inferred from the spiking of premotor neurons. This work provides a powerful approach for characterizing the computational and learning capacities of single neurons and neuronal circuits.},
author = {Memmesheimer, Raoul-Martin and Rubin, Ran and Olveczky, Bence P and Sompolinsky, Haim},
doi = {10.1016/j.neuron.2014.03.026},
issn = {1097-4199},
journal = {Neuron},
month = {may},
number = {4},
pages = {925--938},
pmid = {24768299},
title = {{Learning precisely timed spikes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24768299},
volume = {82},
year = {2014}
}
@article{Olsson-EM-gradient,
author = {Olsson, Rasmus Kongsgaard and Petersen, Kaare Brandt and Lehn-Schioler, Tue},
journal = {Neural Computation},
pages = {1097--1111},
title = {{State-space models: from the {\{}EM{\}} algorithm to a gradient approach}},
volume = {19},
year = {2007}
}
@article{Petrak|2005|,
author = {Petrak, L J and Harris, K M and Kirov, S A},
journal = {J Comp Neurol},
pages = {183--190},
title = {{Synaptogenesis on mature hippocampal dendrites occurs via filopodia and immature spines during blocked synaptic transmission.}},
volume = {484}
}
@article{Markram97,
author = {Markram, H and Luebke, J and Frotscher, M and Sakmann, B},
journal = {Science},
pages = {213--215},
title = {{Regulation of synaptic efficacy by coincidence of postsynaptic APs and EPSPs}},
volume = {275},
year = {1997}
}
@article{HPD03,
author = {Hatsopoulos, N and Paninski, L and Donoghue, J},
journal = {Experimental Brain Research},
pages = {478--486},
title = {{Sequential movement representations based on correlated neuronal activity}},
volume = {149},
year = {2003}
}
@article{Roorda99,
author = {Roorda, A and Williams, D},
journal = {Nature},
pages = {520--522},
title = {{The arrangement of the three cone classes in the living human eye}},
volume = {397},
year = {1999}
}
@article{Chena,
archivePrefix = {arXiv},
arxivId = {1707.09405},
author = {Chen, Qifeng},
eprint = {1707.09405},
title = {{Photographic Image Synthesis with Cascaded Refinement Networks}}
}
@article{Drezner1978,
author = {Drezner, Z},
journal = {Mathematics of Computation},
number = {141},
pages = {277--279},
title = {{Computation of the bivariate normal integral}},
url = {http://www.jstor.org/stable/10.2307/2006276},
volume = {32},
year = {1978}
}
@article{Fahrmeir91,
author = {Fahrmeir, Ludwig and Kaufmann, Heinz},
journal = {Metrika},
pages = {37--60},
title = {{On {\{}Kalman{\}} filtering, posterior mode estimation and Fisher scoring in dynamic exponential family regression}},
volume = {38},
year = {1991}
}
@article{Krumin2010b,
abstract = {Linear-Nonlinear-Poisson (LNP) models are a popular and powerful tool for describing encoding (stimulus-response) transformations by single sensory as well as motor neurons. Recently, there has been rising interest in the second- and higher-order correlation structure of neural spike trains, and how it may be related to specific encoding relationships. The distortion of signal correlations as they are transformed through particular LNP models is predictable and in some cases analytically tractable and invertible. Here, we propose that LNP encoding models can potentially be identified strictly from the correlation transformations they induce, and develop a computational method for identifying minimum-phase single-neuron temporal kernels under white and colored random Gaussian excitation. Unlike reverse-correlation or maximum-likelihood, correlation-distortion based identification does not require the simultaneous observation of stimulus-response pairs-only their respective second order statistics. Although in principle filter kernels are not necessarily minimum-phase, and only their spectral amplitude can be uniquely determined from output correlations, we show that in practice this method provides excellent estimates of kernels from a range of parametric models of neural systems. We conclude by discussing how this approach could potentially enable neural models to be estimated from a much wider variety of experimental conditions and systems, and its limitations.},
author = {Krumin, Michael and Shimron, Avner and Shoham, Shy},
doi = {10.1007/s10827-009-0184-0},
issn = {1573-6873},
journal = {Journal of Computational Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Linear Models,Models, Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Statistics as Topic,Time Factors},
month = {aug},
number = {1-2},
pages = {301--8},
pmid = {19757006},
title = {{Correlation-distortion based identification of Linear-Nonlinear-Poisson models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19757006},
volume = {29},
year = {2010}
}
@article{Stetter2012,
abstract = {A systematic assessment of global neural network connectivity through direct electrophysiological assays has remained technically infeasible, even in simpler systems like dissociated neuronal cultures. We introduce an improved algorithmic approach based on Transfer Entropy to reconstruct structural connectivity from network activity monitored through calcium imaging. We focus in this study on the inference of excitatory synaptic links. Based on information theory, our method requires no prior assumptions on the statistics of neuronal firing and neuronal connections. The performance of our algorithm is benchmarked on surrogate time series of calcium fluorescence generated by the simulated dynamics of a network with known ground-truth topology. We find that the functional network topology revealed by Transfer Entropy depends qualitatively on the time-dependent dynamic state of the network (bursting or non-bursting). Thus by conditioning with respect to the global mean activity, we improve the performance of our method. This allows us to focus the analysis to specific dynamical regimes of the network in which the inferred functional connectivity is shaped by monosynaptic excitatory connections, rather than by collective synchrony. Our method can discriminate between actual causal influences between neurons and spurious non-causal correlations due to light scattering artifacts, which inherently affect the quality of fluorescence imaging. Compared to other reconstruction strategies such as cross-correlation or Granger Causality methods, our method based on improved Transfer Entropy is remarkably more accurate. In particular, it provides a good estimation of the excitatory network clustering coefficient, allowing for discrimination between weakly and strongly clustered topologies. Finally, we demonstrate the applicability of our method to analyses of real recordings of in vitro disinhibited cortical cultures where we suggest that excitatory connections are characterized by an elevated level of clustering compared to a random graph (although not extreme) and can be markedly non-local.},
author = {Stetter, Olav and Battaglia, Demian and Soriano, Jordi and Geisel, Theo},
doi = {10.1371/journal.pcbi.1002653},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Animals,Calcium,Calcium: metabolism,Cells, Cultured,Cluster Analysis,Fluorescence,Models, Biological,Neurons,Neurons: cytology,Neurons: metabolism,Rats,Rats, Sprague-Dawley},
month = {jan},
number = {8},
pages = {e1002653},
pmid = {22927808},
title = {{Model-free reconstruction of excitatory neuronal connectivity from calcium imaging signals.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3426566{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {8},
year = {2012}
}
@article{Briggman2011,
abstract = {The proper connectivity between neurons is essential for the implementation of the algorithms used in neural computations, such as the detection of directed motion by the retina. The analysis of neuronal connectivity is possible with electron microscopy, but technological limitations have impeded the acquisition of high-resolution data on a large enough scale. Here we show, using serial block-face electron microscopy and two-photon calcium imaging, that the dendrites of mouse starburst amacrine cells make highly specific synapses with direction-selective ganglion cells depending on the ganglion cell's preferred direction. Our findings indicate that a structural (wiring) asymmetry contributes to the computation of direction selectivity. The nature of this asymmetry supports some models of direction selectivity and rules out others. It also puts constraints on the developmental mechanisms behind the formation of synaptic connections. Our study demonstrates how otherwise intractable neurobiological questions can be addressed by combining functional imaging with the analysis of neuronal connectivity using large-scale electron microscopy.},
author = {Briggman, Kevin L and Helmstaedter, Moritz and Denk, W},
doi = {10.1038/nature09818},
issn = {1476-4687},
journal = {Nature},
keywords = {Amacrine Cells,Amacrine Cells: cytology,Amacrine Cells: physiology,Amacrine Cells: ultrastructure,Animals,Calcium Signaling,Dendrites,Dendrites: physiology,Mice,Mice, Inbred C57BL,Microscopy, Electron,Microscopy, Fluorescence,Models, Neurological,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neural Pathways: ultrastructure,Neuroanatomical Tract-Tracing Techniques,Retina,Retina: anatomy {\&} histology,Retina: cytology,Retina: physiology,Retina: ultrastructure,Retinal Ganglion Cells,Retinal Ganglion Cells: cytology,Retinal Ganglion Cells: physiology,Retinal Ganglion Cells: ultrastructure,Synapses,Synapses: physiology,Synapses: ultrastructure},
month = {mar},
number = {7337},
pages = {183--8},
pmid = {21390125},
publisher = {Nature Publishing Group},
title = {{Wiring specificity in the direction-selectivity circuit of the retina.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21390125},
volume = {471},
year = {2011}
}
@book{chalgrec,
annote = {This chapter from unknown book deals with variety of methods used{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}for reconstructions from limited number of projections.},
keywords = {algebraic reconstruction,computational,discrete tomography,tomography},
title = {{Chapter 7: Algebraic Reconstruction Algorithms}}
}
@inproceedings{Courbariaux2015,
abstract = {Multipliers are the most space and power-hungry arithmetic operators of the digital implementation of deep neural networks. We train a set of state-of-the-art neural networks (Maxout networks) on three benchmark datasets: MNIST, CIFAR-10 and SVHN. They are trained with three distinct formats: floating point, fixed point and dynamic fixed point. For each of those datasets and for each of those formats, we assess the impact of the precision of the multiplications on the final error after training. We find that very low precision is sufficient not just for running trained networks but also for training them. For example, it is possible to train Maxout networks with 10 bits multiplications.},
archivePrefix = {arXiv},
arxivId = {1412.7024},
author = {Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
booktitle = {ICLR},
doi = {arXiv: 1412.7024},
eprint = {1412.7024},
month = {dec},
title = {{Training deep neural networks with low precision multiplications}},
url = {http://arxiv.org/abs/1412.7024},
year = {2015}
}
@article{Ventura09,
author = {Ventura, V},
journal = {Submitted},
title = {{Automatic Spike Sorting using Tuning Information}},
year = {2008}
}
@article{BW06,
author = {Berkes, P and Wiskott, L},
journal = {Neural Computation},
pages = {1868--1895},
title = {{On the Analysis and Interpretation of Inhomogeneous Quadratic Forms as Receptive Fields}},
volume = {18},
year = {2006}
}
@article{Goychuk2007,
archivePrefix = {arXiv},
arxivId = {arXiv:0705.3718v2},
author = {Goychuk, I},
eprint = {arXiv:0705.3718v2},
journal = {Physical review letters},
number = {x},
pages = {1--4},
title = {{Anomalous escape governed by thermal 1/f noise}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.99.200601},
year = {2007}
}
@article{Haupt2008,
author = {Haupt, Jarvis and Bajwa, WU},
journal = {Signal Processing {\ldots}},
number = {March 2008},
pages = {92--101},
title = {{Compressed sensing for networked data}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4472248},
year = {2008}
}
@article{Guckenheimer1997,
author = {Guckenheimer, J and Harris-warrick, R and Neurobiology, S and Peck, J},
journal = {Journal of Computational Neuroscience},
keywords = {bifurcation,bursting,singular perturbation,spike frequency adaptation,stomatogastric ganglion},
pages = {257--277},
title = {{Bifurcation , Bursting , and Spike Frequency Adaptation}},
volume = {277},
year = {1997}
}
@article{MolitorManis03,
author = {Molitor, Scott C and Manis, Paul B},
journal = {Journal of Neurophysiology},
month = {apr},
number = {4},
pages = {2225--2237},
title = {{Dendritic {\{}Ca{\}}{\^{}}{\{}2+{\}} transients evoked by action potentials in rat dorsal cochlear nucleus pyramidal and cartwheel neurons}},
volume = {89},
year = {2003}
}
@article{Tessone2006,
author = {Tessone, C and Mirasso, C and Toral, R and Gunton, J},
doi = {10.1103/PhysRevLett.97.194101},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {nov},
number = {19},
pages = {1--4},
title = {{Diversity-Induced Resonance}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.97.194101},
volume = {97},
year = {2006}
}
@article{Reynolds|2003|a,
abstract = {It has been reported that when an endogenous cue directs attention
to a brief translation of one of two superimposed surfaces, observers
reliably report the direction of that translation as well as the
direction of a second translation of the cued surface. In contrast,
if the uncued surface translates second, direction judgments are
severely impaired for several hundred milliseconds. We replicated
this result, but found that the impairment survived the removal of
the endogenous cue. The impairment is therefore not due to endogenously
cued attention. Instead, a brief translation of one surface acts
as an exogenous cue that triggers an automatic selection mechanism,
which suppresses processing of the other surface. This study provides
a clear case of exogenous cueing of surface-based attention. We relate
these results to identified competitive selection mechanisms in visual
cortex.},
author = {Reynolds, J H and Alborzian, S and Stoner, G R},
journal = {Vision research},
keywords = {attention,attentional blink,competition,cortex,decision making,neurobiology,object,psychology,unread},
pages = {59},
title = {{Exogenously cued attention triggers competitive selection of surfaces}},
volume = {43}
}
@article{Tian2017,
author = {Tian, Yuandong},
isbn = {0918334918},
journal = {Submitted to ICLR},
title = {{Symmetry-Breaking Convergence Analysis of Certain Two-layered Neural Networks with ReLU nonlinearity}},
year = {2017}
}
@article{Bengio2006,
author = {Bengio, Y and Lamblin, Pascal},
journal = {Advances in neural {\ldots}},
pages = {1--17},
title = {{Greedy layer-wise training of deep networks}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=Tbn1l9P1220C{\&}oi=fnd{\&}pg=PA153{\&}dq=Greedy+Layer-Wise+Training+of+Deep+Networks{\&}ots=V2pbFgilZY{\&}sig=d9TkQXv4ZUSb8Sve-mWiQ-y96qk},
year = {2007}
}
@article{EftychiosCOSYNE11,
author = {Pnevmatikakis, E A and Kelleher, K and Chen, R and Josic, K and Saggau, P and Paninski, L},
journal = {COSYNE},
title = {{Fast nonnegative spatiotemporal calcium smoothing in dendritic trees}},
year = {2011}
}
@article{WED76,
author = {Wedderburn, R},
journal = {Biometrika},
pages = {27--32},
title = {{On the existence and uniqueness of the maximum likelihood estimator for certain generalized linear models}},
volume = {63},
year = {1976}
}
@article{Burkitt06,
abstract = {The integrate-and-fire neuron model describes the state of a neuron in terms of its membrane potential, which is determined by the synaptic inputs and the injected current that the neuron receives. When the membrane potential reaches a threshold, an action potential (spike) is generated. This review considers the model in which the synaptic input varies periodically and is described by an inhomogeneous Poisson process, with both current and conductance synapses. The focus is on the mathematical methods that allow the output spike distribution to be analyzed, including first passage time methods and the Fokker-Planck equation. Recent interest in the response of neurons to periodic input has in part arisen from the study of stochastic resonance, which is the noise-induced enhancement of the signal-to-noise ratio. Networks of integrate-and-fire neurons behave in a wide variety of ways and have been used to model a variety of neural, physiological, and psychological phenomena. The properties of the integrate-and-fire neuron model with synaptic input described as a temporally homogeneous Poisson process are reviewed in an accompanying paper (Burkitt in Biol Cybern, 2006).},
annote = {2010num5.7},
author = {Burkitt, a N},
doi = {10.1007/s00422-006-0082-8},
issn = {0340-1200},
journal = {Biological Cybernetics},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Stochastic Processes,Synapses,Synapses: physiology,Synaptic Transmission},
month = {aug},
number = {1},
pages = {1--19,97--112},
pmid = {16821035},
publisher = {Springer},
title = {{A review of the integrate-and-fire neuron model}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16821035},
volume = {95},
year = {2006}
}
@book{Wiggins2003,
address = {New York},
author = {Wiggins, S},
publisher = {Springer Verlag},
title = {{Introduction to applied nonlinear dynamical systems and chaos}},
url = {http://books.google.com/books?hl=iw{\&}lr={\&}id=RSI4RGdwnU4C{\&}oi=fnd{\&}pg=PR5{\&}dq=introduction+to+applied+nonlinear+dyanmical+systems+and+chaos{\&}ots=mjHVOMcDio{\&}sig=rmlkrP1S-Hrl9ScpOH0PMwpPe{\_}0 http://books.google.com/books?hl=en{\&}lr={\&}id=GYcOfuZDOKMC{\&}oi=fnd{\&}pg=PR5{\&}dq=Introduction+to+applied+nonlinear+dynamical+systems+and+chaos{\&}ots=bFY6jK4Oe1{\&}sig=dXBSWY-C-0ql8-W13GAYf-jYlq0},
volume = {2},
year = {2003}
}
@book{Elad2010,
address = {New York, NY},
author = {Elad, Michael},
publisher = {Springer New York},
title = {{Sparse and redundant representations: from theory to applications in signal and image processing}},
year = {2010}
}
@article{Brette2013,
abstract = {In cortical neurons, spikes are initiated in the axon initial segment. Seen at the soma, they appear surprisingly sharp. A standard explanation is that the current coming from the axon becomes sharp as the spike is actively backpropagated to the soma. However, sharp initiation of spikes is also seen in the input-output properties of neurons, and not only in the somatic shape of spikes; for example, cortical neurons can transmit high frequency signals. An alternative hypothesis is that Na channels cooperate, but it is not currently supported by direct experimental evidence. I propose a simple explanation based on the compartmentalization of spike initiation. When Na channels are placed in the axon, the soma acts as a current sink for the Na current. I show that there is a critical distance to the soma above which an instability occurs, so that Na channels open abruptly rather than gradually as a function of somatic voltage.},
author = {Brette, Romain},
doi = {10.1371/journal.pcbi.1003338},
issn = {1553-7358},
journal = {PLoS computational biology},
month = {dec},
number = {12},
pages = {e1003338},
pmid = {24339755},
publisher = {Public Library of Science},
title = {{Sharpness of spike initiation in neurons explained by compartmentalization.}},
url = {http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1003338{\#}pcbi-1003338-g005},
volume = {9},
year = {2013}
}
@article{Brauchart2015,
abstract = {Geometric properties of {\$}N{\$} random points distributed independently and uniformly on the unit sphere {\$}\backslashmathbb{\{}S{\}}{\^{}}{\{}d{\}}\backslashsubset\backslashmathbb{\{}R{\}}{\^{}}{\{}d+1{\}}{\$} with respect to surface area measure are obtained and several related conjectures are posed. In particular, we derive asymptotics (as {\$}N \backslashto \backslashinfty{\$}) for the expected moments of the radii of spherical caps associated with the facets of the convex hull of {\$}N{\$} random points on {\$}\backslashmathbb{\{}S{\}}{\^{}}{\{}d{\}}{\$}. We provide conjectures for the asymptotic distribution of the scaled radii of these spherical caps and the expected value of the largest of these radii (the covering radius). Numerical evidence is included to support these conjectures. Furthermore, precise asymptotics for the expected separation of random points are deduced from a result of Cai et al. [J. Mach. Learn. Res., 2013].},
archivePrefix = {arXiv},
arxivId = {1512.07470},
author = {Brauchart, Johann S. and Saff, Edward B. and Sloan, Ian H. and Wang, Yu Guang and Womersley, Robert S.},
eprint = {1512.07470},
keywords = {and phrases,brauchart was also supported,by the austrian,covering radius,moments of hole radii,point separa-,project number dp120101816,random polytopes,s,s discovery projects funding,scheme,spherical random points,the research of j,this research was supported,tion,under australian research council},
title = {{Random Point Sets on the Sphere --- Hole Radii, Covering, and Separation}},
url = {http://arxiv.org/abs/1512.07470},
volume = {5510},
year = {2015}
}
@article{Haslinger2010,
abstract = {Neurons perform computations, and convey the results of those computations through the statistical structure of their output spike trains. Here we present a practical method, grounded in the information-theoretic analysis of prediction, for inferring a minimal representation of that structure and for characterizing its complexity. Starting from spike trains, our approach finds their causal state models (CSMs), the minimal hidden Markov models or stochastic automata capable of generating statistically identical time series. We then use these CSMs to objectively quantify both the generalizable structure and the idiosyncratic randomness of the spike train. Specifically, we show that the expected algorithmic information content (the information needed to describe the spike train exactly) can be split into three parts describing (1) the time-invariant structure (complexity) of the minimal spike-generating process, which describes the spike train statistically; (2) the randomness (internal entropy rate) of the minimal spike-generating process; and (3) a residual pure noise term not described by the minimal spike-generating process. We use CSMs to approximate each of these quantities. The CSMs are inferred nonparametrically from the data, making only mild regularity assumptions, via the causal state splitting reconstruction algorithm. The methods presented here complement more traditional spike train analyses by describing not only spiking probability and spike train entropy, but also the complexity of a spike train's structure. We demonstrate our approach using both simulated spike trains and experimental data recorded in rat barrel cortex during vibrissa stimulation.},
annote = {2010IInum12.25},
author = {Haslinger, Robert and Klinkner, Kristina Lisa and Shalizi, Cosma Rohilla},
doi = {10.1162/neco.2009.12-07-678},
issn = {1530-888X},
journal = {Neural Computation},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Brain,Brain: physiology,Computer Simulation,Computer-Assisted,Entropy,Markov Chains,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neuron Model,Neurons,Neurons: physiology,Normal Distribution,Rats,Sensory Receptor Cells,Sensory Receptor Cells: physiology,Signal Processing,Somatosensory Cortex,Somatosensory Cortex: physiology,Stochastic Processes,Synaptic Transmission,Synaptic Transmission: physiology},
mendeley-tags = {Neuron Model},
month = {jan},
number = {1},
pages = {121--57},
pmid = {19764880},
title = {{The computational structure of spike trains.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19764880},
volume = {22},
year = {2010}
}
