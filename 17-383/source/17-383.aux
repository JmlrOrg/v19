\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\citation{fang2014sparse}
\citation{JacquLBB_Robust,LaskaWYB_Trust}
\citation{aziz1996overview,candy1962oversampling}
\citation{BoufoB_1Bit,hunter2010compressive,calderbank2009compressed,davenport2010signal,gupta2010sample,hahn2014adaptive}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Contribution}{2}{subsection.2}}
\citation{CristS_Introduction,hearst1998support,joachims1998text,steinwart2008support}
\citation{JohnsL_Extensions}
\citation{ailon2006approximate,achlioptas2003database,dasgupta2003elementary}
\citation{CandeRT_Stable,CandeRT_Robust,Donoh_Compressed}
\citation{baraniuk2006johnson}
\citation{krahmer2011new}
\citation{BoufoB_1Bit,hunter2010compressive,calderbank2009compressed,davenport2010signal,gupta2010sample,hahn2014adaptive}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Organization}{3}{subsection.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Prior Work}{3}{subsection.4}}
\newlabel{sec:prior}{{1.3}{3}{}{subsection.4}{}}
\citation{BoufoB_1Bit}
\citation{PlanV_One,PlanV_Robust,gopi2013one,JacquLBB_Robust,yan2012robust,jacques2013quantized}
\citation{PlanV_Dimension,yu2014circulant,gong2013iterative,price2015binary,choromanska2016binary,dirksen2016fast}
\citation{dirksen2016fast}
\citation{PlanV_Dimension,PlanV_One}
\citation{krizhevsky2012imagenet,simonyan2014very,szegedy2015going,russakovsky2015imagenet}
\citation{rahimi2009weighted,giryes2016deep}
\citation{kim2016bitwise,courbariaux2015binaryconnect,courbariaux2016binarized}
\citation{lin2015neural,marchesi1993fast,simard1994backpropagation,burge1999rising,rastegari2016xnor,hubara2016quantized}
\citation{rahimi2009weighted,ozuysal2010fast}
\@writefile{toc}{\contentsline {section}{\numberline {2}The Proposed Classification Algorithm}{5}{section.5}}
\newlabel{section::algorithm}{{2}{5}{}{section.5}{}}
\newlabel{RF3}{{1}{6}{}{equation.6}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Training \relax }}{6}{algorithm.8}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{proposed algorithm1}{{1}{6}{Training \relax }{algorithm.8}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Classification\relax }}{7}{algorithm.17}}
\newlabel{proposed algorithm2}{{2}{7}{Classification\relax }{algorithm.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Results}{7}{section.29}}
\newlabel{section::experiments}{{3}{7}{}{section.29}{}}
\citation{exponentialBFNPW14,cambareri2017rare}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Classification of Synthetic Datasets}{8}{subsection.30}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Synthetic classification experiment with three Gaussian clouds ($G=3$), $L=1$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Left) Example training and testing data setup. (Right) Average correct classification rate versus $m$ and for the indicated number of training points per class.\relax }}{9}{figure.caption.31}}
\newlabel{syn:gaussian clouds}{{1}{9}{Synthetic classification experiment with three Gaussian clouds ($G=3$), $L=1$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Left) Example training and testing data setup. (Right) Average correct classification rate versus $m$ and for the indicated number of training points per class.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Synthetic classification experiment with six Gaussian clouds and two classes ($G=2$), $L=4$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Left) Example training and testing data setup. (Right) Average correct classification rate versus $m$ and for the indicated number of training points per class.\relax }}{9}{figure.caption.32}}
\newlabel{syn:gaussian2 alternating6}{{2}{9}{Synthetic classification experiment with six Gaussian clouds and two classes ($G=2$), $L=4$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Left) Example training and testing data setup. (Right) Average correct classification rate versus $m$ and for the indicated number of training points per class.\relax }{figure.caption.32}{}}
\citation{MNIST}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Synthetic classification experiment with eight Gaussian clouds and two classes ($G=2$), $L=5$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Left) Example training and testing data setup. (Right) Average correct classification rate versus $m$ and for the indicated number of training points per class.\relax }}{10}{figure.caption.33}}
\newlabel{syn:gaussian2 alternating8}{{3}{10}{Synthetic classification experiment with eight Gaussian clouds and two classes ($G=2$), $L=5$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Left) Example training and testing data setup. (Right) Average correct classification rate versus $m$ and for the indicated number of training points per class.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Handwritten Digit Classification}{10}{subsection.36}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Synthetic classification experiment with eight Gaussian clouds and three classes ($G=3$), $L=1,\dots  ,4$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Top) Example training and testing data setup. Average correct classification rate versus $m$ and for the indicated number of training points per class for: (middle left) $L=1$, (middle right) $L=2$, (bottom left) $L=3$, (bottom right) $L=4$.\relax }}{11}{figure.caption.34}}
\newlabel{syn:gaussian3 alternating8}{{4}{11}{Synthetic classification experiment with eight Gaussian clouds and three classes ($G=3$), $L=1,\dots ,4$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Top) Example training and testing data setup. Average correct classification rate versus $m$ and for the indicated number of training points per class for: (middle left) $L=1$, (middle right) $L=2$, (bottom left) $L=3$, (bottom right) $L=4$.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Synthetic classification experiment with eight Gaussian clouds and four classes ($G=4$), $L=1,\dots  ,4$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Top) Example training and testing data setup. Average correct classification rate versus $m$ and for the indicated number of training points per class for: (middle left) $L=1$, (middle right) $L=2$, (bottom left) $L=3$, (bottom right) $L=4$.\relax }}{12}{figure.caption.35}}
\newlabel{syn:gaussian4 alternating8}{{5}{12}{Synthetic classification experiment with eight Gaussian clouds and four classes ($G=4$), $L=1,\dots ,4$, $n=2$, 50 test points per group, and 30 trials of randomly generating $A$. (Top) Example training and testing data setup. Average correct classification rate versus $m$ and for the indicated number of training points per class for: (middle left) $L=1$, (middle right) $L=2$, (bottom left) $L=3$, (bottom right) $L=4$.\relax }{figure.caption.35}{}}
\citation{CHHH07,CHH07b,CHHZ06,HYHNZ05}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Classification experiment using the handwritten ``0" and ``1" digit images from the MNIST dataset, $L=1$, $n=28\times 28 =784$, 50 test points per group, and 30 trials of randomly generating $A$. (Top left) Training data images when $p = 50$. (Top right) Average correct classification rate versus $m$ and for the indicated number of training points per class. (Bottom) Testing data images.\relax }}{13}{figure.caption.37}}
\newlabel{mnist:01}{{6}{13}{Classification experiment using the handwritten ``0" and ``1" digit images from the MNIST dataset, $L=1$, $n=28\times 28 =784$, 50 test points per group, and 30 trials of randomly generating $A$. (Top left) Training data images when $p = 50$. (Top right) Average correct classification rate versus $m$ and for the indicated number of training points per class. (Bottom) Testing data images.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Facial Recognition}{13}{subsection.40}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Classification experiment using the handwritten ``0" and ``5" digit images from the MNIST dataset, $L=4$, $n=28\times 28=784$, 50 test points per group, and 30 trials of randomly generating $A$. (Top) Training data images when $p = 50$. (Middle) Testing data images. Average correct classification rate versus $m$ and for the indicated number of training points per class {{(bottom left) when using a Gaussian matrix $A$ and (bottom right) when using a DCT matrix $A$.}}\relax }}{14}{figure.caption.38}}
\newlabel{mnist:05}{{7}{14}{Classification experiment using the handwritten ``0" and ``5" digit images from the MNIST dataset, $L=4$, $n=28\times 28=784$, 50 test points per group, and 30 trials of randomly generating $A$. (Top) Training data images when $p = 50$. (Middle) Testing data images. Average correct classification rate versus $m$ and for the indicated number of training points per class \edit {(bottom left) when using a Gaussian matrix $A$ and (bottom right) when using a DCT matrix $A$.}\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Correct classification rate versus $m$ when using all ten (0-9) handwritten digits from the MNIST dataset, $L=18$, $n=28\times 28=784$, 1,000, 3,000, and 5,000 training points per group, 800 test points per group (8,000 total), and a single instance of randomly generating $A$.\relax }}{14}{figure.caption.39}}
\newlabel{mnist:all}{{8}{14}{Correct classification rate versus $m$ when using all ten (0-9) handwritten digits from the MNIST dataset, $L=18$, $n=28\times 28=784$, 1,000, 3,000, and 5,000 training points per group, 800 test points per group (8,000 total), and a single instance of randomly generating $A$.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Classification experiment using {{four}} individuals from the extended YaleB dataset, $L=4$, $n=32\times 32 = 1024$, 30 test points per group, and 30 trials of randomly generating $A$. (Top left) Training data images when $p = 20$. (Top right) Average correct classification rate versus $m$ and for the indicated number of training points per class. (Bottom) Testing data images.\relax }}{15}{figure.caption.41}}
\newlabel{yaleB}{{9}{15}{Classification experiment using \edit {four} individuals from the extended YaleB dataset, $L=4$, $n=32\times 32 = 1024$, 30 test points per group, and 30 trials of randomly generating $A$. (Top left) Training data images when $p = 20$. (Top right) Average correct classification rate versus $m$ and for the indicated number of training points per class. (Bottom) Testing data images.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Theoretical Analysis for a Simple Case}{15}{section.42}}
\newlabel{section::theory}{{4}{15}{}{section.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Main Results}{15}{subsection.43}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Visualization of the analysis setup for two classes of two dimensions. If a hyperplane intersects the $\theta _1$ region of $G_1$, then $x$ is not on the same side of the hyperplane as $G_2$. If a hyperplane intersects the $\theta _2$ region of $G_1$, then $x$ is on the same side of the hyperplane as $G_2$. That is, $\theta _1$ and $\theta _2$ are determined by the position of $x$ within $G_1$, and $\theta _1+\theta _2 = A_1$.\relax }}{16}{figure.caption.44}}
\newlabel{2d cones}{{10}{16}{Visualization of the analysis setup for two classes of two dimensions. If a hyperplane intersects the $\theta _1$ region of $G_1$, then $x$ is not on the same side of the hyperplane as $G_2$. If a hyperplane intersects the $\theta _2$ region of $G_1$, then $x$ is on the same side of the hyperplane as $G_2$. That is, $\theta _1$ and $\theta _2$ are determined by the position of $x$ within $G_1$, and $\theta _1+\theta _2 = A_1$.\relax }{figure.caption.44}{}}
\newlabel{RF3 continuous}{{2}{16}{}{equation.45}{}}
\newlabel{main theorem}{{2}{17}{}{theorem.46}{}}
\newlabel{RF3 bound multinomial complement}{{3}{17}{}{equation.47}{}}
\newlabel{Corollary 1}{{3}{17}{}{theorem.48}{}}
\newlabel{Corollary 2}{{4}{17}{}{theorem.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Proof of Main Results}{17}{subsection.51}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Proof of Theorem \ref  {main theorem}}{17}{subsubsection.52}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces $\mathbb  {P}[\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle b$}\mathaccent "0362{b}_x = 1]$ versus the number of hyperplanes $m$ when $A_{12}$ is varied (see legend), $A_1 = A_2 = 15^\circ $, and $\theta _1 = \theta _2 = 7.5^\circ $. The solid lines indicate the probability (\ref  {classification with cutting continuous}) with the multinomial probability given by (\ref  {multinomial probability}) and the conditional probability (\ref  {conditional probability continuous RF3}) simulated over 1000 trials of the uniform random variables. The dashed lines indicate the result (\ref  {RF3 bound multinomial complement}) provided in Theorem \ref  {main theorem}.\relax }}{18}{figure.caption.50}}
\newlabel{theorem figure}{{11}{18}{$\mathbb {P}[\widehat {b}_x = 1]$ versus the number of hyperplanes $m$ when $A_{12}$ is varied (see legend), $A_1 = A_2 = 15^\circ $, and $\theta _1 = \theta _2 = 7.5^\circ $. The solid lines indicate the probability (\ref {classification with cutting continuous}) with the multinomial probability given by (\ref {multinomial probability}) and the conditional probability (\ref {conditional probability continuous RF3}) simulated over 1000 trials of the uniform random variables. The dashed lines indicate the result (\ref {RF3 bound multinomial complement}) provided in Theorem \ref {main theorem}.\relax }{figure.caption.50}{}}
\newlabel{theevent}{{4}{18}{}{equation.53}{}}
\newlabel{classification with cutting continuous}{{5}{19}{}{equation.54}{}}
\newlabel{multinomial probability}{{6}{19}{}{equation.55}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of (\ref  {RF3 continuous}) when up to one cone can be cut per hyperplane, where $ u, u'$ {{are independent random variables defined over the interval $[0,1]$}}.\relax }}{19}{table.caption.56}}
\newlabel{table::redness factors for 2d cones}{{1}{19}{Summary of (\ref {RF3 continuous}) when up to one cone can be cut per hyperplane, where $ u, u'$ \edit {are independent random variables defined over the interval $[0,1]$}.\relax }{table.caption.56}{}}
\newlabel{compRF1}{{7}{20}{}{equation.57}{}}
\newlabel{compRF2}{{8}{20}{}{equation.58}{}}
\newlabel{conditional probability continuous RF3}{{9}{20}{}{equation.59}{}}
\newlabel{conditional probability continuous RF3 A1=A2}{{10}{20}{}{equation.60}{}}
\newlabel{choose theta bound}{{12}{21}{}{equation.62}{}}
\newlabel{RF3 bound multinomial}{{15}{21}{}{equation.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Proof of Corollary \ref  {Corollary 1}}{21}{subsubsection.66}}
\newlabel{multinomial count}{{16}{22}{}{equation.67}{}}
\newlabel{RF3 bound multinomial estimate}{{17}{22}{}{equation.68}{}}
\newlabel{multinomial bound}{{18}{22}{}{equation.69}{}}
\newlabel{rest bound}{{20}{22}{}{equation.71}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Proof of Corollary \ref  {Corollary 2}}{23}{subsubsection.73}}
\newlabel{equivalent probability}{{22}{23}{}{equation.74}{}}
\newlabel{facts}{{23}{23}{}{equation.75}{}}
\newlabel{Stirling step}{{24}{23}{}{equation.76}{}}
\newlabel{trinomial bound}{{25}{23}{}{equation.77}{}}
\newlabel{corollary 2 bound}{{26}{23}{}{equation.78}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion and Conclusion}{24}{section.80}}
\newlabel{sec::conclude}{{5}{24}{}{section.80}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Elementary Computations}{25}{section.81}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Derivation of \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {multinomial count}\unskip \@@italiccorr )}}}{25}{subsection.82}}
\newlabel{app:comb}{{A.1}{25}{}{subsection.82}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Derivation of \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {facts}\unskip \@@italiccorr )}}}{25}{subsection.86}}
\newlabel{app:facts}{{A.2}{25}{}{subsection.86}{}}
\bibstyle{natbib}
\bibdata{../bib}
\bibcite{achlioptas2003database}{{1}{2003}{{Achlioptas}}{{}}}
\bibcite{ailon2006approximate}{{2}{2006}{{Ailon and Chazelle}}{{}}}
\bibcite{aziz1996overview}{{3}{1996}{{Aziz et~al.}}{{Aziz, Sorensen, and Vn~der Spiegel}}}
\bibcite{baraniuk2006johnson}{{4}{2006}{{Baraniuk et~al.}}{{Baraniuk, Davenport, DeVore, and Wakin}}}
\bibcite{exponentialBFNPW14}{{5}{2017}{{Baraniuk et~al.}}{{Baraniuk, Foucart, Needell, Plan, and Wootters}}}
\bibcite{BoufoB_1Bit}{{6}{2008}{{Boufounos and Baraniuk}}{{}}}
\bibcite{burge1999rising}{{7}{1999}{{Burge et~al.}}{{Burge, van Daalen, Rising, and Shawe-Taylor}}}
\bibcite{CHHZ06}{{8}{2006}{{Cai et~al.}}{{Cai, He, Han, and Zhang}}}
\bibcite{CHH07b}{{9}{2007{a}}{{Cai et~al.}}{{Cai, He, and Han}}}
\bibcite{CHHH07}{{10}{2007{b}}{{Cai et~al.}}{{Cai, He, Hu, Han, and Huang}}}
\bibcite{calderbank2009compressed}{{11}{2009}{{Calderbank et~al.}}{{Calderbank, Jafarpour, and Schapire}}}
\bibcite{cambareri2017rare}{{12}{2017}{{Cambareri et~al.}}{{Cambareri, Xu, and Jacques}}}
\bibcite{CandeRT_Robust}{{13}{2006{a}}{{Cand\`{e}s et~al.}}{{Cand\`{e}s, Romberg, and Tao}}}
\bibcite{CandeRT_Stable}{{14}{2006{b}}{{Cand\`{e}s et~al.}}{{Cand\`{e}s, Romberg, and Tao}}}
\bibcite{candy1962oversampling}{{15}{1962}{{Candy and Temes}}{{}}}
\bibcite{choromanska2016binary}{{16}{2016}{{Choromanska et~al.}}{{Choromanska, Choromanski, Bojarski, Jebara, Kumar, and LeCun}}}
\bibcite{CristS_Introduction}{{17}{2000}{{Christianini and Shawe-Taylor}}{{}}}
\bibcite{courbariaux2015binaryconnect}{{18}{2015}{{Courbariaux et~al.}}{{Courbariaux, Bengio, and David}}}
\bibcite{courbariaux2016binarized}{{19}{2016}{{Courbariaux et~al.}}{{Courbariaux, Hubara, Soudry, El-Yaniv, and Bengio}}}
\bibcite{dasgupta2003elementary}{{20}{2003}{{Dasgupta and Gupta}}{{}}}
\bibcite{davenport2010signal}{{21}{2010}{{Davenport et~al.}}{{Davenport, Boufounos, Wakin, and Baraniuk}}}
\bibcite{dirksen2016fast}{{22}{2016}{{Dirksen and Stollenwerk}}{{}}}
\bibcite{Donoh_Compressed}{{23}{2006}{{Donoho}}{{}}}
\bibcite{fang2014sparse}{{24}{2014}{{Fang et~al.}}{{Fang, Shen, Li, and Ren}}}
\bibcite{giryes2016deep}{{25}{2016}{{Giryes et~al.}}{{Giryes, Sapiro, and Bronstein}}}
\bibcite{gong2013iterative}{{26}{2013}{{Gong et~al.}}{{Gong, Lazebnik, Gordo, and Perronnin}}}
\bibcite{gopi2013one}{{27}{2013}{{Gopi et~al.}}{{Gopi, Netrapalli, Jain, and Nori}}}
\bibcite{gupta2010sample}{{28}{2010}{{Gupta et~al.}}{{Gupta, Nowak, and Recht}}}
\bibcite{hahn2014adaptive}{{29}{2014}{{Hahn et~al.}}{{Hahn, Rosenkranz, and Zoubir}}}
\bibcite{HYHNZ05}{{30}{2005}{{He et~al.}}{{He, Yan, Hu, Niyogi, and Zhang}}}
\bibcite{hearst1998support}{{31}{1998}{{Hearst et~al.}}{{Hearst, Dumais, Osuna, Platt, and Scholkopf}}}
\bibcite{hubara2016quantized}{{32}{2016}{{Hubara et~al.}}{{Hubara, Courbariaux, Soudry, El-Yaniv, and Bengio}}}
\bibcite{hunter2010compressive}{{33}{2010}{{Hunter et~al.}}{{Hunter, Strohmer, Simos, Psihoyios, and Tsitouras}}}
\bibcite{jacques2013quantized}{{34}{2013{a}}{{Jacques et~al.}}{{Jacques, Degraux, and De~Vleeschouwer}}}
\bibcite{JacquLBB_Robust}{{35}{2013{b}}{{Jacques et~al.}}{{Jacques, Laska, Boufounos, and Baraniuk}}}
\bibcite{joachims1998text}{{36}{1998}{{Joachims}}{{}}}
\bibcite{JohnsL_Extensions}{{37}{1982}{{Johnson and Lindenstrauss}}{{}}}
\bibcite{kim2016bitwise}{{38}{2016}{{Kim and Smaragdis}}{{}}}
\bibcite{krahmer2011new}{{39}{2011}{{Krahmer and Ward}}{{}}}
\bibcite{krizhevsky2012imagenet}{{40}{2012}{{Krizhevsky et~al.}}{{Krizhevsky, Sutskever, and Hinton}}}
\bibcite{LaskaWYB_Trust}{{41}{2011}{{Laska et~al.}}{{Laska, Wen, Yin, and Baraniuk}}}
\bibcite{MNIST}{{42}{2018}{{LeCun}}{{}}}
\bibcite{lin2015neural}{{43}{2015}{{Lin et~al.}}{{Lin, Courbariaux, Memisevic, and Bengio}}}
\bibcite{marchesi1993fast}{{44}{1993}{{Marchesi et~al.}}{{Marchesi, Orlandi, Piazza, and Uncini}}}
\bibcite{ozuysal2010fast}{{45}{2010}{{Ozuysal et~al.}}{{Ozuysal, Calonder, Lepetit, and Fua}}}
\bibcite{PlanV_One}{{46}{2013{a}}{{Plan and Vershynin}}{{}}}
\bibcite{PlanV_Robust}{{47}{2013{b}}{{Plan and Vershynin}}{{}}}
\bibcite{PlanV_Dimension}{{48}{2014}{{Plan and Vershynin}}{{}}}
\bibcite{rahimi2009weighted}{{49}{2009}{{Rahimi and Recht}}{{}}}
\bibcite{rastegari2016xnor}{{50}{2016}{{Rastegari et~al.}}{{Rastegari, Ordonez, Redmon, and Farhadi}}}
\bibcite{russakovsky2015imagenet}{{51}{2015}{{Russakovsky et~al.}}{{Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpathy, Khosla, Bernstein, et~al.}}}
\bibcite{simard1994backpropagation}{{52}{1994}{{Simard and Graf}}{{}}}
\bibcite{simonyan2014very}{{53}{2014}{{Simonyan and Zisserman}}{{}}}
\bibcite{steinwart2008support}{{54}{2008}{{Steinwart and Christmann}}{{}}}
\bibcite{szegedy2015going}{{55}{2015}{{Szegedy et~al.}}{{Szegedy, Liu, Jia, Sermanet, Reed, Anguelov, Erhan, Vanhoucke, and Rabinovich}}}
\bibcite{yan2012robust}{{56}{2012}{{Yan et~al.}}{{Yan, Yang, and Osher}}}
\bibcite{price2015binary}{{57}{2015}{{Yi et~al.}}{{Yi, Caravans, and Price}}}
\bibcite{yu2014circulant}{{58}{2014}{{Yu et~al.}}{{Yu, Kumar, Gong, and Chang}}}
\newlabel{LastPage}{{}{30}{}{page.30}{}}
\xdef\lastpage@lastpage{30}
\xdef\lastpage@lastpageHy{30}
