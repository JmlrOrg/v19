\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\citation{besag1974spatial}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{eq::spexf}{{1}{1}{}{equation.2}{}}
\citation{zhang2010analysis}
\citation{liang2000regression,diao2012maximum,chan2012nuisance,ning2014sparc}
\citation{zhang2010analysis}
\citation{ning2014sparc}
\citation{ning2014sparc}
\citation{lauritzen1996graphical,edwards2000introduction,whittaker2009graphical}
\citation{yuan2007model,banerjee2008model,friedman2008sparse,ravikumar2011high,rothman2008sparse,lam2009sparsistency,shen2012likelihood,yuan2010high,cai2011constrained,sun2013sparse,guo2011joint,danaher2014joint,mohan2014node,meinshausen2006high,peng2009partial,friedman2010applications}
\citation{liu2009nonparanormal,xue2012regularized,liu2012high,ning2013high}
\citation{voorman2014graph}
\citation{lee2006efficient,hofling2009estimation,ravikumar2010high,xue2012nonconcave,cheng2012sparse}
\citation{allen2012log}
\citation{yang2013poisson}
\citation{guo2014graphical}
\citation{yang2013graphical}
\citation{tan2014learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Related Works}{2}{subsection.3}}
\citation{lee2013structure,fellinghauer2013stable,cheng2013high,chen2013selection,fan2014high,yang2014mixed}
\citation{lee2013structure,cheng2013high,chen2013selection,yang2014mixed}
\citation{fellinghauer2013stable}
\citation{fan2014high}
\citation{drton2007multiple,drton2008sinful}
\citation{ren2013asymptotic,jankova2014confidence,gu2015local}
\citation{liu2013gaussian}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Notation}{3}{subsection.4}}
\citation{chen2013selection}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Paper Organization}{4}{subsection.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Semiparametric Exponential Family Graphical Models}{4}{section.6}}
\newlabel{sec::background}{{2}{4}{}{section.6}{}}
\newlabel{def::model}{{1}{4}{Semiparametric exponential family graphical model}{theorem.7}{}}
\newlabel{equ::conditional}{{2}{4}{Semiparametric exponential family graphical model}{equation.8}{}}
\newlabel{equ::joint}{{3}{4}{}{equation.9}{}}
\newlabel{log partition}{{4}{4}{}{equation.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Examples}{5}{subsection.11}}
\citation{ning2014sparc}
\citation{liang2000regression,diao2012maximum,chan2012nuisance}
\@writefile{toc}{\contentsline {section}{\numberline {3}Graph Estimation and Uncertainty Assessment}{6}{section.12}}
\newlabel{sec::methodology}{{3}{6}{}{section.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}A Nuisance-Free Loss Function}{6}{subsection.13}}
\citation{tibshirani1996regression}
\citation{fan2014strong}
\citation{zhang2008sparsity}
\newlabel{eq:conditional_likelihood}{{5}{7}{}{equation.14}{}}
\newlabel{equ::NodewiseLoss}{{6}{7}{}{equation.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Adaptive Multi-stage Convex Relaxation Algorithm}{7}{subsection.16}}
\newlabel{subsec::estimation}{{3.2}{7}{}{subsection.16}{}}
\newlabel{equ::concave}{{7}{7}{}{equation.17}{}}
\newlabel{cond::penalty1}{{3.2}{7}{}{equation.17}{}}
\newlabel{cond::penalty2}{{3.2}{7}{}{equation.17}{}}
\citation{zou2008one,fan2014strong}
\citation{zhang2010analysis,zhang2013multi,fan2018lamm}
\newlabel{cond::penalty3}{{3.2}{8}{}{equation.17}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Adaptive Multi-stage Convex Relaxation algorithm for parameter estimation}}{8}{algorithm.18}}
\newlabel{algo::multi}{{1}{8}{}{algorithm.18}{}}
\newlabel{alg::step4}{{4}{8}{}{ALC@unique.22}{}}
\newlabel{opt::convex}{{8}{8}{}{equation.23}{}}
\newlabel{alg::Step7}{{7}{8}{}{ALC@unique.26}{}}
\citation{ning2017general,neykov2018unified}
\citation{ren2013asymptotic,jankova2014confidence,liu2013gaussian}
\citation{ning2014sparc}
\citation{candes2007dantzig}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Graph Inference: Composite Pairwise Score Test}{9}{subsection.28}}
\newlabel{eq:sw_vec}{{9}{9}{}{equation.29}{}}
\newlabel{equ::score}{{10}{9}{}{equation.30}{}}
\newlabel{equ::Dantzig}{{11}{9}{}{equation.31}{}}
\newlabel{equ::ScoreStat}{{12}{9}{}{equation.32}{}}
\citation{yang2013graphical}
\citation{chen2013selection}
\citation{yang2013graphical}
\newlabel{equ::testFunc1}{{13}{10}{}{equation.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Theoretical Properties}{10}{section.34}}
\newlabel{sec::theory}{{4}{10}{}{section.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Theoretical Results for Parameter Estimation}{10}{subsection.35}}
\newlabel{subsec::TheoryEstimation}{{4.1}{10}{}{subsection.35}{}}
\newlabel{assume::NodeTail}{{2}{10}{}{theorem.36}{}}
\citation{bickel2009simultaneous,raskutti2010restricted,zhang2010analysis,negahban2012unified,xiao2013proximal,loh2013regularized}
\citation{wang2013optimal}
\citation{zhang2010analysis}
\citation{candes2005decoding}
\newlabel{equ::largeDeviation}{{14}{11}{}{equation.37}{}}
\newlabel{def::sparseEig}{{3}{11}{Sparse eigenvalue condition}{theorem.38}{}}
\newlabel{assume::sparseEig}{{4}{11}{}{theorem.39}{}}
\newlabel{thm::l2rate}{{5}{11}{$\ell _2$- and $\ell _1$-rates of convergence}{theorem.40}{}}
\citation{ning2014sparc}
\newlabel{equ::L2Rate}{{15}{12}{$\ell _2$- and $\ell _1$-rates of convergence}{equation.41}{}}
\newlabel{equ::L1Rate}{{16}{12}{$\ell _2$- and $\ell _1$-rates of convergence}{equation.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Theoretical Results for Composite Pairwise Score Test}{12}{subsection.43}}
\newlabel{subsec::score}{{4.2}{12}{}{subsection.43}{}}
\citation{van2000asymptotic}
\newlabel{equ::scoreFun2}{{17}{13}{}{equation.44}{}}
\newlabel{equ::score2}{{18}{13}{}{equation.45}{}}
\newlabel{equ::hajek1}{{19}{13}{}{equation.46}{}}
\newlabel{equ::hajek2}{{20}{13}{}{equation.47}{}}
\newlabel{assume::BoundedHess}{{6}{13}{}{theorem.48}{}}
\newlabel{assume::Dantzig}{{7}{13}{}{theorem.49}{}}
\citation{lee2016exact,lockhart2014significance,belloni2012sparse,belloni2013honest,zhang2014confidence,javanmard2013confidence,van2013asymptotically}
\citation{ning2014sparc}
\citation{fan2011nonconcave,bradic2011penalized}
\newlabel{equ::assumptionDantzig}{{21}{14}{}{equation.50}{}}
\newlabel{thm::score}{{8}{14}{}{theorem.51}{}}
\citation{isingsampler}
\citation{lee2013structure}
\citation{ning2014sparc}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical Results}{15}{section.53}}
\newlabel{sec::simulations}{{5}{15}{}{section.53}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Simulation Studies}{15}{subsection.54}}
\citation{gepicasso}
\citation{van2013asymptotically}
\citation{turnbull2008semantic}
\citation{tsoumakas2011mulan}
\citation{tzanetakis2002musical}
\citation{cheng2013high}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Type-I errors of the composite pairwise score test, asymmetric score test, and the desparsity method for the three graphical models at the $0.05$ significance level. These figures are based on $100$ independent simulations. }}{17}{figure.56}}
\newlabel{fig::type1}{{1}{17}{Type-I errors of the composite pairwise score test, asymmetric score test, and the desparsity method for the three graphical models at the $0.05$ significance level. These figures are based on $100$ independent simulations}{figure.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Powers of the composite pairwise score test, asymmetric score test, and the desparsity method for the three graphical models at the $0.05$ significance level. These figures are based on $100$ independent simulations.}}{17}{figure.58}}
\newlabel{fig::power}{{2}{17}{Powers of the composite pairwise score test, asymmetric score test, and the desparsity method for the three graphical models at the $0.05$ significance level. These figures are based on $100$ independent simulations}{figure.58}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Real Data Analysis}{17}{subsection.59}}
\citation{turnbull2008semantic}
\citation{cheng2013high}
\citation{cheng2013high}
\citation{cheng2013high}
\citation{tan2016replicates}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{19}{section.62}}
\newlabel{sec::conclusion}{{6}{19}{}{section.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Estimated graphs in the \texttt  {CAL500} dataset inferred by the pairwise score test, asymmetric score test, and the desparsity method. We plot the connected components of the estimated graph. In (a)-(c) we plot the graphs obtained by these three approaches, respectively, and plot the common edges in (d). For better illustration, we only plot the connected components, combine the same type of continuous variables, display them as a square and draw each binary variable as a circle. The edges of the estimated graph show the association between these variables. }}{20}{figure.61}}
\newlabel{fig::real_data}{{3}{20}{Estimated graphs in the \texttt {CAL500} dataset inferred by the pairwise score test, asymmetric score test, and the desparsity method. We plot the connected components of the estimated graph. In (a)-(c) we plot the graphs obtained by these three approaches, respectively, and plot the common edges in (d). For better illustration, we only plot the connected components, combine the same type of continuous variables, display them as a square and draw each binary variable as a circle. The edges of the estimated graph show the association between these variables}{figure.61}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proof of the Main Results}{21}{section.63}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Proof of Theorem \ref  {thm::l2rate}}{21}{subsection.64}}
\newlabel{sec::proof_rates}{{A.1}{21}{}{subsection.64}{}}
\newlabel{thm::boundGradient}{{10}{21}{}{theorem.65}{}}
\newlabel{equ::thmGradient}{{22}{21}{}{equation.66}{}}
\newlabel{lemma::BoundByPart}{{11}{21}{}{theorem.67}{}}
\newlabel{equ::IBound}{{23}{21}{}{equation.68}{}}
\newlabel{lemma::StayInL1Ball}{{12}{22}{}{theorem.69}{}}
\newlabel{equ::TwoNormIneq}{{24}{22}{}{equation.70}{}}
\newlabel{equ::crudeRate}{{25}{22}{}{equation.71}{}}
\newlabel{equ::inductionBound}{{26}{22}{}{equation.72}{}}
\newlabel{equ::boundGradG}{{27}{22}{}{equation.73}{}}
\newlabel{equ::boundGradG2}{{28}{22}{}{equation.74}{}}
\newlabel{equ::gDirBound}{{29}{23}{}{equation.75}{}}
\newlabel{equ::lambdaS}{{30}{23}{}{equation.76}{}}
\newlabel{equ::RecursionIk}{{31}{23}{}{equation.77}{}}
\newlabel{equ::InitialTwoNorm}{{32}{23}{}{equation.78}{}}
\newlabel{equ::FinalL2Rate}{{33}{23}{}{equation.79}{}}
\newlabel{equ::IntermediateL1Rate}{{34}{23}{}{equation.80}{}}
\newlabel{equ::FinalL1Rate}{{35}{24}{}{equation.81}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Proof of Theorem \ref  {thm::score}}{24}{subsection.82}}
\newlabel{sec::proof_score}{{A.2}{24}{}{subsection.82}{}}
\newlabel{eqn::two_arguments}{{36}{24}{}{equation.83}{}}
\newlabel{equ::boundI121}{{37}{25}{}{equation.84}{}}
\newlabel{equ::anotherPertHess}{{38}{25}{}{equation.85}{}}
\newlabel{equ::I13bound}{{39}{25}{}{equation.86}{}}
\newlabel{lemma::DantzigRate}{{13}{25}{}{theorem.87}{}}
\newlabel{lemma::normality}{{14}{26}{}{theorem.88}{}}
\newlabel{equ::gradNormality}{{40}{26}{}{equation.89}{}}
\newlabel{equ::UniformConvSbbeta}{{41}{26}{}{equation.90}{}}
\newlabel{lemma::var}{{15}{26}{}{theorem.91}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Additional Estimation Results}{26}{section.92}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Verify the Sparse Eigenvalue Condition for Gaussian Graphical Models}{26}{subsection.93}}
\newlabel{sec::Sparse_Eig_GGM}{{B.1}{26}{}{subsection.93}{}}
\newlabel{prop::SparseEigGGM}{{16}{26}{}{theorem.94}{}}
\newlabel{equ::TheresholdHess}{{42}{27}{}{equation.95}{}}
\newlabel{equ::BoundUseCauchy}{{43}{28}{}{equation.96}{}}
\newlabel{lemma::SymmetricDiff}{{17}{28}{}{theorem.97}{}}
\newlabel{equ::varianceDiff}{{44}{28}{}{equation.98}{}}
\newlabel{equ::GGMlower}{{45}{29}{}{equation.99}{}}
\newlabel{equ::UpperBoundHess}{{46}{29}{}{equation.100}{}}
\newlabel{equ::ConditionalXs}{{47}{29}{}{equation.101}{}}
\newlabel{equ::UpperboundExpectation}{{48}{29}{}{equation.102}{}}
\newlabel{equ::GGMupper}{{49}{29}{}{equation.103}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Refined Statistical Rates of Parameter Estimation}{30}{subsection.104}}
\newlabel{sec::refined_rates}{{B.2}{30}{}{subsection.104}{}}
\newlabel{thm::RefinedRate}{{18}{30}{Refined statistical rates of convergence}{theorem.105}{}}
\newlabel{equ::RefinedL2Rate}{{50}{30}{Refined statistical rates of convergence}{equation.106}{}}
\newlabel{equ::RefinedL1Rate}{{51}{30}{Refined statistical rates of convergence}{equation.107}{}}
\newlabel{equ::RefinedBound1}{{52}{30}{}{equation.108}{}}
\newlabel{equ::refinedGradBound}{{53}{30}{}{equation.109}{}}
\citation{ning2014sparc}
\citation{arcones1995bernstein}
\newlabel{equ::refinedLambdaS}{{54}{31}{}{equation.110}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Proof of the Auxiliary Results for Estimation}{31}{section.111}}
\newlabel{sec::proof_estimation_lemma}{{C}{31}{}{section.111}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Proof of Lemma \ref  {thm::boundGradient}}{31}{subsection.112}}
\newlabel{sec::proof_boundGradient}{{C.1}{31}{}{subsection.112}{}}
\newlabel{eqn::union_tail}{{55}{31}{}{equation.113}{}}
\newlabel{lemma::bernstein}{{19}{32}{Bernstein's inequality for $U$-statistics}{theorem.114}{}}
\newlabel{eqn::bern}{{56}{32}{Bernstein's inequality for $U$-statistics}{equation.115}{}}
\newlabel{equ::gradientTail}{{57}{32}{}{equation.116}{}}
\newlabel{equ::gradientTail2}{{58}{32}{}{equation.117}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Proof of Lemma \ref  {lemma::BoundByPart}}{32}{subsection.118}}
\newlabel{proof::lemma::BoundByPart}{{C.2}{32}{}{subsection.118}{}}
\newlabel{equ::kkt}{{59}{33}{}{equation.119}{}}
\newlabel{equ::twoTerms}{{60}{33}{}{equation.120}{}}
\newlabel{equ::term1}{{61}{33}{}{equation.121}{}}
\newlabel{equ::term2}{{62}{33}{}{equation.122}{}}
\newlabel{equ::CombineTwoTerms}{{63}{33}{}{equation.123}{}}
\newlabel{equ::boundDeltaG}{{64}{34}{}{equation.124}{}}
\newlabel{equ::deltaG}{{65}{34}{}{equation.125}{}}
\newlabel{equ::IcBoundInf}{{66}{34}{}{equation.126}{}}
\newlabel{equ::IcHolder}{{67}{34}{}{equation.127}{}}
\newlabel{equ::deltaBound2}{{68}{34}{}{equation.128}{}}
\citation{zhang2010analysis}
\citation{zhang2013multi}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Proof of Lemma \ref  {lemma::StayInL1Ball}}{35}{subsection.129}}
\newlabel{proof::lemma::StayInL1Ball}{{C.3}{35}{}{subsection.129}{}}
\newlabel{equ::tildeDeltaI}{{69}{35}{}{equation.130}{}}
\newlabel{equ::tildeG1}{{70}{35}{}{equation.131}{}}
\newlabel{lemma::ResCorr}{{20}{35}{}{theorem.132}{}}
\newlabel{equ::piCoef}{{71}{36}{}{equation.133}{}}
\newlabel{lemma::sparseEig}{{21}{36}{}{theorem.134}{}}
\newlabel{equ::piCoef2}{{72}{36}{}{equation.135}{}}
\newlabel{equ::piCoef3}{{73}{36}{}{equation.136}{}}
\newlabel{lemma::quadratic}{{22}{36}{}{theorem.137}{}}
\newlabel{equ::UseQuadratic}{{74}{37}{}{equation.138}{}}
\newlabel{equ::lower}{{75}{37}{}{equation.139}{}}
\newlabel{lemma::bregDiv}{{23}{37}{}{theorem.140}{}}
\newlabel{equ::twoTerms2}{{76}{37}{}{equation.141}{}}
\newlabel{equ::term12}{{77}{37}{}{equation.142}{}}
\newlabel{equ::term22}{{78}{37}{}{equation.143}{}}
\newlabel{equ::tildeDeltaI2}{{79}{37}{}{equation.144}{}}
\newlabel{equ::localBall}{{80}{38}{}{equation.145}{}}
\newlabel{equ::deltaL1}{{81}{38}{}{equation.146}{}}
\newlabel{eqn::lemma_argument1}{{82}{38}{}{equation.147}{}}
\newlabel{eqn::lemma_argument1}{{83}{38}{}{equation.148}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Proof of Auxiliary Results for Asymptotic Inference}{38}{section.149}}
\newlabel{sec::proof_inference}{{D}{38}{}{section.149}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Proof of Lemma \ref  {lemma::normality}}{38}{subsection.150}}
\newlabel{proof::lemma::normality}{{D.1}{38}{}{subsection.150}{}}
\newlabel{equ::MaxNormThreeMat}{{84}{39}{}{equation.151}{}}
\newlabel{equ::I2square}{{85}{39}{}{equation.152}{}}
\newlabel{equ::wCov}{{86}{39}{}{equation.153}{}}
\newlabel{equ::I2square2}{{87}{40}{}{equation.154}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Proof of Lemma \ref  {lemma::DantzigRate}}{40}{subsection.155}}
\newlabel{proof::lemma::DantzigRate}{{D.2}{40}{}{subsection.155}{}}
\newlabel{equ::sampleError}{{88}{40}{}{equation.156}{}}
\newlabel{equ::boundHWcone}{{89}{41}{}{equation.157}{}}
\newlabel{equ::DantzigError1}{{90}{41}{}{equation.158}{}}
\newlabel{lemma::DantzigSE}{{24}{41}{}{theorem.159}{}}
\newlabel{equ::DantzigError4}{{91}{42}{}{equation.160}{}}
\newlabel{equ::DantzigError2}{{92}{42}{}{equation.161}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.3}Proof of Lemma \ref  {lemma::var}}{42}{subsection.162}}
\newlabel{proof::lemma_var}{{D.3}{42}{}{subsection.162}{}}
\newlabel{equ::SigmaHat2}{{93}{42}{}{equation.163}{}}
\newlabel{lemma::ErrorRateSigmaHat}{{25}{43}{}{theorem.164}{}}
\newlabel{equ::SigmaI1Final}{{94}{43}{}{equation.165}{}}
\newlabel{equ::sigmaI21}{{95}{43}{}{equation.166}{}}
\newlabel{equ::sigmaI22}{{96}{43}{}{equation.167}{}}
\newlabel{equ::sigmaI23}{{97}{43}{}{equation.168}{}}
\newlabel{equ::SigmaI2Final}{{98}{43}{}{equation.169}{}}
\newlabel{equ::sigmaI31}{{99}{43}{}{equation.170}{}}
\newlabel{equ::sigmaI32}{{100}{43}{}{equation.171}{}}
\newlabel{equ::SigmaI3Final}{{101}{44}{}{equation.172}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Proof of Technical Lemmas}{44}{section.173}}
\newlabel{sec::proof_technical}{{E}{44}{}{section.173}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Proof of Technical Lemmas in \S  \ref  {sec::proof_estimation_lemma}}{44}{subsection.174}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.1.1}Proof of Lemma \ref  {lemma::ResCorr}}{44}{subsubsection.175}}
\newlabel{proof::lemma::ResCorr}{{E.1.1}{44}{}{subsubsection.175}{}}
\newlabel{equ::Correqu1}{{102}{44}{}{equation.176}{}}
\newlabel{equ::Correqu2}{{103}{44}{}{equation.177}{}}
\newlabel{equ::Correqu3}{{104}{44}{}{equation.178}{}}
\newlabel{equ::Correqu4}{{105}{44}{}{equation.179}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.1.2}Proof of lemma \ref  {lemma::sparseEig}}{45}{subsubsection.180}}
\newlabel{proof::lemma::sparseEig}{{E.1.2}{45}{}{subsubsection.180}{}}
\newlabel{lemma::HessOneNode}{{26}{45}{}{theorem.181}{}}
\newlabel{equ::lemmaPerturb1}{{106}{45}{}{equation.182}{}}
\newlabel{equ::lemmaPerturb2}{{107}{45}{}{equation.183}{}}
\newlabel{equ::lemmaPerturb3}{{108}{45}{}{equation.184}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.1.3}Proof of Lemma \ref  {lemma::quadratic}}{46}{subsubsection.185}}
\newlabel{proof::lemma::quadratic}{{E.1.3}{46}{}{subsubsection.185}{}}
\newlabel{equ::quadrKey}{{109}{46}{}{equation.186}{}}
\newlabel{eqn::conclusion_lemma}{{110}{46}{}{equation.187}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.1.4}Proof of Lemma \ref  {lemma::bregDiv}}{46}{subsubsection.188}}
\newlabel{proof::lemma::bregDiv}{{E.1.4}{46}{}{subsubsection.188}{}}
\newlabel{equ::convex1}{{111}{47}{}{equation.189}{}}
\newlabel{equ::convex2}{{112}{47}{}{equation.190}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.2}Proof of Technical Lemmas in \S  \ref  {sec::proof_inference}}{47}{subsection.191}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.2.1}Proof of lemma \ref  {lemma::ErrorRateSigmaHat}}{47}{subsubsection.192}}
\newlabel{proof::lemma::ErrorRateSigmaHat}{{E.2.1}{47}{}{subsubsection.192}{}}
\newlabel{equ::TailVmat}{{113}{48}{}{equation.193}{}}
\newlabel{eqn::bound_V_1}{{114}{48}{}{equation.194}{}}
\newlabel{eqn::bound_V_2}{{115}{48}{}{equation.195}{}}
\newlabel{eqn::bound_V_3}{{116}{48}{}{equation.196}{}}
\newlabel{equ::I21InftyBound}{{117}{48}{}{equation.197}{}}
\newlabel{eqn::Sigma_first_argument}{{118}{49}{}{equation.198}{}}
\newlabel{eqn::bound_on_part_of_grad}{{119}{49}{}{equation.199}{}}
\newlabel{eqn::bound_big_sigma}{{120}{49}{}{equation.200}{}}
\newlabel{equ::I1InftyBound}{{121}{49}{}{equation.201}{}}
\newlabel{equ::ErrorSigmaHat}{{122}{49}{}{equation.202}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.3}Proof of Lemma \ref  {lemma::HessOneNode}}{49}{subsection.203}}
\newlabel{proof::lemma::HessOneNode}{{E.3}{49}{}{subsection.203}{}}
\newlabel{equ::tailEEHessian}{{123}{50}{}{equation.204}{}}
\newlabel{eqn::tail_of_T}{{124}{50}{}{equation.205}{}}
\newlabel{eqn::hess_bern}{{125}{50}{}{equation.206}{}}
\newlabel{eqn::hess_part1}{{126}{50}{}{equation.207}{}}
\newlabel{eqn::hess_part2}{{127}{50}{}{equation.208}{}}
\newlabel{equ::largeDeviation2}{{128}{51}{}{equation.209}{}}
\newlabel{equ::hessLemma1}{{129}{51}{}{equation.210}{}}
\newlabel{equ::hessLemma2}{{130}{51}{}{equation.211}{}}
\newlabel{equ::hessLemma3}{{131}{51}{}{equation.212}{}}
\bibdata{ref}
\bibcite{allen2012log}{{1}{2012}{{Allen and Liu}}{{}}}
\bibcite{arcones1995bernstein}{{2}{1995}{{Arcones}}{{}}}
\bibcite{banerjee2008model}{{3}{2008}{{Banerjee et~al.}}{{Banerjee, El~Ghaoui, and d'Aspremont}}}
\bibcite{belloni2012sparse}{{4}{2012}{{Belloni et~al.}}{{Belloni, Chen, Chernozhukov, and Hansen}}}
\bibcite{belloni2013honest}{{5}{2013}{{Belloni et~al.}}{{Belloni, Chernozhukov, and Wei}}}
\bibcite{besag1974spatial}{{6}{1974}{{Besag}}{{}}}
\bibcite{bickel2009simultaneous}{{7}{2009}{{Bickel et~al.}}{{Bickel, Ritov, and Tsybakov}}}
\newlabel{equ::IndividualHess}{{132}{52}{}{equation.213}{}}
\bibcite{bradic2011penalized}{{8}{2011}{{Bradic et~al.}}{{Bradic, Fan, and Wang}}}
\bibcite{cai2011constrained}{{9}{2011}{{Cai et~al.}}{{Cai, Liu, and Luo}}}
\bibcite{candes2007dantzig}{{10}{2007}{{Cand\'{e}s et~al.}}{{Cand\'{e}s, Tao, et~al.}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces In (a) we plot estimated graph in the \texttt  {CAL500} dataset inferred by the asymmetric score test based on the loss function $L_k(\bm  {\beta }_k)$ for testing $H_0\penalty \@M \mskip 2mu\mathpunct {}\nonscript \mkern -\thinmuskip {:}\mskip 6muplus1mu\relax \beta _{jk}^* = 0$ for any $1\leq j < k \leq d$. We plot the connected components of the estimated graph for illustration. Compared with Figure \ref  {fig::real_data}, we observe that the two asymmetric score tests yields different graphs. In (b) we plot the edges that appear in (a) and Figure \ref  {fig::real_data}-(a) but not in Figure \ref  {fig::real_data}-(b). In other words, we plot the inconsistent edges of these two asymmetric score tests that are discovered by the pairwise score test. Thus, by taking symmetry into consideration, the pairwise score test is able to correct such inconsistency.}}{53}{figure.215}}
\newlabel{fig:real2}{{4}{53}{In (a) we plot estimated graph in the \texttt {CAL500} dataset inferred by the asymmetric score test based on the loss function $L_k(\bbeta _k)$ for testing $H_0\colon \beta _{jk}^* = 0$ for any $1\leq j < k \leq d$. We plot the connected components of the estimated graph for illustration. Compared with Figure \ref {fig::real_data}, we observe that the two asymmetric score tests yields different graphs. In (b) we plot the edges that appear in (a) and Figure \ref {fig::real_data}-(a) but not in Figure \ref {fig::real_data}-(b). In other words, we plot the inconsistent edges of these two asymmetric score tests that are discovered by the pairwise score test. Thus, by taking symmetry into consideration, the pairwise score test is able to correct such inconsistency}{figure.215}{}}
\bibcite{candes2005decoding}{{11}{2005}{{Cand\'{e}s and Tao}}{{}}}
\bibcite{chan2012nuisance}{{12}{2012}{{Chan}}{{}}}
\bibcite{chen2013selection}{{13}{2015}{{Chen et~al.}}{{Chen, Witten, and Shojaie}}}
\bibcite{cheng2012sparse}{{14}{2014}{{Cheng et~al.}}{{Cheng, Levina, Wang, and Zhu}}}
\bibcite{cheng2013high}{{15}{2017}{{Cheng et~al.}}{{Cheng, Li, Levina, and Zhu}}}
\bibcite{danaher2014joint}{{16}{2014}{{Danaher et~al.}}{{Danaher, Wang, and Witten}}}
\bibcite{diao2012maximum}{{17}{2012}{{Diao et~al.}}{{Diao, Ning, et~al.}}}
\bibcite{drton2008sinful}{{18}{2008}{{Drton and Perlman}}{{}}}
\bibcite{drton2007multiple}{{19}{2007}{{Drton et~al.}}{{Drton, Perlman, et~al.}}}
\bibcite{edwards2000introduction}{{20}{2000}{{Edwards}}{{}}}
\bibcite{isingsampler}{{21}{2015}{{Epskamp}}{{}}}
\bibcite{fan2011nonconcave}{{22}{2011}{{Fan and Lv}}{{}}}
\bibcite{fan2014strong}{{23}{2014}{{Fan et~al.}}{{Fan, Xue, Zou, et~al.}}}
\bibcite{fan2014high}{{24}{2017}{{Fan et~al.}}{{Fan, Liu, Ning, and Zou}}}
\bibcite{fan2018lamm}{{25}{2018}{{Fan et~al.}}{{Fan, Liu, Sun, and Zhang}}}
\bibcite{fellinghauer2013stable}{{26}{2013}{{Fellinghauer et~al.}}{{Fellinghauer, B{\"u}hlmann, Ryffel, Von~Rhein, and Reinhardt}}}
\bibcite{friedman2008sparse}{{27}{2008}{{Friedman et~al.}}{{Friedman, Hastie, and Tibshirani}}}
\bibcite{friedman2010applications}{{28}{2010}{{Friedman et~al.}}{{Friedman, Hastie, and Tibshirani}}}
\bibcite{gepicasso}{{29}{2017}{{Ge et~al.}}{{Ge, Li, Jiang, Liu, Zhang, Wang, and Zhao}}}
\bibcite{gu2015local}{{30}{2015}{{Gu et~al.}}{{Gu, Cao, Ning, and Liu}}}
\bibcite{guo2011joint}{{31}{2011}{{Guo et~al.}}{{Guo, Levina, Michailidis, and Zhu}}}
\bibcite{guo2014graphical}{{32}{2015}{{Guo et~al.}}{{Guo, Levina, Michailidis, and Zhu}}}
\bibcite{hofling2009estimation}{{33}{2009}{{H{\"o}fling and Tibshirani}}{{}}}
\bibcite{jankova2014confidence}{{34}{2015}{{Jankov\'a and van~de Geer}}{{}}}
\bibcite{javanmard2013confidence}{{35}{2014}{{Javanmard and Montanari}}{{}}}
\bibcite{lam2009sparsistency}{{36}{2009}{{Lam and Fan}}{{}}}
\bibcite{lauritzen1996graphical}{{37}{1996}{{Lauritzen}}{{}}}
\bibcite{lee2013structure}{{38}{2015}{{Lee and Hastie}}{{}}}
\bibcite{lee2016exact}{{39}{2016}{{Lee et~al.}}{{Lee, Sun, Sun, Taylor, et~al.}}}
\bibcite{lee2006efficient}{{40}{2006}{{Lee et~al.}}{{Lee, Ganapathi, and Koller}}}
\bibcite{liang2000regression}{{41}{2000}{{Liang and Qin}}{{}}}
\bibcite{liu2009nonparanormal}{{42}{2009}{{Liu et~al.}}{{Liu, Lafferty, and Wasserman}}}
\bibcite{liu2012high}{{43}{2012}{{Liu et~al.}}{{Liu, Han, Yuan, Lafferty, Wasserman, et~al.}}}
\bibcite{liu2013gaussian}{{44}{2013}{{Liu et~al.}}{{}}}
\bibcite{lockhart2014significance}{{45}{2014}{{Lockhart et~al.}}{{Lockhart, Taylor, Tibshirani, Tibshirani, et~al.}}}
\bibcite{loh2013regularized}{{46}{2015}{{Loh and Wainwright}}{{}}}
\bibcite{meinshausen2006high}{{47}{2006}{{Meinshausen and B{\"u}hlmann}}{{}}}
\bibcite{mohan2014node}{{48}{2014}{{Mohan et~al.}}{{Mohan, London, Fazel, Witten, and Lee}}}
\bibcite{negahban2012unified}{{49}{2012}{{Negahban et~al.}}{{Negahban, Ravikumar, Wainwright, and Yu}}}
\bibcite{neykov2018unified}{{50}{2018}{{Neykov et~al.}}{{Neykov, Ning, Liu, Liu, et~al.}}}
\bibcite{ning2013high}{{51}{2013}{{Ning and Liu}}{{}}}
\bibcite{ning2017general}{{52}{2017{a}}{{Ning et~al.}}{{Ning, Liu, et~al.}}}
\bibcite{ning2014sparc}{{53}{2017{b}}{{Ning et~al.}}{{Ning, Zhao, Liu, et~al.}}}
\bibcite{peng2009partial}{{54}{2009}{{Peng et~al.}}{{Peng, Wang, Zhou, and Zhu}}}
\bibcite{raskutti2010restricted}{{55}{2010}{{Raskutti et~al.}}{{Raskutti, Wainwright, and Yu}}}
\bibcite{ravikumar2010high}{{56}{2010}{{Ravikumar et~al.}}{{Ravikumar, Wainwright, Lafferty, et~al.}}}
\bibcite{ravikumar2011high}{{57}{2011}{{Ravikumar et~al.}}{{Ravikumar, Wainwright, Raskutti, Yu, et~al.}}}
\bibcite{ren2013asymptotic}{{58}{2015}{{Ren et~al.}}{{Ren, Sun, Zhang, Zhou, et~al.}}}
\bibcite{rothman2008sparse}{{59}{2008}{{Rothman et~al.}}{{Rothman, Bickel, Levina, and Zhu}}}
\bibcite{shen2012likelihood}{{60}{2012}{{Shen et~al.}}{{Shen, Pan, and Zhu}}}
\bibcite{sun2013sparse}{{61}{2013}{{Sun and Zhang}}{{}}}
\bibcite{tan2014learning}{{62}{2014}{{Tan et~al.}}{{Tan, London, Mohan, Lee, Fazel, and Witten}}}
\bibcite{tan2016replicates}{{63}{2016}{{Tan et~al.}}{{Tan, Ning, Witten, and Liu}}}
\bibcite{tibshirani1996regression}{{64}{1996}{{Tibshirani}}{{}}}
\bibcite{tsoumakas2011mulan}{{65}{2011}{{Tsoumakas et~al.}}{{Tsoumakas, Spyromitros-Xioufis, Vilcek, and Vlahavas}}}
\bibcite{turnbull2008semantic}{{66}{2008}{{Turnbull et~al.}}{{Turnbull, Barrington, Torres, and Lanckriet}}}
\bibcite{tzanetakis2002musical}{{67}{2002}{{Tzanetakis and Cook}}{{}}}
\bibcite{van2013asymptotically}{{68}{2014}{{{van de Geer} et~al.}}{{{van de Geer}, {B{\"u}hlmann}, {Ritov}, and {Dezeure}}}}
\bibcite{van2000asymptotic}{{69}{2000}{{Van~der Vaart}}{{}}}
\bibcite{voorman2014graph}{{70}{2014}{{Voorman et~al.}}{{Voorman, Shojaie, and Witten}}}
\bibcite{wang2013optimal}{{71}{2014}{{Wang et~al.}}{{Wang, Liu, and Zhang}}}
\bibcite{whittaker2009graphical}{{72}{2009}{{Whittaker}}{{}}}
\bibcite{xiao2013proximal}{{73}{2013}{{Xiao and Zhang}}{{}}}
\bibcite{xue2012nonconcave}{{74}{2012{a}}{{Xue et~al.}}{{Xue, Zou, Cai, et~al.}}}
\bibcite{xue2012regularized}{{75}{2012{b}}{{Xue et~al.}}{{Xue, Zou, et~al.}}}
\bibcite{yang2013graphical}{{76}{2013{a}}{{Yang et~al.}}{{Yang, Ravikumar, Allen, and Liu}}}
\bibcite{yang2013poisson}{{77}{2013{b}}{{Yang et~al.}}{{Yang, Ravikumar, Allen, and Liu}}}
\bibcite{yang2014mixed}{{78}{2014}{{Yang et~al.}}{{Yang, Ravikumar, Allen, Baker, Wan, and Liu}}}
\bibcite{yuan2010high}{{79}{2010}{{Yuan}}{{}}}
\bibcite{yuan2007model}{{80}{2007}{{Yuan and Lin}}{{}}}
\bibcite{zhang2008sparsity}{{81}{2008}{{Zhang and Huang}}{{}}}
\bibcite{zhang2014confidence}{{82}{2014}{{Zhang and Zhang}}{{}}}
\bibcite{zhang2010analysis}{{83}{2010}{{Zhang}}{{}}}
\bibcite{zhang2013multi}{{84}{2013}{{Zhang et~al.}}{{}}}
\bibcite{zou2008one}{{85}{2008}{{Zou and Li}}{{}}}
\newlabel{LastPage}{{}{59}{}{page.59}{}}
\xdef\lastpage@lastpage{59}
\xdef\lastpage@lastpageHy{59}
